<!DOCTYPE html>
<html lang="en">
<head>

    <link rel="apple-touch-icon" sizes="57x57" href="./aws/favicon/apple-icon-57x57.png">
    <link rel="apple-touch-icon" sizes="60x60" href="./aws/favicon/apple-icon-60x60.png">
    <link rel="apple-touch-icon" sizes="72x72" href="./aws/favicon/apple-icon-72x72.png">
    <link rel="apple-touch-icon" sizes="76x76" href="./aws/favicon/apple-icon-76x76.png">
    <link rel="apple-touch-icon" sizes="114x114" href="./aws/favicon/apple-icon-114x114.png">
    <link rel="apple-touch-icon" sizes="120x120" href="./aws/favicon/apple-icon-120x120.png">
    <link rel="apple-touch-icon" sizes="144x144" href="./aws/favicon/apple-icon-144x144.png">
    <link rel="apple-touch-icon" sizes="152x152" href="./aws/favicon/apple-icon-152x152.png">
    <link rel="apple-touch-icon" sizes="180x180" href="./aws/favicon/apple-icon-180x180.png">
    <link rel="icon" type="image/png" sizes="192x192"  href="./aws/favicon/android-icon-192x192.png">
    <link rel="icon" type="image/png" sizes="32x32" href="./aws/favicon/favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="96x96" href="./aws/favicon/favicon-96x96.png">
    <link rel="icon" type="image/png" sizes="16x16" href="./aws/favicon/favicon-16x16.png">
    <link rel="manifest" href="./aws/favicon/manifest.json">
    <meta name="msapplication-TileColor" content="#ffffff">
    <meta name="msapplication-TileImage" content="./aws/favicon/ms-icon-144x144.png">
    <meta name="theme-color" content="#ffffff">
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <script defer src="https://use.fontawesome.com/releases/v5.15.4/js/all.js" integrity="sha384-rOA1PnstxnOBLzCLMcre8ybwbTmemjzdNlILg8O7z1lUkLXozs4DHonlDtnE7fpc" crossorigin="anonymous"></script>
    <title> AWS Questions MIX </title>


  </head>


<style>

html{
  box-sizing: border-box;
  margin:0;
  padding: 0;
}

.container .card {
  width: 100%;
  height: 100%;
  margin: 0;
  padding: 0;
  box-sizing: border-box;
  border-radius: 5px;
  box-shadow: 0 0 10px 2px;
}

.answer-buttons {
 
  margin: 0 auto;
  align-items: center;
  /*font-size: calc(1em + 1.5vw);*/
  display: flex;
  justify-content: center;
  flex-direction: column;
}

body{
    /*background-color: beige;*/
    width: 100%;
    height: 100%;
    margin: 0;
    padding: 0;
    background: rgb(63,94,251);
    background: radial-gradient(circle, rgba(63,94,251,1) 0%, rgba(252,70,107,1) 100%);
    box-sizing: border-box;
}
.col-6 {
  font-size: calc(1em + 1.5vw);
  color: white;
  border: 1px solid hsl(var(--hue), 100%, 30%);
  background-color: grey;
  border-radius: 5px;
  color: white;
  outline: none; 
  margin: 2%;
  cursor: pointer;
  justify-content: center;
  max-width: 80%;
  height: auto;
  min-width: 90px; 
}

.btn:hover {
  border-color: red !important;
}

.btn.correct {
  background-color: #DFF6DD;
  color: #000000;
}

.btn.wrong {
    background-color:#FDE7E9;
    color: #000000;  
}

.start-btn, .next-btn, .results-btn, .restart-btn {
  font-size: calc(1em + 1.5vw);
  font-weight: bold;
  margin: 0 auto;
  border-radius: 15px;
  align-items: center;
  font-size: calc(1em + 1.5vw);
  display: flex;
  justify-content: center;

  padding: 1.2vh;
  color: black;
  background-color:greenyellow;
  
}

.controls {
  box-sizing: border-box;
  justify-content: right;
  align-items: right;
  font-size: calc(1em + 1.5vw);
  margin-bottom: 20vh;
}

.hide {
  display: none;
}

#image {
    max-width: 40%;
    padding: 10px;
    box-shadow: 0 0 10px 2px;
    height: auto;
    margin: 5% auto 0 auto;
    border-radius: 6%;
    min-width: 350px;
}

.image {
  display: block;
  margin-left: auto;
  margin-right: auto;
  width: 50%;
}

#question {
    font-family: Arial, Helvetica, sans-serif;
    font-size: calc(1em + 1.5vw);
    margin: 2% 10% -2% 10%;
    padding: 2vw;
    text-align: center;
    color:darkolivegreen;
    /*background-color: blanchedalmond;*/
    background: rgb(238,174,202);
    background: radial-gradient(circle, rgba(238,174,202,1) 0%, rgba(148,187,233,1) 100%);
    border-radius: 2vw;
    margin-bottom: 2vw;
}

.expli {
    font-family: Arial, Helvetica, sans-serif;
    /*font-size: calc(1em + 1.5vw);*/
    margin: 2% 10% -2% 10%;
    padding: 2vw;
    text-align: left;
    color: red;
    background-color:black;
    border-radius: 2vw;
    border: 1vw solid yellow;
    text-overflow: ellipsis;
    overflow: hidden;
}

.choice{
    padding: 1vw;
    border: 1vw solid yellow;
    
    
}

.col {
    margin: 0 auto;
}

.text {
    margin-top: 2%;
    font-size: calc(1em + 1.5vw);
    text-align: center;
    max-width: 50%;
    padding: 2vw;
}

.results {
  font-family: Arial, Helvetica, sans-serif;
  font-size: calc(1em + 1.5vw);
    text-align: center;
    margin: 3% auto;
    color: greenyellow;
    background-color:black;
    text-align: center;
    max-width: 50%;
    padding: 2vw;
}

#restart-btn {
    margin: 2% auto;

}

#banner {
  margin: 2% auto;
  max-width: 70%;
  height: auto;
}


 
#next-btn {
  margin-left: auto;
  margin-right: auto;
}
#title {
  font-size: calc(1em + 1.5vw);
}

footer {
  position: absolute;
  bottom: 0;
  width: 100%;
  box-sizing: border-box;
  display: flex;
  justify-content: center;
}
#p_footer{
  color:aqua;
  background-color: #000000;
  margin: 0;
  padding: 1vw;
  font-size: calc(1em + 0.6vw);
}

.position_cero{
  /*position: absolute;
  bottom: 0;*/
  position:fixed;
  bottom:0;
}
</style>

<body>
    <div class="container card text-center mx-auto">
    
        <div id="question-container" class="row hide">
          <div id="question" class="col">PREGUNTA</div>
        </div>
        
        <div id="image-container" class="row text-center">
            <img id ="image" class="text-center image" />
            <!--<img id ="image" class="text-center image"/>-->
        </div>
    
        <div class="row">
          <p id="text" class="col text text-center"></p> 
        </div>
        <div id="answer-buttons" class="row answer-buttons hide mx-2 mt-1"></div>
        <div id="results" class="results hide row">
            <p class="col">Gracias</p>			
        </div>
        <div class="controls row d-flex">
            <button id="start-btn" class="start-btn btn col col-2 mb-5">GET STARTED WITH AWS </button>
            <button id="restart-btn" class="restart-btn btn hide col col-2" onclick="restartQuiz()">REPEAT</button>
            <button id="next-btn" class="next-btn btn hide col col-2 my-2">NEXT</button>
            <button id="results-btn" class="results-btn btn hide col col-2 my-2">Results</button>
        </div>
        <div class="controls row d-flex">
            <p id="expli"></p>
        </div>
      </div>
    


<script>


const startButton = document.getElementById('start-btn')
const restartButton = document.getElementById('restart-btn')
const nextButton = document.getElementById('next-btn')
const resultsButton = document.getElementById('results-btn')
const questionContainerElement = document.getElementById('question-container')
const questionElement = document.getElementById('question')
let answerButtonsElement = document.getElementById('answer-buttons')
let imageElementContainer = document.getElementById('image-container');
let imageElement = document.getElementById('image');
let resultsElement = document.getElementById('results');
let text = document.getElementById('text');
const bannerElement = document.getElementById('banner');
const titleElement = document.getElementById('title');
const expli = document.getElementById('expli');

let shuffledQuestions, currentQuestionIndex, shuffledAnswers,score;
imageElement.classList.add('hide');
  imageElementContainer.classList.add('hide');
startButton.addEventListener('click', startGame)
restartButton.addEventListener('click', startGame)
nextButton.addEventListener('click', () => {
  currentQuestionIndex++;
  setNextQuestion();
  text.classList.add('hide');
})
resultsButton.addEventListener('click', showResults)


function startGame() {
  startButton.classList.add('hide')
  shuffledQuestions = questions.sort(() => Math.random() - .5)
  currentQuestionIndex = 0;
  questionContainerElement.classList.remove('hide')
  setNextQuestion();
  resultsElement.classList.add('hide');
  restartButton.classList.add('hide')
  score = 0;
  text.classList.add('hide');
  answerButtonsElement.classList.remove('hide');
  
  //ocultar imagen

  //bannerElement.classList.add('hide');
  //titleElement.classList.add('hide');
  questionElement.classList.remove('hide')

}

function setNextQuestion() {
    expli.innerHTML = '';
    expli.classList.remove('expli');
    resetState()
    showQuestion(shuffledQuestions[currentQuestionIndex]);


}

function resetFooter(){
  const footer = document.getElementById('footer')
  footer.classList.remove('block'); // cambio esto
  footer.classList.add('position_cero');
  footer.classList.add('block'); // cambio esto
}


function comprobarSiHayImg(question){
  if(question.img!=""){
      imageElement.src = question.img;
      imageElement.classList.remove('hide');
      imageElementContainer.classList.remove('hide');
    }
    else{
      imageElement.classList.add('hide');
      imageElementContainer.classList.add('hide');
    }
}


function showQuestion(question) {


   
    comprobarSiHayImg(question)

    
	  questionElement.innerText = question.question;

	  question.answers.forEach(answer => {
    const button = document.createElement('button');
    button.setAttribute('class', 'choice');
    button.innerText = answer.text;
   // expli.innerHTML += ' '+answer.expli;

    button.classList.add('col-6');
    if (answer.correct) {
      button.dataset.correct = answer.correct;
    } 
    button.addEventListener('mousedown', selectAnswer);
    button.addEventListener('mouseup', disableButtons);
    answerButtonsElement.appendChild(button);

    resetFooter();

  })

}

function resetState() {
  clearStatusClass(document.body);
  nextButton.classList.add('hide');
  while (answerButtonsElement.firstChild) {
    answerButtonsElement.removeChild(answerButtonsElement.firstChild)
  }


  resetFooter();

}

function selectAnswer(e) {
  const selectedButton = e.target;
  const correct = selectedButton.dataset.correct;
  text.classList.remove('hide');
  setStatusClass(document.body, correct);
  Array.from(answerButtonsElement.children).forEach(button => {
    setStatusClass(button, button.dataset.correct)
  })
  if (shuffledQuestions.length > currentQuestionIndex + 1) {
    nextButton.classList.remove('hide')
  } else {
	resultsButton.classList.remove('hide')	
  }
	if (correct) {
        score += 847/100;
        text.innerHTML = 'Es correcto';
        selectedButton.style.backgroundColor = '#DFF6DD';
        selectedButton.style.color= '#000000';
        text.style.backgroundColor = '#DFF6DD';
        text.style.color= '#000000';
        
	} else {
        text.innerHTML = 'Es incorrecto.';
        text.style.backgroundColor = '#FDE7E9';
        text.style.color= '#000000';
        selectedButton.style.backgroundColor = '#FDE7E9';
        selectedButton.style.color= '#000000';
        expli.innerHTML = '';

        shuffledQuestions[currentQuestionIndex].answers.forEach(answer => {
            expli.innerHTML += ' '+answer.expli;
            expli.classList.add('expli');

        })
       
        
    }
}

function disableButtons() {
  answerButtonsElement.disabled = true;
}

function setStatusClass(element, correct) {
  clearStatusClass(element)
  /*if (correct) {
    element.classList.add('correct')
  } else {
    element.classList.add('wrong')
  }*/
}

function clearStatusClass(element) {
  element.classList.remove('correct')
  element.classList.remove('wrong')

}

function showResults() {
    expli.innerHTML = '';
    expli.classList.remove('expli');
    questionContainerElement.classList.add('hide');
    resultsElement.classList.remove('hide');
    resultsElement.innerHTML = `Tu nota final es ${score}%!`;
    resultsButton.classList.add('hide');
    restartButton.classList.remove('hide');
    questionElement.classList.add('hide');
    answerButtonsElement.classList.add('hide');
    text.classList.add('hide');

 
}


const questions = [
  {
    question: '/Test 30p Cuestionario 8  1/  If you want to run your relational database in the AWS cloud, which service would you choose?',
    answers: [
      { text: 'a. Amazon RDS', correct:true, expli:'The correct answer is : Amazon RDS'  },
      { text: 'b. Amazon DynamoDB', correct: false , expli:''},
	    { text: 'c. Amazon ElastiCache', correct: false, expli:'' },
      { text: 'd. Amazon Redshift', correct: false, expli:'' }
    ],
	img: '',
         
  },
  {
    question: '/Test 30p Cuestionario 8  2/ What is each unique location in the world where AWS has a cluster of data centers called?',
    answers: [
      { text: 'a. Region', correct: true,  expli:'The correct answer is : Region ' },
      { text: 'b. Point of presence ', correct: false,  expli:' ' },
	    { text: 'c. Availability zone ', correct: false,  expli:' ' },
      { text: 'd. Content delivery network ', correct: false,  expli:' ' }
    ],
	img: '',  
  }, 
  {
    question: '/Test 30p Cuestionario 8  3/ You want to be notified for any failure happening in the cloud. Which service would you leverage for receiving the notifications?',
    answers: [
      { text: 'a. Amazon SQS', correct: false,  expli:' ' },
      { text: 'b. AWS Config ', correct: false,  expli:' ' },
	    { text: 'c. Amazon SNS ', correct: true,  expli:'The correct answer is : Amazon SNS ' },
      { text: 'd. Amazon CloudWatch ', correct: false,  expli:' ' }
    ],
	img: '',  
  }, 
  {
    question: '/Test 30p Cuestionario 8  4/ How can you get visibility of user activity by recording the API calls made to your account?',
    answers: [
      { text: 'a. By using Amazon CloudWatch', correct: false,  expli:' ' },
      { text: 'b. By using AWS CloudTrail ', correct: true,  expli:'The correct answer is : By using AWS CloudTrail ' },
	    { text: 'c. By using Amazon Inspector ', correct: false,  expli:' ' },
      { text: 'd. By using Amazon API Gateway ', correct: false,  expli:' ' }
    ],
	img: '',  
  }, 
  {
    question: '/Test 30p Cuestionario 8  5/ You have been tasked with moving petabytes of data to the AWS cloud. What is the most efficient way of doing this? ',
    answers: [
      { text: 'a. Use AWS Database Migration Service', correct: false,  expli:' ' },
      { text: 'b. Upload them to Amazon S3 ', correct: false,  expli:' ' },
	    { text: 'c. Use AWS Server Migration Service ', correct: false,  expli:' ' },
      { text: 'd. Use AWS Snowball ', correct: true,  expli:'The correct answer is : Use AWS Snowball ' }
    ],
	img: '',  
  }, 
  {
    question: '/Test 30p Cuestionario 8  6/ How do you integrate AWS with the directories running on-premise in your organization?',
    answers: [
      { text: 'a. By using AWS Directory Service', correct: false,  expli:' ' },
      { text: 'b. Directly via the Internet ', correct: false,  expli:' ' },
	    { text: 'c. By using AWS Direct Connect ', correct: true,  expli:'The correct answer is : By using AWS Direct Connect ' },
      { text: 'd. By using a VPN ', correct: false,  expli:' ' }
    ],
	img: '',  
  }, 
  {
    question: '/Test 30p Cuestionario 8  7/ How can you have a shared file system across multiple Amazon EC2 instances?',
    answers: [
      { text: 'a. By using Amazon S3', correct: false,  expli:' ' },
      { text: 'b. By mounting Elastic Block Storage across multiple Amazon EC2 servers ', correct: false,  expli:' ' },
	    { text: 'c. By using Amazon EFS  ', correct: true,  expli:'The correct answer is : By using Amazon EFS ' },
      { text: 'd. By using Amazon Glacier ', correct: false,  expli:' ' }
    ],
	img: '',  
  }, 
  {
    question: '/Test 30p Cuestionario 8  8/ What is the main purpose of Amazon S3 Glacier? (Choose all that apply.)',
    answers: [
      { text: 'a. Storing historical or infrequently accessed data  ', correct: true,  expli:'one correct answer : Storing historical or infrequently accessed data ' },
      { text: 'b. Creating a cross-region replication bucket for Amazon S3  ', correct: false,  expli:' ' },
	    { text: 'c. Storing archival data ', correct: true,  expli:' one correct answer : Storing archival data ' },
      { text: 'd. Storing the static content of a web site ', correct: false,  expli:' ' },
      { text: 'e. Storing hot, frequently used data ', correct: false,  expli:' ' }
    ],
	img: '',  
  }, 
  {
    question: '/Test 30p Cuestionario 8  9/ What is the best way to protect a file in Amazon S3 against accidental delete? ',
    answers: [
      { text: 'a. Use MFA for deletion', correct: false,  expli:' ' },
      { text: 'b. Upload the files in multiple buckets so that you can restore from another when a file is deleted ', correct: false,  expli:' ' },
	    { text: 'c. Back up the files regularly to a different bucket or in a different region ', correct: false,  expli:' ' },
      { text: 'd. Enable versioning on the S3 bucket ', correct: true,  expli:'The correct answer is : Enable versioning on the S3 bucket ' }
    ],
	img: '',  
  }, 
  {
    question: '/Test 30p Cuestionario 8  10/ Amazon S3 provides 99.999999999 percent durability. Which of the following are true statements? (Choose all that apply.)',
    answers: [
      { text: 'a. The data in Amazon S3 Standard is designed to handle the concurrent loss of two facilities.', correct: true,  expli:'a correct answer is : The data in Amazon S3 Standard is designed to handle the concurrent loss of two facilities. ' },
      { text: 'b. The data is regularly backed up to AWS Snowball to provide the durability SLA. ', correct: false,  expli:' ' },
	    { text: 'c. The data is mirrored across multiple regions to provide the durability SLA. ', correct: false,  expli:' ' },
      { text: 'd. The data is mirrored across multiple AZs within a region.  ', correct: true,  expli:'one correct answer : The data is mirrored across multiple AZs within a region. ' },
      { text: 'e. The data is automatically mirrored to Amazon S3 Glacier to achieve high availability. ', correct: false,  expli:' ' }
    ],
	img: '',  
  }, 
  {
    question: '/Test 30p Cuestionario 8  11/ How much data can you store on S3?',
    answers: [
      { text: 'a. 1 exabyte per account', correct: false,  expli:' ' },
      { text: 'b. 1 petabyte per account', correct: false,  expli:' ' },
	    { text: 'c. Unlimited  ', correct: true,  expli:'The correct answer is : Unlimited ' },
      { text: 'd. 1 exabyte per region ', correct: false,  expli:' ' },
      { text: 'e. 1 petabyte per region ', correct: false,  expli:' ' }
    ],
	img: '',  
  }, 
  {
    question: '/Test 30p Cuestionario 8  12/ I am running an Oracle database that is very I/O intense. My database administrator needs a minimum of 3,600 IOPS. If my system is not able to meet that number, my application won’t perform optimally. How can I make sure my application always performs optimally?',
    answers: [
      { text: 'a. Use Elastic File System since it automatically handles the performance', correct: false,  expli:' ' },
      { text: 'b. Use Provisioned IOPS SSD to meet the IOPS number  ', correct: true,  expli:' The correct answer is : Use Provisioned IOPS SSD to meet the IOPS number' },
	    { text: 'c. Use your database files in an SSD-based EBS volume and your other files in an HDD-based EBS volume ', correct: false,  expli:' ' },
      { text: 'd. Use a general-purpose SSD under a terabyte that has a burst capability ', correct: false,  expli:' ' }
    ],
	img: '',  
  }, 
  {
    question: '/Test 30p Cuestionario 8  13/ You want to run a MapReduce job (a part of the big data workload) for a noncritical task. Your main goal is to process it in the most cost-effective way. The task is throughput sensitive but not at all mission critical and can take a longer time. Which type of storage would you choose?',
    answers: [
      { text: 'a. General-Purpose SSD (gp2)', correct: false,  expli:' ' },
      { text: 'b. Provisioned IOPS (io1) ', correct: false,  expli:' ' },
	    { text: 'c. Throughput Optimized HDD (st1) ', correct: false,  expli:' ' },
      { text: 'd. Cold HDD (sc1)  ', correct: true,  expli:'The correct answer is : Cold HDD (sc1) ' }
    ],
	img: '',  
  }, 
  {
    question: '/Test 30p Cuestionario 8  14/ You have created a VPC with two subnets. The web servers are running in a public subnet, and the database server is running in a private subnet. You need to download an operating system patch to update the database server. How you are going to download the patch?',
    answers: [
      { text: 'a. By using a NAT gateway', correct: true,  expli:'The correct answer is : By using a NAT gateway ' },
      { text: 'b. By attaching the Internet gateway to the private subnet temporarily ', correct: false,  expli:' ' },
	    { text: 'c. By using peering to another VPC', correct: false,  expli:' ' },
      { text: 'd. By changing the security group of the database server and allowing Internet access ', correct: false,  expli:' ' }
    ],
	img: '',  
  }, 
  {
    question: '/Test 30p Cuestionario 8  15/ How many IP addresses are reserved by AWS for internal purposes in a CIDR block that you can’t use?',
    answers: [
      { text: 'a. 5', correct: true,  expli:'The correct answer is : 5 ' },
      { text: 'b. 3 ', correct: false,  expli:' ' },
	    { text: 'c. 4 ', correct: false,  expli:' ' },
      { text: 'd. 2 ', correct: false,  expli:' ' }
    ],
	img: '',  
  }, 
  {
    question: '/Test 30p Cuestionario 8  16/ You know that you need 24 CPUs for your production server. You also know that your compute capacity is going to remain fixed until next year, so you need to keep the production server up and running during that time. What pricing option would you go with?',
    answers: [
      { text: 'a. Choose the three-year reserved instance', correct: false,  expli:' ' },
      { text: 'b. Choose the one-year reserved instance  ', correct: true,  expli:' The correct answer is : Choose the one-year reserved instance' },
	    { text: 'c. Choose the spot instance ', correct: false,  expli:' ' },
      { text: 'd. Choose the on-demand instance ', correct: false,  expli:' ' }
    ],
	img: '',  
  }, 
  {
    question: '/Test 30p Cuestionario 8  17/ I have to run my analytics, and to optimize I want to store all the data in columnar format. Which database serves my need?',
    answers: [
      { text: 'a. Amazon Aurora for Postgres', correct: false,  expli:' ' },
      { text: 'b. Amazon Redshift  ', correct: true,  expli:' The correct answer is : Amazon Redshift' },
	    { text: 'c. Amazon DynamoDB ', correct: false,  expli:' ' },
      { text: 'd. Amazon Aurora for MySQL ', correct: false,  expli:' ' }
    ],
	img: '',  
  }, 
  {
    question: '/Test 30p Cuestionario 8  18/ I want to store JSON objects. Which database should I choose?',
    answers: [
      { text: 'a. Amazon Aurora for PostgreSQL', correct: false,  expli:' ' },
      { text: 'b. Amazon Aurora for MySQL', correct: false,  expli:' ' },
	    { text: 'c. Amazon DynamoDB  ', correct: true,  expli:'The correct answer is : Amazon DynamoDB ' },
      { text: 'd. Oracle hosted on EC2', correct: false,  expli:' ' }
    ],
	img: '',  
  }, 
  {
    question: '/Test 30p Cuestionario 8  19/ What is an important criterion when planning your network topology in AWS?',
    answers: [
      { text: 'a. You should have the same IP address that you have on-premise.', correct: false,  expli:' ' },
      { text: 'b. Reserve as many EIP addresses as you can since IPv4 IP addresses are limited. ', correct: false,  expli:' ' },
	    { text: 'c. Use both IPv4 and IPv6 IP addresses. ', correct: false,  expli:' ' },
      { text: 'd. Use nonoverlapping IP addresses.  ', correct: true,  expli:'The correct answer is : Use nonoverlapping IP addresses. ' }
    ],
	img: '',  
  }, 
  {
    question: '/Test 30p Cuestionario 8  20/ Which AWS service enables you to purchase and register new domain names that can be used to publish your website on the internet?',
    answers: [
      { text: 'a. VPC', correct: false,  expli:' ' },
      { text: 'b. RDS ', correct: false,  expli:' ' },
	    { text: 'c. Elastic Beanstalk ', correct: false,  expli:' ' },
      { text: 'd. Route53  ', correct: true,  expli:'The correct answer is : Route53 ' }
    ],
	img: '',  
  }, 
  {
    question: '/Test 30p Cuestionario 8  21/ Which AWS service enables you to distribute your digital assets such that it is cached locally to users who attempt to access this content for a time to live, and thus helps to reduce network latency?',
    answers: [
      { text: 'a. AWS CloudFront', correct: true,  expli:' The correct answer is : AWS CloudFront' },
      { text: 'b. AWS CloudTrail', correct: false,  expli:' ' },
	    { text: 'c. AWS CloudWatch', correct: false,  expli:' ' },
      { text: 'd. AWS CloudScape', correct: false,  expli:' ' }
    ],
	img: '',  
  }, 
  {
    question: '/Test 30p Cuestionario 8  22/ A company plans to migrate its on-premises MySQL database to Amazon RDS. Which AWS service should they use for this task?',
    answers: [
      { text: 'a. Amazon Snowball', correct: false,  expli:' ' },
      { text: 'b. AWS Database Migration Service  ', correct: true,  expli:'The correct answer is : AWS Database Migration Service ' },
	    { text: 'c. AWS VM Import/Export ', correct: false,  expli:' ' },
      { text: 'd. AWS Server Migration Service ', correct: false,  expli:' ' }
    ],
	img: '',  
  }, 
  {
    question: '/Test 30p Cuestionario 8  23/ You are running a single RDS DB instance. Which configuration would you recommend so that you can avoid I/O suspension issues when performing backups?',
    answers: [
      { text: 'a. Configure RDS read replicas', correct: false,  expli:' ' },
      { text: 'b. Configure RDS Multi-AZ ', correct: true,  expli:' The correct answer is : Configure RDS Multi-AZ' },
	    { text: 'c. Configure RDS Cross Region Backup', correct: false,  expli:' ' },
      { text: 'd. Configure DynamoDB DaX ', correct: false,  expli:' ' }
    ],
	img: '',  
  }, 
  {
    question: '/Test 30p Cuestionario 8  24/ You are planning on developing a website in multiple languages such that you have one fleet of EC2 instances that serves the English version of your site and another fleet that serves the Spanish version of your site. For each language version, you will be configuring URLs with different paths such that the English version of your site will contain /en/ in the path and the Spanish version will contain /es/. Which type of load balancer would you use to route traffic to ensure users connect to the site in their desired language? ',
    answers: [
      { text: 'a. NLB', correct: false,  expli:' ' },
      { text: 'b. CLB', correct: false,  expli:' ' },
	    { text: 'c. Path-based load balancer ', correct: false,  expli:' ' },
      { text: 'd. ALB ', correct: true,  expli:' The correct answer is : ALB' }
    ],
	img: '',  
  }, 
  {
    question: '/Test 30p Cuestionario 8  25/ When an ELB detects an unhealthy EC2 instance, which action does it perform regarding distributing incoming traffic?',
    answers: [
      { text: 'a. It continues to send traffic to the failed instance. ', correct: false,  expli:' ' },
      { text: 'b. It terminates the failed instance so that it is not part of the ELB target group.', correct: false,  expli:' ' },
	    { text: 'c. It only sends traffic to the remaining healthy instances. ', correct: true,  expli:' The correct answer is : It only sends traffic to the remaining healthy instances.' },
      { text: 'd. It restarts the unhealthy EC2 instance. ', correct: false,  expli:' ' }
    ],
	img: '',  
  }, 
  {
    question: '/Test 30p Cuestionario 8  26/ Which service does an AWS ALB integrate with to protect your applications from common web attacks?',
    answers: [
      { text: 'a. WAF', correct: true,  expli:' The correct answer is : WAF' },
      { text: 'b. Shield', correct: false,  expli:' ' },
	    { text: 'c. Key Management Service (KMS)', correct: false,  expli:' ' },
      { text: 'd. Inspector ', correct: false,  expli:' ' }
    ],
	img: '',  
  }, 
  {
    question: '/Test 30p Cuestionario 8  27/ Which AWS service uses machine learning to classify sensitive information stored in your Amazon S3 buckets and monitor access patterns for anomalies that indicate risks or suspicious behavior, such as large quantities of source code being downloaded?',
    answers: [
      { text: 'a. Amazon Macie', correct: true,  expli:' The correct answer is : Amazon Macie' },
      { text: 'b. AWS Shield ', correct: false,  expli:' ' },
	    { text: 'c. WS WAF ', correct: false,  expli:' ' },
      { text: 'd. Amazon X-Ray ', correct: false,  expli:' ' }
    ],
	img: '',  
  }, 
  {
    question: '/Test 30p Cuestionario 8  28/ Which component of the AWS Global Infrastructure enables you to cache content (videos, images, and documents) and offer low-latency access when your users try to download them?',
    answers: [
      { text: 'a. Availability Zones', correct: false,  expli:' ' },
      { text: 'b. Edge locations ', correct: false,  expli:' ' },
	    { text: 'c. Local Zones ', correct: true,  expli:'The correct answer is : Local Zones ' },
      { text: 'd. AWS Regions ', correct: false,  expli:' ' }
    ],
	img: '',  
  }, 
  {
    question: '/Test 30p Cuestionario 8  29/ Which of the following are regarded as global services on AWS? (Choose two)',
    answers: [
      { text: 'a. Amazon EFS', correct: false,  expli:' ' },
      { text: 'b. AWS IAM  ', correct: true,  expli:' one correct answer : AWS IAM' },
	    { text: 'c. Amazon Route53  ', correct: true,  expli:' one correct answer : Amazon Route53' },
      { text: 'd. Amazon EC2 ', correct: false,  expli:' ' },
      { text: 'e. Amazon RDS ', correct: false,  expli:' ' }
    ],
	img: '',  
  }, 
  {
    question: '/Test 30p Cuestionario 8  30/ Which of the following resource types is tied to the Availability Zone that it was launched in?',
    answers: [
      { text: 'a. Elastic File Store (EFS)', correct: false,  expli:' ' },
      { text: 'b. Elastic Block Store (EBS) ', correct: true,  expli:' The correct answer is : Elastic Block Store (EBS)' },
	    { text: 'c. Amazon DynamoDB', correct: false,  expli:' ' },
      { text: 'd. Amazon Route53 Hosted Zones', correct: false,  expli:' ' }
    ],
	img: '',  
  }, 
  {
    question: '/Test DíA 8-MÓDULO 3.  ARCHITECTING ON AWS/  What is a CloudFormation stack?',
    answers: [
      { text: 'a. All of the provisioned resources defined in a CloudFormation template', correct: true,  expli:' correct A All of the provisioned resources defined in a CloudFormation template ' },
      { text: 'b. All of the resources identified as drifted in a CloudFormation template', correct: false,  expli:'' },
	    { text: 'c. A condition when resources are added on top of each other', correct: false,  expli:' ' },
      { text: 'd. The properties of a single resource', correct: false,  expli:' ' }
    ],
	img: '',  
  }, 
  {
    question: '/Test DíA 8-MÓDULO 3.  ARCHITECTING ON AWS/ Which of the following are benefits of using AWS CDK with CloudFormation? (Select TWO.) ',
    answers: [
      { text: 'a. Developers can use common programming languages.', correct: true,  expli:' correct A Developers can use common programming languages.' },
      { text: 'b. Bulk discounts are automatically applied to resource usage.', correct: false,  expli:' ' },
	    { text: 'c. Developers can call preconfigured resources with proven defaults.', correct: true,  expli:' correct C Developers can call preconfigured resources with proven defaults.' },
      { text: 'd. Components are limited to a single user.', correct: false,  expli:' ' },
      { text: 'e  Using AWS CDK does not require an AWS account or credentials.', correct: false,  expli:' ' },
    ],
	img: '',  
  }, 
  {
    question: '/Test DíA 7-MÓDULO 3.  ARCHITECTING ON AWS/ Which of these is a valid target for an Application Load Balancer?',
    answers: [
      { text: 'a. Amazon EC2 instance', correct: true,  expli:'correct A Amazon EC2 instance ' },
      { text: 'b. An Availability Zone ', correct: false,  expli:' ' },
	    { text: 'c. An Amazon S3 bucket', correct: false,  expli:'' },
      { text: 'd. VPN connection', correct: false,  expli:' ' }
    ],
	img: '',  
  }, 
  {
    question: '/Test DíA 7-MÓDULO 3.  ARCHITECTING ON AWS/ You have an application with unpredictable traffic patterns that runs on at least two instances. You want the CPU utilization to stay at about 75 percent. Which Amazon EC2 Auto Scaling strategy should you choose?',
    answers: [
      { text: 'a. Scheduled', correct: false,  expli:' ' },
      { text: 'b. Dynamic', correct: true,  expli:' correct B Dynamic' },
	    { text: 'c. Predictive', correct: false,  expli:'' },
      { text: 'd. Manual', correct: false,  expli:' ' }
    ],
	img: '',  
  }, 
  {
    question: '/Test DíA 7-MÓDULO 3.  ARCHITECTING ON AWS/ What service can invoke actions based on data from account resources and supported third-party management services?',
    answers: [
      { text: 'a. CloudWatch Logs ', correct: false,  expli:' ' },
      { text: 'b. EventBridge', correct: true,  expli:' correct B EventBridge' },
	    { text: 'c. CloudTrail', correct: false,  expli:'' },
      { text: 'd. Amazon EC2 Auto Scaling', correct: false,  expli:' ' }
    ],
	img: '',  
  }, 
  {
    question: '/Test DíA 6-MÓDULO 3.  ARCHITECTING ON AWS/ What is a benefit of using Amazon RDS in a Multi-AZ configuration?',
    answers: [
      { text: 'a. It delivers two live copies of the database running concurrently.', correct: false,  expli:' ' },
      { text: 'b. It provides automatic failover across Availability Zones.', correct: true,  expli:'correct B It provides automatic failover across Availability Zones.' },
	    { text: 'c. It provides automatic cross-Region replication.', correct: false,  expli:'' },
      { text: 'd. It eliminates the need for read replicas.', correct: false,  expli:' ' }
    ],
	img: '',  
  }, 
  {
    question: '/Test DíA 6-MÓDULO 3.  ARCHITECTING ON AWS/ What type of Elasti Cache installation offers sorting and ranking capabilities for data sets?',
    answers: [
      { text: 'a. ElastiCache for Redis', correct: true,  expli:' correct A ElastiCache for Redis' },
      { text: 'b. DAX', correct: false,  expli:' ' },
	    { text: 'c. Lazy loading', correct: false,  expli:'' },
      { text: 'd. ElastiCache for Memcached', correct: false,  expli:' ' }
    ],
	img: '',  
  }, 
  {
    question: '/Test DíA 6-MÓDULO 3.  ARCHITECTING ON AWS/ Which of the following is true regarding DynamoDB global tables?',
    answers: [
      { text: 'a. Tables are updated manually or through automation tools.', correct: false,  expli:' ' },
      { text: 'b. Only two tables are active at one time.', correct: false,  expli:' ' },
	    { text: 'c. You can select different instance sizes to adjust performance.', correct: false,  expli:'' },
      { text: 'd. Tables can be in different AWS Regions.', correct: true,  expli:'correct D Tables can be in different AWS Regions.' }
    ],
	img: '',  
  }, 
  {
    question: '/Test DíA 6-MÓDULO 3.  ARCHITECTING ON AWS/ Which of the following is true regarding an Aurora database?',
    answers: [
      { text: 'a. Nine copies of the data are stored across three Availability Zones.', correct: false,  expli:' ' },
      { text: 'b. Aurora has a limit of five replicas.', correct: false,  expli:' ' },
	    { text: 'c. Aurora is compatible with MySQL or PostgresQL.', correct: true,  expli:'correct C Aurora is compatible with MySQL or PostgresQL.' },
      { text: 'd. Multi-AZ deployments are not required for high availability.', correct: false,  expli:' ' }
    ],
	img: '',  
  }, 
  {
    question: '/Test 10p Cuestionario 6 - 1 DíA 6-MÓDULO 3.  ARCHITECTING ON AWS/   Do security groups act as a firewall for associated instances?',
    answers: [
      { text: 'a. True', correct: true,  expli:' The correct answer is  True '},
      { text: 'b. False', correct: false,  expli:' ' }
    ],
	img: '',  
  }, 
  {
    question: '/Test 10p Cuestionario 6 - 2 DíA 6-MÓDULO 3.  ARCHITECTING ON AWS/ Which all relational database engines does Amazon RDS support? Select one or more than one:',
    answers: [
      { text: 'a. Oracle ', correct: true,  expli:' one correct answer: Oracle ' },
      { text: 'b. SQL Server ', correct: true,  expli:' one correct answer: SQL Server' },
	    { text: 'c. Amazon Aurora ', correct: true,  expli:' one correct answer: Amazon Aurora' },
      { text: 'd. PostgreSQL ', correct: true,  expli:' one correct answer: PostgreSQL' },
      { text: 'e. MariaDB  ', correct: true,  expli:' one correct answer: MariaDB' },
    ],
	img: '',  
  },
  {
    question: '/Test 10p Cuestionario 6 - 3 DíA 6-MÓDULO 3.  ARCHITECTING ON AWS/ Can you restrict only devices/services inside the VPC that can connect to your database?',
    answers: [
      { text: 'a. True', correct: true,  expli:' The correct answer is  True '},
      { text: 'b. False', correct: false,  expli:' ' }
    ],
	img: '',  
  },
  {
    question: '/Test 10p Cuestionario 6 - 4 DíA 6-MÓDULO 3.  ARCHITECTING ON AWS/ Which SQL statement is used to insert new data in a database?',
    answers: [
      { text: 'a. Insert Into ', correct: true,  expli:' The correct answer is : Insert Into ' },
	    { text: 'b. Insert New', correct: false,  expli:'' },
      { text: 'c. Add Record', correct: false,  expli:' ' },
      { text: 'd. Add New', correct: false,  expli:' ' },
    ],
	img: '',  
  },
  {
    question: '/Test 10p Cuestionario 6 - 5 DíA 6-MÓDULO 3.  ARCHITECTING ON AWS/ Once the DB instance has been terminated. Can it be undone?',
    answers: [
      { text: 'a. Depends on database engine', correct: false,  expli:' ' },
      { text: 'b. Yes. It can be undone!', correct: false,  expli:' ' },
	    { text: 'c. No. It can\'t be undone! ', correct: true,  expli:' The correct answer is : No. It can\'t be undone! ' }
    ],
	img: '',  
  },
  {
    question: '/Test 10p Cuestionario 6 - 6 DíA 6-MÓDULO 3.  ARCHITECTING ON AWS/ Which type of database should be used to query normalized highly structured data? ',
    answers: [
      { text: 'a. Document store', correct: false,  expli:' ' },
      { text: 'b. Key-value store', correct: false,  expli:' ' },
	    { text: 'c. Relational database ', correct: true,  expli:'The correct answer is : Relational database' },
      { text: 'd. Graph store', correct: false,  expli:' ' }
    ],
	img: '',  
  },
  {
    question: '/Test 10p Cuestionario 6 - 7 DíA 6-MÓDULO 3.  ARCHITECTING ON AWS/ Which type of database should be used to store user session data with the highest scalability and effective way?',
    answers: [
      { text: 'a. Relational database', correct: false,  expli:' ' },
      { text: 'b. Wide-column store ', correct: false,  expli:' ' },
	    { text: 'c. Key-value store', correct: true,  expli:' The correct answer is : Key-value store ' },
      { text: 'd. Graph store', correct: false,  expli:' ' }
    ],
	img: '',  
  },
  {
    question: '/Test 10p Cuestionario 6 - 8 DíA 6-MÓDULO 3.  ARCHITECTING ON AWS/ Which of the following is the fastest way to get an item from DynamoDB?',
    answers: [
      { text: 'a. Filter', correct: false,  expli:' ' },
      { text: 'b. Scan', correct: false,  expli:' ' },
	    { text: 'c. ItemQuery', correct: false,  expli:'' },
      { text: 'd. Query', correct: true,  expli:'  The correct answer is : Query ' }
    ],
	img: '',  
  },
  {
    question: '/Test 10p Cuestionario 6 - 9 DíA 6-MÓDULO 3.  ARCHITECTING ON AWS/ How can the data of a DynamoDB Table be encrypted at rest with the least amount of work?',
    answers: [
      { text: 'a. Do nothing, it\'s encrypted by default. ', correct: true,  expli:'The correct answer is : Do nothing, it\'s encrypted by default. ' },
      { text: 'b. Use the Amazon DynamoDB Encryption Client to encrypt the data before storing it in DynamoDB.', correct: false,  expli:' ' },
	    { text: 'c. Use AWS Key Management Service to encrypt the data before storing it in DynamoDB.', correct: false,  expli:'' },
      { text: 'd. Use a library to encrypt the data before storing it in DynamoDB.', correct: false,  expli:' ' }
    ],
	img: '',  
  },
  {
    question: '/Test 10p Cuestionario 6 - 10 DíA 6-MÓDULO 3.  ARCHITECTING ON AWS/ Which of the following is a type of NoSQL Database? Select two.',
    answers: [
      { text: 'a. Document database', correct: true,  expli:' one correct answer: Document database' },
      { text: 'b. Relational database', correct: false,  expli:' ' },
	    { text: 'c. Short-column database', correct: false,  expli:'' },
      { text: 'd. Key-value store ', correct: true,  expli:' one correct answer: Key-value store' },
      { text: 'e. Graphical store', correct: false,  expli:' ' },
    ],
	img: '',  
  },
  {
    question: '/Test DíA 4-MÓDULO 3.  ARCHITECTING ON AWS/  Which of the following are true of AMIs? (Select TWO)',
    answers: [
      { text: 'a. AMIs can specify the subnets for launch.', correct: false,  expli:' ' },
      { text: 'b. AMIs can include block device mapping that specifies the volumes to attach to the Amazon EC2 instance when it is launched.', correct: true,  expli:' correct B AMIs can include block device mapping that specifies the volumes to attach to the Amazon EC2 instance when it is launched.' },
	    { text: 'c. AMIs can only be obtained from the AWS Marketplace.', correct: false,  expli:'' },
      { text: 'd. You can launch multiple instances from a single AMI.', correct: true,  expli:' correct D You can launch multiple instances from a single AMI. ' },
      { text: 'e. AMIs can only be used by users within a single account.', correct: false,  expli:' ' },
    ],
	img: '',  
  },
  {
    question: '/Test DíA 4-MÓDULO 3.  ARCHITECTING ON AWS/ In the instance type name m6g.2xlarge, which aspect of the name indicates the instance family and helps to determine its best use case?',
    answers: [
      { text: 'a. m', correct: true,  expli:' correct A m ' },
      { text: 'b. g', correct: false,  expli:' ' },
	    { text: 'c. 2xlarge', correct: false,  expli:'' },
      { text: 'd. 6', correct: false,  expli:' ' }
    ],
	img: '',  
  },
  {
    question: '/Test DíA 4-MÓDULO 3.  ARCHITECTING ON AWS/ Which of the following are true statements regarding Lambda? (Select TWo.)',
    answers: [
      { text: 'a. Functions currently only support Python.', correct: false,  expli:' ' },
      { text: 'b. You are responsible for updating and patching Lambda servers.', correct: false,  expli:' ' },
	    { text: 'c. Functions can be allocated up to 10 GB of memory.', correct: true,  expli:'correct E Functions can be allocated up to 10 GB of memory.' },
      { text: 'd. Functions can run for a maximum of 15 minutes.', correct: true,  expli:'correct D Functions can run for a maximum of 15 minutes.' },
      { text: 'e. Functions require a security group.', correct: false,  expli:' ' },
    ],
	img: '',  
  },
  {
    question: '/Test 10p Cuestionario 5 - 1 DíA 5-MÓDULO 3.  ARCHITECTING ON AWS/ Bucket name has to be unique globally?',
    answers: [
      { text: 'a. True', correct: true,  expli:' The correct answer is  True' },
      { text: 'b. False', correct: false,  expli:' ' }
    ],
	img: '',  
  },
  {
    question: '/Test 10p Cuestionario 5 - 2 DíA 5-MÓDULO 3.  ARCHITECTING ON AWS/ Bucket Policies are used to manage access at bucket level?',
    answers: [
      { text: 'a. True', correct: true,  expli:' The correct answer is  True' },
      { text: 'b. False', correct: false,  expli:' ' }
    ],
	img: '',  
  },
  {
    question: '/Test 10p Cuestionario 5 - 3 DíA 5-MÓDULO 3.  ARCHITECTING ON AWS/ Why do you need to create a Security Group in AWS? Select one:',
    answers: [
      { text: 'a. Security Group acts as a firewall to filter incomming and outgoing traffic to your resource. ', correct: true,  expli:' The correct answer is : Security Group acts as a firewall to filter incomming and outgoing traffic to your resource.' },
      { text: 'b. Security Group is  required to login to your AWS account programmatically.', correct: false,  expli:' ' },
	    { text: 'c. Security Group is a user group where we can add users to.', correct: false,  expli:'' },
      { text: 'd. Security Group is a group EC2 instances which performs a common job.', correct: false,  expli:' ' }
    ],
	img: '',  
  },
  {
    question: '/Test 10p Cuestionario 5 - 4 DíA 5-MÓDULO 3.  ARCHITECTING ON AWS/How many days will it take to delete EFS? Select one:',
    answers: [
      { text: 'a. You cannot delete the EFS once created.', correct: false,  expli:' ' },
      { text: 'b. You can schedule the deletion and it will take a minimum of 7 days.', correct: false,  expli:' ' },
	    { text: 'c. You can either schedule the deletion of EFS or delete it immediatly according to your choice.', correct: false,  expli:'' },
      { text: 'd. You can delete delete it immediatly by hitting the delete button.', correct: true,  expli:' The correct answer is : You can delete delete it immediatly by hitting the delete button.' }
    ],
	img: '',  
  },
  {
    question: '/Test 10p Cuestionario 5 - 5 DíA 5-MÓDULO 3.  ARCHITECTING ON AWS/ What credentials are needed to programmatically Access AWS resources? Select one or more than one:',
    answers: [
      { text: 'a. AWS_SECRET_KEY_ID', correct: true,  expli:' one correct answer : AWS_SECRET_KEY_ID' },
      { text: 'b. AWS_USERNAME_ID', correct: false,  expli:' ' },
	    { text: 'c. AWS_ACCESS_KEY_ID ', correct: true,  expli:'one correct answer : AWS_ACCESS_KEY_ID' },
      { text: 'd. AWS_SESSION_KEY_ID', correct: false,  expli:' ' },
      { text: 'e. AWS_PASSWORD_KEY_ID', correct: false,  expli:' ' },
    ],
	img: '',  
  },
  {
    question: '/Test 10p Cuestionario 5 - 6 DíA 5-MÓDULO 3.  ARCHITECTING ON AWS/ How can a user who does not have AWS credentials or permission to access an S3 object can be granted temporary access for fixed amount of time?  Select one:',
    answers: [
      { text: 'a. Bucket Policies ', correct: false,  expli:' ' },
      { text: 'b. Access Control Lists', correct: false,  expli:' ' },
	    { text: 'c. CORS', correct: false,  expli:'' },
      { text: 'd. Pre-signed URLs', correct: true,  expli:' The correct answer is : Pre-signed URLs' }
    ],
	img: '',  
  },
  {
    question: '/Test 10p Cuestionario 5 - 7 DíA 5-MÓDULO 3.  ARCHITECTING ON AWS/ How AWS objects can be organized in S3 ? Select one:',
    answers: [
      { text: 'a. Folders', correct: false,  expli:' ' },
      { text: 'b. File systems', correct: false,  expli:' ' },
	    { text: 'c. Buckets only ', correct: false,  expli:' ' },
      { text: 'd. Buckets and Folders', correct: true,  expli:' The correct answer is : Buckets and Folders' },
    ],
	img: '',  
  },
  {
    question: '/Test 10p Cuestionario 5 - 8 DíA 5-MÓDULO 3.  ARCHITECTING ON AWS/ Which of the following ports should be open on the security groups for the EC2 instance and the EFS respectively to enable Secure Shell (SSH) access between them? Select one:',
    answers: [
      { text: 'a. Open port 2049(NFS) on EC2 security group and ports 111(NFS) &amp; 2049(NFS) on EFS security group.', correct: false,  expli:' ' },
      { text: 'b. Open port 111(NFS) on EC2 security group and ports 111(NFS) &amp; 2049(NFS) on EFS security group.', correct: false,  expli:' ' },
	    { text: 'c. Open port 22(SSH) on EC2 security group and ports 111(NFS) & 2049(NFS) on EFS security group.', correct: false,  expli:'' },
      { text: 'd. Open port 22(SSH) on EC2 security group and port 2049(NFS) on EFS security group. ', correct: true,  expli:' The correct answer is : Open port 22(SSH) on EC2 security group and port 2049(NFS) on EFS security group.' }
    ],
	img: '',  
  },
  {
    question: '/Test 10p Cuestionario 5 - 9 DíA 5-MÓDULO 3.  ARCHITECTING ON AWS/You have created an S3 bucket in the us-east-1 region with the default configuration. Versioning is not enabled. You are located in Asia and deleted an object in the bucket using AWS CLI. What will happen when you try to list the objects in the bucket? Select one:',
    answers: [
      { text: 'a. The object is deleted completely.', correct: true,  expli:' The correct answer is : The object is deleted completely.' },
      { text: 'b. The object is still there. ', correct: false,  expli:' ' },
	    { text: 'c. The object may still be there or deleted, depending on whether the deletion is finished in AWS.', correct: false,  expli:'' },
      { text: 'd. The object is attached with a deletion mark.', correct: false,  expli:' ' }
    ],
	img: '',  
  },
  {
    question: '/Test 10p Cuestionario 5 - 10 DíA 5-MÓDULO 3.  ARCHITECTING ON AWS/ You created a bucket named “myfirstwhizbucket” in the US West region. What are valid URLs for accessing the bucket? (Choose 2 options)',
    answers: [
      { text: 'a. https://s3-us-west-1-amazonaws.com/myfirstwhizbucket ', correct: false,  expli:' ' },
      { text: 'b. https://myfirstwhizbucket.s3.us-west-1.amazonaws.com', correct: true,  expli:' one correct answer: https://myfirstwhizbucket.s3.us-west-1.amazonaws.com' },
	    { text: 'c. https://s3.myfirstwhizbucket.us-west-1.amazonaws.com', correct: false,  expli:'' },
      { text: 'd. https://s3.us-west-1.amazonaws.com/myfirstwhizbucket ', correct: true,  expli:' one correct answer: https://s3.us-west-1.amazonaws.com/myfirstwhizbucket' },
      { text: 'e. https://s3.amazonaws.com/myfirstwhizbucket', correct: false,  expli:' ' },
    ],
	img: '',  
  },
  {
    question: '/Test DíA 5-MÓDULO 3.  ARCHITECTING ON AWS/ Which of the following Amazon S3 features would you use to automatically copy new objects to a bucket in a different AWS Region?',
    answers: [
      { text: 'a. Same-Region Replication (SRR)', correct: false,  expli:' ' },
      { text: 'b. Amazon S3 Versioning', correct: false,  expli:' ' },
	    { text: 'c. CAWS DataSync', correct: false,  expli:' ' },
      { text: 'd. Cross-Region Replication (CRR)', correct: true,  expli:' correct D Cross-Region Replication (CRR)' }
    ],
	img: '',  
  },
  {
    question: '/Test DíA 5-MÓDULO 3.  ARCHITECTING ON AWS/ Which Amazon s3 feature can force an action to Occur after an event takes place within a bucket?',
    answers: [
      { text: 'a. Invoking', correct: false,  expli:' ' },
      { text: 'b. Event notification', correct: true,  expli:'correct B Event notification' },
	    { text: 'c. Lambda ', correct: false,  expli:' ' },
      { text: 'd. Alarm', correct: false,  expli:' ' }
    ],
	img: '',  
  },
  {
    question: '/Test DíA 5-MÓDULO 3.  ARCHITECTING ON AWS/ You have two Linux applications in different Availability Zones that must share a common file system. Which of the following is the best solution for this use case?',
    answers: [
      { text: 'a. Storage Gateway', correct: false,  expli:' ' },
      { text: 'b. FSx for Windows File Server', correct: false,  expli:' ' },
	    { text: 'c. Amazon S3', correct: false,  expli:' ' },
      { text: 'd. Amazon EFS', correct: true,  expli:' correct D Amazon EFS' }
    ],
	img: '',  
  },
  {
    question: '/Test DíA 5-MÓDULO 3.  ARCHITECTING ON AWS/  Which of the following are modes available in the Storage Gateway appliance? (Select THREE.)',
    answers: [
      { text: 'a. Memory Gateway', correct: false,  expli:' ' },
      { text: 'b. Tape Gateway', correct: true,  expli:' correct B Tape Gateway' },
	    { text: 'c. Volume Gateway', correct: true,  expli:' correct C Volume Gateway' },
      { text: 'd. Amazon EBS File Gateway', correct: false,  expli:' ' },
      { text: 'e. Amazon S3 File Gateway', correct: true,  expli:' correct E Amazon S3 File Gateway' },
      { text: 'f. Amazon S3 Glacier File Gateway', correct: false,  expli:' ' }
    ],
	img: '',  
  },
  {
    question: '/Test 10p Cuestionario 4 - 1 DíA 4-MÓDULO 3.  ARCHITECTING ON AWS/ A solutions architect is designing a web application that consists of a public-facing web tier hosted on Amazon EC2 in public subnets. The database tier consists of Microsoft SQL Server running on Amazon EC2 in a private subnet. Security is a high priority for the company. How should security groups be configured? (Select TWO)',
    answers: [
      { text: 'a. Configure the security group for the database tier to allow outbound traffic on ports 443 and 1433 to the security group for the web tier.', correct: false,  expli:' ' },
      { text: 'b. Configure the security group for the web tier to allow inbound traffic on port 443 from 0.0.0.0/0.', correct: true,  expli:'one correct answer:Configure the security group for the web tier to allow inbound traffic on port 443 from 0.0.0.0/0. ' },
	    { text: 'c. Configure the security group for the database tier to allow inbound traffic on ports 443 and 1433 from the security group for the web tier.', correct: false,  expli:'' },
      { text: 'd. Configure the security group for the database tier to allow inbound traffic on port 1433 from the security group for the web tier.', correct: true,  expli:' one correct answer: Configure the security group for the database tier to allow inbound traffic on port 1433 from the security group for the web tier. ' }
    ],
	img: '',  
  },  
  {
    question: '/Test 10p Cuestionario 4 - 2 DíA 4-MÓDULO 3.  ARCHITECTING ON AWS/ Which of the following statements are correct with respect to the instance store and EBS volume? Please select 2 correct options. ',
    answers: [
      { text: 'a. All available EC2 instance types support instance store and EBS volumes ', correct: false,  expli:' ' },
      { text: 'b. You cannot add instance store volumes once the EC2 instance is launched.', correct: true,  expli:'one correct answer: You cannot add instance store volumes once the EC2 instance is launched.' },
	    { text: 'c. Instance store backed EC2 instance will persist storage only during instance stop and start.', correct: false,  expli:'' },
      { text: 'd. Instance store backed EC2 instances will persist storage across instance stop, terminate, and failures.', correct: false,  expli:' ' },
      { text: 'e. EBS backed EC2 instances can persist storage across instance stop, terminate, and failures. ', correct: true,  expli:'one correct answer: EBS backed EC2 instances can persist storage across instance stop, terminate, and failures.' },
    ],
	img: '',  
  },  
  {
    question: '/Test 10p Cuestionario 4 - 3 DíA 4-MÓDULO 3.  ARCHITECTING ON AWS/ What are the ways you can connect to your instance using the Amazon EC2 console?  (Select ONE.)',
    answers: [
      { text: 'a. EC2 Instance Connect', correct: false,  expli:' ' },
      { text: 'b. Session Manager', correct: false,  expli:' ' },
	    { text: 'c. SSH client', correct: false,  expli:'' },
      { text: 'd. All of the above ', correct: true,  expli:' The correct answer is : All of the above' }
    ],
	img: '',  
  },  
  {
    question: '/Test 10p Cuestionario 4 - 4 DíA 4-MÓDULO 3.  ARCHITECTING ON AWS/ What is the root volume of the Amazon EC2 instance?  (Select ONE.)',
    answers: [
      { text: 'a. Simple Storage Service (S3) ', correct: false,  expli:' ' },
      { text: 'b. Elastic File System (EFS)', correct: false,  expli:' ' },
	    { text: 'c. Relational Database Service (RDS)', correct: false,  expli:'' },
      { text: 'd. Elastic Block Store (EBS)', correct: true,  expli:'The correct answer is : Elastic Block Store (EBS) ' }
    ],
	img: '',  
  },  
  {
    question: '/Test 10p Cuestionario 4 - 5 DíA 4-MÓDULO 3.  ARCHITECTING ON AWS/ How can a systems administrator specify a script run on an EC2 instance during launch?  (Select ONE.)',
    answers: [
      { text: 'a. User Data. ', correct: true,  expli:' The correct answer is : User Data.' },
      { text: 'b. Metadata.', correct: false,  expli:' ' },
	    { text: 'c. AWS ECS.', correct: false,  expli:'' },
      { text: 'd. Launch Template.', correct: false,  expli:' ' }
    ],
	img: '',  
  },  
  {
    question: '/Test 10p Cuestionario 4 - 6 DíA 4-MÓDULO 3.  ARCHITECTING ON AWS/Amazon EC2 instances run between 10 am and 6 pm Monday-Thursday in a development environment. Production instances run 24/7. Which pricing models should be used? (Select TWO)',
    answers: [
      { text: 'a. Use scheduled reserved instances for the development environment.', correct: true,  expli:'  one correct answer: Use scheduled reserved instances for the development environment.' },
      { text: 'b. Use On-Demand instances for the production environment.', correct: false,  expli:' ' },
	    { text: 'c. Use Spot instances for the development environment.', correct: false,  expli:'' },
      { text: 'd. Use Reserved instances for the production environment. ', correct: true,  expli:'  one correct answer: Use Reserved instances for the production environment.' },
      { text: 'e. Use Reserved instances for the development environment.', correct: false,  expli:' ' },
    ],
	img: '',  
  },  
  {
    question: '/Test 10p Cuestionario 4 - 7 DíA 4-MÓDULO 3.  ARCHITECTING ON AWS/ What is the default username For Amazon Linux 2 or the Amazon Linux AMI? (Select ONE.)',
    answers: [
      { text: 'a. admin', correct: false,  expli:' ' },
      { text: 'b. ec2-user ', correct: true,  expli:' The correct answer is : ec2-user' },
	    { text: 'c. ssm-agent', correct: false,  expli:'' },
      { text: 'd. root', correct: false,  expli:' ' }
    ],
	img: '',  
  },  
  {
    question: '/Test 10p Cuestionario 4 - 8 DíA 4-MÓDULO 3.  ARCHITECTING ON AWS/ What is the purpose of the private key set up while launching an instance?',
    answers: [
      { text: 'a. To pair with the public key created and allow a user to connect to their instance.', correct: true,  expli:' The correct answer is : To pair with the public key created and allow a user to connect to their instance.' },
      { text: 'b. To allow for access to the virtual machine on only on Apple devices.', correct: false,  expli:' ' },
	    { text: 'c. To store a password to be used when connecting to your VM.', correct: false,  expli:'' },
      { text: 'd. To create a copy of the instance for a user\'s local computer.', correct: false,  expli:' ' },
    ],
	img: '',  
  },  
  {
    question: '/Test 10p Cuestionario 4 - 9 DíA 4-MÓDULO 3.  ARCHITECTING ON AWS/ Once the instance has been terminated. Can it be undone?',
    answers: [
      { text: 'a. True', correct: false,  expli:' ' },
      { text: 'b. False', correct: true,  expli:'The correct answer is  False ' }
    ],
	img: '',  
  },  
  {
    question: '/Test 10p Cuestionario 4 - 10 DíA 4-MÓDULO 3.  ARCHITECTING ON AWS/ You are planning to deploy several EC2 instances in your VPC. You will deploy the EC2 instances across several subnets and multiple AZs. What AWS feature can act as an instance-level firewall to control traffic between your EC2 instances?  (Select ONE.)',
    answers: [
      { text: 'a. Route table', correct: false,  expli:' ' },
      { text: 'b. Security group ', correct: true,  expli:' The correct answer is : Security group' },
	    { text: 'c. Network ACL', correct: false,  expli:'' },
      { text: 'd. AWS WAF', correct: false,  expli:' ' }
    ],
	img: '',  
  },  
  {
    question: '/Test DíA 3-MÓDULO 3.  ARCHITECTING ON AWS/ True or False: A single Amazon VPC can span multiple Regions.',
    answers: [
      { text: 'a. True', correct: false,  expli:' ' },
      { text: 'b. False', correct: true,  expli:'correct B False ' }
    ],
	img: '',  
  },  
  {
    question: '/Test DíA 3-MÓDULO 3.  ARCHITECTING ON AWS/ What action must you take to make a subnet public?',
    answers: [
      { text: 'a. Route outbound traffic from the subnet.', correct: false,  expli:' ' },
      { text: 'b. Route inbound traffic from the internet gateway.', correct: false,  expli:' ' },
	    { text: 'c. Route outbound traffic to the internet gateway.', correct: true,  expli:'correct C Route outbound traffic to the internet gateway.' },
      { text: 'd. Subnets are public by default.', correct: false,  expli:' ' }
    ],
	img: '',  
  },  
  {
    question: '/Test DíA 3-MÓDULO 3.  ARCHITECTING ON AWS/ What function does the NAT gateway serve?',
    answers: [
      { text: 'a. Load balances incoming traffic to multiple instances', correct: false,  expli:' ' },
      { text: 'b. Allows internet traffic initiated by private subnet instances', correct: true,  expli:' correct B Allows internet traffic initiated by private subnet instances' },
	    { text: 'c. Allows instances to communicate between subnets', correct: false,  expli:' ' },
      { text: 'd. Increases security for instances in a public subnet', correct: false,  expli:' ' }
    ],
	img: '',  
  },  
  {
    question: '/Test DíA 3-MÓDULO 3.  ARCHITECTING ON AWS/ What should you use to create traffic filtering rules for a subnet?',
    answers: [
      { text: 'a. NAT gateway', correct: false,  expli:' ' },
      { text: 'b. Route table', correct: false,  expli:' ' },
	    { text: 'c. Security group', correct: false,  expli:' ' },
      { text: 'd. Network ACL', correct: true,  expli:' correct D Network ACL ' }
    ],
	img: '',  
  }, 
  {
    question: '/Test DíA 3-MÓDULO 3.  ARCHITECTING ON AWS/ Which ports are open by default when you create a new security group? (Select TWO.)',
    answers: [
      { text: 'a. Nothing allowed inbo bound', correct: true,  expli:' correct A Nothing allowed inbo bound' },
      { text: 'b. Nothing allowed outbound', correct: false,  expli:' ' },
	    { text: 'c. Anything allowed inbound', correct: false,  expli:' ' },
      { text: 'd. Anything allowed outbound', correct: true,  expli:' correct D Anything allowed outbound' },
      { text: 'e. Inbound traffic is allowed on public subnets', correct: false,  expli:' ' },
    ],
	img: '',  
  },   
  {
    question: '/Test 10p Cuestionario 3 - 1 el no permitido DíA 3-MÓDULO 3.  ARCHITECTING ON AWS/ A user has created a VPC with CIDR 20.0.0.0/24. The user has created a public subnet with CIDR 20.0.0.0/25 and a private subnet with CIDR 20.0.0.128/25. The user has launched one instance each in the private and public subnets. Which of the below mentioned options cannot be the correct IP address (private IP) assigned to an instance in the public or private subnet? (Select ONE.)',
    answers: [
      { text: 'a. 20.0.0.122', correct: false,  expli:' ' },
      { text: 'b. 20.0.0.55', correct: false,  expli:' ' },
	    { text: 'c. 20.0.0.255', correct: true,  expli:'The correct answer is : 20.0.0.255 ' },
      { text: 'd. 20.0.0.132', correct: false,  expli:' ' }
    ],
	img: '',  
  }, 
  {
    question: '/Test 10p Cuestionario 3 - 2 el no permitido DíA 3-MÓDULO 3.  ARCHITECTING ON AWS/ What is true for a VPC Subnet & AZ?  (Select ONE.)',
    answers: [
      { text: 'a. An AZ can have 1 subnet, a subnet can be in one AZ', correct: false,  expli:' ' },
      { text: 'b. AZ can have many subnets, a subnet can be in many AZs', correct: false,  expli:' ' },
	    { text: 'c. An AZ can have many subnets, a subnet is in one AZ ', correct: true,  expli:' The correct answer is : An AZ can have many subnets, a subnet is in one AZ' },
      { text: 'd. An AZ can have 1 subnet, a subnet can be in many AZs', correct: false,  expli:' ' }
    ],
	img: '',  
  }, 
  {
    question: '/Test 10p Cuestionario 3 - 3 el no permitido DíA 3-MÓDULO 3.  ARCHITECTING ON AWS/ A new VPC with CIDR range 10.10.0.0/16 has been set up with a public and a private subnet. Internet Gateway and a custom route table have been created, and a route has been added with the Destination as 0.0.0.0/0 and the Target with Internet Gateway ( igw-id ). A new Linux EC2 instance has been launched on the public subnet with the auto-assign public IP option enabled, but the connection is getting failed when trying to SSH into the machine. What could be the reason?  (Select ONE.)',
    answers: [
      { text: 'a. The Security group of the instance disallows the egress traffic on port 80.', correct: false,  expli:' ' },
      { text: 'b. The NACL of the public subnet disallows the ingress SSH traffic. ', correct: true,  expli:' The correct answer is : The NACL of the public subnet disallows the ingress SSH traffic.' },
	    { text: 'c. A public IP address is not assigned.', correct: false,  expli:' ' },
      { text: 'd. Elastic IP is not assigned.', correct: false,  expli:' ' }
    ],
	img: '',  
  }, 
  {
    question: '/Test 10p Cuestionario 3 - 4 el no permitido DíA 3-MÓDULO 3.  ARCHITECTING ON AWS/ Which AWS Services is used to make VPC accessible from internet?  (Select ONE.)',
    answers: [
      { text: 'a. Public Subnet', correct: false,  expli:' ' },
      { text: 'b. Internet Gateway ', correct: true,  expli:' The correct answer is : Internet Gateway' },
	    { text: 'c. Network Access Control List', correct: false,  expli:' ' },
      { text: 'd. Security group', correct: false,  expli:' ' }
    ],
	img: '',  
  }, 
  {
    question: '/Test 10p Cuestionario 3 - 5 el no permitido DíA 3-MÓDULO 3.  ARCHITECTING ON AWS/ How can an Internet Gateway (IGW) be configured to be highly available?  (Select ONE.)',
    answers: [
      { text: 'a. Add the AZs which are used to its configuration.', correct: false,  expli:' ' },
      { text: 'b. Create and attach multiple IGWs to the VPC.', correct: false,  expli:' ' },
	    { text: 'c. It\'s HA by default - attached to a VPC', correct: true,  expli:' The correct answer is : It\'s HA by default - attached to a VPC ' },
      { text: 'd. It cannot be HA.', correct: false,  expli:' ' }
    ],
	img: '',  
  }, 
  {
    question: '/Test 10p Cuestionario 3 - 6 el no permitido DíA 3-MÓDULO 3.  ARCHITECTING ON AWS/ What service does a VPC provide?  (Select ONE.)',
    answers: [
      { text: 'a. a. Public only network services', correct: false,  expli:' ' },
      { text: 'b. Isolated Account', correct: false,  expli:' ' },
	    { text: 'c. Isolated Network ', correct: true,  expli:' The correct answer is : Isolated Network' },
      { text: 'd. None of the above', correct: false,  expli:' ' }
    ],
	img: '',  
  }, 
  {
    question: '/Test 10p Cuestionario 3 - 7 el no permitido DíA 3-MÓDULO 3.  ARCHITECTING ON AWS/ Your organization already had a VPC(10.10.0.0/16) setup with one public(10.10.1.0/24) and two private subnets – private subnet 1 (10.10.2.0/24) and private subnet 2 (10.10.3.0/24). The public subnet has the main route table, and two private subnets have two different route tables respectively. AWS sysops team reports a problem starting the EC2 instance in private subnet 1 cannot communicate to the RDS MySQL database on private subnet 2. What are the possible reasons? (choose 2 options)',
    answers: [
      { text: 'a. 10.10.3.0/24 subnet\'s NACL is modified to deny inbound on port 3306 from subnet 10.10.2.0/24', correct: true,  expli:'one correct answer: 10.10.3.0/24 subnet\'s NACL is modified to deny inbound on port 3306 from subnet 10.10.2.0/24' },
      { text: 'b. One of the private subnet route table’s local route has been changed to restrict access only within the subnet IP range. ', correct: false,  expli:' ' },
	    { text: 'c. RDS security group inbound rule is incorrectly configured with 10.10.1.0/24 instead of 10.10.2.0/24. ', correct: true,  expli:'one correct answer: RDS security group inbound rule is incorrectly configured with 10.10.1.0/24 instead of 10.10.2.0/24.' },
      { text: 'd. RDS Security group outbound does not contain a rule for ALL traffic or port 3306 for 10.10.2.0/24 IP range.', correct: false,  expli:' ' }
    ],
	img: '',  
  }, 
  {
    question: '/Test 10p Cuestionario 3 - 8 el no permitido DíA 3-MÓDULO 3.  ARCHITECTING ON AWS/ What function does NAT serve? (Select ONE.)',
    answers: [
      { text: 'a. Allows IPv6 private instances outgoing access to the internet.', correct: false,  expli:' ' },
      { text: 'b. Allows IPv4 and IPv6 public instances to access the internet.', correct: false,  expli:' ' },
	    { text: 'c. Allows IPv4 private instances outgoing access to the internet. ', correct: true,  expli:' The correct answer is : Allows IPv4 private instances outgoing access to the internet. ' },
      { text: 'd. IPv4 and IPv6 private instances to access the internet.', correct: false,  expli:' ' }
    ],
	img: '',  
  }, 
  {
    question: '/Test 10p Cuestionario 3 - 9 el no permitido DíA 3-MÓDULO 3.  ARCHITECTING ON AWS/ Which of the following is NOT a benefit of Virtual Private Clouds (VPC)?  (Select ONE.)',
    answers: [
      { text: 'a. VPCs offer better performance', correct: false,  expli:' ' },
      { text: 'b. VPCs can offer overall better cybersecurity', correct: false,  expli:' ' },
	    { text: 'c. VPCs are highly scalable.', correct: false,  expli:' ' },
      { text: 'd. VPCs are typically cheaper than a public cloud.', correct: true,  expli:' The correct answer is : VPCs are typically cheaper than a public cloud.' }
    ],
	img: '',  
  }, 
  {
    question: '/Test 10p Cuestionario 3 - 10 el no permitido DíA 3-MÓDULO 3.  ARCHITECTING ON AWS/ A user has created a VPC with a subnet and a security group. The user has launched an instance in that subnet and attached a public IP. The user is still unable to connect to the instance. The internet gateway has also been created. What can be the reason for the error?',
    answers: [
      { text: 'a. The internet gateway is not configured with the security group', correct: false,  expli:' ' },
      { text: 'b. The private IP is not present', correct: false,  expli:' ' },
	    { text: 'c. The internet gateway is not configured with the route table ', correct: true,  expli:'The correct answer is : The internet gateway is not configured with the route table ' },
      { text: 'd. The outbound traffic on the security group is disabled', correct: false,  expli:' ' }
    ],
	img: '',  
  }, 
  {
    question: '/Test DíA 2-MÓDULO 3.  ARCHITECTING ON AWS/ Which of the following can be attached to a user, group, or role?',
    answers: [
      { text: 'a. Resource-based policies', correct: false,  expli:' ' },
      { text: 'b. AWS STS', correct: false,  expli:' ' },
	    { text: 'c. Security groups', correct: false,  expli:' ' },
      { text: 'd. correct dentity-based policies', correct: true,  expli:'correct D correct dentity-based policies ' }
    ],
	img: '',  
  },
  {
    question: '/Test DíA 2-MÓDULO 3.  ARCHITECTING ON AWS/ Which of the following sets permissions on a specific resource and requires a principal to be listed in the policy?',
    answers: [
      { text: 'a. ldentity-based policies', correct: false,  expli:' ' },
      { text: 'b. Service control policies (SCPs)', correct: false,  expli:' ' },
	    { text: 'c. Resource-based policies', correct: true,  expli:' correct C Resource-based policies ' },
      { text: 'd. Permissions boundaries', correct: false,  expli:' ' }
    ],
	img: '',  
  },
  {
    question: '/Test DíA 2-MÓDULO 3.  ARCHITECTING ON AWS/ Which of the following are elements of an IAM user\'s programmatic access? (Select TWO.)',
    answers: [
      { text: 'a. Username', correct: false,  expli:' ' },
      { text: 'b. Access key ID', correct: true,  expli:' correct B Access key ID ' },
	    { text: 'c. Password', correct: false,  expli:' ' },
      { text: 'd. Secret access key', correct: true,  expli:' corect D Secret access key ' },
      { text: 'e. MFA token', correct: false,  expli:' ' },
    ],
	img: '',  
  },
  {
    question: '/Test DíA 2-MÓDULO 3.  ARCHITECTING ON AWS/ The root user should be used for daily administration of your AWS account.',
    answers: [
      { text: 'a. True', correct: false,  expli:' ' },
      { text: 'b. False', correct: true,  expli:' correct B False' }
    ],
	img: '',  
  },
  {
    question: '/Test DíA 2-MÓDULO 3.  ARCHITECTING ON AWS/ Which of the following can only be managed with AWS Organizations?  (Select ONE.)',
    answers: [
      { text: 'a. Service control policies (SCPs)', correct: true,  expli:'correct A Service control policies (SCPs)' },
      { text: 'b. Resource-based policies', correct: false,  expli:' ' },
	    { text: 'c. Permissions boundaries', correct: false,  expli:' ' },
      { text: 'd. Identity-based policies', correct: false,  expli:' ' }
    ],
	img: '',  
  },
  {
    question: '/Test 10p Cuestionario 2 - 1  DíA 2-MÓDULO 3.  ARCHITECTING ON AWS/ AWS Identity and Access Management policies are used to define permissions for what kind of operation methods? (Select ONE.)',
    answers: [
      { text: 'a. API calls made through an SDK', correct: false,  expli:' ' },
      { text: 'b. AWS Command Line Interface', correct: false,  expli:' ' },
	    { text: 'c. AWS Management Console operations', correct: false,  expli:' ' },
      { text: 'd. All of the above ', correct: true,  expli:' The correct answer is : All of the above' }
    ],
	img: '',  
  },
  {
    question: '/Test 10p Cuestionario 2 - 2  DíA 2-MÓDULO 3.  ARCHITECTING ON AWS/ What is the term for an external user trusted in AWS through identity federation?  (Select ONE.)',
    answers: [
      { text: 'a. Federated identity', correct: true,  expli:' The correct answer is : Federated identity' },
      { text: 'b. External user', correct: false,  expli:' ' },
	    { text: 'c. Outside identity', correct: false,  expli:' ' },
      { text: 'd. Federated external', correct: false,  expli:' ' }
    ],
	img: '',  
  },
  {
    question: '/Test 10p Cuestionario 2 - 3  DíA 2-MÓDULO 3.  ARCHITECTING ON AWS/ What do ALL users created through AWS Identity and Access Management have?  (Select ONE.)',
    answers: [
      { text: 'a. Username and encryption key', correct: false,  expli:' ' },
      { text: 'b. Access Key and Secret Access Key ', correct: false,  expli:' ' },
	    { text: 'c. Username and password', correct: false,  expli:' ' },
      { text: 'd. Name and credentials', correct: true,  expli:' The correct answer is : Name and credentials' }
    ],
	img: '',  
  },
  {
    question: '/Test 10p Cuestionario 2 - 4  DíA 2-MÓDULO 3.  ARCHITECTING ON AWS/ What is an Organizational Unit?  (Select ONE.)',
    answers: [
      { text: 'a. An Organizational unit (OU) is a container which has all the Root Users in an AWS Organization.', correct: false,  expli:' ' },
      { text: 'b. An Organizational Unit (OU) is the dafault name of policy attached to member accounts in an Organization.', correct: false,  expli:' ' },
	    { text: 'c. An Organizational Unit (OU) is a logical grouping of accounts in AWS Organization. ', correct: true,  expli:' The correct answer is : An Organizational Unit (OU) is a logical grouping of accounts in AWS Organization.' },
      { text: 'd. An Organizational Unit (OU) is the default name of Role created for member accounts in an AWS Organization.', correct: false,  expli:' ' }
    ],
	img: '',  
  },
  {
    question: '/Test 10p Cuestionario 2 - 5  DíA 2-MÓDULO 3.  ARCHITECTING ON AWS/ Which of the following best defines authentication?  (Select ONE.)',
    answers: [
      { text: 'a. The process of verifying a user’s permissions.', correct: false,  expli:' ' },
      { text: 'b. The process of validating a user’s identity.', correct: true,  expli:' The correct answer is : The process of validating a user’s identity.' },
	    { text: 'c. The validation of a user’s identity and verification of their permissions', correct: false,  expli:' ' },
      { text: 'd. The process of protecting your personal information as data is transferred', correct: false,  expli:' ' }
    ],
	img: '',  
  },
  {
    question: '/Test 10p Cuestionario 2 - 6  DíA 2-MÓDULO 3.  ARCHITECTING ON AWS/ Which of the following is a true about IAM roles?  (Select ONE.)',
    answers: [
      { text: 'a. You should rarely use roles as an authentication method.', correct: false,  expli:' ' },
      { text: 'b. Roles are assumed by users and services when they need short term credentials. ', correct: true,  expli:' The correct answer is : Roles are assumed by users and services when they need short term credentials.' },
	    { text: 'c. Roles are associated with a specific person or machine.', correct: false,  expli:' ' },
      { text: 'd. IAM roles are considered long-term credentials.', correct: false,  expli:' ' }
    ],
	img: '',  
  },
  {
    question: '/Test 10p Cuestionario 2 - 7  DíA 2-MÓDULO 3.  ARCHITECTING ON AWS/ ‘You can restrict the “Root User” of member accounts using “Service Control Policy"',
    answers: [
      { text: 'a. True', correct: true,  expli:' The correct answer is  True' },
      { text: 'b. False', correct: false,  expli:' ' }
    ],
	img: '',  
  },
  {
    question: '/Test 10p Cuestionario 2 - 8  DíA 2-MÓDULO 3.  ARCHITECTING ON AWS/ Which among the following is a benefit associated with AWS Organization? Select all that apply .  (Select TWO.)',
    answers: [
      { text: 'a. Managed assistance for company', correct: false,  expli:' ' },
      { text: 'b. Consolidated Billing  ', correct: true,  expli:' one correct answer: Consolidated Billing' },
	    { text: 'c. Configure AWS Services across multiple accounts', correct:  true,  expli:' one correct answer: Configure AWS Services across multiple accounts' },
      { text: 'd. Protection against Cyber attacks', correct: false,  expli:' ' }
    ],
	img: '',  
  },
  {
    question: '/Test 10p Cuestionario 2 - 9  DíA 2-MÓDULO 3.  ARCHITECTING ON AWS/ What do the letters E-PARC refer to in a policy?  (Select ONE.)',
    answers: [
      { text: 'a. Effect, Principal, Allowable, Refusal, Conclusion', correct: false,  expli:' ' },
      { text: 'b. Element, Principal, Allowable, Refusal, Condition', correct: false,  expli:' ' },
	    { text: 'c. Effect, Principal, Action, Resource, Condition ', correct: true,  expli:' The correct answer is : Effect, Principal, Action, Resource, Condition' },
      { text: 'd. Element, Partition, Allowable, Refusal, Conclusion', correct: false,  expli:' ' }
    ],
	img: '',  
  },
  {
    question: '/Test 10p Cuestionario 2 - 10  DíA 2-MÓDULO 3.  ARCHITECTING ON AWS/ What will be the default Policy attached to all Organizational Units, when you enable Service Control Policy in an AWS Organization ?  (Select ONE.)',
    answers: [
      { text: 'a.Deny All Access ', correct: false,  expli:' ' },
      { text: 'b. Allow Only IAM Access', correct: false,  expli:' ' },
	    { text: 'c. Full AWS Access ', correct: true,  expli:'The correct answer is : Full AWS Access ' },
      { text: 'd. Deny Only IAM Access', correct: false,  expli:' ' }
    ],
	img: '',  
  },
  {
    question: '/Test DíA 1-MÓDULO 3.  ARCHITECTING ON AWS/ Which of the following is the best example of one responsibility of an AWS architect?  (Select ONE.)',
    answers: [
      { text: 'a. Monitor alarms for disaster response.', correct: false,  expli:' ' },
      { text: 'b. Maintain application-level code in the AWS Cloud.', correct: false,  expli:' ' },
	    { text: 'c. Manage access to a group of AWS accounts.', correct: false,  expli:' ' },
      { text: 'd. Analyze solutions for business needs and requirements.', correct: true,  expli:' correct D Analyze solutions for business needs and requirements. ' }
    ],
	img: '',  
  },
  {
    question: '/Test DíA 1-MÓDULO 3.  ARCHITECTING ON AWS/ Which of the following is a cluster of data centers within a geographic location with low latency network connectivity?  (Select ONE.)',
    answers: [
      { text: 'a. Availability Zone', correct: true,  expli:' correct A Availability Zone' },
      { text: 'b. Region', correct: false,  expli:' ' },
	    { text: 'c. Edge location', correct: false,  expli:' ' },
      { text: 'd. Outposts', correct: false,  expli:' ' }
    ],
	img: '',  
  },
  {
    question: '/Test DíA 1-MÓDULO 3.  ARCHITECTING ON AWS/ The principle of least privilege is a principle under which Well-Architected Framework pillar?  (Select ONE.)',
    answers: [
      { text: 'a. Operational excellence', correct: false,  expli:' ' },
      { text: 'b. Security', correct: true,  expli:' correct B Security' },
	    { text: 'c. Resilience', correct: false,  expli:' ' },
      { text: 'd. Performance efficiency', correct: false,  expli:' ' }
    ],
	img: '',  
  },
  {
    question: '/Test DíA 1-MÓDULO 3.  ARCHITECTING ON AWS/ Which of the following factors do you consider when picking an AWS Region? (Select TWO.)',
    answers: [
      { text: 'a. Local data regulations', correct: true,  expli:' correct A Local data regulations' },
      { text: 'b. Operating system requirements', correct: false,  expli:' ' },
	    { text: 'c. Latency to end users', correct: true,  expli:' correct C Latency to end users' },
      { text: 'd. Support for hybrid networking', correct: false,  expli:' ' },
      { text: 'e. Programming language of your application', correct: false,  expli:' ' },
    ],
	img: '',  
  },
  {
    question: '/Test DíA 1-MÓDULO 3.  ARCHITECTING ON AWS/ What is the primary benefit of deploying your applications into multiple Availability Zones?  (Select ONE.)',
    answers: [
      { text: 'a. Stronger security policies for resources', correct: false,  expli:' ' },
      { text: 'b. Decreased latency to resources', correct: false,  expli:' ' },
	    { text: 'c. High availability for resources ', correct: true,  expli:' correct C High availability for resources' },
      { text: 'd. There is no benefit to this design', correct: false,  expli:' ' }
    ],
	img: '',  
  },
  {
    question: '/Test 10p Cuestionario 1 - 1  DíA 1-MÓDULO 3.  ARCHITECTING ON AWS/ A user is hosting a solution on Amazon Elastic Compute Cloud (Amazon EC2). Which networking component is needed to create a private network for their AWS resources?  (Select ONE.)',
    answers: [
      { text: 'a.Amazon Machine Image (AMI) ', correct: false,  expli:' ' },
      { text: 'b. Instance', correct: false,  expli:' ' },
	    { text: 'c. Virtual private cloud (VPC) ', correct: true,  expli:'The correct answer is: Virtual private cloud (VPC) ' },
      { text: 'd.Tags ', correct: false,  expli:' ' }
    ],
	img: '',  
  },
  {
    question: '/Test 10p Cuestionario 1 - 2  DíA 1-MÓDULO 3.  ARCHITECTING ON AWS/ What is the difference between using AWS Fargate or Amazon Elastic Compute Cloud (Amazon EC2) as the compute platform for Amazon Elastic Container Service (Amazon ECS)?  (Select ONE.)',
    answers: [
      { text: 'a. With Amazon ECS on Amazon EC2, AWS manages and provisions the underlying EC2 instance for containers.', correct: false,  expli:' ' },
      { text: 'b. With Amazon ECS on Amazon EC2, users need to upload only the source code. Amazon ECS takes care of the rest.', correct: false,  expli:' ' },
	    { text: 'c. With AWS Fargate, AWS manages and provisions the underlying infrastructure for hosting containers. ', correct: true,  expli:'The correct answer is : With AWS Fargate, AWS manages and provisions the underlying infrastructure for hosting containers. ' },
      { text: 'd. With AWS Fargate, users need to manage cluster capacity and scaling.', correct: false,  expli:' ' }
    ],
	img: '',  
  },
  {
    question: '/Test 10p Cuestionario 1 - 3  DíA 1-MÓDULO 3.  ARCHITECTING ON AWS/ A company wants to manage AWS services by using the command line and automating them with scripts. What should the company use to accomplish this goal?  (Select ONE.)',
    answers: [
      { text: 'a. AWS SDKs ', correct: false,  expli:' ' },
      { text: 'b. AWS Management Console and AWS SDKs ', correct: false,  expli:' ' },
	    { text: 'c. AWS Management Console', correct: false,  expli:' ' },
      { text: 'd. AWS Command Line Interface (AWS CLI)', correct: true,  expli:'The correct answer is: AWS Command Line Interface (AWS CLI) ' }
    ],
	img: '',  
  },
  {
    question: '/Test 10p Cuestionario 1 - 4  DíA 1-MÓDULO 3.  ARCHITECTING ON AWS/ What are the three components of Amazon EC2 Auto Scaling?  (Select ONE.)',
    answers: [
      { text: 'a.Launch template, scaling policies, EC2 Auto Scaling group  ', correct: true,  expli:' The correct answer is: Launch template, scaling policies, EC2 Auto Scaling group' },
      { text: 'b. Security group, instance type, key pair', correct: false,  expli:' ' },
	    { text: 'c. Scaling policies, security group, EC2 Auto Scaling group', correct: false,  expli:' ' },
      { text: 'd. Amazon Machine Image (AMI) ID, instance type, storage ', correct: false,  expli:' ' }
    ],
	img: '',  
  },
  {
    question: '/Test 10p Cuestionario 1 - 5  DíA 1-MÓDULO 3.  ARCHITECTING ON AWS/ Which information is needed to create a virtual private cloud (VPC)?  (Select ONE.)',
    answers: [
      { text: 'a.The subnet that the VPC will reside in.  ', correct: false,  expli:' ' },
      { text: 'b. The AWS Region that the VPC will reside in.. ', correct: true,  expli:' The correct answer is: The AWS Region that the VPC will reside in.' },
	    { text: 'c. The group of subnets that the VPC will reside in. ', correct: false,  expli:' ' },
      { text: 'd. The Availability Zone that the VPC will reside in.', correct: false,  expli:' ' }
    ],
	img: '',  
  },
  {
    question: '/Test 10p Cuestionario 1 - 6  DíA 1-MÓDULO 3.  ARCHITECTING ON AWS/ According to the AWS shared responsibility model, a customer is responsible for security in the cloud.',
    answers: [
      { text: 'a. True', correct: true,  expli:' The correct answer is:  True' },
      { text: 'b. False', correct: false,  expli:' ' }
    ],
	img: '',  
  },
  {
    question: '/Test 10p Cuestionario 1 - 7  DíA 1-MÓDULO 3.  ARCHITECTING ON AWS/ What are the two ways that an application can be scaled?  (Select ONE.)',
    answers: [
      { text: 'a. Vertically and horizontally ', correct: true,  expli:' The correct answer is: Vertically and horizontally' },
      { text: 'b. Horizontally and diagonally', correct: false,  expli:' ' },
	    { text: 'c. Independently and vertically ', correct: false,  expli:' ' },
      { text: 'd. Diagonally and vertically. ', correct: false,  expli:' ' }
    ],
	img: '',  
  },
  {
    question: '/Test 10p Cuestionario 1 - 8  DíA 1-MÓDULO 3.  ARCHITECTING ON AWS/ What is a benefit of monitoring on AWS?  (Select ONE.)',
    answers: [
      { text: 'a. Monitoring recognizes security threats and events. ', correct: true,  expli:' The correct answer is: Monitoring recognizes security threats and events.' },
      { text: 'b. Increases speed and agility ', correct: false,  expli:' ' },
	    { text: 'c. Monitoring creates operation overhead. ', correct: false,  expli:' ' },
      { text: 'd. Monitoring decreases the performance and reliability of resources. ', correct: false,  expli:' ' }
    ],
	img: '',  
  },
  {
    question: '/Test 10p Cuestionario 1 - 9  DíA 1-MÓDULO 3.  ARCHITECTING ON AWS/ AWS Identity and Access Management (IAM) policies can restrict the actions of the AWS account root user.  (Select ONE.)',
    answers: [
      { text: 'a. True', correct: false,  expli:' ' },
      { text: 'b. False', correct: true,  expli:' The correct answer is:  False' }
    ],
	img: '',  
  },
  {
    question: '/Test 10p Cuestionario 1 - 10  DíA 1-MÓDULO 3.  ARCHITECTING ON AWS/ Which of the following provides temporary credentials (that expire after a defined period of time) to AWS services?',
    answers: [
      { text: 'a. Identity provider (IdP) ', correct: false,  expli:' ' },
      { text: 'b. Principle of least privilege', correct: false,  expli:' ' },
	    { text: 'c. AWS IAM Identity Center (successor to AWS Single Sign-On) ', correct: false,  expli:' ' },
      { text: 'd. IAM role', correct: true,  expli:' The correct answer is: IAM role' }
    ],
	img: '',  
  },
  {
    question: 'Exam 15p 1, 1ST EVALUATION TEST: TECHNICAL ESSENTIALS ON AWS SECURITY FUNDAMENTALS ON AWS MÓDULO 1. TECHNICAL ESSENTIALS ON AWS y MODULO 2. SECURITY FUNDAMENTALS ON AWS/ 1.- Which of the following services can be used in an EC2 instance to store data? Select one:',
    answers: [
      { text: 'a. EBS Volumes. ', correct: true,  expli:' The correct answer is: EBS Volumes.' },
      { text: 'b. SQS.', correct: false,  expli:' ' },
	    { text: 'c. Glacier.', correct: false,  expli:' ' },
      { text: 'd. EBS Snapshots.', correct: false,  expli:' ' }
    ],
	img: '',  
  },
  {
    question: 'Exam 15p 2, 1ST EVALUATION TEST: TECHNICAL ESSENTIALS ON AWS SECURITY FUNDAMENTALS ON AWS MÓDULO 1. TECHNICAL ESSENTIALS ON AWS y MODULO 2. SECURITY FUNDAMENTALS ON AWS/ Which of the following network components can be used to host EC2 resources?  Select one:',
    answers: [
      { text: 'a. Autoscaling.', correct: false,  expli:' ' },
      { text: 'b. Elastic Load Balancer.', correct: false,  expli:' ' },
	    { text: 'c. VPC. ', correct: true,  expli:' The correct answer is: VPC. ' },
      { text: 'd. Trusted Advisor.', correct: false,  expli:' ' }
    ],
	img: '',  
  },
  {
    question: 'Exam 15p 3, 1ST EVALUATION TEST: TECHNICAL ESSENTIALS ON AWS SECURITY FUNDAMENTALS ON AWS MÓDULO 1. TECHNICAL ESSENTIALS ON AWS y MODULO 2. SECURITY FUNDAMENTALS ON AWS/  A company wants to host resources on AWS. They want to use services that can be used to decouple cloud resources. Which of the following services can help this? Select one:',
    answers: [
      { text: 'a. EBS Volumes.', correct: false,  expli:' ' },
      { text: 'b. SQS.', correct: true,  expli:' The correct answer is: SQS.' },
	    { text: 'c. EBS Snapshots. ', correct: false,  expli:' ' },
      { text: 'd. Glacier.', correct: false,  expli:' ' }
    ],
	img: '',  
  },
  {
    question: 'Exam 15p 4, 1ST EVALUATION TEST: TECHNICAL ESSENTIALS ON AWS SECURITY FUNDAMENTALS ON AWS MÓDULO 1. TECHNICAL ESSENTIALS ON AWS y MODULO 2. SECURITY FUNDAMENTALS ON AWS/ Which of the following Cloudfront components can be used to distribute content around the world? .Select one:',
    answers: [
      { text: 'a. Availability zones.', correct: false,  expli:' ' },
      { text: 'b. Regions.', correct: false,  expli:' ' },
	    { text: 'c. Edge locations. ', correct: true,  expli:' The correct answer is: Edge locations.' },
      { text: 'd.  VPC.', correct: false,  expli:' ' }
    ],
	img: '',  
  },
  {
    question: 'Exam 15p 5, 1ST EVALUATION TEST: TECHNICAL ESSENTIALS ON AWS SECURITY FUNDAMENTALS ON AWS MÓDULO 1. TECHNICAL ESSENTIALS ON AWS y MODULO 2. SECURITY FUNDAMENTALS ON AWS/ A company is thinking of migrating to AWS. They ask you to give a presentation from a cost perspective. What advantage does EC2 have from a cost perspective? Select one:',
    answers: [
      { text: 'a. You only pay for what you use. ', correct: true,  expli:' The correct answer is: You only pay for what you use.' },
      { text: 'b. You have the possibility to automate backups so you don\'t have to worry about maintenance costs. ', correct: false,  expli:' ' },
	    { text: 'c. You can choose low-cost AMIs for your EC2 instances.', correct: false,  expli:' ' },
      { text: 'd. You have the possibility to tag the resources to reduce the cost.', correct: false,  expli:' ' }
    ],
	img: '',  
  },
  {
    question: 'Exam 15p 6, 1ST EVALUATION TEST: TECHNICAL ESSENTIALS ON AWS SECURITY FUNDAMENTALS ON AWS MÓDULO 1. TECHNICAL ESSENTIALS ON AWS y MODULO 2. SECURITY FUNDAMENTALS ON AWS/ Your company wants to move to the cloud. Once they are there they want to make sure that the security settings are correct. What tools can help from a security compliance standpoint? Mark 2 answers.',
    answers: [
      { text: 'a. Inspector. ', correct: true,  expli:' one correct answer: Inspector. ' },
      { text: 'b. Support.', correct: false,  expli:' ' },
	    { text: 'c. Kinesis.', correct: false,  expli:' ' },
      { text: 'd. Trusted Advisor. ', correct: true,  expli:' one correct answer: Trusted Advisor.' }
    ],
	img: '',  
  },
  {
    question: 'Exam 15p 7, 1ST EVALUATION TEST: TECHNICAL ESSENTIALS ON AWS SECURITY FUNDAMENTALS ON AWS MÓDULO 1. TECHNICAL ESSENTIALS ON AWS y MODULO 2. SECURITY FUNDAMENTALS ON AWS/ In an application there is a requirement to collect important metrics from an RDS database and EC2 instances. What service can help with this requirement? Select one:',
    answers: [
      { text: 'a. Cloudmap.', correct: false,  expli:' ' },
      { text: 'b. Cloudsearch.', correct: false,  expli:' ' },
	    { text: 'c. Cloudfront.', correct: false,  expli:' ' },
      { text: 'd. Cloudwatch.', correct: true,  expli:'The correct answer is: Cloudwatch. ' }
    ],
	img: '',  
  },
  {
    question: 'Exam 15p 8, 1ST EVALUATION TEST: TECHNICAL ESSENTIALS ON AWS SECURITY FUNDAMENTALS ON AWS MÓDULO 1. TECHNICAL ESSENTIALS ON AWS y MODULO 2. SECURITY FUNDAMENTALS ON AWS/  An administrator is running his infrastructure in the cloud using the good practices provided by the Inspector and Trusted Advisor services. Which of the following answers correctly describes how this can be achieved? Mark 2 answers. ',
    answers: [
      { text: 'a. Run the Inspector service to regularly probe and protect the cloud infrastructure from threats.', correct: false,  expli:' ' },
      { text: 'b. Regularly run the Inspector service on EC2 instances to get a concise list of security vulnerabilities and attack exposures. ', correct: true,  expli:' correct B Regularly run the Inspector service on EC2 instances to get a concise list of security vulnerabilities and attack exposures.' },
	    { text: 'c. Trusted Advisor will highlight pending tasks that need to be resolved based only on performance and cost optimization best practices, while Inspector will alert the administrator to security vulnerabilities.', correct: false,  expli:' ' },
      { text: 'd. Adhere to the recommendations given in the main Trusted Advisor pillars, which are cost optimization, security, performance, fault tolerance and service limits. ', correct:  true,  expli:' correct D Adhere to the recommendations given in the main Trusted Advisor pillars, which are cost optimization, security, performance, fault tolerance and service limits. ' },
      { text: 'e. Inspector will highlight pending tasks that need to be resolved only based on performance and cost optimization best practices, while AWS Trusted Advisor will alert the administrator to security vulnerabilities.', correct: false,  expli:' ' },
    ],
	img: '',  
  },
  {
    question: 'Exam 15p 9, 1ST EVALUATION TEST: TECHNICAL ESSENTIALS ON AWS SECURITY FUNDAMENTALS ON AWS MÓDULO 1. TECHNICAL ESSENTIALS ON AWS y MODULO 2. SECURITY FUNDAMENTALS ON AWS/ Which of the following services is most useful when a Disaster Recovery method is launched on AWS? Select one:',
    answers: [
      { text: 'a. SNS.', correct: false,  expli:' ' },
      { text: 'b. Inspector.', correct: false,  expli:' ' },
	    { text: 'c. SQS.', correct: false,  expli:' ' },
      { text: 'd. Highway 53. ', correct: true,  expli:' The correct answer is: Route 53.' }
    ],
	img: '',  
  },
  {
    question: 'Exam 15p 10, 1ST EVALUATION TEST: TECHNICAL ESSENTIALS ON AWS SECURITY FUNDAMENTALS ON AWS MÓDULO 1. TECHNICAL ESSENTIALS ON AWS y MODULO 2. SECURITY FUNDAMENTALS ON AWS/ Which statement is correct about AWS Budgets and Cost Explorer? Select one:',
    answers: [
      { text: 'a. Due to the sensitivity of billing and cost management information, with the Cost Explorer and Budgets services, it is not possible to view information from multiple accounts.', correct: false,  expli:' ' },
      { text: 'b. Budgets uses the cost visualizations provided by Cost Explorer to show the status of preset budgets and to provide forecasts of estimated costs.', correct: true,  expli:' The correct answer is: Budgets uses the cost visualizations provided by Cost Explorer to show the status of preset budgets and to provide forecasts of estimated costs.' },
	    { text: 'c. Both Budgets and Cost Explorer can be used to predict usage and recommend cost optimization measures. ', correct: false,  expli:' ' },
      { text: 'd. Cost Explorer displays costs incurred over a period of time with a breakdown by region and linked account.', correct: false,  expli:' ' }
    ],
	img: '',  
  },
  {
    question: 'Exam 15p 11, 1ST EVALUATION TEST: TECHNICAL ESSENTIALS ON AWS SECURITY FUNDAMENTALS ON AWS MÓDULO 1. TECHNICAL ESSENTIALS ON AWS y MODULO 2. SECURITY FUNDAMENTALS ON AWS/ When designing a system, the principle of "design for failure and nothing will fail" is used. Which of the following AWS services/features can help implement this design principle. Mark 3 answers.',
    answers: [
      { text: 'a. Availability zones. ', correct: true,  expli:' one correct answer: Availability zones.' },
      { text: 'b. Regions. ', correct: true,  expli:' one correct answer:Regions.' },
	    { text: 'c. Pay per use.', correct: false,  expli:' ' },
      { text: 'd. Elastic Load Balancer. ', correct: true,  expli:' one correct answer: Elastic Load Balancer.' }
    ],
	img: '',  
  },
  {
    question: 'Exam 15p 12, 1ST EVALUATION TEST: TECHNICAL ESSENTIALS ON AWS SECURITY FUNDAMENTALS ON AWS MÓDULO 1. TECHNICAL ESSENTIALS ON AWS y MODULO 2. SECURITY FUNDAMENTALS ON AWS/  Your company currently has an operational team that is in charge of ID management in its on-premise data center. Now they also need to manage the users and groups created in AWS. Which of the following AWS tools should they use to perform this management function? . Select one:',
    answers: [
      { text: 'a. IAM.', correct: true,  expli:' The correct answer is: IAM.' },
      { text: 'b. KMS.', correct: false,  expli:' ' },
	    { text: 'c. Cloud Trail.', correct: false,  expli:' ' },
      { text: 'd. Config.', correct: false,  expli:' ' }
    ],
	img: '',  
  },
  {
    question: 'Exam 15p 13, 1ST EVALUATION TEST: TECHNICAL ESSENTIALS ON AWS SECURITY FUNDAMENTALS ON AWS MÓDULO 1. TECHNICAL ESSENTIALS ON AWS y MODULO 2. SECURITY FUNDAMENTALS ON AWS/ In your company there is a development team. They are interested in knowing if there are any services available on AWS that can be used to manage infrastructure as code. Which of the following services can satisfy this requirement? Select one:',
    answers: [
      { text: 'a. Inspector.', correct: false,  expli:' ' },
      { text: 'b. Config.', correct: false,  expli:' ' },
	    { text: 'c. Trusted Advisor.', correct: false,  expli:' ' },
      { text: 'd. Cloudformation. ', correct: true,  expli:' The correct answer is: Cloudformation.' }
    ],
	img: '',  
  },
  {
    question: 'Exam 15p 14, 1ST EVALUATION TEST: TECHNICAL ESSENTIALS ON AWS SECURITY FUNDAMENTALS ON AWS MÓDULO 1. TECHNICAL ESSENTIALS ON AWS y MODULO 2. SECURITY FUNDAMENTALS ON AWS/ Select 2 sentences that describe the main roles of the WAF and Shield services. Mark 2 answers. ',
    answers: [
      { text: 'a. Shield Standard is available inherently in the AWS WAF service at no additional cost.', correct: true,  expli:'one correct answer:  Shield Standard is available inherently in the AWS WAF service at no additional cost.' },
      { text: 'b. WAF will provide increased protection against SYN floods, DNS query attacks, and UDP reflection attacks at no additional cost. ', correct: false,  expli:' ' },
	    { text: 'c. WAF is a web application firewall that includes AWS Shield, a service that prevents Distributed Denial of Service (DDoS) attacks.', correct: true,  expli:' one correct answer: WAF is a web application firewall that includes AWS Shield, a service that prevents Distributed Denial of Service (DDoS) attacks.' },
      { text: 'd. WAF is inherently available in the Shield Standard service at an additional charge.', correct: false,  expli:' ' },
      { text: 'e. Web Application Firewall and Shield are fully managed services.', correct: false,  expli:' ' },
    ],
	img: '',  
  },
  {
    question: 'Exam 15p 15, 1ST EVALUATION TEST: TECHNICAL ESSENTIALS ON AWS SECURITY FUNDAMENTALS ON AWS MÓDULO 1. TECHNICAL ESSENTIALS ON AWS y MODULO 2. SECURITY FUNDAMENTALS ON AWS/ Which of the following is the responsibility of AWS according to the Shared Security Model? Mark 3 answers. ',
    answers: [
      { text: 'a. Manage IAM.', correct: false,  expli:' ' },
      { text: 'b. Securing edge locations', correct: true,  expli:'A correct question is: Securing edge locations' },
	    { text: 'c. Monitor the security of physical resources.', correct: true,  expli:'A correct question is: Monitor the security of physical resources.' },
      { text: 'd. Application of service organization control standards (SOC). ', correct: true,  expli:'A correct question is: Application of service organization control standards (SOC).' }
    ],
	img: '',  
  },
  {
    question: 'Test DíA 1 .TECHNICAL ESSENTIALS ON AWS MÓDULO 1/ What are the four main factors to consider when choosing a Region?',
    answers: [
      { text: 'a. Latency, price, service availability, and compliance', correct: true,  expli: ' correct A Latency, price, service availability, and compliance' },
      { text: 'b. Latency, high availability, taxes, and compliance', correct: false,  expli:' ' },
	    { text: 'c. Latency, taxes, speed, and compliance', correct: false,  expli:' ' },
      { text: 'd. Latency, security, high availability, and resiliency', correct: false,  expli:' ' }
    ],
	img: '',  
  },
  {
    question: 'Test DíA 1 .TECHNICAL ESSENTIALS ON AWS MÓDULO 1/ Which of the following accurately describes the relationship among Regions, Availability Zones, and data centers?',
    answers: [
      { text: 'a. Availability Zones consist of one or more  Regions. Regions are clusters of data centers.', correct: false,  expli:' ' },
      { text: 'b. Data centers are clusters of Availability Zones. Regions are clusters of Availability Zones.', correct: false,  expli:' ' },
	    { text: 'c. Regions are clusters of Availability Zones. Availability Zones consist of one or more data centers.', correct: true,  expli:' correct C Regions are clusters of Availability Zones. Availability Zones consist of one or more data centers. ' },
      { text: 'd. Data centers are clusters of Regions. Regions are clusters of Availability Zones.', correct: false,  expli:' ' }
    ],
	img: '',  
  },
  {
    question: 'Test DíA 1 .TECHNICAL ESSENTIALS ON AWS MÓDULO 1/ Which of the following is a benefit of cloud computing?',
    answers: [
      { text: 'a. Run and maintain your own data centers', correct: false,  expli:' ' },
      { text: 'b. Increase time to market', correct: false,  expli:' ' },
	    { text: 'c. Overprovision for scale', correct: false,  expli:' ' },
      { text: 'd. Go global in minutes ', correct: true,  expli:' correct D Go global in minutes ' }
    ],
	img: '',  
  },
  {
    question: 'Test DíA 1 .TECHNICAL ESSENTIALS ON AWS MÓDULO 1/ Users in a company are authenticated in their corporate network and want to use AWS without signing in again. Which is the best option along with user federation or single sign-on to grant permissions?',
    answers: [
      { text: 'a. IAM root user', correct: false,  expli:' ' },
      { text: 'b. IAM user', correct: false,  expli:' ' },
	    { text: 'c. IAM role ', correct: true,  expli:' correct C IAM role ' },
      { text: 'd. IAM group', correct: false,  expli:' ' }
    ],
	img: '',  
  },
  {
    question: 'Test DíA 2 .TECHNICAL ESSENTIALS ON AWS MÓDULO 1/ Which of the following can a route table be attached to?',
    answers: [
      { text: 'a. AWS accounts', correct: false,  expli:' ' },
      { text: 'b. Availability Zones', correct: false,  expli:' ' },
	    { text: 'c. Subnets', correct: true,  expli:' correct C Subnets ' },
      { text: 'd. Regions', correct: false,  expli:' ' }
    ],
	img: '',  
  },
  {
    question: 'Test DíA 2 .TECHNICAL ESSENTIALS ON AWS MÓDULO 1/ Which of the following is true for the default settings of a newly created security group?',
    answers: [
      { text: 'a. Allows all inbound traffic and blocks all outbound traffic', correct: false,  expli:' ' },
      { text: 'b. Blocks all inbound traffic and allows all outbound traffic', correct: true,  expli:' correct B Blocks all inbound traffic and allows all outbound traffic. ' },
	    { text: 'c. Allows all inbound and outbound traffic', correct: false,  expli:' ' },
      { text: 'd. Blocks all inbound and outbound traffic', correct: false,  expli:' ' }
    ],
	img: '',  
  },
  {
    question: 'Test DíA 3 .TECHNICAL ESSENTIALS ON AWS MÓDULO 1/ Which of the following is a typical use case for Amazon Simple Storage Service (Amazon S3)?',
    answers: [
      { text: 'a. Object storage for media hosting ', correct: true,  expli:' correct A Object storage for media hosting' },
      { text: 'b. Object storage for a boot drive', correct: false,  expli:' ' },
	    { text: 'c. Block storage for an EC2 instance', correct: false,  expli:' ' },
      { text: 'd. File storage for multiple EC2 instances', correct: false,  expli:' ' }
    ],
	img: '',  
  },
  {
    question: 'Test DíA 3 .TECHNICAL ESSENTIALS ON AWS MÓDULO 1/ Which of the following storage services is recommended if a customer needs a storage layer for a high-transaction relational database on an EC2 instance?',
    answers: [
      { text: 'a. Amazon Simple Storage Service (Amazon S3)', correct: false,  expli:' ' },
      { text: 'b. Amazon Elastic File System (Amazon EFS)', correct: false,  expli:' ' },
	    { text: 'c. Amazon Elastic Block Store (Amazon EBS)', correct: true,  expli:' correct C Amazon Elastic Block Store (Amazon EBS)' },
      { text: 'd. Amazon S3 Glacier', correct: false,  expli:' ' }
    ],
	img: '',  
  },
  {
    question: 'Test DíA 3 .TECHNICAL ESSENTIALS ON AWS MÓDULO 1/ An employee at a healthcare facility must store 7 years of patient information thatis rarely accessed. Which Amazon S3 storage tier should they use?',
    answers: [
      { text: 'a. Amazon S3 Standard', correct: false,  expli:' ' },
      { text: 'b. Amazon S3 Glacier Deep Archive ', correct: true,  expli:' correct B Amazon S3 Glacier Deep Archive ' },
	    { text: 'c. Amazon S3 Standard-Infrequent Access', correct: false,  expli:' ' },
      { text: 'd. Amazon S3 Intelligent-Tiering', correct: false,  expli:' ' }
    ],
	img: '',  
  },
  {
    question: 'Test DíA 4 .TECHNICAL ESSENTIALS ON AWS MÓDULO 1/ An AWS solutions architect needs a database for a dataset that has variations in the data. Not every piece of data shares the same attributes. Which database should the solutions architect choose?',
    answers: [
      { text: 'a. Amazon Relational Database Service (Amazon RDS)', correct: false,  expli:' ' },
      { text: 'b. Amazon Neptune', correct: false,  expli:' ' },
	    { text: 'c. Amazon DynamoDB ', correct: true,  expli:' correct C Amazon DynamoDB' },
      { text: 'd. Amazon Quantum Ledger Database (Amazon QLDB)', correct: false,  expli:' ' }
    ],
	img: '',  
  },
  {
    question: 'Test DíA 4 .TECHNICAL ESSENTIALS ON AWS MÓDULO 1/ When using Amazon Relational Database Service (Amazon RDS), which database task is the customer\'s responsibility?',
    answers: [
      { text: 'a. Optimize the database', correct: true,  expli:' correct A Optimize the database' },
      { text: 'b. Provision and manage the underlying infrastructure', correct: false,  expli:' ' },
	    { text: 'c. Install the RDBMS onto the DB instance', correct: false,  expli:' ' },
      { text: 'd. Install patches to the OS for the DB instance', correct: false,  expli:' ' }
    ],
	img: '',  
  },
  {
    question: 'Test DíA 5 .TECHNICAL ESSENTIALS ON AWS MÓDULO 1/ What are the three components of Amazon EC2 Auto Scaling?',
    answers: [
      { text: 'a. Scaling policies, security group, Amazon EC2 Auto Scaling group', correct: false,  expli:' ' },
      { text: 'b. Launch template, scaling policies, Amazon EC2 Auto Scaling group', correct: true,  expli:' correct B Launch template, scaling policies, Amazon EC2 Auto Scaling group ' },
	    { text: 'c. Security group, instance type, key pair', correct: false,  expli:' ' },
      { text: 'd. AMI ID, instance type, storage', correct: false,  expli:' ' }
    ],
	img: '',  
  },
  {
    question: 'Test DíA 5 .TECHNICAL ESSENTIALS ON AWS MÓDULO 1/ Which load balancer should be used for an application that requires a target group selection by using a rule based on website domains?',
    answers: [
      { text: 'a. Classic Load Balancer', correct: false,  expli:' ' },
      { text: 'b. Application Load Balancer ', correct: true,  expli:' correct B Application Load Balancer' },
	    { text: 'c. Network Load Balancer', correct: false,  expli:' ' },
      { text: 'd. Gateway Load Balancer', correct: false,  expli:' ' }
    ],
	img: '',  
  },
  {
    question: 'Test DíA 1 .SECURITY FUNDAMENTALS ON AWS MÓDULO 2/ Select statements that correctly describe security features of the AWS Cloud. (Select TWO.) ',
    answers: [
      { text: 'a. Customers can schedule AWS data center tours and private showings.', correct: false,  expli:' ' },
      { text: 'b. AWS is audited by external compliance bodies and independent auditors.', correct: true,  expli:' correct B AWS is audited by external compliance bodies and independent auditors.' },
	    { text: 'c. Running workloads on AWS automatically makes them compliant.', correct: false,  expli:' ' },
      { text: 'd. AWS provides compliance certificates and security reports to its customers.', correct: true,  expli:' correct D AWS provides compliance certificates and security reports to its customers.' },
      { text: 'e. Applications can only be deployed across a single Availability Zone.', correct: false,  expli:' ' },
    ],
	img: '',  
  },
  {
    question: 'Test DíA 1 .SECURITY FUNDAMENTALS ON AWS MÓDULO 2/ Which of the following statements about AWS ldentity and Access Management (IAM) is recommended asa best practice?',
    answers: [
      { text: 'a. Enforce multi-factor authentication (MFA) with software or hardware mechanisms to provide additional access control.', correct: true,  expli:' correct A Enforce multi-factor authentication (MFA) with software or hardware mechanisms to provide additional access control.' },
      { text: 'b. Use the root user credentials for any administrative tasks.', correct: false,  expli:' ' },
	    { text: 'c. Do not change the root user account password to avoid the potential of account lockout.', correct: false,  expli:' ' },
      { text: 'd. Passwords for IAM users should be short and easy to remember.', correct: false,  expli:' ' }
    ],
	img: '',  
  },
  {
    question: 'Test DíA 1 .SECURITY FUNDAMENTALS ON AWS MÓDULO 2/ Which of the following is an AWS service that can help you to filter or block web application traffic based on criteria such as IP address, malicious SQL code, or country of origin?',
    answers: [
      { text: 'a. Amazon Inspector', correct: false,  expli:' ' },
      { text: 'b. AWS Shield', correct: false,  expli:' ' },
	    { text: 'c. Network access control lists', correct: false,  expli:' ' },
      { text: 'd. AWS WAF', correct: true,  expli:' correct D AWS WAF ' }
    ],
	img: '',  
  },
  {
    question: 'Test DíA 2 .SECURITY FUNDAMENTALS ON AWS MÓDULO 2/ Which of the following is correct regarding the use and benefit of an AWS service in detecting and responding to incidents?',
    answers: [
      { text: 'a. Step Functions lets you coordinate multiple AWS services into serverless workflows so you can respond to incidents quickly.', correct: false,  expli:' ' },
      { text: 'b. Amazon CloudTrail is the service that tracks and logs user activity and API usage in your AWS account.', correct: false,  expli:' ' },
	    { text: 'c. Using CloudWatch agents, Amazon CloudWatch can be used to collect metrics in AWS and on premises.', correct: true,  expli:' correct C Using CloudWatch agents, Amazon CloudWatch can be used to collect metrics in AWS and on premises.' },
      { text: 'd. AWS Lambda is a serverless compute service that can be invoked by events.', correct: false,  expli:' ' }
    ],
	img: '',  
  },
  {
    question: 'Test Fundamentos de la nube de AWS para profesionales/ What is cloud computing?',
    answers: [
      { text: 'a. Back up files stored on desktop and mobile devices to prevent data loss.', correct: false,  expli:'• It is possible to back up files to the cloud, but this answer does not describe cloud computing as a whole. ' },
      { text: 'b. Deploy infrastructure-connected applications on-premises.', correct: false,  expli:'• Deploying applications connected to on-premises infrastructure is a use case example of a hybrid cloud deployment. Remember that cloud computing also has cloud and on-premises (or private cloud) deployment models. ' },
	    { text: 'c. Launch code without the need to manage or provision servers.', correct: false,  expli:' • AWS Lambda is an AWS service that allows you to run code without the need to manage or provision servers. This description does not describe cloud computing as a whole. AWS Lambda is explained in more detail later in the course.' },
      { text: 'd. On-demand delivery of IT resources and applications over the Internet at pay-as-you-go pricing', correct: true,  expli:' correct D The correct answer is On-demand delivery of IT resources and applications over the Internet with pay-per-use pricing' }
    ],
	img: '',  
  },
  {
    question: 'Test Fundamentos de la nube de AWS para profesionales/ How else is on-premise deployment known?',
    answers: [
      { text: 'a. Private cloud implementation.', correct: true,  expli:'correct A  The correct answer is Private cloud implementation.' },
      { text: 'b. Cloud based application.', correct: false,  expli:'• Cloud-based applications are fully implemented in the cloud and have no parts that run on-premises.' },
	    { text: 'c. Hybrid deployment.', correct: false,  expli:' • A hybrid deployment connects infrastructure and applications between cloud-based resources and existing non-cloud resources, such as on-premises resources. However, a hybrid deployment is not the same as an on-premises deployment because it involves resources located in the cloud.' },
      { text: 'd. AWS cloud.', correct: false,  expli:'• AWS Cloud offers three cloud deployment models: cloud, hybrid, and on-premises. This answer is incorrect because AWS Cloud is not just the same as an on-premises deployment.  ' }
    ],
	img: '',  
  },
  {
    question: 'Test Fundamentos de la nube de AWS para profesionales/ How does the scale of cloud computing help save costs?',
    answers: [
      { text: 'a. You do not have to invest in technological resources before using them.', correct: false,  expli:'• Not having to invest in technological resources before using them refers to Going from initial expense to variable expense. ' },
      { text: 'b. Average cloud usage by a large number of customers results in lower pay-as-you-go prices.', correct: true,  expli:'correct B The correct answer is Average cloud usage by a large number of customers results in lower pay-as-you-go prices. This answer describes how customers can take advantage of the massive economies of scale in cloud computing.' },
	    { text: 'c. Access to services on demand helps avoid excess or limited capacity.', correct: false,  expli:' • Access to services on demand to avoid excess or limited capacity refers to Without Calculating Capacity.' },
      { text: 'd. You can quickly deploy applications to clients and provide them with low latency.', correct: false,  expli:' • Rapid application deployment to clients and low latency delivery means Go Global in Minutes.' }
    ],
	img: '',  
  },
  {
    question: 'Test Fundamentos de la nube de AWS para profesionales/ Which AWS service is the best option to publish messages to Subscribers? ',
    answers: [
      { text: 'a. Amazon Simple Queuing Service (Amazon SQS).', correct: false,  expli:'Amazon Simple Queue Service (Amazon SQS) is a message queuing service. It does not use the message subscription or topic model related to Amazon SNS. ' },
      { text: 'b. Amazon EC2 Auto Scaling.', correct: false,  expli:'Amazon EC2 Auto Scaling enables you to automatically add or remove Amazon EC2 instances in response to changing application demand. ' },
	    { text: 'c. Amazon Simple Notification Service (Amazon SNS)', correct: true,  expli:' The correct answer is Amazon Simple Notification Service (Amazon SNS). Amazon SNS is a publish/subscribe service. Using Amazon SNS topics, a publisher publishes messages to subscribers.' },
      { text: 'd. Elastic Load Balancing', correct: false,  expli:' Elastic Load Balancing is the AWS service that automatically distributes incoming application traffic across multiple resources, such as Amazon EC2 instances.' }
    ],
	img: '',  
  }, 
  {
    question: 'Test Fundamentos de la nube de AWS para profesionales/ You want to use an Amazon EC2 instance for a batch processing workload. Which Amazon EC2 instance type would be best to use?',
    answers: [
      { text: 'a. General purpose.', correct: false,  expli:' General Purpose instances provide a balance between compute, memory, and networking resources. This instance family would not be the best choice for your application in this situation.' },
      { text: 'b. Memory optimized.', correct: false,  expli:' Memory-optimized instances are best suited for workloads that process large data sets in memory, such as high-performance databases.' },
	    { text: 'c. Optimized computing.', correct: true,  expli:' correct C The correct answer is Optimized computing.Compute Optimized instances are better suited for batch processing workloads than general purpose instances. The question does not specify the size of the data to be processed. Batch processing involves processing data in groups. An Optimized Compute instance is ideal for this type of workload, which would benefit from a high-performance processor.' },
      { text: 'd. Optimized for storage.', correct: false,  expli:'Storage-optimized instances are designed for workloads that require high, sequential read and write access to large data sets on local storage. ' }
    ],
	img: '',  
  },
  {
    question: 'Test Fundamentos de la nube de AWS para profesionales/ What are my contract length options for Amazon EC2 Reserved Instances? (Select TWO). ',
    answers: [
      { text: 'a. 1 year.', correct: true,  expli:' Reserved Instances require a 1-year or 3-year commitment.' },
      { text: 'b. 2 years.', correct: false,  expli:' ' },
	    { text: 'c. 3 years.', correct: true,  expli:' The 3-year option offers a greater discount.' },
      { text: 'd. 4 years.', correct: false,  expli:' ' },
      { text: 'e. 5 years.', correct: false,  expli:' ' },
    ],
	img: '',  
  },
  {
    question: 'Test Fundamentos de la nube de AWS para profesionales/ You have a workload that will last a total of 6 months and can withstand interruptions. What would be the most profitable Amazon EC2 purchase option?',
    answers: [
      { text: 'a. Reserved instance.', correct: false,  expli:' Reserved Instances require a 1-year or 3-year contract term. The workload in this situation will only run for 6 months.' },
      { text: 'b. Spot Instance.', correct: true,  expli:' correct B The correct answer is Spot Instance.' },
	    { text: 'c. Dedicated instance.', correct: false,  expli:'Dedicated instances run in a Virtual Private Cloud (VPC) on hardware dedicated to a single customer. They are more costly than the other response options, which run on shared hardware. ' },
      { text: 'd. Instance on demand.', correct: false,  expli:' On-Demand Instances are eligible to run for only 6 months and are outage-resistant. However, a Spot Instance would be the best option because it requires no minimum contract length, can withstand interruptions, and costs less than an On-Demand Instance.' }
    ],
	img: '',  
  },
  {
    question: 'Test Fundamentos de la nube de AWS para profesionales/ Which process is an example of Elastic Load Balancing?',
    answers: [
      { text: 'a. Ensuring that no single Amazon EC2 instance has to carry the entire workload on its own.', correct: true,  expli:' correct A The correct answer is to ensure that no single Amazon EC2 instance has to carry the entire workload on its own. ' },
      { text: 'b. Remove unnecessary Amazon EC2 instances when demand is low.', correct: false,  expli:' Elastic Load Balancing is the AWS service that automatically distributes incoming application traffic across multiple resources, such as Amazon EC2 instances. ' },
	    { text: 'c. Adding a second Amazon EC2 instance during a hot sale for an online store.', correct: false,  expli:' This helps ensure that no resource is used excessively.' },
      { text: 'd. Automatically adjust the number of Amazon EC2 instances to meet demand.', correct: false,  expli:' The other answers are examples of Auto Scaling.' }
    ],
	img: '',  
  },
  {
    question: 'Test Fundamentos de la nube de AWS para profesionales/ You want to deploy and manage containerized applications. What service should I use?',
    answers: [
      { text: 'a. AWS Lambda.', correct: false,  expli:' AWS Lambda is a service that allows you to run code without provisioning or managing servers.' },
      { text: 'b. Amazon Simple Notification Service (Amazon SNS).', correct: false,  expli:'Amazon Simple Notification Service (Amazon SNS) is a publish/subscribe service. Using Amazon SNS topics, a publisher publishes messages to subscribers. ' },
	    { text: 'c. Amazon Simple Queuing Service (Amazon SQS).', correct: false,  expli:' Amazon Simple Queue Service (Amazon SQS) is a service that allows you to send, store, and receive messages between software components through a queue.' },
      { text: 'd. Amazon Elastic Kubernetes Service (Amazon EKS).', correct: true,  expli:' correct D The correct answer choice is Amazon Elastic Kubernetes Service (Amazon EKS). Amazon EKS is a fully managed Kubernetes service. Kubernetes is open source software that enables you to deploy and manage containerized applications at scale.' }
    ],
	img: '',  
  },
  {
    question: 'Test Fundamentos de la nube de AWS para profesionales/ ¿Qué frase describe mejor lo que es una zona de disponibilidad?',
    answers: [
      { text: 'a. Un área geográfica que contiene recursos de AWS.', correct: false,  expli:' ' },
      { text: 'b. Un centro de datos único o un grupo de centros de datos dentro de una región.', correct: true,  expli:'The correct answer choice is A single data center or a group of data centers within a region. ' },
	    { text: 'c. Un centro de datos que utiliza un servicio de AWS para realizar operaciones específicas del servicio.', correct: false,  expli:' ' },
      { text: 'd. Un servicio que puedes utilizar para lanzar la infraestructura de AWS en tu propio centro de datos en las instalaciones con una estrategia híbrida.', correct: false,  expli:' ' }
    ],
	img: '',  
  },
  {
    question: 'Test Fundamentos de la nube de AWS para profesionales/ Which statement is TRUE regarding AWS global infrastructure?',
    answers: [
      { text: 'a. A Region consists of a single Availability Zone.', correct: false,  expli:' ' },
      { text: 'b. An Availability Zone consists of two or more Regions.', correct: false,  expli:' ' },
	    { text: 'c. A Region consists of two or more Availability Zones.', correct: true,  expli:' The correct answer is A Region consists of two or more Availability Zones.' },
      { text: 'd. An Availability Zone consists of a single Region.', correct: false,  expli:' ' }
    ],
	img: '',  
  },
  {
    question: 'Test Fundamentos de la nube de AWS para profesionales/ What factors should be considered when selecting a region? (Select TWO).',
    answers: [
      { text: 'a. Compliance with legal and data management requirements.', correct: true,  expli:' correct A Compliance with legal and data management requirements.' },
      { text: 'b. Proximity to your customers.', correct: true,  expli:' correct B Proximity to your customers. Two other factors to consider when selecting a region are pricing and the services available in a region.' },
	    { text: 'c. Uninterrupted access to technical support. ', correct: false,  expli:'The support level you choose is not determined by region. AWS Support plans are discussed later in this course. ' },
      { text: 'd. Possibility of assigning custom permissions to different users.', correct: false,  expli:' Assigning custom permissions to different users is a feature that is available in all AWS Regions.' },
      { text: 'e. Access to the AWS Command Line Interface (AWS CLI).', correct: false,  expli:' The AWS Command Line Interface (AWS CLI) is available in all AWS Regions.' },
    ],
	img: '',  
  },
  {
    question: 'Test Fundamentos de la nube de AWS para profesionales/ Which statement best describes Amazon CloudFront?',
    answers: [
      { text: 'a. A service that allows launching the infrastructure with a hybrid cloud strategy.', correct: false,  expli:' AWS Outposts is a service that allows you to run your infrastructure with a hybrid cloud strategy.' },
      { text: 'b. A serverless compute engine for containers.', correct: false,  expli:'AWS Fargate is a serverless computing engine for containers. ' },
	    { text: 'c. A service that allows messages to be sent and received between software components via a queue.', correct: false,  expli:' Amazon Simple Queue Service (Amazon SQS) is a service that allows you to send, store, and receive messages between software components through a queue.' },
      { text: 'd. A global content delivery service.', correct: true,  expli:' The correct answer is A global content delivery service. https://aws.amazon.com/cloudfront Amazon CloudFront is a content delivery service. It uses a network of edge locations to store and deliver content to clients around the world. The content is stored locally as a copy. This content may consist of video files, photos, web pages, etc.' }
    ],
	img: '',  
  },
  {
    question: 'Test Fundamentos de la nube de AWS para profesionales/ Which site uses Amazon CloudFront to store copies of content for faster delivery to users in any location?',
    answers: [
      { text: 'a. Region.', correct: false,  expli:' A region is a separate geographic location with multiple locations isolated from each other.' },
      { text: 'b. Availability zone.', correct: false,  expli:'An Availability Zone is a completely isolated part of the overall AWS infrastructure. ' },
	    { text: 'c. Perimeter location.', correct: true,  expli:' The correct answer is Perimeter location.' },
      { text: 'd. Source.', correct: false,  expli:' An origin is the server from which CloudFront gets its files. Some examples of CloudFront sources include Amazon Simple Storage Service (Amazon S3) buckets and web servers. Note: Amazon S3 is discussed later in this course.' }
    ],
	img: '',  
  },
  {
    question: 'Test Fundamentos de la nube de AWS para profesionales/ What action can you take with AWS Outposts?',
    answers: [
      { text: 'a. Automate the actions of AWS services and applications using scripts.', correct: false,  expli:' The AWS Command Line Interface (AWS CLI) is used to automate the actions of AWS applications and services using scripts.' },
      { text: 'b. Access wizards and automated workflows to perform tasks on AWS services.', correct: false,  expli:' The AWS Management Console includes wizards and workflows that you can use to complete tasks in AWS services.' },
	    { text: 'c. Develop AWS applications in supported programming languages.', correct: false,  expli:' Software Development Kits (SDKs) allow you to develop AWS applications in supported programming languages.' },
      { text: 'd. Extend AWS infrastructure and services to your on-premises data center.', correct: true,  expli:' The correct answer is Extending AWS infrastructure and services to your on-premises data center.' }
    ],
	img: '',  
  },
  {
    question: 'IMPORTANTE Test Fundamentos de la nube de AWS para profesionales/ Which statement best describes the default network access control list for an AWS account?',
    answers: [
      { text: 'a. It is stateless and denies all incoming and outgoing traffic.', correct: false,  expli:'Network access control lists (ACLs) perform stateless packet filtering. They do not remember anything and check the packets that cross the border of the subnet in each direction: incoming and outgoing. ' },
      { text: 'b. It is stateful and allows all incoming and outgoing traffic.', correct: false,  expli:' Every AWS account includes a default network ACL. When configuring the VPC, you can use your account\'s default network ACLs or create custom network ACLs.' },
	    { text: 'c. It is stateless and allows all incoming and outgoing traffic.', correct: true,  expli:' The correct answer is It is stateless and allows all incoming and outgoing traffic.' },
      { text: 'd. It is stateful and denies all incoming and outgoing traffic.', correct: false,  expli:' By default, your account\'s default network ACL allows all incoming and outgoing traffic, but you can modify it by adding your own rules. In the case of custom network ACLs, all inbound and outbound traffic is denied until rules are added to specify which traffic to allow. Also, all network ACLs have an explicit deny rule. This rule ensures that if a packet does not match any of the other rules in the list, it is denied.' }
    ],
	img: '',  
  },
  {
    question: 'Test Fundamentos de la nube de AWS para profesionales/ Which statement best describes DNS resolution?',
    answers: [
      { text: 'a. Launch of resources in a virtual network that you define.', correct: false,  expli:' For example, if you want to visit the OneCompany website, enter the domain name on your computer and this request will be sent to a DNS server. ' },
      { text: 'b. Storing local copies of content at edge locations around the world.', correct: false,  expli:' Next, the DNS server will request the web server for the IP address that corresponds to the UnaEmpresa website. ' },
	    { text: 'c. Connecting a VPC to the Internet.', correct: false,  expli:'The web server will respond by providing the IP address of the OneCompany website, 192.0.2.0. ' },
      { text: 'd. Translation of a domain name into an IP address.', correct: true,  expli:' The correct answer is Translation of a domain name into an IP address.' }
    ],
	img: '',  
  },
  {
    question: 'Test Fundamentos de la nube de AWS para profesionales/ Your company has an application that uses Amazon EC2 instances to launch the customer-facing website and Amazon RDS database instances to store customers personal information. How should the developer configure the VPC according to best practices',
    answers: [
      { text: 'a. You must place your Amazon EC2 instances in a private subnet and your Amazon RDS DB instances in a public subnet.', correct: false,  expli:' A subnet is a section of a VPC into which you can group resources based on security or operational needs. Subnets can be public or private.' },
      { text: 'b. You must place your Amazon EC2 instances in a public subnet and your Amazon RDS DB instances in a private subnet.', correct: true,  expli:' The correct answer is you should put your Amazon EC2 instances in a public subnet and your Amazon RDS DB instances in a private subnet.' },
	    { text: 'c. You must place your Amazon EC2 instances and Amazon RDS DB instances in a public subnet.', correct: false,  expli:' Public subnets contain resources that the public should have access to, such as an online store website.' },
      { text: 'd. You must place your Amazon EC2 instances and Amazon RDS DB instances in a private subnet.', correct: false,  expli:' Private subnets contain resources that should only be accessed through the private network, such as a database that contains customers personal information and order histories.' }
    ],
	img: '',  
  },
  {
    question: 'Test Fundamentos de la nube de AWS para profesionales/ What component can be used to establish a specific private connection between your company\'s data center and AWS?',
    answers: [
      { text: 'a. private subnet.', correct: false,  expli:' A private subnet is a section of a VPC into which you can group resources that should be accessed only through your private network. Although it is private, it is not used to establish a connection between a data center and AWS.' },
      { text: 'b. dns.', correct: false,  expli:' DNS stands for Domain Name System, which is a directory used to match domain names to IP addresses.' },
	    { text: 'c. AWS Direct Connect.', correct: true,  expli:' The correct answer is AWS Direct Connect.' },
      { text: 'd. Virtual private gateway.', correct: false,  expli:' A virtual private gateway allows you to create a VPN connection between your VPC and a private network, such as your company\'s data center. Although this connection is private and encrypted, it travels over the public Internet, not through a specific connection.' }
    ],
	img: '',  
  },
  {
    question: 'Test Fundamentos de la nube de AWS para profesionales/ Which statement best describes security groups?',
    answers: [
      { text: 'a. They are stateful and deny all incoming traffic by default.', correct: true,  expli:'The correct answer is they are stateful and deny all incoming traffic by default. ' },
      { text: 'b. They are stateful and allow all incoming traffic by default.', correct: false,  expli:' Security groups have state. ' },
	    { text: 'c. They are stateless and deny all incoming traffic by default.', correct: false,  expli:' This means that they use previous patterns and traffic flows when evaluating new requests for an instance.' },
      { text: 'd. They are stateless and allow all incoming traffic by default.', correct: false,  expli:'By default, security groups deny all incoming traffic, but you can add custom rules to suit your security and operational needs. ' }
    ],
	img: '',  
  },
  {
    question: 'Test Fundamentos de la nube de AWS para profesionales/ What component is used to connect a VPC to the Internet?',
    answers: [
      { text: 'a. public subnet.', correct: false,  expli:'A public subnet is a section of a VPC that contains publicly facing resources. ' },
      { text: 'b. Perimeter location.', correct: false,  expli:' An edge location is a site that Amazon CloudFront uses to store cached copies of your content for faster delivery to clients.' },
	    { text: 'c. Security group.', correct: false,  expli:'A security group is a virtual firewall that controls traffic in and out of an Amazon EC2 instance. ' },
      { text: 'd. Internet gateway.', correct: true,  expli:' The correct answer is Internet gateway.' }
    ],
	img: '',  
  },
  {
    question: 'Test Fundamentos de la nube de AWS para profesionales/ What service is used to manage the DNS records for domain names?',
    answers: [
      { text: 'a. Amazon Virtual Private Cloud.', correct: false,  expli:' Amazon Virtual Private Cloud (Amazon VPC) is a service that allows you to provision an isolated section of the AWS cloud. In this isolated section, you can launch resources in a virtual network that you define.' },
      { text: 'b. AWS Direct Connect.', correct: false,  expli:'AWS Direct Connect is a service that allows you to establish a specific private connection between your data center and the VPC. ' },
	    { text: 'c. Amazon Cloud Front.', correct: false,  expli:' Amazon CloudFront is a content delivery service. It uses a network of edge locations to cache content and deliver it to clients around the world.' },
      { text: 'd. Amazon Route 53.', correct: true,  expli:' The correct answer is Amazon Route 53.Amazon Route 53 is a DNS web service. It offers developers and businesses a reliable way to direct end users to Internet applications that are hosted on AWS. Another feature of Route 53 is the ability to manage DNS records for domain names. You can transfer DNS records of existing domain names managed by other domain registrars. You can also register new domain names directly with Route 53.' } 
    ],
	img: '',  
  },
  {
    question: 'Test Fundamentos de la nube de AWS para profesionales/ You want to store data that is accessed infrequently, but must be immediately available when needed. What kind of Amazon S3 storage should I use?',
    answers: [
      { text: 'a. S3 Intelligent Tiering.', correct: false,  expli:' The S3 Standard - Infrequent Access storage class is ideal for data that is accessed infrequently, but requires high availability when needed. Both S3 Standard and S3 Standard - Infrequent Access store data in a minimum of three Availability Zones. S3 Standard - Infrequent Access provides the same level of availability as S3 Standard, but at a lower storage price.' },
      { text: 'b. S3 Glacier Deep Archive.', correct: false,  expli:' In the S3 Intelligent-Tiering storage class, Amazon S3 monitors the access patterns of objects. If you haven\'t accessed an object for 30 consecutive days, Amazon S3 automatically moves it to the Infrequent Access tier, Standard - S3 Infrequent Access. If you access an object in the infrequent access tier, Amazon S3 automatically moves it to the frequent access tier, S3 Standard.' },
	    { text: 'c. S3 Standard-Infrequent Access.', correct: true,  expli:' The correct answer is Standard - S3 Infrequent Access.' },
      { text: 'd. S3 Glacier.', correct: false,  expli:' S3 Glacier and S3 Glacier Deep Archive are low-priced storage classes that are ideal for archiving data. They would not be the best option for this situation because high availability is required. You can retrieve objects stored in the S3 Glacier storage class in a matter of minutes to a few hours. By comparison, you can retrieve objects stored in the S3 Glacier Deep Archive storage class within 12 hours.' }
    ],
	img: '',  
  },
  {
    question: 'Test Fundamentos de la nube de AWS para profesionales/ In what situations should you use Amazon Relational Database Service (Amazon RDS)? (Select TWO).',
    answers: [
      { text: 'a. Using a serverless database.', correct: false,  expli:' The other three answers are scenarios in which you should use Amazon DynamoDB.' },
      { text: 'b. Using SQL to organize data.', correct: true,  expli:' correct B one correct answer is: Use SQL to organize data ' },
	    { text: 'c. Storing data in a key value database.', correct: false,  expli:' ' },
      { text: 'd. Expansion of up to 10 billion requests per day.', correct: false,  expli:' ' },
      { text: 'e. Data storage in an Amazon Aurora database.', correct: true,  expli:' correct E one correct answer is Storing data in an Amazon Aurora database' },
    ],
	img: '',  
  },
  {
    question: 'Test Fundamentos de la nube de AWS para profesionales/ Which Amazon S3 storage classes are optimized for archive data? (Select TWO).',
    answers: [
      { text: 'a. S3 Standard.', correct: false,  expli:' S3 Standard is an ideal storage class for frequently accessed data, not archived data.' },
      { text: 'b. S3 Glacier.', correct: true,  expli:' S3 Glacier.Objects stored in the S3 Glacier storage class can be recovered in a matter of minutes to a few hours.' },
	    { text: 'c. S3 Intelligent Tiering.', correct: false,  expli: 'S3 Intelligent-Tiering monitors the access patterns of objects and automatically moves them between the S3 Standard and S3 Standard-Infrequent Access storage classes. It is not designed for archival data.' },
      { text: 'd. S3 Standard-Infrequent Access.', correct: false,  expli:' S3 Standard-Infrequent Access is ideal for data that is accessed infrequently, but requires high availability when needed.' },
      { text: 'e. S3 Glacier Deep Archive. ', correct: true,  expli:' S3 Glacier Deep Archive. In contrast, objects stored in the S3 Glacier Deep Archive storage class can be retrieved within 12 hours.' },
    ],
	img: '',  
  },
  {
    question: 'Test Fundamentos de la nube de AWS para profesionales/ Which statement or statements are TRUE about Amazon EBS volumes and Amazon EFS file systems?',
    answers: [
      { text: 'a. EBS volumes store data in a single Availability Zone. Amazon EFS file systems store data in multiple Availability Zones.', correct: true,  expli:'The correct answer is: EBS volumes store data in a single Availability Zone. Amazon EFS file systems store data in multiple Availability Zones. An EBS volume must be located in the same Availability Zone as the Amazon EC2 instance to which it is attached. ' },
      { text: 'b. EBS volumes store data in multiple Availability Zones. Amazon EFS file systems store data in a single Availability Zone', correct: false,  expli:' ' },
	    { text: 'c. EBS volumes and Amazon EFS file systems store data in a single Availability Zone.', correct: false,  expli:' Data in an Amazon EFS file system can be accessed simultaneously from all Availability Zones in the region in which the file system is located.' },
      { text: 'd. EBS volumes and Amazon EFS file systems store data in multiple Availability Zones.', correct: false,  expli:' ' }
    ],
	img: '',  
  },
  {
    question: 'Test Fundamentos de la nube de AWS para profesionales/ You want to store data in an object storage service. Which AWS service is best for this type of storage?',
    answers: [
      { text: 'a. Amazon Managed Blockchain.', correct: false,  expli:' Amazon Managed Blockchain is a service that you can use to build and manage blockchain networks using open source frameworks. Blockchain is a distributed ledger system that allows multiple parties to execute transactions and share data without a central authority.' },
      { text: 'b. Amazon Elastic File System (Amazon EFS).', correct: false,  expli:' Amazon Elastic File System (Amazon EFS) is a scalable file system for use with AWS cloud services and on-premises resources. It does not store data like object storage.' },
	    { text: 'c. Amazon Elastic Block Store (Amazon EBS).', correct: false,  expli:' Amazon Elastic Block Store (Amazon EBS) is a service that provides block-level storage volumes that you can use with Amazon EC2 instances.' },
      { text: 'd. Amazon Simple Storage Service (Amazon S3).', correct: true,  expli:' The correct answer is Amazon Simple Storage Service (Amazon S3).' }
    ],
	img: '',  
  },
  {
    question: 'Test Fundamentos de la nube de AWS para profesionales/ Which statement best describes Amazon DynamoDB?',
    answers: [
      { text: 'a. A service that allows you to use relational databases in the AWS cloud.', correct: false,  expli:'One service that enables you to run relational databases in the AWS Cloud is the Amazon Relational Database Service (Amazon RDS) description. ' },
      { text: 'b. A serverless key-value database service.', correct: true,  expli:' The correct answer is A serverless key-value database service.Amazon DynamoDB is a key-value database service. It\'s serverless, which means you don\'t have to provision, patch, or manage servers.' },
	    { text: 'c. A service that can be used to migrate relational databases, non-relational databases, and other types of data stores.', correct: false,  expli:'One service that you can use to migrate relational databases, nonrelational databases, and other types of data stores is the AWS Database Migration Service (AWS DMS) description. ' },
      { text: 'd. An enterprise-class relational database.', correct: false,  expli:' An enterprise-class relational database is the description of Amazon Aurora.' }
    ],
	img: '',  
  },
  {
    question: 'Test Fundamentos de la nube de AWS para profesionales/ What service is used to query and analyze data in a data warehouse?',
    answers: [
      { text: 'a. Amazon Redshift.', correct: true,  expli:' The correct answer is Amazon Redshift. Amazon Redshift is a data warehousing service that can be used for big data analytics. Use Amazon Redshift to collect data from many sources and understand data trends and relationships.' },
      { text: 'b. Amazon Neptune.', correct: false,  expli:' Amazon Neptune is a graph database service. You can use Amazon Neptune to build and run applications that work with highly connected data sets, such as recommendation engines, fraud detection, and knowledge graphs.' },
	    { text: 'c. Amazon DocumentDB.', correct: false,  expli:'Amazon DocumentDB is a document database service that supports MongoDB workloads. ' },
      { text: 'd. Amazon ElastiCache.', correct: false,  expli:' Amazon ElastiCache is a service that adds storage layers to your databases to help improve read times for common requests.' }
    ],
	img: '',  
  },
  {
    question: 'Test Fundamentos de la nube de AWS para profesionales/ What tasks are the clients responsibility? (Select TWO).',
    answers: [
      { text: 'a. Maintain network infrastructure.', correct: false,  expli:' The other three answers are tasks that are the responsibility of AWS.' },
      { text: 'b. Apply software patches to Amazon EC2 instances.', correct: true,  expli:' correct B Apply Software Patches to Amazon EC2 Instances' },
	    { text: 'c. Implement physical security controls in data centers.', correct: false,  expli:' ' },
      { text: 'd. Configure permissions for Amazon S3 objects.', correct: true,  expli:' correct D Set Permissions for Amazon S3 Objects' },
      { text: 'e. Maintain the servers that launch Amazon EC2 instances.', correct: false,  expli:' ' },
    ],
	img: '',  
  },
  {
    question: 'Test Fundamentos de la nube de AWS para profesionales/ You are configuring Service Control Policies (SCPs) in AWS Organizations. What identities and resources can SCP apply to? (Select TWO).',
    answers: [
      { text: 'a. IAM users.', correct: false,  expli:' In AWS Organizations, you can apply service control policies (SCPs) on the organization root account, an individual member account, or an organizational unit.' },
      { text: 'b. IAM groups.', correct: false,  expli:' An SCP affects all IAM users, groups, and roles in an account, including the AWS account root user.' },
	    { text: 'c. An individual member account.', correct: true,  expli:' correct C An individual member account.' },
      { text: 'd. IAM roles.', correct: false,  expli:' You can apply IAM policies to IAM users, groups, or roles. You can\'t apply an IAM policy to the AWS account root user.' },
      { text: 'e. An organizational unit (OU).', correct: true,  expli:' correct D An organizational unit (OU).' },
    ],
	img: '',  
  },
  {
    question: 'Test Fundamentos de la nube de AWS para profesionales/ What tasks can you complete in AWS Artifact? (Select TWO).',
    answers: [
      { text: 'a. Access AWS compliance reports on demand.', correct: true,  expli:' Access AWS compliance reports on demand.' },
      { text: 'b. Consolidate and manage multiple AWS accounts in one central location.', correct: false,  expli:' Consolidate and manage multiple AWS accounts in one central location – This task can be completed in AWS Organizations.' },
	    { text: 'c. Create users to allow people and applications to interact with AWS services and resources.', correct: false,  expli:' Create users to allow people and applications to interact with AWS services and resources – This task can be completed in AWS Identity and Access Management (IAM).' },
      { text: 'd. Set permissions for accounts by configuring Service Control Policies (SCPs).', correct: false,  expli:' Set permissions for accounts by configuring Service Control Policies (SCPs): This task can be completed in AWS Organizations.' },
      { text: 'e. Review, accept, and manage agreements with AWS.', correct: true,  expli:'Review, accept, and manage agreements with AWS. ' },
    ],
	img: '',  
  },
  {
    question: 'Test Fundamentos de la nube de AWS para profesionales/ Which statement best describes an IAM policy?',
    answers: [
      { text: 'a. An authentication process that provides an additional layer of protection for your AWS account.', correct: false,  expli:' Multi-Factor Authentication (MFA) is an authentication process that provides an additional layer of protection for your AWS account.' },
      { text: 'b. A document that grants or denies permissions to AWS services and resources.', correct: true,  expli:' The correct answer is: A document that grants or denies permissions to AWS services and resources. IAM policies provide flexibility to customize user access levels to resources. For example, you can allow users to access all Amazon S3 buckets in your AWS account, or just a specific bucket.' },
	    { text: 'c. An identity that can be assumed to gain temporary access to permissions.', correct: false,  expli:' An IAM role is an identity that can be assumed to gain temporary access to permissions.' },
      { text: 'd. The identity that is established when an AWS account is first created.', correct: false,  expli:' The root user identity is the identity that is established when an AWS account is first created.' }
    ],
	img: '',  
  },
  {
    question: 'Test Fundamentos de la nube de AWS para profesionales/ An employee needs temporary access to create multiple Amazon S3 buckets. Which option would be best for this task?',
    answers: [
      { text: 'a. AWS account root user.', correct: false,  expli:' The AWS account root user is set the first time an AWS account is created. As a best practice, do not use the root user for everyday tasks.' },
      { text: 'b. IAM group.', correct: false,  expli:' Although IAM policies can be attached to an IAM group, this would not be the best option for this scenario because the employee should only be granted temporary permissions.' },
	    { text: 'c. IAM role.', correct: true,  expli:' The correct answer is: IAM role. An IAM role is an identity that can be assumed to gain temporary access to permissions. When someone adopts an IAM role, they relinquish all the permissions they had in a previous role and adopt the permissions of the new role. IAM roles are ideal for situations where access to services or resources needs to be granted temporarily rather than long-term.' },
      { text: 'd. Service Control Policy (SCP).', correct: false,  expli:' Service Control Policies (SCPs) allow you to centrally control the permissions of your organization\'s accounts. An SCP is not the best option for granting temporary leave to an individual employee.' }
    ],
	img: '',  
  },
  {
    question: 'Test Fundamentos de la nube de AWS para profesionales/ Which statement best describes the principle of least privilege?',
    answers: [
      { text: 'a. Add an IAM user to at least one IAM group.', correct: false,  expli:' ' },
      { text: 'b. Check the permissions of a package in an access control list.', correct: false,  expli:' ' },
	    { text: 'c. Grant only the permissions necessary to perform specific tasks.', correct: true,  expli:' The correct answer is: Grant only the permissions necessary to perform specific work tasks. By granting permissions following the principle of least privilege, you prevent users or roles from having more permissions than necessary to perform specific work tasks. For example, cafeteria cashiers must have access to the cash register system. As a best practice, grant IAM users and roles a minimal set of permissions, and then grant additional permissions as needed.' },
      { text: 'd. Perform a denial of service attack that comes from at least one device.', correct: false,  expli:' ' }
    ],
	img: '',  
  },
  {
    question: 'Test Fundamentos de la nube de AWS para profesionales/ Which service helps protect applications against Distributed Denial of Service (DDoS) attacks?',
    answers: [
      { text: 'a. Amazon Guard Duty.', correct: false,  expli:' Amazon GuardDuty is a service that provides intelligent threat detection for AWS infrastructure and resources. Identifies threats by continuously monitoring network activity and account behavior in your AWS environment.' },
      { text: 'b. Amazon Inspector.', correct: false,  expli:'Amazon Inspector checks applications for security vulnerabilities and deviations from security best practices, such as open access to Amazon EC2 instances and installations of vulnerable software versions. ' },
	    { text: 'c. AWS Artifact.', correct: false,  expli:'AWS Artifact is a service that provides on-demand access to AWS security and compliance reports and certain online agreements. ' },
      { text: 'd. AWS Shield.', correct: true,  expli:' The correct answer is: AWS Shield. As network traffic reaches applications, AWS Shield uses various analysis techniques to detect potential DDoS attacks in real time and automatically mitigate them.' }
    ],
	img: '',  
  },
  {
    question: 'Test Fundamentos de la nube de AWS para profesionales/ What can you do in AWS Key Management Service (AWS KMS)?',
    answers: [
      { text: 'a. Configure multi-factor authentication (MFA).', correct: false,  expli:' You can configure multi-factor authentication (MFA) in AWS Identity and Access Management (IAM).' },
      { text: 'b. Update the AWS account root user password.', correct: false,  expli:' You can update the password of the AWS account root user in the AWS Management Console.' },
	    { text: 'c. Create cryptographic keys.', correct: true,  expli:'The correct answer is: Create cryptographic keys. AWS Key Management Service (AWS KMS) allows you to perform encryption operations by using cryptographic keys. A cryptographic key is a random string of digits used to lock (encrypt) and unlock (decrypt) data. You can use AWS KMS to create, manage, and use cryptographic keys. You can also control the use of keys in a wide range of services and applications. ' },
      { text: 'd. Assign permissions to users and groups.', correct: false,  expli:' You can assign permissions to users and groups in AWS Identity and Access Management (IAM).' }
    ],
	img: '',  
  },
  {
    question: 'Test Fundamentos de la nube de AWS para profesionales/ What can you do with AWS CloudTrail? (Select TWO).',
    answers: [
      { text: 'a. Monitor AWS infrastructure and resources in real time.', correct: false,  expli:' ' },
      { text: 'b. Track user activities and API requests across the infrastructure.', correct: true,  expli:' correct B Track user activities and API requests across AWS infrastructure' },
	    { text: 'c. View metrics and charts to monitor resource performance.', correct: false,  expli:' ' },
      { text: 'd. Filter logs to help with operational analysis and troubleshooting.', correct: true,  expli:' correct D Filter logs to help with operational analysis and troubleshooting' },
      { text: 'e. Configure automatic actions and alerts in response to metrics.', correct: false,  expli:' The other answers are tasks that you can perform in Amazon CloudWatch.' },
    ],
	img: '',  
  },
  {
    question: 'Test Fundamentos de la nube de AWS para profesionales/ What can you do with Amazon CloudWatch? (Select TWO).',
    answers: [
      { text: 'a. Monitor the use and performance of your resources.', correct: true,  expli:' correct A Monitor the usage and performance of your resources' },
      { text: 'b. Receive real-time guidance to improve your AWS environment.', correct: false,  expli:' AWS Trusted Advisor can receive real-time recommendations to improve your AWS environment.' },
	    { text: 'c. Compare your infrastructure against AWS best practices in five categories.', correct: false,  expli:' AWS Trusted Advisor can compare your infrastructure against AWS best practices in five categories.' },
      { text: 'd. Access metrics from a single dashboard.', correct: true,  expli:' correct D Access metrics from a single dashboard' },
      { text: 'e. Automatically detect unusual account activity.', correct: false,  expli:' AWS CloudTrail can automatically detect unusual account activity.' },
    ],
	img: '',  
  },
  {
    question: 'Test Fundamentos de la nube de AWS para profesionales/ Which service allows you to review the security of Amazon S3 buckets by checking open access permissions?',
    answers: [
      { text: 'a. Amazon CloudWatch.', correct: false,  expli:' Amazon CloudWatch is a web service that allows you to monitor and manage various metrics of the resources running your applications.' },
      { text: 'b. AWS CloudTrail.', correct: false,  expli:' AWS CloudTrail is a web service that allows you to review details of user activities and API calls that have occurred in your AWS environment.' },
	    { text: 'c. AWS Trusted Advisor.', correct: true,  expli:' The correct answer is AWS Trusted Advisor. AWS Trusted Advisor is a web service that inspects your AWS environment and provides real-time recommendations, based on AWS best practices. The inspection includes security checks, such as Amazon S3 buckets with open access permissions.' },
      { text: 'd. Amazon Guard Duty.', correct: false,  expli:'Amazon GuardDuty is a service that provides intelligent threat detection for your AWS environment and resources. Identify threats by continuously monitoring network activity and account behavior in your AWS environment. ' }
    ],
	img: '',  
  },
  {
    question: 'Test Fundamentos de la nube de AWS para profesionales/ What categories are included in the AWS Trusted Advisor dashboard? (Select TWO).',
    answers: [
      { text: 'a. reliability.', correct: false,  expli:' ' },
      { text: 'b. Performance.', correct: true,  expli:' correct B Performance.' },
	    { text: 'c. scalability.', correct: false,  expli:' ' },
      { text: 'd. Elasticity.', correct: false,  expli:' ' },
      { text: 'e. Error tolerance.', correct: true,  expli:' correct E Error tolerance. AWS Trusted Advisor continually inspects your AWS environment and provides best practice recommendations in five categories: Optimizing Price, Performance, Security, Fault Tolerance, and Service Limits.' },
    ],
	img: '',  
  },
  {
    question: 'Test Fundamentos de la nube de AWS para profesionales/ The AWS Free Tier includes offers available to new AWS customers for a set period of time from the date of signing up with AWS. How long does this period last?',
    answers: [
      { text: 'a. 3 months.', correct: false,  expli:' ' },
      { text: 'b. 6 months.', correct: false,  expli:' ' },
	    { text: 'c. 9 months.', correct: false,  expli:' ' },
      { text: 'd. 12 months.', correct: true,  expli:' The correct answer is 12 months. The AWS Free Tier consists of three types of offers that allow customers to use AWS services at no cost: Free Forever, 12 Months of Free Use, and Trials. For 12 months after you first sign up for an account with AWS, you can take advantage of offers in the 12 months free usage category. Examples of offers in this category include specific Amazon S3 Standard storage amounts, Amazon EC2 compute time monthly hour thresholds, and Amazon CloudFront outbound data transfer amounts.' }
    ],
	img: '',  
  },
  {
    question: 'Test Fundamentos de la nube de AWS para profesionales/ Which Support plan includes all AWS Trusted Advisor checks at the lowest cost?',
    answers: [
      { text: 'a. BASIC.', correct: false,  expli:' ' },
      { text: 'b. Developer. ', correct: false,  expli:' ' },
	    { text: 'c. Business.', correct: true,  expli:'The correct answer is Business. Only Business Support and Enterprise Support plans include all AWS Trusted Advisor checks. Of these two Support plans, the Business Support plan is cheaper. ' },
      { text: 'd. Enterprise.', correct: false,  expli:' Enterprise Support is more expensive than Business Support' }
    ],
	img: '',  
  },
  {
    question: 'Test Fundamentos de la nube de AWS para profesionales/ What can be done with consolidated billing?',
    answers: [
      { text: 'a. Review how much your projected usage of AWS will cost at the end of the month.', correct: false,  expli:' Review how much your projected AWS usage will incur at the end of the month – You can do this in AWS Budgets.' },
      { text: 'b. Create a cost estimate for your use cases on AWS.', correct: false,  expli:' Create a price estimate for your use cases on AWS – You can do this on the AWS Pricing Calculator.' },
	    { text: 'c. Combine usage across all accounts to receive volume price discounts.', correct: true,  expli:' The correct answer is: Combine the use of all accounts to receive volume price discounts.' },
      { text: 'd. View and manage AWS costs and usage over time.', correct: false,  expli:' View and manage AWS prices and usage over time – You can do this in AWS Cost Explorer.' }
    ],
	img: '',  
  },
  {
    question: 'Test Fundamentos de la nube de AWS para profesionales/ What pricing tool is used to visualize, understand, and manage AWS costs and usage over time?',
    answers: [
      { text: 'a. AWS Pricing Calculator.', correct: false,  expli:' The AWS Pricing Calculator allows you to create a cost estimate for your use cases on AWS.' },
      { text: 'b. AWS Budgets.', correct: false,  expli:' AWS Budgets allows you to create budgets to plan for service usage, service costs, and instance reservations. In AWS Budgets, you can also set custom alerts when your usage exceeds (or is expected to exceed) the budgeted amount.' },
	    { text: 'c. AWS Cost Explorer.', correct: true,  expli:' The correct answer is AWS Cost Explorer. AWS Cost Explorer includes a default report of costs and usage for the top five accumulated cost AWS services. You can apply custom filters and groups to analyze the data. For example, you can see resource usage per hour.' },
      { text: 'd. AWS Free Tier.', correct: false,  expli:' The AWS Free Tier is a program that consists of three types of offers that allow customers to use AWS services at no cost: Always Free, 12 Months Free, and Trials.' }
    ],
	img: '',  
  },
  {
    question: 'Test Fundamentos de la nube de AWS para profesionales/ Which pricing tool allows me to receive alerts when the use of the service exceeds the established threshold?',
    answers: [
      { text: 'a. The billing dashboard in the AWS Management Console.', correct: false,  expli:' In the billing dashboard of the AWS Management Console, you can view details of your AWS bill, such as the cost of services by Region, your monthly spend to date, and more. However, you cannot set up alerts from the billing panel.' },
      { text: 'b. AWS Budgets.', correct: true,  expli:' The correct answer is: AWS Budgets. In AWS Budgets, you can set up custom alerts to let you know when your service usage exceeds (or is expected to exceed) your budgeted amount. Your budget can be based on costs or usage. For example, you can set up an alert that will notify you when you have incurred costs of $100.00 on Amazon EC2 or 500,000 requests on AWS Lambda.' },
	    { text: 'c. The AWS Free Tier.', correct: false,  expli:' The AWS Free Tier is a program that consists of three types of offers that allow customers to use AWS services at no cost: Always Free, 12 Months Free, and Trials.' },
      { text: 'd. AWS Cost Explorer.', correct: false,  expli:' AWS Cost Explorer is a tool for viewing, understanding, and managing AWS costs and usage over time.' }
    ],
	img: '',  
  },
  {
    question: 'Test Fundamentos de la nube de AWS para profesionales/ Your company wants to receive support from an AWS Technical Account Manager (TAM). Which support plan should you choose?',
    answers: [
      { text: 'a. Developer.', correct: false,  expli:' ' },
      { text: 'b. Enterprise.', correct: true,  expli:' The correct answer is: Enterprise. Technical Account Manager (TAM) is only available to AWS customers with an Enterprise Support plan. A TAM provides guidance, architecture reviews, and ongoing communication to your business as applications are planned, deployed, and optimized.' },
	    { text: 'c. BASIC.', correct: false,  expli:' ' },
      { text: 'd. Business.', correct: false,  expli:' ' }
    ],
	img: '',  
  },
  {
    question: 'Test Fundamentos de la nube de AWS para profesionales/ What service or resource is used to find third-party software used on AWS?',
    answers: [
      { text: 'a. AWS Marketplace.', correct: true,  expli:' The correct answer is: AWS Marketplace. AWS Marketplace is a digital catalog that includes thousands of software listings from independent software vendors. You can use AWS Marketplace to find, try, and buy software that runs on AWS.' },
      { text: 'b. AWS Free Tier.', correct: false,  expli:' The AWS Free Tier consists of offers that allow customers to use AWS services without incurring charges. These offers are related to AWS services, not third-party software that may be used on AWS.' },
	    { text: 'c. AWS Support.', correct: false,  expli:' AWS Support is a resource that can answer questions about best practices, help troubleshoot problems, help identify ways to optimize the use of AWS services, and more.' },
      { text: 'd. The billing dashboard in the AWS Management Console.', correct: false,  expli:' You can use the billing dashboard in the AWS Management Console to view details such as service costs by region, the top services used by the account, and projected billing costs. From the billing dashboard, you can also access other AWS billing tools, such as AWS Cost Explorer, AWS Budgets, and AWS Budgets reports.' }
    ],
	img: '',  
  },
  {
    question: 'Test Fundamentos de la nube de AWS para profesionales/ What perspective of the AWS Cloud Adoption Framework helps to design, deploy, and optimize AWS infrastructure based on business goals and perspectives?',
    answers: [
      { text: 'a. Business perspective.', correct: false,  expli:' The business perspective helps you move from a model that separates business and IT strategies to a business model that integrates IT strategy.' },
      { text: 'b. Platform perspective.', correct: true,  expli:' The correct answer is Platform perspective. The AWS Cloud Adoption Framework platform perspective also includes principles for implementing new solutions and migrating workloads from on-premises to the cloud.' },
	    { text: 'c. Operations perspective.', correct: false,  expli:' The operations perspective focuses on operating and recovering IT workloads to meet the requirements of your business investors.' },
      { text: 'd. Staff perspective.', correct: false,  expli:'The People Perspective helps Human Resources (HR) employees prepare their teams for cloud adoption by updating organizational processes and staff skills to include cloud-based competencies. ' }
    ],
	img: '',  
  },
  {
    question: 'Test Fundamentos de la nube de AWS para profesionales/ What migration strategy involves switching to a different product?',
    answers: [
      { text: 'a. refactor.', correct: false,  expli:' Refactoring involves changing the way an app is designed and developed, typically by using cloud-native features.' },
      { text: 'b. Withdraw. ', correct: false,  expli:' Retire means removing an app that is no longer used or can be disabled.' },
	    { text: 'c. Redefine platform.', correct: false,  expli:' Re-platforming involves selectively optimizing aspects of an application for cloud benefits without changing the application\'s core architecture. It is also known as “lift, tinker and shift”.' },
      { text: 'd. Repurchase. ', correct: true,  expli:' The correct answer is Buy again. Repurchasing means replacing an existing application with a cloud-based version, such as software found on AWS Marketplace.' }
    ],
	img: '',  
  },
  {
    question: 'Test Fundamentos de la nube de AWS para profesionales/ How much storage does Snowball Edge Storage Optimized have?',
    answers: [
      { text: 'a. 40TB.', correct: false,  expli:' ' },
      { text: 'b. 60TB.', correct: false,  expli:' ' },
	    { text: 'c. 80TB.', correct: true,  expli:' The correct answer is 80TB. Snowball Edge Storage Optimized is an appliance that allows you to transfer large amounts of data both in and out of AWS. Provides 80TB of usable HDD storage.' },
      { text: 'd. 100TB.', correct: false,  expli:' ' }
    ],
	img: '',  
  },
  {
    question: 'Test Fundamentos de la nube de AWS para profesionales/ What service allows you to quickly build, train, and deploy machine learning models?',
    answers: [
      { text: 'a. Amazon Textract.', correct: false,  expli:' Amazon Textract is a machine learning service that automatically extracts text and data from scanned documents.' },
      { text: 'b. Amazon Lex.', correct: false,  expli:' Amazon Lex is a service that allows you to create conversational interfaces using voice and text.' },
	    { text: 'c. AWS Dee Pracer.', correct: false,  expli:' AWS DeePracer is a 1/18 scale autonomous racing car that you can use to test reinforcement learning models.' },
      { text: 'd. Amazon SageMaker.', correct: true,  expli:' The correct answer is Amazon SageMaker. With Amazon SageMaker, you can quickly and easily get started on machine learning projects. You don\'t have to go through the traditional process of manually putting together separate tools and workflows.' }
    ],
	img: '',  
  },
  {
    question: 'Test Fundamentos de la nube de AWS para profesionales/ What perspective from the AWS Cloud Adoption Framework helps structure permission selection and implementation?',
    answers: [
      { text: 'a. Direction perspective. ', correct: false,  expli:' The management perspective helps identify and implement best practices for IT management and support business processes with technology.' },
      { text: 'b. Security perspective.', correct: true,  expli:'The correct answer is security perspective. The AWS Cloud Adoption Framework security perspective also helps you identify areas of non-compliance and plan for ongoing security initiatives. ' },
	    { text: 'c. Operations perspective.', correct: false,  expli:' The operations perspective focuses on operating and recovering IT workloads to meet the requirements of your business investors.' },
      { text: 'd. Business perspective.', correct: false,  expli:'The business perspective helps move from a model that separates business and IT strategies to a business model that integrates IT strategy. ' }
    ],
	img: '',  
  },
  {
    question: 'Test Fundamentos de la nube de AWS para profesionales/ What strategies are included in the six application migration strategies? (Select TWO).',
    answers: [
      { text: 'a. revisit.', correct: false,  expli:' ' },
      { text: 'b. To hold back.', correct: true,  expli:' correct B To hold back' },
	    { text: 'c. To remember.', correct: false,  expli:' ' },
      { text: 'd. Reconvert.', correct: false,  expli:' ' },
      { text: 'e. Re-host. ', correct: true,  expli:' correct E re-host Application migration strategies are rehost, replatform, refactor/rearchitecture, repurchase, retain, and retire.' },
    ],
	img: '',  
  },
  {
    question: 'Test Fundamentos de la nube de AWS para profesionales/ What is the storage capacity of AWS Snowmobile?',
    answers: [
      { text: 'a. 40 BP. ', correct: false,  expli:' ' },
      { text: 'b. 60 BP.', correct: false,  expli:' ' },
	    { text: 'c. 80 BP.', correct: false,  expli:' ' },
      { text: 'd. 100 BP.', correct: true,  expli:' The correct answer is 100 PB. AWS Snowmobile is a service used to transfer up to 100 PB of data to AWS. The Uun Snowmobile is a nearly 14 meter long shipping container pulled by a semi-trailer truck.' }
    ],
	img: '',  
  },
  {
    question: 'Test Fundamentos de la nube de AWS para profesionales/ Which statement best describes Amazon Lex?',
    answers: [
      { text: 'a. A service that allows you to create conversational interfaces through voice and text.', correct: true,  expli:' The correct answer is Amazon Lex. In Amazon Lex, you can quickly build, test, and deploy conversational chatbots for use in your applications.' },
      { text: 'b. Machine learning service that automatically extracts text and data from scanned documents.', correct: false,  expli:' A machine learning service that automatically extracts text and data from the scanned document is referred to as Amazon Textract.' },
	    { text: 'c. A document database service compatible with MongoDB workloads.', correct: false,  expli:'A document database service that supports MongoDB workloads is referred to as Amazon DocumentDB. ' },
      { text: 'd. A service that makes it possible to identify potentially fraudulent online activities.', correct: false,  expli:' A service that allows you to identify potentially fraudulent online activities is referred to as Amazon Fraud Detector.' }
    ],
	img: '',  
  },
  {
    question: 'Test Fundamentos de la nube de AWS para profesionales/ Which pillar of the AWS Well-Architected framework focuses on the ability of a workload to consistently and successfully perform its intended functions?',
    answers: [
      { text: 'a. operational excellence.', correct: false,  expli:' The operational excellence pillar includes the ability to run workloads efficiently, gain insight into your operations, and continually improve support processes to deliver business value.' },
      { text: 'b. performance efficiency.', correct: false,  expli:'The Performance Efficiency pillar focuses on efficiently using computing resources to meet system requirements and maintaining that efficiency as demand changes and technology evolves. ' },
	    { text: 'c. Security.', correct: false,  expli:'The security pillar includes the protection of data, systems and assets, and the use of cloud technologies to improve the security of your workloads. ' },
      { text: 'd. reliability.', correct: true,  expli:' The correct answer is Reliability.' }
    ],
	img: '',  
  },
  {
    question: 'Test Fundamentos de la nube de AWS para profesionales/ Which process is an example of benefiting from huge economies of scale?',
    answers: [
      { text: 'a. Deploy an app to multiple regions around the world. ', correct: false,  expli:'Deploy an application to multiple regions of the world: This process is an example of Go Global in Minutes. ' },
      { text: 'b. Receive lower pay-as-you-go prices as a result of aggregate usage of the services by AWS customers.', correct: true,  expli:' The correct answer is: Receive lower pay-as-you-go prices as a result of aggregate usage of services by AWS customers. Since the usage of hundreds of thousands of customers is aggregated in the cloud, providers like AWS can achieve greater economies of scale. Economies of scale translate into lower pay-per-use prices.' },
	    { text: 'c. Pay airtime count instead of investing upfront costs in data centers.', correct: false,  expli:' Pay for airtime count instead of investing upfront costs in data centers: This process is an example of Moving from Upfront to Variable Spend.' },
      { text: 'd. Scale the capacity of your infrastructure to meet demand. ', correct: false,  expli:'Scale the capacity of your infrastructure to meet demand: This process is an example of No Calculated Capacity. ' }
    ],
	img: '',  
  },
  {
    question: 'Test Fundamentos de la nube de AWS para profesionales/ The results of the AWS Certified Cloud Practitioner exams indicate a score from 100 to 1000. What is the minimum passing score?',
    answers: [
      { text: 'a. 650.', correct: false,  expli:' ' },
      { text: 'b. 700.', correct: true,  expli:' The correct answer is 700.' },
	    { text: 'c. 850. ', correct: false,  expli:' ' },
      { text: 'd. 900. ', correct: false,  expli:' ' }
    ],
	img: '',  
  },
  {
    question: 'Test Fundamentos de la nube de AWS para profesionales/ What domains are included in the AWS Certified Cloud Practitioner exam? (Select TWO).Strategy: Reflect on the exam domains that were reviewed earlier in this module. Based on the domains that you remember learning, which answers do you think you can mark as incorrect? Keywords and phrases that might be identified in this question include domains and AWS Certified Cloud Practitioner.',
    answers: [
      { text: 'a. Security and compliance.', correct: true,  expli:' correct A Security and compliance.' },
      { text: 'b. Automation and optimization.', correct: false,  expli:' ' },
	    { text: 'c. Monitoring and reports. ', correct: false,  expli:' ' },
      { text: 'd. Billing and prices.', correct: true,  expli:' correct D Billing and prices.' },
      { text: 'e. Implementation and provisioning.', correct: false,  expli:' The other three answers are domains included in the AWS Certified Sysops Administrator – Associate exam.' },
    ],
	img: '',  
  },
  {
    question: 'Test Fundamentos de la nube de AWS para profesionales/ Which of the following scenarios provides an excellent opportunity to use Amazon Elastic File System (Amazon EFS) as a solution? (Select THREE.)',
    answers: [
      { text: 'a. Applications running on multiple EC2 instances that require access to a shared data set', correct: true,  expli:' corrent A Applications running on multiple EC2 instances that require access to a shared data set' },
      { text: 'b. Applications that require globally available object storage for data that does not change', correct: false,  expli:' ' },
	    { text: 'c. Applications that can take advantage of cost optimization for less accessed files', correct: true,  expli:' correct C Applications that can take advantage of cost optimization for less accessed files' },
      { text: 'd. Applications that exist in multiple availability zones for high availability and durability', correct: true,  expli:' correct D Applications that exist in multiple availability zones for high availability and durability ' }
    ],
	img: '',  
  },
  {
    question: 'Test Fundamentos de la nube de AWS para profesionales/ Which services does Amazon Elastic File System (Amazon EFS) integrate with? (Select THREE.)',
    answers: [
      { text: 'a. AWS Lambda', correct: true,  expli:' correct A Amazon EFS integrates with AWS Lambda. ' },
      { text: 'b. Amazon Polly', correct: false,  expli:' ' },
	    { text: 'c. Amazon Honeycode', correct: false,  expli:' ' },
      { text: 'd. Amazon Chime', correct: false,  expli:' ' },
      { text: 'e. AWS Backup', correct: true,  expli:' correct E Amazon EFS integrates with AWS Backup. ' },
      { text: 'f. Amazon EKS', correct: true,  expli:' correct F Amazon EFS integrates with Amazon EKS. Amazon EFS provides a convenient, serverless, set-and-forget elastic file system that is a good storage option for many workloads and use cases. In this section, you\'ll learn about some of the most common use cases for Amazon EFS storage. This includes big data analytics, web services, application development and testing, media and entertainment, backup, and container storage.' },
    ],
	img: '',  
  },
  {
    question: 'Test Fundamentos de la nube de AWS para profesionales/ Which of the following are common use cases for Amazon Elastic File System (Amazon EFS)? (Select THREE.)',
    answers: [
      { text: 'a. Long-term storage of logs and metrics', correct: false,  expli:' ' },
      { text: 'b. container storage', correct: true,  expli:' correct B Common use cases for Amazon EFS include container storage. ' },
	    { text: 'c. multimedia applications', correct: true,  expli:' correct C Common use cases for Amazon EFS include media and entertainment. ' },
      { text: 'd. big data analytics', correct: true,  expli:' correct D Common use cases for Amazon EFS include big data analytics. Long-term storage of logs and metrics is best for Amazon EBS.' }
    ],
	img: '',  
  },
  {
    question: 'Test Fundamentos de la nube de AWS para profesionales/ How is access to the file system controlled in Amazon EFS?',
    answers: [
      { text: 'a. Amazon VPC Security Groups', correct: false,  expli:' ' },
      { text: 'b. AWS IAM Roles', correct: false,  expli:' ' },
	    { text: 'c. AWS KMS keys', correct: false,  expli:' ' },
      { text: 'd. POSIX-compliant user and group permissions', correct: true,  expli:' To control access to the file system, you can use POSIX-compliant user and group permissions.' },
      { text: 'e. TLS', correct: false,  expli:' ' },
    ],
	img: '',  
  },
  {
    question: 'Test Fundamentos de la nube de AWS para profesionales/ Can you share Amazon EFS file systems across multiple Amazon EC2 instances?',
    answers: [
      { text: 'a. Never. Only one instance per file system.', correct: false,  expli:' ' },
      { text: 'b. Yes always.', correct: false,  expli:' ' },
	    { text: 'c. Yes. Only if they are in the same region as the file system.', correct: true,  expli:'You can share Amazon EFS file systems across multiple Amazon EC2 instances, even if the instances are in different Availability Zones, as long as they are in the same region as the file system. ' },
      { text: 'd. Yes. Only if they are in the same Availability Zone as the file system.', correct: false,  expli:' ' }
    ],
	img: '',  
  },
  {
    question: 'Test Fundamentos de la nube de AWS para profesionales/ How do you access the Amazon EFS file system in a VPC?',
    answers: [
      { text: 'a. Connect to your Amazon VPC with AWS Direct Connect.', correct: false,  expli:' ' },
      { text: 'b. Connect to your Amazon VPC with AWS VPN.', correct: false,  expli:' ' },
	    { text: 'c. Create one or more mount targets in the VPC.', correct: true,  expli:' To access the Amazon EFS file system in a VPC, create one or more mount targets in the VPC. You can create a mount target in each Availability Zone in a Region' },
      { text: 'd. Use NFS clients.', correct: false,  expli:' ' }
    ],
	img: '',  
  },
  {
    question: 'Test Fundamentos de la nube de AWS para profesionales/ True or False: You can access Amazon EFS across multiple AWS VPCs and accounts.',
    answers: [
      { text: 'a. True', correct: true,  expli:' True. You can access Amazon EFS in multiple AWS VPCs and accounts. You can connect to EFS file systems from EC2 instances in another AWS account or VPC. Accounts and VPCs can be connected using VPC Peering, VPC Transit Gateway, or Shared VPCs, so that applications in different accounts and VPCs can share a central file system.' },
      { text: 'b. False', correct: false,  expli:' ' }
    ],
	img: '',  
  },
  {
    question: 'Test Fundamentos de la nube de AWS para profesionales/ Which performance mode should you choose if your workloads need to scale to high levels of aggregate performance?',
    answers: [
      { text: 'a. general use', correct: false,  expli:' ' },
      { text: 'b. I/O max.', correct: true,  expli:' General Usage is the default performance mode and is best suited for most workloads. Maximum I/O performance mode is recommended for workloads that need to scale to higher levels of aggregate performance and operations.' }
    ],
	img: '',  
  },
  {
    question: 'Test Fundamentos de la nube de AWS para profesionales/ Which performance mode should you choose if your workloads have a higher performance to storage ratio?',
    answers: [
      { text: 'a. by bursts', correct: false,  expli:' ' },
      { text: 'b. provisioned', correct: true,  expli:' Bursting performance is the default performance mode and is recommended for most workloads. Provisioned throughput mode is recommended for workloads that have a higher ratio of performance to storage.' }
    ],
	img: '',  
  },
  {
    question: 'Test Fundamentos de la nube de AWS para profesionales/ How can you centrally manage and automate backups of Amazon EFS file systems?',
    answers: [
      { text: 'a. Amazon S3', correct: false,  expli:' ' },
      { text: 'b. AWS Backup', correct: true,  expli:' AWS Backup is a fully managed backup service that makes it easy to centrally manage and automate your Amazon EFS file system backups. Using AWS Backup, you can centrally configure and audit AWS resources, automate backup scheduling, set retention policies, and monitor backup activity.' },
	    { text: 'c. AWS DataSync', correct: false,  expli:' ' },
      { text: 'd. AWS Direct Connect', correct: false,  expli:' ' }
    ],
	img: '',  
  },
  {
    question: 'Exam 30p Test Fundamentos de la nube de AWS para profesionales/ You want to send and receive messages between distributed application components. What service should I use?',
    answers: [
      { text: 'a. Amazon ElastiCache.', correct: false,  expli:' • AWS Snowball is a device that allows you to transfer large amounts of data in and out of AWS.' },
      { text: 'b. AWS Snowball.', correct: false,  expli:'• Amazon ElastiCache is a service that adds caching layers to databases to help improve read times for common requests. ' },
	    { text: 'c. Amazon Simple Queuing Service (Amazon SQS).', correct: true,  expli:' The correct answer is Amazon Simple Queue Service (Amazon SQS). Amazon SQS is a message queuing service. With Amazon SQS, messages can be sent, stored, and received between software components of any size, without losing them or requiring the availability of other services. In Amazon SQS, an application sends messages to a queue. A user or service retrieves a message from the queue, processes it, and then removes it from the queue.' },
      { text: 'd. Amazon Route 53.', correct: false,  expli:' • Amazon Route 53 is a DNS web service. It offers developers and businesses a reliable way to direct end users to Internet applications hosted on AWS. Additionally, you can transfer DNS records of existing domain names currently managed by other domain registrars, or register new domain names directly with Amazon Route 53.' }
    ],
	img: '',  
  },
  {
    question: 'Exam 30p Test Fundamentos de la nube de AWS para profesionales/ You want Amazon S3 to monitor the access patterns of your objects. What kind of storage should be used?',
    answers: [
      { text: 'a. Standard - S3 Infrequent Access.', correct: false,  expli:' • S3 Glacier is a low-cost storage class ideal for archiving data. You can retrieve objects stored in the S3 Glacier storage class in a few minutes to a few hours.' },
      { text: 'b. S3 Glacier.', correct: false,  expli:' • The S3 Standard - Infrequent Access storage class is ideal for data that is accessed infrequently but requires high availability when needed. Both S3 Standard and S3 Standard - Infrequent Access store data in a minimum of three Availability Zones. S3 Standard - Infrequent Access provides the same level of availability as S3 Standard but at a lower storage price.' },
	    { text: 'c. Single zone - Infrequent access of S3.', correct: false,  expli:' • S3 Single Zone - Infrequent Access is ideal for infrequently accessed data that does not require high availability.' },
      { text: 'd. S3 Intelligent Tiering.', correct: true,  expli:'  The correct answer is S3 Intelligent-Tiering. In the S3 Intelligent-Tiering storage class, Amazon S3 monitors the access patterns of objects. If you haven\'t accessed an object for 30 consecutive days, Amazon S3 automatically moves it to the Infrequent Access tier, Standard - S3 Infrequent Access. If you access an object in the infrequent access tier, Amazon S3 automatically moves it to the frequent access tier, S3 Standard.' }
    ],
	img: '',  
  },
  {
    question: 'Exam 30p Test Fundamentos de la nube de AWS para profesionales/ Which service allows you to review details of user activities and API calls that have occurred in your AWS environment?',
    answers: [
      { text: 'a. AWS CloudTrail.', correct: true,  expli:' The correct answer is AWS CloudTrail. With CloudTrail, you can view a complete history of user activity and API calls from applications and resources. Events are typically updated in CloudTrail within 15 minutes of the API call. You can filter events by specifying the time and date an API call occurred, the user who requested the action, the type of resource that participated in the API call, and more.' },
      { text: 'b. Amazon Inspector.', correct: false,  expli:' • Amazon CloudWatch is a service that provides data that you can use to monitor applications, optimize resource utilization, and respond to system-wide performance changes.' },
	    { text: 'c. Amazon CloudWatch.', correct: false,  expli:'• Amazon Inspector is a service that checks applications for security vulnerabilities and deviations from security best practices. ' },
      { text: 'd. AWS Trusted Advisor.', correct: false,  expli:' • AWS Trusted Advisor is an online tool that inspects your AWS environment and provides real-time guidance in accordance with AWS best practices.' } 
    ],
	img: '',  
  },
  {
    question: 'Exam 30p Test Fundamentos de la nube de AWS para profesionales/ Which service allows you to create the necessary workflows for human review of machine learning predictions?',
    answers: [
      { text: 'a. Amazon Lex.', correct: false,  expli:' • Amazon Textract is a machine learning service that automatically extracts text and data from scanned documents.' },
      { text: 'b. Amazon Aurora.', correct: false,  expli:'• Amazon Lex is a service that allows you to create conversational interfaces using voice and text. ' },
	    { text: 'c. Amazon Textract.', correct: false,  expli:' • Amazon Aurora is an enterprise-class relational database.' },
      { text: 'd. Amazon Augmented AI.', correct: true,  expli:' The correct answer is Amazon Augmented AI. Amazon Augmented AI (Amazon A2I) provides built-in human review workflows for common machine learning use cases, such as content moderation and extracting text from documents. With Amazon A2I, you can also create your own workflows for machine learning models based on Amazon SageMaker or any other tool.' }
    ],
	img: '',  
  },
  {
    question: 'Exam 30p Test Fundamentos de la nube de AWS para profesionales/ You are launching an Amazon EC2 instance and want to store data in an attached resource. Your data is temporary and will not be kept long term. What resource should you use?',
    answers: [
      { text: 'a. Amazon S3 Bucket.', correct: false,  expli:' • Amazon EBS volumes are ideal for data that needs to be preserved. When an Amazon EC2 instance is stopped or terminated, all data on the attached EBS volume is still available.' },
      { text: 'b. Instance store.', correct: true,  expli:' The correct answer is the instance store. Instance stores are ideal for temporary data that does not need to be retained for the long term. When an Amazon EC2 instance is stopped or terminated, all data that has been written to the attached instance store is deleted.' },
	    { text: 'c. subnet.', correct: false,  expli:' • Amazon S3 buckets cannot be associated with Amazon EC2 instances.' },
      { text: 'd. Amazon Elastic Block Store (Amazon EBS) volume.', correct: false,  expli:' • A subnet is a section of a Virtual Private Cloud (VPC) into which you can group resources based on security or operational needs.' }
    ],
	img: '',  
  },
  {
    question: 'Exam 30p Test Fundamentos de la nube de AWS para profesionales/ What tool allows you to visualize, understand, and manage AWS costs and usage over time?',
    answers: [
      { text: 'a. AWS Cost Explorer.', correct: true,  expli:' The correct answer is AWS Cost Explorer.With AWS Cost Explorer, you can quickly create custom reports to analyze AWS cost and usage data.' },
      { text: 'b. AWS Artifact.', correct: false,  expli:'• AWS Budgets allows you to set custom alerts that will notify you when service usage exceeds (or is expected to exceed) your budgeted amount. ' },
	    { text: 'c. AWS Budgets.', correct: false,  expli:'• The AWS Pricing Calculator lets you explore AWS services and create a cost estimate for your use cases on AWS. In this calculator, you can enter details of your cloud computing requirements, and then receive a detailed estimate that can be exported and shared. ' },
      { text: 'd. AWS Pricing Calculator.', correct: false,  expli:' • AWS Artifact is a service that provides access to AWS security and compliance reports and special agreements online.' }
    ],
	img: '',  
  },
  {
    question: 'Exam 30p Test Fundamentos de la nube de AWS para profesionales/ What service is used to transfer up to 80 PB of data to AWS?',
    answers: [
      { text: 'a. Amazon Cloud Front.', correct: false,  expli:' • Amazon Neptune is a graph database service. Amazon Neptune can be used to build and launch applications that work with highly connected data sets, such as recommendation engines, fraud detection, and knowledge graphs.' },
      { text: 'b. Amazon Neptune.', correct: false,  expli:' • Amazon CloudFront is a content delivery service.' },
	    { text: 'c. AWS Snowmobile.', correct: true,  expli:' The correct answer is AWS Snowmobile. AWS Snowmobile is a service used to transfer up to 80 PB of data to AWS. A Snowmobile is a shipping container almost 14 meters long pulled by a semi-trailer truck. You can transfer up to 80 PB of data.' },
      { text: 'd. AWS Dee Pracer.', correct: false,  expli:' • AWS DeePracer is a 1/18 scale autonomous racing car that can be used to test reinforcement learning models.' }
    ],
	img: '',  
  },
  {
    question: 'Exam 30p Test Fundamentos de la nube de AWS para profesionales/ Which AWS Trusted Advisor category includes checks for Service Limits and Overutilized Instances?',
    answers: [
      { text: 'a. Price optimization.', correct: false,  expli:' • The security category includes checks that help you review your permissions and identify which AWS security features should be enabled.' },
      { text: 'b. Security.', correct: false,  expli:' • The Price Optimization category includes checks for idle or unused resources that could be eliminated and provide cost savings.' },
	    { text: 'c. Error tolerance.', correct: false,  expli:' • The fault tolerance category includes checks to help improve the availability and redundancy of applications.' },
      { text: 'd. Performance.', correct: true,  expli:' The correct answer is performance. In this category, AWS Trusted Advisor also helps improve service performance by providing recommendations on how to take advantage of provisioned throughput.' }
    ],
	img: '',  
  },
  {
    question: 'Exam 30p Test Fundamentos de la nube de AWS para profesionales/ What perspective of the AWS Cloud Adoption Framework is focused on IT workload recovery to meet the requirements of your business investors?',
    answers: [
      { text: 'a. Operations perspective.', correct: true,  expli:' The correct answer is operations perspective. The AWS Cloud Adoption Framework operations perspective also includes principles for operating in the cloud using agile best practices.' },
      { text: 'b. Business perspective.', correct: false,  expli:' • The business perspective helps move from a model that separates business and IT strategies to a business model that integrates IT strategy.' },
	    { text: 'c. Staff perspective.', correct: false,  expli:' • The people perspective helps Human Resources (HR) employees prepare teams for cloud adoption by updating organizational processes and staff skills to include cloud-based competencies.' },
      { text: 'd. Direction perspective.', correct: false,  expli:' • The management perspective helps you understand how to upgrade the skills of your staff and the organizational processes needed to ensure business leadership in the cloud.' }
    ],
	img: '',  
  },
  {
    question: 'Exam 30p Test Fundamentos de la nube de AWS para profesionales/ Which pillar of the AWS Well-Architected Framework focuses on using compute resources in ways that meet system requirements?',
    answers: [
      { text: 'a. performance efficiency.', correct: true,  expli:' The correct answer is performance efficiency. The performance efficiency pillar focuses on using computing resources efficiently to meet system requirements and maintaining that efficiency as demand changes and technology evolves.' },
      { text: 'b. operational excellence.', correct: false,  expli:' • The operational excellence pillar includes the ability to launch workloads efficiently, gain insight into your operations, and continually improve support processes to deliver business value.' },
	    { text: 'c. Security.', correct: false,  expli:' • The security pillar focuses on the protection of data, systems and assets. It is also focused on using cloud technologies to improve the security of its workloads.' },
      { text: 'd. reliability.', correct: false,  expli:' • The reliability pillar focuses on the ability of a workload to consistently and correctly perform its intended functions.' }
    ],
	img: '',  
  },
  {
    question: 'Exam 30p Test Fundamentos de la nube de AWS para profesionales/ Which computing option reduces costs when you commit to a constant amount of computing usage over a period of 1 or 3 years?',
    answers: [
      { text: 'a. Savings plans.', correct: true,  expli:' The correct answer is savings plans. Amazon EC2 Savings Plans help reduce computing costs by committing to consistent computing usage over a period of 1 or 3 years. This is a savings of up to 72% compared to On-Demand Instance pricing. Any usage up to commitment is charged at the discounted savings plan rate (for example, $10 per hour). Any usage over commitment is charged at regular On-Demand Instance rates.' },
      { text: 'b. Dedicated hosts.', correct: false,  expli:' • Reserved Instances are a billing discount applied to the use of On-Demand Instances in your account. You can purchase Standard and Convertible Reserved Instances for a one-year or three-year term, and Scheduled Reserved Instances for a one-year term. Unlike savings plans, Reserved Instances do not require a consistent compute usage commitment for the life of the contract.' },
	    { text: 'c. Spot Instances.', correct: false,  expli:' • Spot Instances are ideal for workloads that have flexible start and end times or can withstand interruptions. Spot Instances take advantage of unused EC2 compute capacity and offer you cost savings of up to 90% over On-Demand Instance prices.' },
      { text: 'd. Reserved Instances.', correct: false,  expli:' • Dedicated hosts are physical servers with the capacity of EC2 instances totally dedicated to your use. You can use existing software licenses per socket, per core, or per VM to help maintain license compliance. You can buy on-demand dedicated hosts or reserved dedicated hosts. Of all the Amazon EC2 options covered in this course, Dedicated Hosts are the most expensive.' }
    ],
	img: '',  
  },
  {
    question: 'Exam 30p Test Fundamentos de la nube de AWS para profesionales/ What tasks are AWS responsible for? (Select TWO).',
    answers: [
      { text: 'a. Configuration of security groups in Amazon EC2 instances.', correct: false,  expli:' ' },
      { text: 'b. Maintenance of the virtualization infrastructure.', correct: true,  expli:' correct B Maintenance of the virtualization infrastructure.' },
	    { text: 'c. Configuration of AWS infrastructure devices.', correct: true,  expli:' correct C Configuration of AWS infrastructure devices.' },
      { text: 'd. Training of company employees on how to use AWS services.', correct: false,  expli:' ' },
      { text: 'e. Creating IAM users and groups.', correct: false,  expli:'The other three answers are tasks that are the responsibility of the clients. ' },
    ],
	img: '',  
  },
  {
    question: 'Exam 30p Test Fundamentos de la nube de AWS para profesionales/ Which support plans include access to all AWS Trusted Advisor checks? (Select TWO). ',
    answers: [
      { text: 'a. AWS Free Tier.', correct: false,  expli:'• The AWS tier is not a support plan. It is a program that consists of three types of offers that allow customers to use AWS services without incurring costs: Always free, 12 months free and Trials. ' },
      { text: 'b. Basic.', correct: false,  expli:' • The Basic and Developer plans provide access to a limited selection of AWS Trusted Advisor checks.' },
	    { text: 'c. Enterprise.', correct: true,  expli:' correct C Enterprise.' },
      { text: 'd. Business.', correct: true,  expli:' correct D Business.' },
      { text: 'e. developer.', correct: false,  expli:'' },
    ],
	img: '',  
  },
  {
    question: 'Exam 30p Test Fundamentos de la nube de AWS para profesionales/ You want to store data in a key value database. What service should I use?',
    answers: [
      { text: 'a. Amazon RDS.', correct: false,  expli:' ' },
      { text: 'b. Amazon DynamoDB.', correct: true,  expli:' correct B Amazon DynamoDB.' },
	    { text: 'c. Amazon DocumentDB.', correct: false,  expli:' ' },
      { text: 'd. Amazon Aurora.', correct: false,  expli:' ' }
    ],
	img: '',  
  },
  {
    question: 'Exam 30p Test Fundamentos de la nube de AWS para profesionales/ Which statement is TRUE regarding AWS Lambda?',
    answers: [
      { text: 'a. You pay only for computing time while the code is being released.', correct: true,  expli:'correct A You pay only for computing time while the code is being released. ' },
      { text: 'b. The first step in using AWS Lambda is to provision a server.', correct: false,  expli:' ' },
	    { text: 'c. Before using AWS Lambda, estimated compute time must be paid in advance.', correct: false,  expli:' ' },
      { text: 'd. To use AWS Lambda, the servers that launch the code must be configured.', correct: false,  expli:' ' }
    ],
	img: '',  
  },
  {
    question: 'Exam 30p Test Fundamentos de la nube de AWS para profesionales/ You want to store data on a volume attached to an Amazon EC2 instance. What service should you use?',
    answers: [
      { text: 'a. Amazon Elastic Block Store (Amazon EBS).', correct: true,  expli:' The correct answer is Amazon Elastic Block Store (Amazon EBS). Amazon EBS provides block-level storage volumes that you can use with Amazon EC2 instances. If you stop or terminate an Amazon EC2 instance, all data on the attached EBS volume remains available.' },
      { text: 'b. AWS Lambda.', correct: false,  expli:' • Amazon Simple Storage Service (Amazon S3) is a service that provides object-level storage. Amazon S3 stores data as objects within buckets.' },
	    { text: 'c. Amazon Simple Storage Service (Amazon S3).', correct: false,  expli:' • AWS Lambda is a service that allows you to launch code without provisioning or managing servers.' },
      { text: 'd.Amazon ElastiCache. ', correct: false,  expli:' • Amazon ElastiCache is a service that adds caching layers to databases to help improve read times for common requests.' }
    ],
	img: '',  
  },
  {
    question: 'Exam 30p Test Fundamentos de la nube de AWS para profesionales/ Which Virtual Private Cloud (VPC) component controls traffic in and out of Amazon EC2 instances?',
    answers: [
      { text: 'a. subnet.', correct: false,  expli:' • A subnet is a section of a VPC into which resources can be grouped based on operational or security needs.' },
      { text: 'b. Internet gateway.', correct: false,  expli:' • A network access control list (ACL) is a virtual firewall that controls incoming and outgoing traffic at the subnet level.' },
	    { text: 'c. Network access control list.', correct: false,  expli:' • An Internet gateway is a connection between a VPC and the Internet. Allows public traffic from the Internet to access a VPC.' },
      { text: 'd. Security group.', correct: true,  expli:'A security group is a virtual firewall that controls traffic in and out of an Amazon EC2 instance. By default, a security group denies all incoming traffic and allows all outgoing traffic. Custom rules can be added to configure what traffic should be allowed or denied. ' }
    ],
	img: '',  
  },
  {
    question: 'Exam 30p Test Fundamentos de la nube de AWS para profesionales/  Which service allows you to consolidate and manage multiple AWS accounts from a central location?',
    answers: [
      { text: 'a. AWS Identity and Access Management (IAM).', correct: false,  expli:' • AWS Identity and Access Management (IAM) is a service that allows you to manage access to AWS services and resources.' },
      { text: 'b. AWS Key Management Service (AWS KMS).', correct: false,  expli:' • AWS Artifact is a service that provides access to AWS security and compliance reports and special agreements online.' },
	    { text: 'c. AWS Artifact.', correct: false,  expli:'• AWS Key Management Service (AWS KMS) allows you to create, manage, and use cryptographic keys. ' },
      { text: 'd. AWS Organizations.', correct: true,  expli:'The correct answer is AWS Organizations. In AWS Organizations, you can centrally control the permissions of your organization\'s accounts using Service Control Policies (SCPs). Additionally, you can use the consolidated billing feature for AWS Organizations to combine usage and receive a single bill from multiple AWS accounts. ' }
    ],
	img: '',  
  },
  {
    question: 'Exam 30p Test Fundamentos de la nube de AWS para profesionales/ Which statement best describes AWS Marketplace?',
    answers: [
      { text: 'a. Online tool that inspects your AWS environment and provides real-time guidance based on AWS best practices.', correct: false,  expli:' • Resource that can answer questions about best practices and help troubleshoot. This answer option refers to AWS Support.' },
      { text: 'b. Resource that can answer questions about best practices and help with troubleshooting.', correct: false,  expli:' • Resource that provides guidance, architectural reviews, and ongoing communication with the business as it plans, deploys, and optimizes applications. This answer choice refers to Technical Account Manager (TAM).' },
	    { text: 'c. Digital catalog that includes thousands of software listings from independent software vendors.', correct: true,  expli:'The correct answer is a digital catalog that includes thousands of listings from independent software providers. You can use AWS Marketplace to find, try, and buy software used on AWS. ' },
      { text: 'd. Resource that provides guidance, architectural reviews, and ongoing communication with your business as you plan, deploy, and optimize your applications.', correct: false,  expli:' • An online tool that inspects your AWS environment and provides real-time guidance in accordance with AWS best practices. This answer choice refers to AWS Trusted Advisor.' }
    ],
	img: '',  
  },
  {
    question: 'Exam 30p Test Fundamentos de la nube de AWS para profesionales/ Which phrase best describes what an Availability Zone is?',
    answers: [
      { text: 'a. A separate geographic location with multiple locations isolated from each other.', correct: false,  expli:' A separate geographic location with multiple locations isolated from each other. This answer describes a region.' },
      { text: 'b. A fully isolated part of the global AWS infrastructure.', correct: true,  expli:' The correct answer is a totally isolated part of the overall AWS infrastructure. An Availability Zone is a single data center or a group of data centers within a region. Availability zones are located tens of kilometers apart. This helps provide interconnectivity to support services and applications that are launched within a region.' },
	    { text: 'c. The server from which Amazon CloudFront gets the files.', correct: false,  expli:' The server from which Amazon Cloudfront gets the files. This answer describes an origin.' },
      { text: 'd. A site that Amazon CloudFront uses to cache copies of content for faster delivery to users in any location.', correct: false,  expli:' Site that Amazon CloudFront uses to cache copies of content for faster delivery to users in any location. This answer describes an edge location.' }
    ],
	img: '',  
  },
  {
    question: 'Exam 30p Test Fundamentos de la nube de AWS para profesionales/ What service is used to launch containerized applications on AWS?',
    answers: [
      { text: 'a. Amazon Redshift.', correct: false,  expli:' • Amazon SageMaker is a service that enables you to quickly build, train, and deploy machine learning models.' },
      { text: 'b. Amazon Elastic Kubernetes Service (Amazon EKS).', correct: true,  expli:' The correct answer is Amazon Elastic Kubernetes Service (Amazon EKS). Amazon EKS is a fully managed service that can be used to launch Kubernetes on AWS. Kubernetes is open source software that enables you to deploy and manage containerized applications at scale. Containers provide a standard way to package your application\'s code and dependencies into a single object. Containers are frequently used for processes and workflows where there are essential requirements for security, reliability, and scalability.' },
	    { text: 'c. Amazon Aurora.', correct: false,  expli:' • Amazon Aurora is an enterprise-class relational database.' },
      { text: 'd. Amazon SageMaker.', correct: false,  expli:' • Amazon Redshift is a data warehousing service that can be used for big data analytics.' }
    ],
	img: '',  
  },
  {
    question: 'Exam 30p Test Fundamentos de la nube de AWS para profesionales/ What migration strategy involves changing the way an application is designed and developed, typically by using cloud-native capabilities?',
    answers: [
      { text: 'a. Redefine platform.', correct: false,  expli:' • Repurchasing means replacing an existing application with a cloud-based version, such as software found on AWS Marketplace.' },
      { text: 'b. Re-host.', correct: false,  expli:' • Rehosting involves moving an application to the cloud with little or no changes to the application itself. It is also known as lift and shift.' },
	    { text: 'c. refactor.', correct: true,  expli:' The correct answer is to refactor.' },
      { text: 'd. Repurchase.', correct: false,  expli:' • Re-platforming involves selectively optimizing aspects of an application for cloud benefits without changing the application\'s core architecture. It is also known as lift, tinker and shift.' }
    ],
	img: '',  
  },
  {
    question: 'Exam 30p Test Fundamentos de la nube de AWS para profesionales/ What can you do on Amazon CloudFront?',
    answers: [
      { text: 'a. Provision an isolated section of the AWS Cloud to launch resources in a virtual network that you define.', correct: false,  expli:' • Launch infrastructure with a hybrid cloud strategy – This action can be done with AWS Outposts.' },
      { text: 'b. Provision resources using programming languages or a text file.', correct: false,  expli:' • Provisioning resources using programming languages or a text file – This can be done in AWS CloudFormation.' },
	    { text: 'c. Launch infrastructure with a hybrid cloud strategy.', correct: false,  expli:' • Provision an isolated section of the AWS cloud to launch resources in a virtual network that you define – This can be done in Amazon Virtual Private Cloud (Amazon VPC).' },
      { text: 'd. Deliver content to clients through a global network of edge locations.', correct: true,  expli:' The correct answer is to deliver content to clients through a global network of edge locations. Amazon CloudFront is a content delivery service. It uses a network of edge locations to cache content and deliver content to clients around the world. The content is stored locally as a copy. This content may consist of video files, photos, web pages, etc.' }
    ],
	img: '',  
  },
  {
    question: 'Exam 30p Test Fundamentos de la nube de AWS para profesionales/ What can you do on Amazon Route 53? (Select TWO).',
    answers: [
      { text: 'a. Automate the deployment of workloads in your AWS environment.', correct: false,  expli:' • Monitor applications and respond to system-wide performance changes. These actions can be performed in Amazon CloudWatch.' },
      { text: 'b. Access AWS security and compliance reports and certain agreements online.', correct: false,  expli:' • Access AWS security and compliance reports and special agreements online. This action can be performed in AWS Artifact.' },
	    { text: 'c. Manage DNS records of domain names.', correct: true,  expli:' • Manage DNS records of domain names.Amazon Route 53 is a DNS web service. It offers developers and businesses a reliable way to direct end users to Internet applications hosted on AWS.' },
      { text: 'd. Monitor applications and respond to system-wide performance changes.', correct: false,  expli:'• Automate the deployment of workloads in your AWS environment. This action can be done with AWS Quick Starts. ' },
      { text: 'e. Connect user requests to AWS infrastructure and outside of AWS.', correct: true,  expli:' • Connect user requests to AWS infrastructure and outside of AWS.Additionally, you can transfer DNS records of existing domain names currently managed by other domain registrars, or register new domain names directly on Amazon Route 53.' },
    ],
	img: '',  
  },
  {
    question: 'Exam 30p Test Fundamentos de la nube de AWS para profesionales/ Which statement best describes Amazon GuardDuty?',
    answers: [
      { text: 'a. Service that allows you to monitor network requests coming into your web applications.', correct: false,  expli:' • Service that helps protect your applications against Distributed Denial of Service (DDoS) attacks. This answer choice refers to AWS Shield.' },
      { text: 'b. Service that provides intelligent threat detection for AWS infrastructure and resources.', correct: true,  expli:' The correct answer is a service that provides intelligent threat detection for AWS infrastructure and resources. AWS GuardDuty identifies threats by continuously monitoring network activity and account behavior in your AWS environment.' },
	    { text: 'c. Service that helps protect your applications against distributed denial-of-service (DDoS) attacks.', correct: false,  expli:' • Service that checks applications for security vulnerabilities and deviations from security best practices. This answer choice refers to Amazon Inspector.' },
      { text: 'd. A service that checks for application security vulnerabilities and deviations from security best practices.', correct: false,  expli:' • Service that allows you to monitor network requests coming into your web applications. This answer option refers to AWS WAF.' }
    ],
	img: '',  
  },
  {
    question: 'Exam 30p Test Fundamentos de la nube de AWS para profesionales/ What service is used to rapidly deploy and scale applications on AWS?',
    answers: [
      { text: 'a. Amazon Cloud Front.', correct: false,  expli:' • AWS Outposts is a service that allows infrastructure to be launched with a hybrid cloud strategy.' },
      { text: 'b. AWS Outposts.', correct: false,  expli:' • Amazon CloudFront is a content delivery service.' },
	    { text: 'c. AWS Snowball.', correct: false,  expli:' • AWS Snowball is a device that allows you to transfer large amounts of data in and out of AWS.' },
      { text: 'd. AWS Elastic Beanstalk.', correct: true,  expli:' The correct answer is AWS Elastic Beanstalk. Upload the application, and Elastic Beanstalk will automatically manage the implementation details of capacity provisioning, load balancing, autoscaling, and application health monitoring.' }
    ],
	img: '',  
  },
  {
    question: 'Exam 30p Test Fundamentos de la nube de AWS para profesionales/ In the S3 Intelligent-Tiering storage class, Amazon S3 moves objects between a high-access tier and a low-access tier. What storage classes are used for these tiers? (Select TWO).',
    answers: [
      { text: 'a. Single zone - Infrequent access of S3.', correct: false,  expli:' ' },
      { text: 'b. S3 Glacier.', correct: false,  expli:' ' },
	    { text: 'c. S3 Glacier Deep Archive.', correct: false,  expli:' ' },
      { text: 'd. Standard - S3 Infrequent Access.', correct: true,  expli:' correct D S3 Standard-IA.' },
      { text: 'e. S3 Standard.', correct: true,  expli:' correct E S3 Standard. In the S3 Intelligent-Tiering storage class, Amazon S3 monitors object access patterns. If you haven\'t accessed an object for 30 consecutive days, Amazon S3 automatically moves it to the Infrequent Access tier, S3 Standard - Infrequent Access. If you access an object in the infrequent access tier, Amazon S3 automatically moves it to the high access tier, S3 Standard.' },
    ],
	img: '',  
  },
  {
    question: 'Exam 30p Test Fundamentos de la nube de AWS para profesionales/ Which statement best describes Elastic Load Balancing?',
    answers: [
      { text: 'a. A service that monitors your applications and automatically adds or removes capacity from Resource Groups in response to changing demand.', correct: false,  expli:' ' },
      { text: 'b. A service that enables you to configure, manage, and scale a distributed in-memory or cloud-cache environment.', correct: false,  expli:' ' },
	    { text: 'c. A service that distributes incoming traffic among multiple destinations, such as Amazon EC2 instances.', correct: true,  expli:'correct C, A service that distributes incoming traffic among multiple destinations, such as Amazon EC2 instances. ' },
      { text: 'd. A service that provides data that can be used to monitor applications, optimize resource utilization, and respond to changes in system-wide performance.', correct: false,  expli:' ' }
    ],
	img: '',  
  },
  {
    question: 'Exam 30p Test Fundamentos de la nube de AWS para profesionales/ What component or service enables a dedicated private connection to be established between the data center and the Virtual Private Cloud (VPC)?',
    answers: [
      { text: 'a. Amazon Cloud Front.', correct: false,  expli:'• Amazon CloudFront is a content delivery service. It uses a network of edge locations to cache content and deliver content to clients around the world. ' },
      { text: 'b. Virtual private gateway.', correct: false,  expli:'• A virtual private gateway allows you to establish a virtual private network (VPN) connection between your VPC and a private network, such as an on-premises data center or internal corporate network. A virtual private gateway only allows traffic to the VPC if it is coming from an approved network. ' },
	    { text: 'c. Internet gateway.', correct: false,  expli:'• An Internet gateway is a connection between a VPC and the Internet. Allows public Internet traffic to access a VPC. ' },
      { text: 'd. AWS Direct Connect.', correct: true,  expli:' The correct answer is AWS Direct Connect. AWS Direct Connect is a service that allows you to establish a dedicated private connection between the data center and the VPC. The private connection provided by AWS Direct Connect helps you reduce network costs and increase the amount of bandwidth that can travel across the network.' }
    ],
	img: '',  
  },
  {
    question: 'Exam 30p Test Fundamentos de la nube de AWS para profesionales/ What tool is used to automate the actions of AWS services and applications using scripts?',
    answers: [
      { text: 'a. Amazon Redshift.', correct: false,  expli:' • Amazon Redshift is a data warehousing service that can be used for big data analysis. It has the ability to collect data from many sources to help you understand data trends and relationships.' },
      { text: 'b. AWS Snowball.', correct: false,  expli:'• Amazon Quantum Ledger Database (Amazon QLDB) is a general ledger database service. You can use Amazon QLDB to review a complete history of all changes that have been made to application data. ' },
	    { text: 'c. AWS Command Line Interface.', correct: true,  expli:' The correct answer is AWS Command Line Interface. The AWS Command Line Interface (AWS CLI) allows you to control multiple AWS services directly from the command line within one tool. For example, you can use commands to start an Amazon EC2 instance, connect an Amazon EC2 instance to a specific Auto Scaling group, and much more. AWS CLI is available for Windows, macOS, and Linux users.' },
      { text: 'd. Amazon QLDB.', correct: false,  expli:' • AWS Snowball is a device that allows you to transfer large amounts of data in and out of AWS.' }
    ],
	img: '',  
  },
  
  {
    question: 'Test Fundamentos de la nube de AWS para profesionales webinars/ What component or service can be used to establish a private dedicated connection between a company\'s data center and AWS?',
    answers: [
      { text: 'a. Private subnet.', correct: false,  expli:' ' },
      { text: 'b. DNS.', correct: false,  expli:' ' },
	    { text: 'c. AWS Direct Connect.', correct: true,  expli:'  correct C AWS Direct Connect.' },
      { text: 'd. Amazon CloudFront.', correct: false,  expli:' ' }
    ],
	img: '',  
  },
  {
    question: 'Test Fundamentos de la nube de AWS para profesionales webinars/ Which statement describes security groups?',
    answers: [
      { text: 'a. They are stateful and allow all incoming traffic by default', correct: false,  expli:' ' },
      { text: 'b. They are stateful and deny all incoming traffic by default.', correct: true,  expli:' correct B  They are stateful and deny all incoming traffic by default.' },
	    { text: 'c. They are stateless and allow all incoming traffic by default.', correct: false,  expli:' ' },
      { text: 'd. They are stateless and deny all incoming traffic by default.', correct: false,  expli:' ' }
    ],
	img: '',  
  },
  {
    question: 'Test Fundamentos de la nube de AWS para profesionales webinars/ What component is used to connect a VPC to the Internet?',
    answers: [
      { text: 'a. Internet Gateway.', correct: true,  expli:' correct A Internet Gateway.' },
      { text: 'b. Public subnet.', correct: false,  expli:' ' },
	    { text: 'c. Peripheral location.', correct: false,  expli:' ' },
      { text: 'd. Security group.', correct: false,  expli:' ' }
    ],
	img: '',  
  },
  {
    question: 'Test Fundamentos de la nube de AWS para profesionales webinars/ What service is used to manage the DNS records of domain names?',
    answers: [
      { text: 'a. Amazon Virtual Private Cloud.', correct: false,  expli:' ' },
      { text: 'b. AWS Direct Connect.', correct: false,  expli:' ' },
	    { text: 'c. Amazon Cloud Front.', correct: false,  expli:' ' },
      { text: 'd. Amazon Route 53.', correct: true,  expli:' correct D Amazon Route 53. ' }
    ],
	img: '',  
  },
  {
    question: 'Test Fundamentos de la nube de AWS para profesionales webinars / Which statement describes DNS resolution?',
    answers: [
      { text: 'a. Starting resources in a customer-defined virtual network', correct: false,  expli:' ' },
      { text: 'b. Storing local copies of content in peripheral locations around the world.', correct: false,  expli:' ' },
	    { text: 'c. Connecting a VPC to the Internet.', correct: false,  expli:' ' },
      { text: 'd. Translation of a domain name into an IP address.', correct: true,  expli:' correct D Translation of a domain name into an IP address.' }
    ],
	img: '',  
  },
  {
    question: 'Test Fundamentos de la nube de AWS para profesionales webinars / You want to store data that is accessed infrequently, but must be immediately available when needed. What kind of Amazon S3 storage should you use?',
    answers: [
      { text: 'a. S3 Intelligent Tiering.', correct: false,  expli:' ' },
      { text: 'b. S3 Glacier Deep Archive.', correct: false,  expli:' ' },
	    { text: 'c. S3 Standard-IA.', correct: true,  expli:' correct C S3 Standard-IA.' },
      { text: 'd. S3 Glacier.', correct: false,  expli:' ' }
    ],
	img: '',  
  },
  {
    question: 'Test Fundamentos de la nube de AWS para profesionales webinars / One of the cafeteria employees has an idea for a new inventory management system. He thinks they should keep the data in an Amazon S3 text file. Do you agree with his suggestion? Why yes or why not?',
    answers: [
      { text: 'a. Yes ', correct: false,  expli:' ' },
      { text: 'b. No ', correct: true,  expli:' No, there are many changes, better with a database, with a relational database, if the products have several different attributes with a non-relational database, ' }
    ],
	img: '',  
  },
  {
    question: 'Test Fundamentos de la nube de AWS para profesionales webinars / In each of the following situations, should you use Amazon RDS? ',
    answers: [
      { text: 'a. Store data in a relational database', correct: true,  expli:' correct A Store data in a relational database' },
      { text: 'b. Run a serverless database', correct: false,  expli:' ' },
	    { text: 'c. Storing data in a key-value database', correct: false,  expli:' ' },
      { text: 'd. Use SQL to organize data', correct: true,  expli:' correct D Use SQL to organize data' },
      { text: 'e. Scale up to 10 billion requests a day', correct: false,  expli:' ' },
      { text: 'f. Store data in an Amazon Aurora database', correct: true,  expli:' correct F Store data in an Amazon Aurora database' }
    ],
	img: '',  
  },
  {
    question: 'Test Fundamentos de la nube de AWS para profesionales webinars / In each of the following situations, should you use DynamoDB?  (choose three answers )',
    answers: [
      { text: 'a. Store data in a relational database', correct: false,  expli:'' },
      { text: 'b. Run a serverless database', correct:  true,  expli:' correct B Run a serverless database' },
	    { text: 'c. Storing data in a key-value database', correct: true,  expli:' correct C Storing data in a key-value database' },
      { text: 'd. Use SQL to organize data', correct: false,  expli:' ' },
      { text: 'e. Scale up to 10 billion requests a day', correct: true,  expli:' correct E Scale up to 10 billion requests a day' },
      { text: 'f. Store data in an Amazon Aurora database', correct: false,  expli:' ' }
    ],
	img: '',  
  },
  {
    question: 'Test Fundamentos de la nube de AWS para profesionales webinars / Are these tasks the responsibility of customers?',
    answers: [
      { text: 'a. Configure security groups on Amazon EC2 instances', correct: true,  expli:' correct A Configure security groups on Amazon EC2 instances' },
      { text: 'b. Maintain the network infrastructure', correct: false,  expli:' ' },
	    { text: 'c. Implement physical security controls in data centers', correct: false,  expli:' ' },
      { text: 'd. Apply software patches on Amazon EC2 instances', correct: true,  expli:' correct D Apply software patches on Amazon EC2 instances' },
      { text: 'e. Maintain servers running Amazon EC2 instances', correct: false,  expli:' ' },
      { text: 'f. Set permissions for Amazon S3 objects', correct: true,  expli:' correct F Set permissions for Amazon S3 objects' }
    ],
	img: '',  
  },
  {
    question: 'Test Fundamentos de la nube de AWS para profesionales webinars / Are these tasks the responsibility of AWS?',
    answers: [
      { text: 'a. Configure security groups on Amazon EC2 instances', correct: false,  expli:' ' },
      { text: 'b. Maintain the network infrastructure', correct: true,  expli:' correct B Maintain the network infrastructure' },
	    { text: 'c. Implement physical security controls in data centers', correct: true,  expli:' correct C Implement physical security controls in data centers' },
      { text: 'd. Apply software patches on Amazon EC2 instances', correct: false,  expli:' ' },
      { text: 'e. Maintain servers running Amazon EC2 instances', correct: true,  expli:' correct E Maintain servers running Amazon EC2 instances' },
      { text: 'f. Set permissions for Amazon S3 objects', correct: false,  expli:' ' }
    ],
	img: '',  
  },
  {
    question: 'Test Fundamentos de la nube de AWS para profesionales webinars / Which statement describes an IAM policy?',
    answers: [
      { text: 'a. An authentication process that provides an additional layer of protection for your AWS account.', correct: false,  expli:' ' },
      { text: 'b. A document that grants or denies permissions to AWS services and resources.', correct: true,  expli:' correct B, A document that grants or denies permissions to AWS services and resources.' },
	    { text: 'c. An identity that can be assumed to gain temporary access to permits.', correct: false,  expli:' ' },
      { text: 'd. The identity that is established when an AWS account is first created.', correct: false,  expli:' ' }
    ],
	img: '',  
  },
  {
    question: 'Test Fundamentos de la nube de AWS para profesionales webinars / Which service helps protect your applications against Distributed Denial of Service (DDoS) attacks?',
    answers: [
      { text: 'a. Amazon Guard Duty.', correct: false,  expli:' ' },
      { text: 'b. Amazon Inspector.', correct: false,  expli:' ' },
	    { text: 'c. AWS Artifact.', correct: false,  expli:' ' },
      { text: 'd. AWS Shield.', correct: true,  expli:' correct D AWS Shield.' }
    ],
	img: '',  
  },
  {
    question: 'Test Fundamentos de la nube de AWS para profesionales webinars /  Do the alarms have a cost?',
    answers: [
      { text: 'a. Yes ', correct: true,  expli:' The first 10 are free. Watch https://aws.amazon.com/cloudwatch/pricing/' },
      { text: 'b. No ', correct: false,  expli:' ' }
    ],
	img: '',  
  },
  {
    question: 'Test Fundamentos de la nube de AWS para profesionales webinars /  Can roles be assigned to groups?',
    answers: [
      { text: 'a. Yes ', correct: false,  expli:' ' },
      { text: 'b. No ', correct: true,  expli:' No, roles are not assigned, it\'s the other way around. They are prepared in IAM but the user decides to assume them when necessary. Only users can assume roles. And only one at a time. It is the user who decides when he needs to assume the role.' }
    ],
	img: '',  
  },
  {
    question: 'Test Fundamentos de la nube de AWS para profesionales webinars / But all the resources that are consumed, to start paying, you always have to exceed the free limit first?',
    answers: [
      { text: 'a. Yes ', correct: true,  expli:' Yes, but look at aws.com/service/pricing for the services you use, lest there be any exceptions to the general rule.' },
      { text: 'b. No ', correct: false,  expli:' ' }
    ],
	img: '',  
  },
  {
    question: 'Test Fundamentos de la nube de AWS para profesionales webinars / Which AWS Cloud Adoption Framework perspective helps implement new cloud solutions and migrate on-premises workloads to the cloud? ',
    answers: [
      { text: 'a. Commercial Perspective.', correct: false,  expli:' ' },
      { text: 'b. Platform Perspective.', correct: true,  expli:' correct B Platform Perspective. ' },
	    { text: 'c. Operations Perspective.', correct: false,  expli:' ' },
      { text: 'd. People Perspective. ', correct: false,  expli:' ' }
    ],
	img: '',  
  },
  {
    question: 'Test Fundamentos de la nube de AWS para profesionales webinars / What Service can you use to review the security of your Amazon S3 buckets indicating if there are public access permissions? AWS GuardDuty or AWS Trusted Advisor',
    answers: [
      { text: 'a. AWS GuardDuty ', correct: false,  expli:' ' },
      { text: 'b. AWS Trusted Advisor', correct: true,  expli:' correct B AWS Trusted Advisor' }
    ],
	img: '',  
  },
  {
    question: 'Test Fundamentos de la nube de AWS para profesionales webinars / Is it necessary to turn it off to change the instance type?',
    answers: [
      { text: 'a. Yes', correct: true,  expli:' Currently yes.' },
      { text: 'b. No ', correct: false,  expli:' ' }
    ],
	img: '',  
  },
  {
    question: '/Test Selección de curso/ AWS stands for Amazing Web Services. Select one:',
    answers: [
      { text: 'a. True', correct: false,  expli:' ' },
      { text: 'b. False', correct: true,  expli:' The correct answer is: False ' }
    ],
	img: '',  
  },
  {
    question: '/Test Selección de curso/ S3 is an acronym for Simple Storage Service.',
    answers: [
      { text: 'a. True', correct: true,  expli:' The correct answer is: True' },
      { text: 'b. False', correct: false,  expli:' ' }
    ],
	img: '',  
  },
  {
    question: '/Test Selección de curso/ Which of these databases is not relational? Select one:',
    answers: [
      { text: 'a. MariaDB', correct: false,  expli:' ' },
      { text: 'b. Oracle', correct: false,  expli:' ' },
	    { text: 'c. mysql', correct: false,  expli:' ' },
      { text: 'd. DynamoDB', correct: true,  expli:' The correct answer is: DynamoDB' }
    ],
	img: '',  
  },
  {
    question: '/Test Selección de curso/ What is the central service of the entire AWS catalog? Select one:',
    answers: [
      { text: 'a. Amazon Simple Notification Service', correct: false,  expli:' ' },
      { text: 'b. Amazon Elastic Compute Cloud', correct: true,  expli:' The correct answer is: Amazon Elastic Compute Cloud' },
	    { text: 'c. Amazon Simple Storage System', correct: false,  expli:' ' },
      { text: 'd. Amazon Simple Queuing Service', correct: false,  expli:' ' }
    ],
	img: '',  
  },
  {
    question: '/Test Selección de curso/ How many bits does an IPv4 address have? Select one:',
    answers: [
      { text: 'a. 32', correct: true,  expli:' The correct answer is: 32' },
      { text: 'b. 8', correct: false,  expli:' ' },
	    { text: 'c. 16', correct: false,  expli:' ' },
      { text: 'd. 64', correct: false,  expli:' ' }
    ],
	img: '',  
  },
  {
    question: '/Test Selección de curso/ What service category would S3 be in? Select one:',
    answers: [
      { text: 'a. Migration', correct: false,  expli:' ' },
      { text: 'b. computing', correct: false,  expli:' ' },
	    { text: 'c. networks', correct: false,  expli:' ' },
      { text: 'd. Storage', correct: true,  expli:' The correct answer is: Storage' }
    ],
	img: '',  
  },
  {
    question: '/Test Selección de curso/ For the subnet mask 255.255.255.0 what CIDR notation does it correspond to? Select one:',
    answers: [
      { text: 'a. /24', correct: true,  expli:' The correct answer is: /24' },
      { text: 'b. /20', correct: false,  expli:' ' },
	    { text: 'c. /16', correct: false,  expli:' ' },
      { text: 'd. /8', correct: false,  expli:' ' }
    ],
	img: '',  
  },
  {
    question: '/Test Selección de curso/ What is a hypervisor? Select one:',
    answers: [
      { text: 'a. Software used to create highly available websites', correct: false,  expli:' ' },
      { text: 'b. Software used to monitor the performance of Windows servers', correct: false,  expli:' ' },
	    { text: 'c. Hardware that allows you to increase the performance of your physical servers', correct: false,  expli:' ' },
      { text: 'd. Software that allows you to create and manage virtualized resources that run on physical hardware, such as virtual machines', correct: true,  expli:'The correct answer is: Software that allows you to create and manage virtualized resources that run on physical hardware, such as virtual machines. ' }
    ],
	img: '',  
  },
  {
    question: '/Test Selección de curso/ Which cloud computing model provides a platform where you can easily deploy an application without having to manage the necessary servers? Select one:',
    answers: [
      { text: 'a. Infrastructure as a Service (IaaS)', correct: false,  expli:' ' },
      { text: 'b. Platform as a Service (PaaS)', correct: true,  expli:' The correct answer is: Platform as a Service (PaaS)' },
	    { text: 'c. Software as a Service (SaaS)', correct: false,  expli:' ' },
      { text: 'd. Infrastructure as Code (IaC)', correct: false,  expli:' ' }
    ],
	img: '',  
  },
  {
    question: '/Test Selección de curso/ Which AWS service allows you to create a user and provides access security? Select one:',
    answers: [
      { text: 'a. AWS CloudFormation', correct: false,  expli:' ' },
      { text: 'b. AWS Redshift', correct: false,  expli:' ' },
	    { text: 'c. AWS IAM', correct: false,  expli:' The correct answer is: AWS IAM' },
      { text: 'd. AWS Direct Connect', correct: false,  expli:' ' }
    ],
	img: '',  
  },
  {
    question: '/Test AWS Cloud Practitioner Essentials/ What is cloud computing?',
    answers: [
      { text: 'a. A backup of files stored on mobile and desktop devices to prevent data loss', correct: false,  expli:' It is possible to back up files to the cloud, but this answer does not fully describe cloud computing.' },
      { text: 'b. A deployment of infrastructure-connected applications on-premises', correct: false,  expli:' Deploying infrastructure-connected applications on-premises is an example of a use case for a hybrid cloud deployment. Remember that cloud computing also has cloud and on-premises (or private cloud) deployment models.' },
	    { text: 'c. One code run without the need to manage or provision servers', correct: false,  expli:' AWS Lambda is an AWS service that allows you to run code without the need to manage or provision servers. This description does not fully describe cloud computing. AWS Lambda is explained in more detail later.' },
      { text: 'd. An on-demand delivery of IT resources and applications over the Internet with pay-as-you-go pricing', correct: true,  expli:' The correct answer is: An on-demand delivery of IT resources and applications over the Internet at pay-per-use prices.' }
    ],
	img: '',  
  },
  {
    question: '/Test AWS Cloud Practitioner Essentials/ How else is on-premises deployment known?',
    answers: [
      { text: 'a. Private cloud implementation', correct: true,  expli:' The correct answer is Private cloud implementation.' },
      { text: 'b. cloud based application', correct: false,  expli:' • Cloud-based applications are fully implemented in the cloud and have no parts running on-premises.' },
	    { text: 'c. hybrid deployment', correct: false,  expli:' • A hybrid deployment connects infrastructure and applications between cloud-based resources and existing non-cloud resources, such as on-premises resources. However, a hybrid deployment is not the same as an on-premises deployment because it involves resources located in the cloud.' },
      { text: 'd. AWS Cloud', correct: false,  expli:' • AWS Cloud offers three cloud deployment models: cloud-based, hybrid, and on-premises. This answer is incorrect because AWS Cloud is not just the same as an on-premises deployment.' }
    ],
	img: '',  
  },
  {
    question: '/Test AWS Cloud Practitioner Essentials/ How does the scale of cloud computing help save costs?',
    answers: [
      { text: 'a. It is not necessary to invest in technological resources before using them.', correct: false,  expli:' Not having to invest in technological resources before using them is related to Changing initial expenses for variable expenses.' },
      { text: 'b. Aggregate cloud usage by a large number of customers translates into lower pay-as-you-go prices.', correct: true,  expli:'The correct answer is Aggregate use of the cloud by a large number of customers translates into lower pay-as-you-go prices. This answer describes how customers can take advantage of the huge economies of scale in cloud computing. ' },
	    { text: 'c. Access to services on demand helps to avoid excess or limited capacity.', correct: false,  expli:' Accessing services on demand to avoid overcapacity or limited capacity is related to Stop Guessing Capacity.' },
      { text: 'd. You can quickly deploy applications to clients and provide them with low latency.', correct: false,  expli:' Quickly deploying applications to customers and providing them with low latency is all about Going Global in Minutes.' }
    ],
	img: '',  
  },
  {
    question: '/Test AWS Cloud Practitioner Essentials/ Which AWS service is the best option to publish messages to subscribers?',
    answers: [
      { text: 'a. Amazon Simple Queuing Service (Amazon SQS)', correct: false,  expli:' • Amazon Simple Queue Service (Amazon SQS) is a message queuing service. It does not use the message subscription or topic model related to Amazon SNS.' },
      { text: 'b. Amazon EC2 Auto Scaling', correct: false,  expli:' • Amazon EC2 Auto Scaling allows you to automatically add or remove Amazon EC2 instances in response to changing application demand.' },
	    { text: 'c. Amazon Simple Notification Service (SNS)', correct: true,  expli:' The correct answer is Amazon Simple Notification Service (Amazon SNS). Amazon SNS is a publish/subscribe service. With Amazon SNS topics, a publisher publishes messages to subscribers.' },
      { text: 'd. Elastic Load Balancing', correct: false,  expli:' • Elastic Load Balancing is the AWS service that automatically distributes incoming application traffic across multiple resources, such as Amazon EC2 instances.' }
    ],
	img: '',  
  },
  {
    question: '/Test AWS Cloud Practitioner Essentials/ Let\'s say you want to use an Amazon EC2 instance for a batch processing workload. What would be the best Amazon EC2 instance type?',
    answers: [
      { text: 'a. general use', correct: false,  expli:' • General Purpose instances provide a balance between compute, memory, and network resources. This instance family would not be the best choice for your application in this scenario. Compute-optimized instances are better suited for batch processing workloads than General Purpose instances.' },
      { text: 'b. Optimized for storage', correct: false,  expli:' • Memory-optimized instances are more ideal for workloads that process large data sets in memory, such as high-performance databases.' },
	    { text: 'c. Optimized for computing', correct: true,  expli:'The correct answer choice is optimized for computing. ' },
      { text: 'd. Optimized for storage', correct: false,  expli:' • Storage-optimized instances are designed for workloads that require high, sequential read and write access to large data sets on local storage. The question does not specify the size of the data to be processed. Batch processing involves processing data in groups. A compute-optimized instance is ideal for this type of workload, which would benefit from a high-performance processor.' }
    ],
	img: '',  
  },
  {
    question: '/Test AWS Cloud Practitioner Essentials/ What are the contract length options for Amazon EC2 Reserved Instances? (Select TWO).',
    answers: [
      { text: 'a. •	1 year', correct: true,  expli:' one correct answer is: 1 year' },
      { text: 'b. •	2 years', correct: false,  expli:' ' },
	    { text: 'c. •	3 years', correct: true,  expli:' one correct answer is: 3 years' },
      { text: 'd. •	4 years', correct: false,  expli:' Reserved Instances require either a 1-year or 3-year commitment. The 3-year option offers a greater discount.' },
      { text: 'e. •	5 years', correct: false,  expli:' ' },
    ],
	img: '',  
  },
  {
    question: '/Test AWS Cloud Practitioner Essentials/ Let\'s say you have a workload that will last a total of 6 months and can handle interruptions. What would be the most profitable Amazon EC2 purchase option?',
    answers: [
      { text: 'a. reserved instance', correct: false,  expli:' • Reserved Instances require a contract length of 1 or 3 years. The workload in this scenario will only run for 6 months.' },
      { text: 'b. Spot Instance', correct: true,  expli:' The correct answer is Spot Instance.' },
	    { text: 'c. dedicated instance', correct: false,  expli:' • Dedicated instances run in a virtual private cloud (VPC) on hardware dedicated to a single customer. They cost more than the other answers, which run on shared hardware.' },
      { text: 'd. On Demand Instance', correct: false,  expli:' • On-Demand Instances are eligible to run for only 6 months and can withstand interruptions. However, a Spot Instance would be the best option because it doesn\'t require a minimum contract length, can withstand outages, and costs less than an On-Demand Instance.' }
    ],
	img: '',  
  },
  {
    question: '/Test AWS Cloud Practitioner Essentials/ Which process is an example of Elastic Load Balancing?',
    answers: [
      { text: 'a. Ensuring that no single Amazon EC2 instance has to support the entire workload on its own', correct: true,  expli:' The correct answer choice is Ensure that no single Amazon EC2 instance has to support the entire workload on its own. Elastic Load Balancing is the AWS service that automatically distributes incoming application traffic across multiple resources, such as Amazon EC2 instances. This helps ensure that no resource is overused.' },
      { text: 'b. Remove unnecessary Amazon EC2 instances when demand is low', correct: false,  expli:' The other answers are examples of Auto Scaling.' },
	    { text: 'c. Adding a Second Amazon EC2 Instance During an Online Store Hot Sale', correct: false,  expli:' ' },
      { text: 'd. Automatically adjust the number of Amazon EC2 instances to meet demand', correct: false,  expli:' ' }
    ],
	img: '',  
  },
  {
    question: '/Test AWS Cloud Practitioner Essentials/ Let\'s say you want to deploy and manage containerized applications. What service should I use?',
    answers: [
      { text: 'a. AWS Lambda', correct: false,  expli:' • AWS Lambda is a service that allows you to run code without provisioning or managing servers.' },
      { text: 'b. Amazon Simple Notification Service (SNS)', correct: false,  expli:' • Amazon Simple Queue Service (Amazon SQS) is a service that allows you to send, store, and receive messages between software components through a queue.' },
	    { text: 'c. Amazon Simple Queuing Service (Amazon SQS)', correct: false,  expli:' • Amazon Simple Notification Service (Amazon SNS) is a publish/subscribe service. With Amazon SNS topics, a publisher publishes messages to subscribers.' },
      { text: 'd. Amazon Elastic Kubernetes Service (Amazon EKS)', correct: true,  expli:' The correct answer is Amazon Elastic Kubernetes Service (Amazon EKS). Amazon EKS is a fully managed Kubernetes service. Kubernetes is open source software that enables you to deploy and manage containerized applications at scale.' }
      ],
	img: '',  
  },
  {
    question: '/Test AWS Cloud Practitioner Essentials/ Which statement best describes an Availability Zone?',
    answers: [
      { text: 'a. A geographic area that contains AWS resources', correct: false,  expli:' • A Region is a geographic area that contains AWS resources.' },
      { text: 'b. A single data center or group of data centers within a region', correct: true,  expli:' The correct answer is A single data center or a group of data centers within a region.' },
	    { text: 'c. A data center that uses an AWS service to perform service-specific operations', correct: false,  expli:' • An edge location is a data center that an AWS service uses to perform service-specific operations. Edge locations are examined in the next section of this module.' },
      { text: 'd. A service you can use to run AWS infrastructure in your own on-premises data center with a hybrid approach', correct: false,  expli:' • AWS Outposts is a service you can use to run AWS infrastructure, services, and tools in your own on-premises data center using a hybrid approach. AWS Outposts is explored later in this module.' }
    ],
	img: '',  
  },
  {
    question: '/Test AWS Cloud Practitioner Essentials/ Which statement is TRUE for AWS Global Infrastructure?',
    answers: [
      { text: 'a. A Region consists of a single Availability Zone.', correct: false,  expli:' ' },
      { text: 'b. An Availability Zone consists of two or more Regions.', correct: false,  expli:' ' },
	    { text: 'c. A Region consists of two or more Availability Zones.', correct: true,  expli:' The correct answer is A Region consists of two or more Availability Zones. For example, the South America (São Paulo) region is sa-east-1. It includes three Availability Zones: sa-east-1a, sa-east-1b, and sa-east-1c.' },
      { text: 'd. An Availability Zone consists of a single Region.', correct: false,  expli:' ' }
    ],
	img: '',  
  },
  {
    question: '/Test AWS Cloud Practitioner Essentials/ What factors should be considered when selecting a region? (Select TWO).',
    answers: [
      { text: 'a. Compliance with legal and data governance requirements', correct: true,  expli:' one correct answer is: Compliance with legal and data governance requirements' },
      { text: 'b. Proximity with customers', correct: true,  expli:' one correct answer is: Proximity with customers. Two other factors to consider when selecting a region are the prices and the services available in a region.' },
	    { text: 'c. Access to technical assistance 24/7', correct: false,  expli:' • The region does not determine the level of support you choose. AWS Support plans are discussed later in this course.' },
      { text: 'd. Possibility of assigning custom permissions to different users', correct: false,  expli:' • Assigning custom permissions to different users is a feature that is supported in all AWS Regions.' },
      { text: 'e. Access to the AWS Command Line Interface (AWS CLI)', correct: false,  expli:' • The AWS Command Line Interface (AWS CLI) is available in all AWS Regions.' },
    ],
	img: '',  
  },
  {
    question: '/Test AWS Cloud Practitioner Essentials/ Which statement best describes Amazon CloudFront?',
    answers: [
      { text: 'a. A service that allows you to run infrastructure with a hybrid cloud approach', correct: false,  expli:' • AWS Outposts is a service that allows you to run infrastructure with a hybrid cloud approach.' },
      { text: 'b. A serverless compute engine for containers', correct: false,  expli:' • AWS Fargate is a serverless compute engine for containers.' },
	    { text: 'c. A service that allows messages to be sent and received between software components via a queue.', correct: false,  expli:' • Amazon Simple Queue Service (Amazon SQS) is a service that allows you to send, store, and receive messages between software components through a queue.' },
      { text: 'd. A global content delivery service', correct: true,  expli:'The correct answer is A global content delivery service. Amazon CloudFront is a content delivery service. It uses a network of edge locations to cache content and deliver content to clients around the world. When content is cached, it is stored locally as a copy. This content can be video files, photos, web pages, etc. ' }
    ],
	img: '',  
  },
  {
    question: '/Test AWS Cloud Practitioner Essentials/ Which site uses Amazon CloudFront to cache copies of content for faster delivery to users in any location?',
    answers: [
      { text: 'a. Region', correct: false,  expli:' • A region is a separate geographic location with multiple locations isolated from each other.' },
      { text: 'b. Availability zone', correct: false,  expli:' • An Availability Zone is a completely isolated part of the overall AWS infrastructure.' },
	    { text: 'c. edge location', correct: true,  expli:' The correct answer is Edge location.' },
      { text: 'd. Source', correct: false,  expli:' • An origin is the server from which CloudFront gets the files. Some examples of CloudFront sources include Amazon Simple Storage Service (Amazon S3) buckets and web servers. Note: Amazon S3 will be covered in detail later in this course.' }
    ],
	img: '',  
  },
  {
    question: '/Test AWS Cloud Practitioner Essentials/ What action can you take with AWS Outposts?',
    answers: [
      { text: 'a. Automate the actions of AWS services and applications using scripts.', correct: false,  expli:' • The AWS Command Line Interface (AWS CLI) is used to automate the actions of AWS services and applications using scripts.' },
      { text: 'b. Access wizards and automated workflows to perform tasks on AWS services.', correct: false,  expli:' • The AWS Management Console includes wizards and workflows that you can use to complete tasks in AWS services.' },
	    { text: 'c. Develop AWS applications in supported programming languages.', correct: false,  expli:' • Software Development Kits (SDKs) allow you to develop AWS applications in supported programming languages.' },
      { text: 'd. Extend AWS infrastructure and services to your on-premises data center.', correct: true,  expli:' The correct answer is Extending AWS infrastructure and services to the on-premises data center.' }
    ],
	img: '',  
  },
  {
    question: '/Test AWS Cloud Practitioner Essentials/ Which statement best describes the default network access control list for an AWS account?',
    answers: [
      { text: 'a. It is stateless and denies all incoming and outgoing traffic.', correct: false,  expli:' ' },
      { text: 'b. It is stateful and allows all incoming and outgoing traffic.', correct: false,  expli:' ' },
	    { text: 'c. It is stateless and allows all incoming and outgoing traffic.', correct: true,  expli:' The correct answer is It is stateless and allows all incoming and outgoing traffic. Network access control lists (ACLs) perform stateless packet filtering. They do not remember anything and check the packets that cross the border of the subnet in each direction: incoming and outgoing. Every AWS account includes a default network ACL. When configuring the VPC, you can use your account\'s default network ACL or create a custom network ACL. By default, your account\'s default network ACL allows all incoming and outgoing traffic, but you can modify it and add your own rules. For custom network ACLs, all inbound and outbound traffic is denied until you add rules to specify which traffic to allow. Also, all network ACLs have an explicit deny rule. This rule ensures that if a packet does not match any of the other rules in the list, the packet is denied. ' },
      { text: 'd. It is stateful and denies all incoming and outgoing traffic.', correct: false,  expli:' ' }
    ],
	img: '',  
  },
  {
    question: '/Test AWS Cloud Practitioner Essentials/ Which statement best describes DNS resolution?',
    answers: [
      { text: 'a. Launch resources in a virtual network that you define', correct: false,  expli:' ' },
      { text: 'b. Storing local copies of content at edge locations around the world', correct: false,  expli:' ' },
	    { text: 'c. Connecting a VPC to the Internet', correct: false,  expli:' ' },
      { text: 'd. Translation a domain name to an IP address', correct: true,  expli:' The correct answer is Translation of a domain name to an IP address. For example, if you want to visit the AnyCompany website, you enter the domain name on the PC and this request is sent to a DNS server. The DNS server then asks the web server for the IP address that corresponds to the AnyCompany website. The web server responds by providing the IP address of the AnyCompany website, 192.0.2.0.' }
    ],
	img: '',  
  },
  {
    question: '/Test AWS Cloud Practitioner Essentials/ Your company has an application that uses Amazon EC2 instances to run the customer-facing website and Amazon RDS database instances to store customers\' personal information. How should the developer configure the VPC according to best practices?',
    answers: [
      { text: 'a. You must put your Amazon EC2 instances in a private subnet and your Amazon RDS DB instances in a public subnet.', correct: false,  expli:' ' },
      { text: 'b. You must put your Amazon EC2 instances in a public subnet and your Amazon RDS DB instances in a private subnet.', correct: true,  expli:' The correct answer is You should put your Amazon EC2 instances in a public subnet and your Amazon RDS DB instances in a private subnet. A subnet is a section of a VPC into which resources can be grouped based on operational or security needs. Subnets can be public or private. Public subnets contain resources that the public should have access to, such as an online store website. Private subnets contain resources that should only be accessed through the private network, such as a database that contains customers\' personal information and order histories.' },
	    { text: 'c. You must put your Amazon EC2 instances and Amazon RDS DB instances in a public subnet.', correct: false,  expli:' ' },
      { text: 'd. You must put your Amazon EC2 instances and Amazon RDS DB instances in a private subnet.', correct: false,  expli:' ' }
    ],
	img: '',  
  },
  {
    question: '/Test AWS Cloud Practitioner Essentials/ What component can be used to establish a dedicated private connection between your company\'s data center and AWS?',
    answers: [
      { text: 'a. private subnet', correct: false,  expli:' • A private subnet is a section of a VPC into which you can group resources that should only be accessed through the private network. Although it is private, it is not used to establish a connection between a data center and AWS.' },
      { text: 'b. dns', correct: false,  expli:' • DNS stands for Domain Name System, which is a directory used to match domain names to IP addresses.' },
	    { text: 'c. AWS Direct Connect', correct: true,  expli:' The correct answer is AWS Direct Connect.' },
      { text: 'd. Virtual Private Gateway', correct: false,  expli:' • A virtual private gateway allows you to create a VPN connection between your VPC and a private network, such as your company\'s data center. Although this connection is private and encrypted, it travels over the public Internet, not through a dedicated connection.' },
    ],
	img: '',  
  },
  {
    question: '/Test AWS Cloud Practitioner Essentials/ Which statement best describes security groups?',
    answers: [
      { text: 'a. They are stateful and deny all incoming traffic by default.', correct: true,  expli:' The correct answer is Security groups are stateful and deny all incoming traffic by default. Security groups have state. This means that they use previous patterns and traffic flows when evaluating new requests for an instance. By default, security groups deny all incoming traffic, but you can add custom rules to suit your security and operational needs.' },
      { text: 'b. They are stateful and allow all incoming traffic by default.', correct: false,  expli:' ' },
	    { text: 'c. They are stateless and deny all incoming traffic by default.', correct: false,  expli:' ' },
      { text: 'd. They are stateless and allow all incoming traffic by default.', correct: false,  expli:' ' }
    ],
	img: '',  
  },
  {
    question: '/Test AWS Cloud Practitioner Essentials/ What component is used to connect a VPC to the Internet?',
    answers: [
      { text: 'a. public subnet', correct: false,  expli:' • A public subnet is a section of a VPC that contains public resources.' },
      { text: 'b. edge location', correct: false,  expli:' • An edge location is a site that Amazon CloudFront uses to store cached copies of content for faster delivery to clients.' },
	    { text: 'c. security group', correct: false,  expli:' • A security group is a virtual firewall that controls traffic in and out of an Amazon EC2 instance.' },
      { text: 'd. internet gateway', correct: true,  expli:' The correct answer is Internet Gateway.' }
    ],
	img: '',  
  },
  {
    question: '/Test AWS Cloud Practitioner Essentials/ You want to store data that is accessed infrequently but must be immediately available when needed. What Amazon S3 storage class should I use?',
    answers: [
      { text: 'a. S3 Intelligent Tiering', correct: false,  expli:' In the S3 Intelligent-Tiering storage class, Amazon S3 monitors the access patterns of objects. If you haven\'t accessed an object for 30 consecutive days, Amazon S3 automatically moves it to the infrequent access tier, S3 Standard-IA. If you access an object in the infrequent access tier, Amazon S3 automatically moves it to the frequent access tier, S3 Standard.' },
      { text: 'b. S3 Glacier Deep Archive', correct: false,  expli:' ' },
	    { text: 'c. S3 Standard-IA', correct: true,  expli:' The correct answer is S3 Standard-IA. The S3 Standard-IA storage class is ideal for data that is accessed infrequently but requires high availability when needed. Both S3 Standard and S3 Standard-IA store data in a minimum of three Availability Zones. S3 Standard-IA provides the same level of availability as S3 Standard but at a lower storage price.' },
      { text: 'd. S3 Glacier', correct: false,  expli:' S3 Glacier and S3 Glacier Deep Archive are low-cost storage classes that are ideal for archiving data. They would not be the best option for this scenario, which requires high availability. You can recover objects stored in the S3 Glacier storage class in a matter of minutes to a few hours. By comparison, you can retrieve objects stored in the S3 Glacier Deep Archive storage class within 12 hours.' }
    ],
	img: '',  
  },
  {
    question: '/Test AWS Cloud Practitioner Essentials/ What are the scenarios in which I should use Amazon Relational Database Service (Amazon RDS)? (Select TWO).',
    answers: [
      { text: 'a. Running a serverless database', correct: false,  expli:' The other three answers (A, C, D)  are scenarios in which you should use Amazon DynamoDB.' },
      { text: 'b. Using SQL to organize data', correct: true,  expli:' one correct answer is: Using SQL to organize data' },
	    { text: 'c. Storing data in a key value database', correct: false,  expli:' ' },
      { text: 'd. Vertical scaling of up to 10 billion requests per day', correct: false,  expli:' ' },
      { text: 'e. Data storage in an Amazon Aurora database', correct: true,  expli:' one correct answer is: Data storage in an Amazon Aurora database' },
    ],
	img: '',  
  },
  {
    question: '/Test AWS Cloud Practitioner Essentials/ Which Amazon S3 storage classes are optimized for archived data? (Select TWO).',
    answers: [
      { text: 'a. S3 Standard', correct: false,  expli:' S3 Standard is an ideal storage class for frequently accessed data, not archived data.' },
      { text: 'b. S3 Glacier', correct: true,  expli:' one correct answer is: S3 Glacier' },
	    { text: 'c. S3 Intelligent Tiering', correct: false,  expli:' S3 Intelligent-Tiering monitors the access patterns of objects and automatically moves them between the S3 Standard and S3 Standard-IA storage classes. It is not designed to archive data.' },
      { text: 'd. S3 Standard-IA', correct: false,  expli:' S3 Standard-IA is ideal for data that is accessed infrequently but requires high availability when needed.' },
      { text: 'e. S3 Glacier Deep Archive', correct: true,  expli:' one correct answer is: S3 Glacier Deep Archive Objects stored in the S3 Glacier storage class can be retrieved in minutes to a few hours. By comparison, objects stored in the S3 Glacier Deep Archive storage class can be retrieved within 12 hours.' },
    ],
	img: '',  
  },
  {
    question: '/Test AWS Cloud Practitioner Essentials/ Which statement or statements are TRUE about Amazon EBS volumes and Amazon EFS file systems?',
    answers: [
      { text: 'a. EBS volumes store data in a single Availability Zone. Amazon EFS file systems store data in multiple Availability Zones.', correct: true,  expli:' The correct answer is EBS volumes store data within a single Availability Zone. Amazon EFS file systems store data in multiple Availability Zones. An EBS volume must be located in the same Availability Zone as the Amazon EC2 instance to which it is attached. Data in an Amazon EFS file system can be accessed simultaneously from all Availability Zones in the region in which the file system is located.' },
      { text: 'b. EBS volumes store data in multiple Availability Zones. Amazon EFS file systems store data in a single Availability Zone.', correct: false,  expli:' ' },
	    { text: 'c. EBS volumes and Amazon EFS file systems store data in a single Availability Zone. ', correct: false,  expli:' ' },
      { text: 'd. Both EBS volumes and Amazon EFS file systems store data in multiple Availability Zones.', correct: false,  expli:' ' }
    ],
	img: '',  
  },
  {
    question: '/Test AWS Cloud Practitioner Essentials/ Suppose you want to store data in an object storage service. Which AWS service is best for this type of storage?',
    answers: [
      { text: 'a. Amazon Managed Blockchain', correct: false,  expli:' Amazon Managed Blockchain is a service you can use to build and manage blockchain networks using open source frameworks. The blockchain is a distributed ledger system that allows multiple parties to execute transactions and share data without a central authority.' },
      { text: 'b. Amazon Elastic File System (Amazon EFS)', correct: false,  expli:'Amazon Elastic File System (Amazon EFS) is a scalable file system for use with AWS cloud services and on-premises resources. It does not store data like object storage. ' },
	    { text: 'c. Amazon Elastic Block Store (Amazon EBS)', correct: false,  expli:' Amazon Elastic Block Store (Amazon EBS) is a service that provides block-level storage volumes that you can use with Amazon EC2 instances.' },
      { text: 'd. Amazon Simple Storage Service (Amazon S3)', correct: true,  expli:'The correct answer is Amazon Simple Storage Service (Amazon S3). ' }
    ],
	img: '',  
  },
  {
    question: '/Test AWS Cloud Practitioner Essentials/ Which statement best describes Amazon DynamoDB?',
    answers: [
      { text: 'a. A service that allows you to run relational databases on AWS Cloud', correct: false,  expli:' A service that allows you to run relational databases in the AWS Cloud describes Amazon Relational Database Service (Amazon RDS).' },
      { text: 'b. A serverless key-value database service', correct: true,  expli:' The correct answer is A serverless key-value database service. Amazon DynamoDB is a key-value database service. It\'s serverless, which means you don\'t have to provision, patch, or manage servers.' },
	    { text: 'c. A service that you can use to migrate relational databases, nonrelational databases, and other types of data stores', correct: false,  expli:' A service that you can use to migrate relational databases, nonrelational databases, and other types of data stores describes AWS Database Migration Service (AWS DMS).' },
      { text: 'd. An enterprise-class relational database', correct: false,  expli:' An enterprise-class relational database describes Amazon Aurora.' }
    ],
	img: '',  
  },
  {
    question: '/Test AWS Cloud Practitioner Essentials/ What service is used to query and analyze data in a data warehouse?',
    answers: [
      { text: 'a. Amazon Redshift', correct: true,  expli:' The correct answer is Amazon Redshift. Amazon Redshift is a data warehousing service that you can use for big data analytics. Use Amazon Redshift to collect data from a variety of sources to help you understand data trends and relationships.' },
      { text: 'b. Amazon Neptune', correct: false,  expli:' Amazon Neptune is a graph database service. You can use Amazon Neptune to build and run applications that work with highly connected data sets, such as recommendation engines, fraud detection, and knowledge graphs.' },
	    { text: 'c. Amazon DocumentDB', correct: false,  expli:' Amazon DocumentDB is a document database service that supports MongoDB workloads.' },
      { text: 'd. Amazon ElastiCache', correct: false,  expli:' • Amazon ElastiCache is a service that adds caching layers to databases to help improve read times for common requests.' }
    ],
	img: '',  
  },
  {
    question: '/Test AWS Cloud Practitioner Essentials/ What tasks are the clients\' responsibility? (Select TWO).',
    answers: [
      { text: 'a. Network infrastructure maintenance', correct: false,  expli:' ' },
      { text: 'b. Application of software patches on Amazon EC2 instances', correct: true,  expli:' one correct answer is: Application of software patches on Amazon EC2 instances' },
	    { text: 'c. Implementation of physical security controls in data center', correct: false,  expli:' ' },
      { text: 'd. Setting permissions for Amazon S3 objects', correct: true,  expli:' one correct answer is: Setting permissions for Amazon S3 objects' },
      { text: 'e. Maintenance of servers running Amazon EC2 instances', correct: false,  expli:' The other three answers (A, C, E) are tasks that are the responsibility of AWS.' },
    ],
	img: '',  
  },
  {
    question: '/Test AWS Cloud Practitioner Essentials/ Let\'s say you\'re configuring Service Control Policies (SCPs) in AWS Organizations. What identities and resources can SCPs apply to? (Select TWO).',
    answers: [
      { text: 'a. IAM users', correct: false,  expli:' ' },
      { text: 'b. IAM groups', correct: false,  expli:' ' },
	    { text: 'c. An individual member account', correct: true,  expli:' one correct answer is: An individual member account' },
      { text: 'd. IAM roles', correct: false,  expli:' ' },
      { text: 'e. An organizational unit (OU)', correct: true,  expli:' one correct answer is: An organizational unit (OU) In AWS Organizations, you can apply service control policies (SCPs) to the organization root, an individual member account, or an organizational unit. An SCP affects all IAM users, groups, and roles in an account, including the AWS account root user. You can apply IAM policies to IAM users, groups, or roles. You can\'t apply an IAM policy to the AWS account root user.' },
    ],
	img: '',  
  },
  {
    question: '/Test AWS Cloud Practitioner Essentials/ What tasks can be completed in AWS Artifact? (Select TWO).',
    answers: [
      { text: 'a. Access AWS compliance reports on demand', correct: true,  expli:' one correct answer is: Access AWS compliance reports on demand.' },
      { text: 'b. Consolidate and manage multiple AWS accounts in one central location.', correct: false,  expli:' Consolidate and manage multiple AWS accounts in one central location – This task can be completed in AWS Organizations.' },
	    { text: 'c. Create users to allow people and applications to interact with AWS services and resources.', correct: false,  expli:' Create users to allow people and applications to interact with AWS services and resources – This task can be completed in AWS Identity and Access Management (IAM).' },
      { text: 'd. Set permissions for accounts by configuring Service Control Policies (SCPs).', correct: false,  expli:' Set permissions for accounts by configuring Service Control Policies (SCPs): This task can be completed in AWS Organizations.' },
      { text: 'e. Review, accept, and manage agreements with AWS.', correct: true,  expli:' one correct answer is: Review, accept, and manage agreements with AWS.' },
    ],
	img: '',  
  },
  {
    question: '/Test AWS Cloud Practitioner Essentials/ Which statement best describes an IAM policy?',
    answers: [
      { text: 'a. An authentication process that provides an additional layer of protection for your AWS account', correct: false,  expli:' Multi-Factor Authentication (MFA) is an authentication process that provides an additional layer of protection for your AWS account.' },
      { text: 'b. A document that grants or denies permissions for AWS services and resources', correct: true,  expli:' The correct answer is A document that grants or denies permissions for AWS services and resources. IAM policies give you the flexibility to customize user access levels to resources. For example, you can allow users to access all Amazon S3 buckets in your AWS account, or only a specific bucket.' },
	    { text: 'c. An identity that you can assume to gain temporary access to permissions', correct: false,  expli:' An IAM role is an identity that you can assume to gain temporary access to permissions.' },
      { text: 'd. The identity that is established when you first create an AWS account', correct: false,  expli:' The root user identity is the identity that is established when you first create an AWS account.' }
    ],
	img: '',  
  },
  {
    question: '/Test AWS Cloud Practitioner Essentials/ An employee needs temporary access to create multiple Amazon S3 buckets. What would be the best option for this task?',
    answers: [
      { text: 'a. AWS account root user', correct: false,  expli:' The AWS account root user is set when you first create an AWS account. As a best practice, do not use the root user for everyday tasks.' },
      { text: 'b. IAM group', correct: false,  expli:' Although IAM policies can be attached to an IAM group, this would not be the best option for this scenario because the employee should only be granted temporary permissions.' },
	    { text: 'c. IAM role', correct: true,  expli:' The correct answer is IAM role. An IAM role is an identity that you can assume to gain temporary access to permissions. When someone assumes an IAM role, they relinquish all the permissions they had in a previous role and assume the permissions of the new role. IAM roles are ideal for situations where access to services or resources must be granted temporarily rather than long-term.' },
      { text: 'd. Service Control Policy (SCP)', correct: false,  expli:' Service Control Policies (SCPs) allow you to centrally control the permissions of your organization\'s accounts. An SCP is not the best option for granting temporary leave to an individual employee.' }
    ],
	img: '',  
  },
  {
    question: '/Test AWS Cloud Practitioner Essentials/ Which statement best describes the principle of least privilege?',
    answers: [
      { text: 'a. Add an IAM user to at least one IAM group', correct: false,  expli:' ' },
      { text: 'b. Check a package\'s permissions against an access control list', correct: false,  expli:' ' },
	    { text: 'c. Grant only the permissions necessary to perform specific tasks', correct: true,  expli:' The correct answer is Grant only permissions necessary to perform specific job tasks. By granting permissions following the principle of least privilege, you prevent users or roles from having more permissions than necessary to perform specific job tasks. For example, cafeteria cashiers must have access to the cash register system. As a best practice, grant IAM users and roles a minimal set of permissions, and grant additional permissions as needed.' },
      { text: 'd. Perform a denial of service attack that originates from at least one device', correct: false,  expli:' ' }
    ],
	img: '',  
  },
  {
    question: '/Test AWS Cloud Practitioner Essentials/ Which service helps protect applications against Distributed Denial of Service (DDoS) attacks?',
    answers: [
      { text: 'a. Amazon Guard Duty', correct: false,  expli:' Amazon GuardDuty is a service that provides intelligent threat detection for AWS infrastructure and resources. Identifies threats by continuously monitoring network activity and account behavior in the AWS environment.' },
      { text: 'b. Amazon Inspector', correct: false,  expli:' Amazon Inspector checks applications for security vulnerabilities and deviations from security best practices, such as open access to Amazon EC2 instances and installations of vulnerable software versions.' },
	    { text: 'c. AWS Artifact', correct: false,  expli:' AWS Artifact is a service that provides on-demand access to AWS security and compliance reports and certain online agreements.' },
      { text: 'd. AWS Shield', correct: true,  expli:' The correct answer is AWS Shield. As network traffic reaches applications, AWS Shield uses various analysis techniques to detect potential DDoS attacks in real time and automatically mitigate them.' }
    ],
	img: '',  
  },
  {
    question: '/Test AWS Cloud Practitioner Essentials/ What task can AWS Key Management Service (AWS KMS) perform?',
    answers: [
      { text: 'a. Configure multi-factor authentication (MFA).', correct: false,  expli:'You can configure multi-factor authentication (MFA) in AWS Identity and Access Management (IAM). ' },
      { text: 'b. Update the password of the AWS account root user.', correct: false,  expli:' You can update the password of the AWS account root user in the AWS Management Console.' },
	    { text: 'c. Create cryptographic keys.', correct: true,  expli:'The correct answer is Create cryptographic keys. AWS Key Management Service (AWS KMS) allows you to perform encryption operations using cryptographic keys. A cryptographic key is a random string of digits used to lock (encrypt) and unlock (decrypt) data. You can use AWS KMS to create, manage, and use cryptographic keys. You can also control key usage across a wide range of services and applications. ' },
      { text: 'd. Assign permissions to users and groups.', correct: false,  expli:' You can assign permissions to users and groups in AWS Identity and Access Management (IAM).' }
    ],
	img: '',  
  },
  {
    question: '/Test AWS Cloud Practitioner Essentials/ What tasks can you accomplish with AWS CloudTrail? (Select TWO).',
    answers: [
      { text: 'a. Monitor AWS infrastructure and resources in real time', correct: false,  expli:' ' },
      { text: 'b. Track user activities and API requests across the entire AWS infrastructure', correct: true,  expli:'one correct answer is: Track user activities and API requests across the entire AWS infrastructure ' },
	    { text: 'c. View metrics and charts to monitor resource performance', correct: false,  expli:' ' },
      { text: 'd. Filter logs to facilitate operational analysis and troubleshooting', correct: true,  expli:' one correct answer is: Filter logs to help with operational analysis and troubleshooting' },
      { text: 'e. Configure automatic actions and alerts in response to metrics', correct: false,  expli:' The other answers (A, C, E ) are tasks that you can perform in Amazon CloudWatch.' },
    ],
	img: '',  
  },
  {
    question: '/Test AWS Cloud Practitioner Essentials/ What actions can you take with Amazon CloudWatch? (Select TWO).',
    answers: [
      { text: 'a. Monitor resource utilization and performance', correct: true,  expli:'one correct answer is: Monitor resource utilization and performance ' },
      { text: 'b. Receive real-time guidance to improve the AWS environment', correct: false,  expli:' AWS Trusted Advisor can receive real-time recommendations to improve the AWS environment.' },
	    { text: 'c. Compare infrastructure against AWS best practices in five categories', correct: false,  expli:' AWS Trusted Advisor can compare infrastructure against AWS best practices in five categories.' },
      { text: 'd. Access metrics from a single dashboard', correct: true,  expli:' one correct answer is: Access metrics from a single dashboard' },
      { text: 'e. Automatically detect unusual account activity', correct: false,  expli:' AWS CloudTrail can automatically detect unusual account activity' },
    ],
	img: '',  
  },
  {
    question: '/Test AWS Cloud Practitioner Essentials/ What service allows you to review the security of your Amazon S3 buckets by checking open access permissions?',
    answers: [
      { text: 'a. amazon cloudwatch', correct: false,  expli:' Amazon CloudWatch is a web service that allows you to monitor and manage various metrics of the resources running your applications.' },
      { text: 'b. AWS CloudTrail', correct: false,  expli:' AWS CloudTrail is a web service that allows you to review details of user activities and API calls that have occurred in the AWS environment.' },
	    { text: 'c. AWS Trusted Advisor ', correct: true,  expli:' The correct answer is AWS Trusted Advisor. AWS Trusted Advisor is a web service that inspects your AWS environment and provides real-time recommendations based on AWS best practices. The inspection includes security checks such as buckets from Amazon S3 with open access permissions.' },
      { text: 'd. Amazon Guard Duty', correct: false,  expli:'Amazon GuardDuty is a service that provides intelligent threat detection for the AWS environment and resources. Identifies threats by continuously monitoring network activity and account behavior in the AWS environment. ' }
    ],
	img: '',  
  },
  {
    question: '/Test AWS Cloud Practitioner Essentials/ What categories are included in the AWS Trusted Advisor dashboard? (Select TWO).',
    answers: [
      { text: 'a. Reliability', correct: false,  expli:' ' },
      { text: 'b. Performance ', correct: true,  expli:' one correct answer is: Performance' },
	    { text: 'c. Scalability', correct: false,  expli:' ' },
      { text: 'd. Elasticity', correct: false,  expli:' AWS Trusted Advisor continually inspects the AWS environment and provides best practice recommendations in five categories: cost optimization, performance, security, fault tolerance, and service limits.' },
      { text: 'e. Error tolerance', correct: true,  expli:' one correct answer is: Error tolerance' },
    ],
	img: '',  
  },
  {
    question: '/Test AWS Cloud Practitioner Essentials/ The AWS Free Tier includes offers that are available to new AWS customers for a specified period of time after your AWS enrollment date. What is the duration of this period?',
    answers: [
      { text: 'a. 3 months', correct: false,  expli:' ' },
      { text: 'b. 6 months', correct: false,  expli:' ' },
	    { text: 'c. 9 months', correct: false,  expli:' ' },
      { text: 'd. 12 months', correct: true,  expli:' The correct answer is 12 months. The AWS Free Tier consists of three offer types that allow customers to use AWS services at no cost: always free, 12 months free, and trials. For 12 months after you first sign up for an AWS account, you can take advantage of offers in the 12 Months Free category. Examples of offers in this category include specific Amazon S3 Standard storage amounts, Amazon EC2 compute time monthly hour thresholds, and Amazon CloudFront data transfer outbound amounts.' }
    ],
	img: '',  
  },
  {
    question: '/Test AWS Cloud Practitioner Essentials/ Which support plan includes all AWS Trusted Advisor verifications at the lowest cost?',
    answers: [
      { text: 'a. BASIC', correct: false,  expli:' ' },
      { text: 'b. developer', correct: false,  expli:' ' },
	    { text: 'c. business', correct: true,  expli:' The correct answer is Business. Only Business and Enterprise support plans include all AWS Trusted Advisor verifications. Of these two support plans, the Business support plan has a lower cost.' },
      { text: 'd. business', correct: false,  expli:' ' }
    ],
	img: '',  
  },
  {
    question: '/Test AWS Cloud Practitioner Essentials/ What action can you take with consolidated billing?',
    answers: [
      { text: 'a. Review how much your projected usage of AWS will cost at the end of the month.', correct: false,  expli:' Review how much your projected AWS usage will incur at the end of the month – You can do this in AWS Budgets.' },
      { text: 'b. Create a cost estimate for use cases on AWS.', correct: false,  expli:' Create a cost estimate for use cases on AWS – You can do this on the AWS Pricing Calculator.' },
	    { text: 'c. Combine usage across all accounts to receive volume pricing discounts.', correct: true,  expli:' The correct answer is Combine usage across all accounts to receive volume pricing discounts.' },
      { text: 'd. View and manage AWS costs and usage over time.', correct: false,  expli:'View and manage AWS costs and usage over time – You can do this in AWS Cost Explorer. ' }
    ],
	img: '',  
  },
  {
    question: '/Test AWS Cloud Practitioner Essentials/  What pricing tool is used to visualize, understand, and manage AWS costs and usage over time?',
    answers: [
      { text: 'a. AWS Pricing Calculator', correct: false,  expli:' The AWS Pricing Calculator allows you to create a cost estimate for use cases on AWS.' },
      { text: 'b. AWS Budgets', correct: false,  expli:' AWS Budgets allows you to create budgets to plan for service usage, service costs, and instance reservations. In AWS Budgets, you can also set custom alerts when usage exceeds (or is expected to exceed) the budgeted amount.' },
	    { text: 'c. AWS Cost Explorer', correct: true,  expli:' The correct answer is AWS Cost Explorer. AWS Cost Explorer includes a default report of costs and usage for the top five highest-cost AWS services in aggregate. You can apply custom filters and groups to analyze the data. For example, you can view resource usage by hour.' },
      { text: 'd. AWS Free Tier', correct: false,  expli:'The AWS Free Tier is a program that consists of three types of offers that allow customers to use AWS services at no cost: always free, 12 months free, and trials. ' }
    ],
	img: '',  
  },
  {
    question: '/Test AWS Cloud Practitioner Essentials/ Which pricing tool allows you to receive alerts when service usage exceeds the threshold you have defined?',
    answers: [
      { text: 'a. Billing Dashboard in the AWS Management Console', correct: false,  expli:' In the AWS Management Console\'s billing dashboard, you can view AWS bill details, such as your service costs by Region, your monthly spend to date, and more. However, you cannot set alerts from the billing panel.' },
      { text: 'b. AWS Budgets', correct: true,  expli:' The correct answer is AWS Budgets. In AWS Budgets, you can set custom alerts that notify you when your service usage exceeds (or is expected to exceed) your budgeted amount. Your budget can be based on cost or usage. For example, you can set an alert that will notify you when you have incurred costs of $100 in Amazon EC2 or 500,000 requests in AWS Lambda.' },
	    { text: 'c. AWS Free Tier', correct: false,  expli:' The AWS Free Tier is a program that consists of three types of offers that allow customers to use AWS services at no cost: always free, 12 months free, and trials.' },
      { text: 'd. AWS Cost Explorer', correct: false,  expli:' AWS Cost Explorer is a tool that allows you to view, understand, and manage AWS costs and usage over time.' }
    ],
	img: '',  
  },
  {
    question: '/Test AWS Cloud Practitioner Essentials/ Let\'s say your company wants to receive support from an AWS Technical Account Manager (TAM). Which support plan should I choose?',
    answers: [
      { text: 'a. developer', correct: false,  expli:' ' },
      { text: 'b. Enterprise', correct: true,  expli:' The correct answer is Enterprise. Technical Account Manager (TAM) is only available to AWS customers with an Enterprise support plan. A TAM provides guidance, architecture reviews, and ongoing communication with your business as you plan, deploy, and optimize applications.' },
	    { text: 'c. BASIC', correct: false,  expli:' ' },
      { text: 'd. business', correct: false,  expli:' ' }
    ],
	img: '',  
  },
  {
    question: '/Test AWS Cloud Practitioner Essentials/ What service or resource is used to find third-party software running on AWS?',
    answers: [
      { text: 'a. AWS Marketplace', correct: true,  expli:' The correct answer is AWS Marketplace. AWS Marketplace is a digital catalog that includes thousands of software listings from Independent Software Vendors. You can use the AWS Marketplace to find, try, and buy software that runs on AWS.' },
      { text: 'b. AWS Free Tier', correct: false,  expli:' The AWS Free Tier consists of offers that allow customers to use AWS services at no cost. These offers are related to AWS services, not third-party software that may be used on AWS.' },
	    { text: 'c. AWS Support', correct: false,  expli:' AWS Support is a resource that can answer questions about best practices, help troubleshoot problems, help you identify ways to optimize your use of AWS services, and more.' },
      { text: 'd. Billing Dashboard in the AWS Management Console', correct: false,  expli:' You can use the billing dashboard in the AWS Management Console to view details such as service costs by region, the top services your account uses, and projected billing costs. From the billing dashboard, you can also access other AWS billing tools, such as AWS Cost Explorer, AWS Budgets, and AWS Budgets Reports.' }
    ],
	img: '',  
  },
  {
    question: '/Test AWS Cloud Practitioner Essentials/ What perspective does the AWS Cloud Adoption Framework help you design, deploy, and optimize AWS infrastructure based on your business goals and perspectives?',
    answers: [
      { text: 'a. Business Perspective', correct: false,  expli:' The Business perspective helps you move from a model that separates IT and business strategies to a business model that integrates IT strategy.' },
      { text: 'b. Platform Perspective', correct: true,  expli:' The correct answer is Platform Perspective. The Platform perspective of the AWS Cloud Adoption Framework also includes principles for implementing new solutions and migrating on-premises workloads to the cloud.' },
	    { text: 'c. Operations Perspective', correct: false,  expli:' The Operations perspective focuses on operating and recovering IT workloads to meet the requirements of your business investors.' },
      { text: 'd. People Perspective', correct: false,  expli:' The People perspective helps Human Resources (HR) employees prepare teams for cloud adoption by updating organizational processes and staff skills to include cloud-based competencies.' }
    ],
	img: '',  
  },
  {
    question: '/Test AWS Cloud Practitioner Essentials/ What migration strategy involves switching to a different product?',
    answers: [
      { text: 'a. Refactor', correct: false,  expli:' Refactoring involves changing the way an application is designed and developed, typically by using cloud-native features.' },
      { text: 'b. Withdraw', correct: false,  expli:' Retire means removing an application that is no longer used or can be disabled.' },
	    { text: 'c. change platform', correct: false,  expli:' Changing the platform involves selectively optimizing aspects of an application for cloud benefits without changing the application\'s core architecture. It is also known as “transpose, touch up and transfer”.' },
      { text: 'd. Repurchase', correct: true,  expli:' The correct answer is Repurchase.Buyback involves replacing an existing application with a cloud-based version, such as software found on AWS Marketplace.' }
    ],
	img: '',  
  },
  {
    question: '/Test AWS Cloud Practitioner Essentials/ What is the storage capacity of Snowball Edge Storage Optimized?',
    answers: [
      { text: 'a. 40TB', correct: false,  expli:' ' },
      { text: 'b. 60TB', correct: false,  expli:' ' },
	    { text: 'c. 80TB', correct: true,  expli:' The correct answer is 80TB. Snowball Edge Storage Optimized is an appliance that allows you to transfer large amounts of data in and out of AWS. Provides 80TB of usable HDD storage.' },
      { text: 'd. 100TB', correct: false,  expli:' ' }
    ],
	img: '',  
  },
  {
    question: '/Test AWS Cloud Practitioner Essentials/ Which service allows you to quickly build, train, and deploy machine learning models?',
    answers: [
      { text: 'a. Amazon text', correct: false,  expli:' Amazon Textract is a Machine Learning service that automatically extracts text and data from scanned documents.' },
      { text: 'b. Amazon Lex', correct: false,  expli:' Amazon Lex is a service that allows you to create conversational interfaces using voice and text.' },
	    { text: 'c. AWS Dee Pracer', correct: false,  expli:' AWS DeePracer is a 1/18 scale autonomous racing car that you can use to test reinforcement learning models.' },
      { text: 'd. Amazon SageMaker', correct: true,  expli:' The correct answer is Amazon SageMaker. With Amazon SageMaker, you can quickly and easily get started on Machine Learning projects. You don\'t have to go through the traditional process of manually putting together separate tools and workflows.' }
    ],
	img: '',  
  },
  {
    question: '/Test AWS Cloud Practitioner Essentials/ What insight from the AWS Cloud Adoption Framework helps you structure permission selection and implementation?',
    answers: [
      { text: 'a. Governance Perspective ', correct: false,  expli:' The Governance perspective helps you identify and implement best practices for IT governance and support business processes with technology.' },
      { text: 'b. Security Perspective', correct: true,  expli:' The correct answer is Security perspective. The AWS Cloud Adoption Framework Security perspective also helps you identify areas of noncompliance and plan for ongoing security initiatives.' },
	    { text: 'c. Operations Perspective', correct: false,  expli:' The Operations perspective focuses on operating and recovering IT workloads to meet the requirements of your business investors.' },
      { text: 'd. Business Perspective', correct: false,  expli:' The Business perspective helps you move from a model that separates IT and business strategies to a business model that integrates IT strategy.' }
    ],
	img: '',  
  },
  {
    question: '/Test AWS Cloud Practitioner Essentials/ What strategies are included in the six application migration strategies? (Select TWO).',
    answers: [
      { text: 'a. Visit again', correct: false,  expli:' ' },
      { text: 'b. To hold back', correct: true,  expli:' one correct answer is: To hold back' },
	    { text: 'c. To remember', correct: false,  expli:' ' },
      { text: 'd. Redevelop', correct: false,  expli:' Application migration strategies are to rehost, replatform, refactor/rebuild, buy back, retain, and retire.' },
      { text: 'e. Rehost', correct: true,  expli:' one correct answer is:  Rehost' },
    ],
	img: '',  
  },
  {
    question: '/Test AWS Cloud Practitioner Essentials/ What is the storage capacity of AWS Snowmobile?',
    answers: [
      { text: 'a. 40 BP', correct: false,  expli:' ' },
      { text: 'b. 60 BP', correct: false,  expli:' ' },
	    { text: 'c. 80 BP', correct: false,  expli:' ' },
      { text: 'd. 100 BP', correct: true,  expli:' The correct answer is 100 PB. AWS Snowmobile is a service used to transfer up to 100 PB of data to AWS. Each Snowmobile is a 13.7 meter long shipping container that is pulled by a semi-trailer truck.' }
    ],
	img: '',  
  },
  {
    question: '/Test AWS Cloud Practitioner Essentials/ Which statement best describes Amazon Lex?',
    answers: [
      { text: 'a. A service that allows you to create conversational interfaces using voice and text', correct: true,  expli:' The correct answer is Amazon Lex. In Amazon Lex, you can quickly build, test, and deploy conversational chatbots for use in applications.' },
      { text: 'b. A Machine Learning service that automatically extracts text and data from scanned documents', correct: false,  expli:' A Machine Learning service that automatically extracts text and data from the scanned document describes Amazon Textract.' },
	    { text: 'c. A document database service compatible with MongoDB workloads', correct: false,  expli:' A document database service that supports MongoDB workloads describes Amazon DocumentDB.' },
      { text: 'd. A service that allows you to identify potentially fraudulent online activities', correct: false,  expli:' A service that allows you to identify potentially fraudulent online activity describes Amazon Fraud Detector.' }
    ],
	img: '',  
  },
  {
    question: '/Test AWS Cloud Practitioner Essentials/ Which pillar of the AWS Well-Architected Framework focuses on the ability of a workload to consistently and correctly perform its intended functions?',
    answers: [
      { text: 'a. Operational excellence', correct: false,  expli:' The operational excellence pillar includes the ability to run workloads efficiently, gain insight into operations, and continually improve support processes to deliver business value.' },
      { text: 'b. Performance efficiency', correct: false,  expli:' The performance efficiency pillar focuses on the efficient use of computing resources to meet system requirements and maintaining that efficiency as demand changes and technology evolves.' },
	    { text: 'c. Security', correct: false,  expli:' The security pillar includes the protection of data, systems and assets, and the use of cloud technologies to improve the security of workloads.' },
      { text: 'd. Reliability', correct: true,  expli:' The correct answer is Reliability.' }
    ],
	img: '',  
  },
  {
    question: '/Test AWS Cloud Practitioner Essentials/ Which process is an example of how to benefit from huge economies of scale?',
    answers: [
      { text: 'a. Deploy an app to multiple regions of the world', correct: false,  expli:' Deploy an application to multiple regions of the world: This process is an example of Go Global in Minutes.' },
      { text: 'b. Receive lower pay-as-you-go prices as a result of aggregate usage of services by AWS customers', correct: true,  expli:' The correct answer is: Receive lower pay-as-you-go prices as a result of aggregate usage of services by AWS customers. Since the usage of hundreds of thousands of customers can be aggregated in the cloud, providers like AWS can achieve greater economies of scale. Economies of scale translate into lower pay-per-use prices. ' },
	    { text: 'c. Pay for compute time as you use it instead of investing upfront costs in data centers', correct: false,  expli:' Pay for compute time as you use it instead of investing up-front costs in data centers: This process is an example of Shifting up-front costs to variable costs.' },
      { text: 'd. Scale out or scale out infrastructure capacity to meet demand', correct: false,  expli:'Scale out or scale out infrastructure capacity to meet demand: This process is an example of Stop Guessing Capacity. ' }
    ],
	img: '',  
  },
  {
    question: '/Test AWS Cloud Practitioner Essentials/ Which pillar of the AWS Well-Architected Framework includes the ability to run workloads efficiently and gain insight into operations?',
    answers: [
      { text: 'a. Cost optimization', correct: false,  expli:' The cost optimization pillar focuses on the ability to run systems to deliver business value at the lowest price.' },
      { text: 'b. operational excellence', correct: true,  expli:' The correct answer is Operational Excellence.' },
	    { text: 'c. performance efficiency', correct: false,  expli:' The performance efficiency pillar focuses on the efficient use of computing resources to meet system requirements and maintaining that efficiency as demand changes and technology evolves.' },
      { text: 'd. reliability', correct: false,  expli:' The reliability pillar focuses on the ability of a workload to consistently and correctly perform its intended functions.' }
    ],
	img: '',  
  },
  {
    question: '/Test AWS Cloud Practitioner Essentials/ What are the benefits of cloud computing? (Select TWO).',
    answers: [
      { text: 'a. Increase speed and agility.', correct: true,  expli:' one correct answer is: Increase speed and agility.' },
      { text: 'b. Benefit from small economies of scale.', correct: false,  expli:' ' },
	    { text: 'c. Change variable expenses for initial expenses. ', correct: false,  expli:' ' },
      { text: 'd. Maintain infrastructure capacity.', correct: false,  expli:' • Change the initial expenses for variable expenses. • Benefit from huge economies of scale • Stop guessing at capacity. • Increase speed and agility. • Stop spending money running and maintaining data centers. • Go global in minutes. ' },
      { text: 'e. Stop wasting money running and maintaining data centers.', correct: true,  expli:' one correct answer is: Stop spending money running and maintaining data centers.' },
    ],
	img: '',  
  },
  {
    question: '/Test AWS Cloud Practitioner Essentials/ Which statement is TRUE for AWS Lambda?',
    answers: [
      { text: 'a. The first step in using AWS Lambda is to provision a server.', correct: false,  expli:' ' },
      { text: 'b. You only pay for compute time while your code is running.', correct: true,  expli:' The correct answer is You only pay for compute time while the code is running. AWS Lambda is a service that allows you to run code without the need to provision and manage servers. By using AWS Lambda, you only pay for the compute time you consume. You will only be charged when your code is running. With AWS Lambda, you can run code for virtually any type of application or backend service, all without any administration.' },
	    { text: 'c. To use AWS Lambda, you must set up the servers that run your code.', correct: false,  expli:' ' },
      { text: 'd. Before using AWS Lambda, you must pay for estimated compute time in advance.', correct: false,  expli:' ' }
    ],
	img: '',  
  },
  {
    question: '/Test AWS Cloud Practitioner Essentials/ Suppose you want to send and receive messages between distributed application components. What service should I use?',
    answers: [
      { text: 'a. Amazon Route 53', correct: false,  expli:' Amazon Route 53 is a DNS web service. It offers developers and businesses a reliable way to direct end users to Internet applications hosted on AWS. Additionally, you can transfer DNS records of existing domain names currently managed by other domain registrars, or register new domain names directly on Amazon Route 53.' },
      { text: 'b. Amazon ElastiCache', correct: false,  expli:' Amazon ElastiCache is a service that adds caching layers to databases to help improve read times for common requests.' },
	    { text: 'c. Amazon Simple Queuing Service (Amazon SQS)', correct: true,  expli:' The correct answer is Amazon Simple Queue Service (Amazon SQS). Amazon SQS is a message queuing service. With Amazon SQS, you can send, store, and receive messages between software components of any volume size, without losing messages or requiring the availability of other services. In Amazon SQS, an application sends messages to a queue. A user or service gets a message from the queue, processes it, and then removes it from the queue.' },
      { text: 'd. AWS Snowball', correct: false,  expli:' AWS Snowball is a device that allows you to transfer large amounts of data in and out of AWS.' }
    ],
	img: '',  
  },
  {
    question: '/Test AWS Cloud Practitioner Essentials/ Which computing option reduces costs when you commit to using a uniform amount of computing over a period of 1 or 3 years?',
    answers: [
      { text: 'a. Spot Instances', correct: false,  expli:' Reserved Instances are a billing discount applied to the use of On-Demand Instances in your account. You can purchase Standard and Convertible Reserved Instances for a one-year or three-year term, and Scheduled Reserved Instances for a one-year term. Unlike savings plans, Reserved Instances do not require you to commit to consistent compute usage for the life of your contract.' },
      { text: 'b. Reserved Instances', correct: false,  expli:' Spot Instances are ideal for workloads that have flexible start and end times or can withstand interruptions. Spot Instances take advantage of unused EC2 compute capacity and offer you cost savings of up to 90% over On-Demand Instance prices.' },
	    { text: 'c. Dedicated Hosts', correct: false,  expli:' Dedicated hosts are physical servers with the capacity of EC2 instances fully dedicated to the use you want to give them. You can use existing software licenses per socket, per core, or per virtual machine to help maintain license compliance. You can buy On-Demand Dedicated Hosts or Reserved Dedicated Hosts. Of all the Amazon EC2 options covered in this course, Dedicated Hosts are the most expensive.' },
      { text: 'd. savings plans', correct: true,  expli:'The correct answer is Savings Plans. Amazon EC2 Savings Plans allow you to reduce computing costs by committing to consistent computing usage over a period of 1 or 3 years. This translates to savings of up to 72% compared to the costs of On-Demand Instances. Any usage up to commitment is charged at the discounted savings plan rate (for example, $10 per hour). Any usage over commitment is charged at regular On-Demand Instance rates.' }
    ],
	img: '',  
  },
  {
    question: '/Test AWS Cloud Practitioner Essentials/ What action can you take in Amazon CloudFront?',
    answers: [
      { text: 'a. Provision resources using programming languages or a text file.', correct: false,  expli:'Run the infrastructure in a hybrid cloud approach – This can be done with AWS Outposts. ' },
      { text: 'b. Provision an isolated section of the AWS Cloud to launch resources in a virtual network that you define.', correct: false,  expli:'Provision an isolated section of the AWS cloud to launch resources in a virtual network that you define – This can be done in Amazon Virtual Private Cloud (Amazon VPC). ' },
	    { text: 'c. Deliver content to customers through a global network of edge locations.', correct: true,  expli:' The correct answer is Deliver content to customers through a global network of edge locations. Amazon CloudFront is a content delivery service. It uses a network of edge locations to cache content and deliver content to clients around the world. When content is cached, it is stored locally as a copy. This content can be video files, photos, web pages, etc.' },
      { text: 'd. Run the infrastructure with a hybrid cloud approach.', correct: false,  expli:' Provisioning resources using programming languages or a text file – This can be done in AWS CloudFormation.' }
    ],
	img: '',  
  },
  {
    question: '/Test AWS Cloud Practitioner Essentials/ Which pillar of the AWS Well-Architected Framework focuses on using compute resources in a way that meets system requirements?',
    answers: [
      { text: 'a. operational excellence', correct: false,  expli:' The operational excellence pillar includes the ability to run workloads efficiently, gain insight into operations, and continually improve support processes to deliver business value.' },
      { text: 'b. reliability', correct: false,  expli:' The reliability pillar focuses on the ability of a workload to consistently and correctly perform its intended functions.' },
	    { text: 'c. performance efficiency', correct: true,  expli:' The correct answer is Performance Efficiency. Performance efficiency is the ability to use computing resources efficiently to meet system requirements and maintain that efficiency as demand changes and technology evolves.' },
      { text: 'd. Security', correct: false,  expli:' The security pillar focuses on the protection of data, systems and assets. It also focuses on the use of cloud technologies to improve workload security.' }
    ],
	img: '',  
  },
  {
    question: '/Test AWS Cloud Practitioner Essentials/ Suppose you want to store data in a key value database. What service should I use?',
    answers: [
      { text: 'a. Amazon RDS', correct: false,  expli:' Amazon Relational Database Service (Amazon RDS) and Amazon Aurora use Structured Query Language (SQL) to store and query data. They are not key value databases.' },
      { text: 'b. Amazon DocumentDB', correct: false,  expli:' Amazon DocumentDB is a document database service that supports MongoDB workloads.' },
	    { text: 'c. Amazon Aurora', correct: false,  expli:' ' },
      { text: 'd. Amazon DynamoDB', correct: true,  expli:' The correct answer is Amazon DynamoDB. Amazon DynamoDB is a key-value database service. A key values database might include data pairs such as “Name: John Smith,” “Address: Any 123 Street,” and “City: Any City.” In a key-value database, you can add or remove attributes from table elements at any time. Also, not all table elements have to have the same attributes.' }
    ],
	img: '',  
  },
  {
    question: '/Test AWS Cloud Practitioner Essentials/ Suppose you want Amazon S3 to monitor the access patterns of objects. What kind of storage should I use?',
    answers: [
      { text: 'a. S3 One Zone-IA', correct: false,  expli:'S3 One Zone-IA is ideal for data that is accessed infrequently and does not require high availability. ' },
      { text: 'b. S3 Glacier', correct: false,  expli:' S3 Glacier is a low-cost storage class ideal for archiving data. You can get objects stored in the S3 Glacier storage class in a matter of a few minutes to a few hours.' },
	    { text: 'c. S3 Standard-IA', correct: false,  expli:' The S3 Standard-IA storage class is ideal for data that is accessed infrequently but requires high availability when needed. Both S3 Standard and S3 Standard-IA store data in a minimum of three Availability Zones. S3 Standard-IA provides the same level of availability as S3 Standard but at a lower storage price.' },
      { text: 'd. S3 Intelligent Tiering', correct: true,  expli:' The correct answer is S3 Intelligent-Tiering. In the S3 Intelligent-Tiering storage class, Amazon S3 monitors the access patterns of objects. If you haven\'t accessed an object for 30 consecutive days, Amazon S3 automatically moves it to the infrequent access tier, S3 Standard-IA. If you access an object in the infrequent access tier, Amazon S3 automatically moves it to the frequent access tier, S3 Standard.' }
    ],
	img: '',  
  },
  {
    question: '/Test AWS Cloud Practitioner Essentials/ Let\'s say you want to store data on a volume attached to an Amazon EC2 instance. What service should I use?',
    answers: [
      { text: 'a. AWS Lambda', correct: false,  expli:' AWS Lambda is a service that allows you to run code without provisioning or managing servers.' },
      { text: 'b. Amazon Elastic Block Store (Amazon EBS)', correct: true,  expli:' The correct answer is Amazon Elastic Block Store (Amazon EBS). Amazon EBS provides block-level storage volumes that you can use with Amazon EC2 instances. If you stop or terminate an Amazon EC2 instance, all data on the attached EBS volume is still available.' },
	    { text: 'c. Amazon ElastiCache', correct: false,  expli:' Amazon ElastiCache is a service that adds caching layers to databases to help improve read times for common requests.' },
      { text: 'd. Amazon Simple Storage Service (Amazon S3)', correct: false,  expli:' Amazon Simple Storage Service (Amazon S3) is a service that provides object-level storage. Amazon S3 stores data as objects inside buckets.' }
    ],
	img: '',  
  },
  {
    question: '/Test AWS Cloud Practitioner Essentials/ What tool is used to automate the actions of AWS services and applications using scripts?',
    answers: [
      { text: 'a. Amazon QLDB', correct: false,  expli:' Amazon Quantum Ledger Database (Amazon QLDB) is a general ledger database service. You can use Amazon QLDB to review a complete history of all the changes that have been made to the data in your application.' },
      { text: 'b. Amazon Redshift', correct: false,  expli:' Amazon Redshift is a data warehousing service that you can use for big data analytics.  Provides the ability to collect data from many sources and helps you understand data trends and relationships.' },
	    { text: 'c. AWS Command Line Interface', correct: true,  expli:' The correct answer is AWS Command Line Interface. The AWS Command Line Interface (AWS CLI) allows you to control various AWS services directly from the command line of one tool. For example, you can use commands to launch an Amazon EC2 instance, connect an Amazon EC2 instance to a specific Auto Scaling group, and much more. The AWS CLI is available for Windows, macOS, and Linux users.' },
      { text: 'd. AWS Snowball', correct: false,  expli:'AWS Snowball is a device that allows you to transfer large amounts of data in and out of AWS. ' }
    ],
	img: '',  
  },
  {
    question: '/Test AWS Cloud Practitioner Essentials/ Which AWS Trusted Advisor category includes service limit checks and overutilized instances?',
    answers: [
      { text: 'a. Error tolerance', correct: false,  expli:' The Fault Tolerance category includes checks to help you improve application availability and redundancy.' },
      { text: 'b. Security', correct: false,  expli:' The Security category includes checks that help you review permissions and identify which AWS security features you should enable.' },
	    { text: 'c. Performance', correct: true,  expli:' The correct answer is performance. In this category, AWS Trusted Advisor also helps improve service performance by providing recommendations on how to take advantage of provisioned throughput.' },
      { text: 'd. Cost optimization', correct: false,  expli:' The Cost Optimization category includes checks for idle or unused resources that could be eliminated and provide cost savings.' }
    ],
	img: '',  
  },
  {
    question: '/Test AWS Cloud Practitioner Essentials/ Which statement best describes Elastic Load Balancing?',
    answers: [
      { text: 'a. A service that enables you to configure, manage, and scale a distributed in-memory or cache environment in the cloud', correct: false,  expli:'A service that allows you to configure, manage, and scale a distributed in-memory or cache environment in the cloud. This answer describes Amazon ElastiCache. ' },
      { text: 'b. A service that distributes incoming traffic among multiple destinations, such as Amazon EC2 instances ', correct: true,  expli:' The correct answer is A service that distributes incoming traffic across multiple destinations, such as Amazon EC2 instances. A load balancer acts as a single point of contact for all incoming web traffic for your Auto Scaling group. This means that as Amazon EC2 instances are added or removed in response to the amount of incoming traffic, these requests are first directed to the load balancer and then distributed to multiple resources that will handle them.' },
	    { text: 'c. A service that monitors your applications and automatically adds or removes capacity from resource pools in response to changing demand', correct: false,  expli:' A service that provides data that you can use to monitor your applications, optimize resource utilization, and respond to system-wide performance changes. This answer option describes Amazon CloudWatch. Although Elastic Load Balancing optimizes resource utilization by distributing incoming traffic among available resources, this would not be the best answer because Elastic Load Balancing does not provide all of the other listed features.' },
      { text: 'd. A service that provides data that you can use to monitor applications, optimize resource utilization, and respond to changes in system-wide performance', correct: false,  expli:'  A service that monitors applications and automatically adds or removes capacity from resource groups in response to changes in demand – This response describes AWS Auto Scaling.' }
    ],
	img: '',  
  },
  {
    question: '/Test AWS Cloud Practitioner Essentials/ Which statement best describes AWS Marketplace',
    answers: [
      { text: 'a. A resource that can answer questions about best practices and help troubleshoot', correct: false,  expli:' A resource that can answer best practice questions and help troubleshoot: This answer describes AWS Support.' },
      { text: 'b. An online tool that inspects the AWS environment and provides real-time guidance in accordance with AWS best practices', correct: false,  expli:' An online tool that inspects the AWS environment and provides real-time guidance in accordance with AWS best practices – This answer option describes AWS Trusted Advisor.' },
	    { text: 'c. A resource that provides guidance, architecture reviews, and ongoing communication with your business as you plan, deploy, and optimize applications', correct: false,  expli:' A resource that provides guidance, architecture reviews, and ongoing communication with your business as you plan, deploy, and optimize applications: This answer describes a Technical Account Manager (TAM).' },
      { text: 'd. A digital catalog that includes thousands of software listings from independent software vendors', correct: true,  expli:' The correct answer is a digital catalog that includes thousands of independent software vendor listings. You can use the AWS Marketplace to find, try, and buy software that runs on AWS.' }
    ],
	img: '',  
  },
  {
    question: '/Test AWS Cloud Practitioner Essentials/ Which statement best describes an Availability Zone?',
    answers: [
      { text: 'a. A separate geographic location with multiple locations isolated from each other ', correct: false,  expli:' A separate geographic location with multiple locations isolated from each other: This answer describes a region.' },
      { text: 'b. The server from which Amazon CloudFront gets the files', correct: false,  expli:' A site that Amazon CloudFront uses to store cached copies of content for faster delivery to users in any location. This answer describes an edge location.' },
	    { text: 'c. Site that Amazon CloudFront uses to store cached copies of content for faster delivery to users in any location', correct: false,  expli:' Server from which Amazon CloudFront gets files – This answer option describes an origin.' },
      { text: 'd. A fully isolated part of the global AWS infrastructure', correct: true,  expli:' The correct answer is A fully isolated part of the overall AWS infrastructure. An Availability Zone is a single data center or a group of data centers within a region. Availability zones are located tens of kilometers apart. This helps them provide interconnectivity to support services and applications running within a region.' }
    ],
	img: '',  
  },
  {
    question: '/Test AWS Cloud Practitioner Essentials/ What service is used to rapidly deploy and scale applications on AWS?',
    answers: [
      { text: 'a. AWS Snowball', correct: false,  expli:' AWS Snowball is a device that allows you to transfer large amounts of data in and out of AWS.' },
      { text: 'b. Amazon Cloud Front', correct: false,  expli:' Amazon CloudFront is a content delivery service.' },
	    { text: 'c. AWS Elastic Beanstalk', correct: true,  expli:' The correct answer is AWS Elastic Beanstalk. You load the application, and Elastic Beanstalk automatically manages the deployment details of capacity provisioning, load balancing, autoscaling, and application health monitoring.' },
      { text: 'd. AWS Outposts', correct: false,  expli:'AWS Outposts is a service that allows you to run infrastructure with a hybrid cloud approach. ' }
    ],
	img: '',  
  },
  {
    question: '/Test AWS Cloud Practitioner Essentials/ Which service allows you to create the workflows required for human review of machine learning predictions?',
    answers: [
      { text: 'a. Amazon Aurora', correct: false,  expli:' Amazon Aurora is an enterprise-class relational database.' },
      { text: 'b. Amazon text', correct: false,  expli:' Amazon Textract is a Machine Learning service that automatically extracts text and data from scanned documents.' },
	    { text: 'c. Amazon Lex', correct: false,  expli:' Amazon Lex is a service that allows you to create conversational interfaces using voice and text.' },
      { text: 'd. Amazon Augmented AI', correct: true,  expli:'The correct answer is Amazon Augmented AI. Amazon Augmented AI (Amazon A2I) provides built-in human review workflows for common Machine Learning use cases, such as content moderation and extracting text from documents. With Amazon A2I, you can also create your own workflows for Machine Learning models based on Amazon SageMaker or any other tool. ' }
    ],
	img: '',  
  },
  {
    question: '/Test AWS Cloud Practitioner Essentials/ In the S3 Intelligent-Tiering storage class, Amazon S3 moves objects between a high-access tier and a low-access tier. What storage classes are used for these tiers? (Select TWO).',
    answers: [
      { text: 'a. S3 One Zone-IA', correct: false,  expli:' ' },
      { text: 'b. S3 Glacier Deep Archive', correct: false,  expli:' ' },
	    { text: 'c. S3 Standard-IA', correct: true,  expli:' one correct answer is:  S3 Standard-IA' },
      { text: 'd. S3 Standard', correct: true,  expli:' one correct answer is: S3 Standard' },
      { text: 'e. S3 Glacier', correct: false,  expli:' In the S3 Intelligent-Tiering storage class, Amazon S3 monitors the access patterns of objects. If you haven\'t accessed an object for 30 consecutive days, Amazon S3 automatically moves it to the infrequent access tier, S3 Standard-IA. If you access an object in the infrequent access tier, Amazon S3 automatically moves it to the frequent access tier, S3 Standard.' },
    ],
	img: '',  
  },
  {
    question: '/Test AWS Cloud Practitioner Essentials/ What tasks are AWS responsible for? (Select TWO).',
    answers: [
      { text: 'a. Training of company employees on how to use AWS services', correct: false,  expli:' ' },
      { text: 'b. Configuring AWS infrastructure devices', correct: true,  expli:'one correct answer is: Configuring AWS infrastructure devices ' },
	    { text: 'c. Maintenance of virtualization infrastructure', correct: true,  expli:' one correct answer is: Maintenance of virtualization infrastructure' },
      { text: 'd. Creating IAM users and groups', correct: false,  expli:'The other three answers (A, D, E) are tasks that are the responsibility of the clients. ' },
      { text: 'e. Configuring security groups on Amazon EC2 instances', correct: false,  expli:' ' },
    ],
	img: '',  
  },
  {
    question: '/Test AWS Cloud Practitioner Essentials/ What component or service allows you to establish a dedicated private connection between your data center and the virtual private cloud (VPC)?',
    answers: [
      { text: 'a. Virtual Private Gateway', correct: false,  expli:' A virtual private gateway allows you to establish a virtual private network (VPN) connection between your VPC and a private network, such as an on-premises data center or internal corporate network. A virtual private gateway only allows traffic to the VPC if it is coming from an approved network.' },
      { text: 'b. Amazon Cloud Front', correct: false,  expli:' Amazon CloudFront is a content delivery service. It uses a network of edge locations to cache content and deliver it to clients around the world.' },
	    { text: 'c. internet gateway', correct: false,  expli:' An Internet gateway is a connection between a VPC and the Internet. Allows public Internet traffic to access a VPC.' },
      { text: 'd. AWS Direct Connect', correct: true,  expli:' The correct answer is AWS Direct Connect. AWS Direct Connect is a service that allows you to establish a dedicated private connection between your data center and the VPC. The private connection provided by AWS Direct Connect helps you reduce network costs and increase the amount of bandwidth that can travel across the network.' }
    ],
	img: '',  
  },
  {
    question: '/Test AWS Cloud Practitioner Essentials/ Which statement best describes Guardduty?',
    answers: [
      { text: 'a. A service that provides intelligent threat detection for AWS infrastructure and resources', correct: true,  expli:' The correct answer is A service that provides intelligent threat detection for AWS infrastructure and resources. AWS GuardDuty identifies threats by continuously monitoring network activity and account behavior in the AWS environment.' },
      { text: 'b. A service that helps protect applications against Distributed Denial of Service (DDoS) attacks', correct: false,  expli:' A service that helps protect applications against Distributed Denial of Service (DDoS) attacks – This answer describes AWS Shield .' },
	    { text: 'c. A service that allows you to monitor network requests reaching web applications', correct: false,  expli:' A service that allows you to monitor network requests arriving at web applications: This answer describes AWS WAF.' },
      { text: 'd. A service that checks for application security vulnerabilities and deviations from security best practices', correct: false,  expli:' A service that checks applications for security vulnerabilities and deviations from security best practices – This answer describes Amazon Inspector.' }
    ],
	img: '',  
  },
  {
    question: '/Test AWS Cloud Practitioner Essentials/ What service is used to run containerized applications on AWS?',
    answers: [
      { text: 'a. Amazon Aurora', correct: false,  expli:' Amazon Aurora is an enterprise-class relational database.' },
      { text: 'b. Amazon Elastic Kubernetes Service (Amazon EKS)', correct: true,  expli:' The correct answer is Amazon Elastic Kubernetes Service (Amazon EKS). Amazon EKS is a fully managed service that you can use to run Kubernetes on AWS. Kubernetes is open source software that enables you to deploy and manage containerized applications at scale. Containers provide you with a standard way to package your application\'s code and dependencies into a single object. Containers are frequently used for processes and workflows where there are essential requirements for security, reliability, and scalability.' },
	    { text: 'c. Amazon SageMaker', correct: false,  expli:' Amazon SageMaker is a service that allows you to quickly build, train, and deploy machine learning models.' },
      { text: 'd. Amazon Redshift', correct: false,  expli:' Amazon Redshift is a data warehousing service that you can use for big data analysis.' }
    ],
	img: '',  
  },
  {
    question: '/Test AWS Cloud Practitioner Essentials/ What migration strategy involves changing the way an application is designed and developed, typically by using cloud-native features?',
    answers: [
      { text: 'a. re-host', correct: false,  expli:' Rehosting involves moving an application to the cloud with little or no changes to the application itself. It is also known as “transport and transfer”.' },
      { text: 'b. change platform', correct: false,  expli:' Changing the platform involves selectively optimizing aspects of an application for cloud benefits without changing the application\'s core architecture. It is also known as transpose, touch up and transfer.' },
	    { text: 'c. Repurchase', correct: false,  expli:' Buyback means replacing an existing application with a cloud-based version, such as software found on AWS Marketplace.' },
      { text: 'd. Refactor ', correct: true,  expli:' The correct answer is Refactor.' }
    ],
	img: '',  
  },
  {
    question: '/Test AWS Cloud Practitioner Essentials/ Which support plans include access to all AWS Trusted Advisor verifications? (Select TWO).',
    answers: [
      { text: 'a. Business', correct: true,  expli:' one correct answer is: Business' },
      { text: 'b. developer', correct: false,  expli:' ' },
	    { text: 'c. Enterprise', correct: true,  expli:' one correct answer is: Enterprise' },
      { text: 'd. Basic', correct: false,  expli:' The Basic and Developer support plans provide access to a limited selection of AWS Trusted Advisor verifications.' },
      { text: 'e. AWS Free Tier', correct: false,  expli:' The AWS Free Tier is not a support plan. It is a program that consists of three types of offers that allow customers to use AWS services without incurring costs: Always free, 12 months free and Trials. ' },
    ],
	img: '',  
  },
  {
    question: '/Test AWS Cloud Practitioner Essentials/ Which service allows you to review details of user activities and API calls that have occurred in the AWS environment?',
    answers: [
      { text: 'a. AWS CloudTrail', correct: true,  expli:' The correct answer is AWS Lambda. With CloudTrail, you can view a complete history of user activity and API calls for applications and resources. Events are typically updated in CloudTrail 15 minutes after an API call. You can filter events by specifying the time and date an API call occurred, the user who requested the action, the type of resource that participated in the API call, and more.' },
      { text: 'b. Amazon Inspector', correct: false,  expli:' Amazon Inspector is a service that checks applications for security vulnerabilities and deviations from security best practices.' },
	    { text: 'c. AWS Trusted Advisor', correct: false,  expli:' AWS Trusted Advisor is an online tool that inspects the AWS environment and provides real-time guidance in accordance with AWS best practices.' },
      { text: 'd. amazon cloudwatch', correct: false,  expli:' Amazon CloudWatch is a service that provides data that you can use to monitor applications, optimize resource utilization, and respond to system-wide changes in performance.' }
    ],
	img: '',  
  },
  {
    question: '/Test AWS Cloud Practitioner Essentials/ What actions can you perform on Amazon Route 53? (Select TWO).',
    answers: [
      { text: 'a. Automate the deployment of workloads in the AWS environment.', correct: false,  expli:' Automate the deployment of workloads in the AWS environment – This can be done using AWS Quick Starts.' },
      { text: 'b. Access AWS security and compliance reports and select agreements online.', correct: false,  expli:' Access AWS Security and Compliance Reports and Special Agreements online – This can be done in AWS Artifact.' },
	    { text: 'c. Manage DNS records of domain names.', correct: true,  expli:' one correct answer is: Manage DNS records of domain names. Amazon Route 53 is a DNS web service. It offers developers and businesses a reliable way to direct end users to Internet applications hosted on AWS. Additionally, you can transfer DNS records of existing domain names currently managed by other domain registrars, or register new domain names directly on Amazon Route 53.' },
      { text: 'd. Connect user requests to AWS infrastructure and outside of AWS.', correct: true,  expli:' one correct answer is: Connect user requests to AWS infrastructure and outside of AWS.' },
      { text: 'e. Monitor applications and respond to system-wide performance changes.', correct: false,  expli:' Monitor applications and respond to system-wide performance changes – These actions can be performed in Amazon CloudWatch.' },
    ],
	img: '',  
  },
  {
    question: '/Test AWS Cloud Practitioner Essentials/ Let\'s say you\'re running an Amazon EC2 instance and you want to store data in an attached resource. The data is temporary and will not be retained for the long term. What resource should you use?',
    answers: [
      { text: 'a. Amazon S3 Bucket', correct: false,  expli:' Amazon S3 buckets cannot be attached to Amazon EC2 instances.' },
      { text: 'b. subnet', correct: false,  expli:' A subnet is a section of a virtual private cloud (VPC) into which resources can be grouped based on operational or security needs.' },
	    { text: 'c. Amazon Elastic Block Store (Amazon EBS) volume', correct: false,  expli:'Amazon EBS volumes are ideal for data that needs to be preserved. When an Amazon EC2 instance is stopped or terminated, all data on the attached EBS volume is still available. ' },
      { text: 'd. instance store', correct: true,  expli:' The correct answer is Instance Store. Instance stores are ideal for temporary data that does not need to be retained for the long term. When an Amazon EC2 instance is stopped or terminated, all data that has been written to the attached instance store is deleted. ' }
    ],
	img: '',  
  },
  {
    question: '/Test AWS Cloud Practitioner Essentials/ What perspective of the AWS Cloud Adoption Framework do you focus on IT workload recovery to satisfy your business stakeholders?',
    answers: [
      { text: 'a. Business Perspective', correct: false,  expli:' The Business perspective helps you move from a model that separates IT and business strategies to a business model that integrates IT strategy.' },
      { text: 'b. People Perspective', correct: false,  expli:' The People perspective helps Human Resources (HR) employees prepare teams for cloud adoption by updating organizational processes and staff skills to include cloud-based competencies.' },
	    { text: 'c. Operations Perspective', correct: true,  expli:'The correct answer is Operations Perspective. The AWS Cloud Adoption Framework Operations perspective also includes principles for operating in the cloud by using agile best practices. ' },
      { text: 'd. Governance Perspective', correct: false,  expli:' The Governance perspective helps you understand how to upgrade your staff skills and organizational processes needed to ensure enterprise governance in the cloud.' }
    ],
	img: '',  
  },
  {
    question: '/Test Lambda/ Which of the following are characteristics of Lambda? (Select FOUR options).',
    answers: [
      { text: 'a. You can run code without provisioning or managing servers.', correct: true,  expli:' correct (A, B, D, E) With AWS Lambda, the user can run code without provisioning or managing servers. Lambda initiates events on your behalf, scales automatically, and offers built-in monitoring and logging. You can write code in your preferred language. You have to configure the memory for it to work, but not the CPU. You don\'t have to work with the operating system. AWS provides the runtime operating environment.' },
      { text: 'b. Initiates functions on your behalf in response to events.', correct: true,  expli:' ' },
	    { text: 'c. No need to configure memory or CPU. ', correct: false,  expli:' ' },
      { text: 'd. Scale automatically.', correct: true,  expli:' ' },
      { text: 'e. Provides integrated monitoring and logging. ', correct: true,  expli:' ' },
      { text: 'f. You can update the operating system dynamically. ', correct: false,  expli:' ' }
    ],
	img: '',  
  },
  {
    question: '/Test Lambda/ Which statements about invocation models are correct? (Select THREE options).',
    answers: [
      { text: 'a. Amazon S3 triggers Lambda through an asynchronous push.', correct: true,  expli:' correct (A, B, E) Well done! Alexa is a synchronous event source, so Lambda will not try to retry the invocation.' },
      { text: 'b. Amazon API Gateway triggers Lambda synchronously.', correct: true,  expli:' ' },
	    { text: 'c. When Alexa is the event source, Lambda will make three attempts to call the function before putting the failed call on the dead-letter queue.', correct: false,  expli:' ' },
      { text: 'd. DynamoDB must have an execution role to invoke Lambda.', correct: false,  expli:' ' },
      { text: 'e. Amazon SQS triggers Lambda with the probe invocation model.', correct: true,  expli:' ' },
    ],
	img: '',  
  },
  {
    question: '/Test Lambda/ What IAM entities must be included in an execution role for a Lambda function to interact with other services, such as DynamoDB? (Select TWO options).',
    answers: [
      { text: 'a. IAM policy that defines the actions that can be performed within DynamoDB', correct: true,  expli:' correct (A, B) You need both the IAM policy that defines the actions that Lambda can perform, and a trust policy that grants Lambda the “AssumeRole” permission. You do not need to create any IAM users or groups to allow Lambda to take action.' },
      { text: 'b. Trust policy that grants Lambda “AssumeRole” permission to act on DynamoDB', correct: true,  expli:' ' },
	    { text: 'c. IAM group that defines the users of the Lambda function', correct: false,  expli:' ' },
      { text: 'd. IAM user with administrator permissions for Lambda and DynamoDB', correct: false,  expli:' ' }
    ],
	img: '',  
  },
  {
    question: '/Test Lambda/ Which of these statements describes a resource policy? (Select THREE options).',
    answers: [
      { text: 'a. Must be chosen or created when creating a Lambda function', correct: false,  expli:' ' },
      { text: 'b. You can give Amazon S3 permission to trigger a Lambda function', correct: true,  expli:'  correct (B, D, E)  A resource policy determines who is allowed in (who can activate your feature, such as Amazon S3) and can be used to grant access to all accounts. An execution role must be created or selected when creating your function, and it controls what Lambda can do (such as write to a DynamoDB table). Includes a trust policy with AssumeRole.' },
	    { text: 'c. You can give Lambda permission to write data to a DynamoDB table ', correct: false,  expli:' ' },
      { text: 'd. You can grant access to the Lambda function in all AWS accounts', correct: true,  expli:' ' },
      { text: 'e. Determines who has access to invoke the function', correct: true,  expli:' ' },
      { text: 'f. Determine what Lambda can do ', correct: false,  expli:' ' }
    ],
	img: '',  
  },
  {
    question: '/Test Lambda/ What is the best purpose of creating using the AWS Management Console?',
    answers: [
      { text: 'a. Small standalone apps under 10MB', correct: false,  expli:' ' },
      { text: 'b. Simple single function apps without custom libraries and experimentation', correct: true,  expli:' Very well! The Lambda Management Console is best for simple functions without custom libraries, and is a great way to start experimenting with Lambda.' },
	    { text: 'c. Packages larger than 10 MB or part of managed continuous integration and delivery (CI/CD) applications', correct: false,  expli:' ' }
    ],
	img: '',  
  },
  {
    question: '/Test Lambda/ A developer has been asked to troubleshoot a Lambda function that is in production. You have been told that it runs for 5 minutes and have been asked to reduce the duration to save on billable costs. What actions should the developer take? (Select THREE options).',
    answers: [
      { text: 'a. Test the function from the console once to confirm that it takes 5 minutes.', correct: false,  expli:' ' },
      { text: 'b. Confirm if 5 minutes is the typical duration through production monitoring.', correct: true,  expli:' correct (B, D, E) A developer must ensure that a duration of 5 minutes does not reflect a single invocation. Instead of running it once from the console, you should examine how it actually runs in production. Reducing the wait time would save costs, but would likely mean that the function would frequently fail to complete. A best practice is to experiment with different memory configurations and estimate whether a higher memory configuration would actually be less expensive. In addition, it is possible to determine if there are any unnecessary components in the function itself that could be removed to speed up its initialization.' },
	    { text: 'c. Decrease the waiting time to 4 minutes.', correct: false,  expli:' ' },
      { text: 'd. Try higher memory configurations and compare the duration and cost of each configuration.', correct: true,  expli:' ' },
      { text: 'e. Check if there are any unnecessary SDK components in the deployment package.', correct: true,  expli:' ' },
    ],
	img: '',  
  },
  {
    question: '/Test Lambda/ What are some of the reasons a developer would define a concurrency limit (or reservation) for a function? (Select THREE options).',
    answers: [
      { text: 'a. Manage costs', correct: true,  expli:'correct (A, B, C) These are all reasons to set a concurrency reservation for a function.' },
      { text: 'b. Regulate the time it takes to process a batch of events', correct: true,  expli:' ' },
	    { text: 'c. Associate the limit with a lower level resource', correct: true,  expli:' ' },
      { text: 'd. Help CloudWatch track log events', correct: false,  expli:' ' },
      { text: 'e. Ensure that Amazon Simple Queue Service (Amazon SQS) queues are cleaned up efficiently', correct: false,  expli:' ' },
      { text: 'f. Limit the memory used', correct: false,  expli:' ' },
    ],
	img: '',  
  },
  {
    question: '/Test Lambda/ Which statements are true? (Select THREE options). ',
    answers: [
      { text: 'a. When a Lambda function is created, only one version exists: the version $LATEST.', correct: true,  expli:' correct (A, D, E) You can reference any version with an alias, a version, or an alias in the Amazon Resource Name (ARN), and when you create a Lambda function, only the $Latest version exists. ' },
      { text: 'b. Version control is a requirement for Lambda functions.', correct: false,  expli:' ' },
	    { text: 'c. You can specify a version control number scheme that Lambda will use.', correct: false,  expli:' ' },
      { text: 'd. You can reference any version with an alias.', correct: true,  expli:' Now that you know how to deploy and test your serverless applications, it\'s important to verify that your applications run efficiently and smoothly. ' },
      { text: 'e. You can reference a version or an alias in the Amazon Resource Name (ARN).', correct: true,  expli:' To do this, you need to monitor its performance and security. In the next lesson, you\'ll learn how to monitor and troubleshoot Lambda functions.' },
    ],
	img: '',  
  },
  {
    question: '/Test DíA 9-MÓDULO 3.  ARCHITECTING ON AWS/ Which of the following are characteristics of containers? (Select TWO.)',
    answers: [
      { text: 'a. Portable and scalable', correct: true,  expli:' correct A Portable and scalable' },
      { text: 'b. Requires a hypervisor', correct: false,  expli:' ' },
	    { text: 'c. Automatic', correct: false,  expli:' ' },
      { text: 'd. Repeatable', correct: true,  expli:' correct D Repeatable' },
      { text: 'e. Each requires its own operating system', correct: false,  expli:' ' },
    ],
	img: '',  
  }, 
  {
    question: '/Test DíA 9-MÓDULO 3.  ARCHITECTING ON AWS/ Containers in Amazon ECS are logically organized in:',
    answers: [
      { text: 'a. A cluster', correct: true,  expli:' correct A,A cluster ' },
      { text: 'b. Pods', correct: false,  expli:' ' },
	    { text: 'c. EBS volumes', correct: false,  expli:' ' },
      { text: 'd. Amazon S3', correct: false,  expli:' ' }
    ],
	img: '',  
  }, 
  {
    question: '/Test DíA 9-MÓDULO 3.  ARCHITECTING ON AWS/ Which of the following are characteristics of microservices? (Select TWO.)',
    answers: [
      { text: 'a. Loosely coupled', correct: true,  expli:' correct A Loosely coupled' },
      { text: 'b. Redundant', correct: false,  expli:' ' },
	    { text: 'c. Autonomous and independent', correct: true,  expli:' correct C Autonomous and independent' },
      { text: 'd. Tightly integrated and dependent', correct: false,  expli:' ' },
      { text: 'e. Interdependent components', correct: false,  expli:' ' },
    ],
	img: '',  
  }, 
  {
    question: '/Test DíA 9-MÓDULO 3.  ARCHITECTING ON AWS/ Why would you choose to deploy your containers to AWS Fargate over Amazon EC2?',
    answers: [
      { text: 'a. To take control of your infrastructure', correct: false,  expli:' ' },
      { text: 'b. To avoid manual infrastructure updates', correct: true,  expli:' correct B To avoid manual infrastructure updates ' },
	    { text: 'c. To optimize price for a large load', correct: false,  expli:' ' },
      { text: 'd. To manage your own patches and updates', correct: false,  expli:' ' }
    ],
	img: '',  
  }, 
  {
    question: '/Test 16p Cuestionario 9 - 1  DíA 1-MÓDULO 3.  ARCHITECTING ON AWS/ How can you prevent Stacks from being accidentally deleted? Select one:',
    answers: [
      { text: 'a. Apply an IAM policy to all users to prevent CloudFormation stack deletion API', correct: false,  expli:' ' },
      { text: 'b. Use Termination Protection ', correct: true,  expli:' The correct answer is: Use Termination Protection' },
	    { text: 'c. Protect the CloudFormation templates with passwords stored in SSM Parameter Store', correct: false,  expli:' ' }
    ],
	img: '',  
  }, 
  {
    question: '/Test 16p Cuestionario 9 - 2  DíA 1-MÓDULO 3.  ARCHITECTING ON AWS/ In EKS a user manages both master nodes and worker nodes Select one:',
    answers: [
      { text: 'a.  Verdadero', correct: false,  expli:' ' },
      { text: 'b.  Falso ', correct: true,  expli:'La respuesta correcta es Falso'  }
    ],
	img: '',  
  }, 
  {
    question: '/Test 16p Cuestionario 9 - 3  DíA 1-MÓDULO 3.  ARCHITECTING ON AWS/ Which permission is needed to give a user admin privileges in AWS Elastic Container Registry? Select one:',
    answers: [
      { text: 'a. AmazonECRContainerRegistry', correct: false,  expli:' ' },
      { text: 'b. AmazonEC2ContainerRegistryFullAccess', correct: true,  expli:' The correct answer is: AmazonEC2ContainerRegistryFullAccess' },
	    { text: 'c. AmazonECRContainerRegistryFullAccess ', correct: false,  expli:' ' },
      { text: 'd. AmazonEC2ContainerRegistry', correct: false,  expli:' ' }
    ],
	img: '',  
  }, 
  {
    question: '/Test 16p Cuestionario 9 - 4  DíA 1-MÓDULO 3.  ARCHITECTING ON AWS/ The development department in your organization need to quickly access a platform for running Docker containers. The platform service should be fully managed. Which AWS service should you provision for them? Select one:',
    answers: [
      { text: 'a. Amazon Elastic Container Service (ECS) with the EC2 launch type', correct: false,  expli:' ' },
      { text: 'b. Amazon Elastic Kubernetes Service (EKS) ', correct: false,  expli:' ' },
	    { text: 'c. Amazon Elastic Container Registry (ECR)', correct: false,  expli:' ' },
      { text: 'd. Amazon Elastic Container Service (ECS) with the Fargate launch type', correct: true,  expli:' The correct answer is: Amazon Elastic Container Service (ECS) with the Fargate launch type' }
    ],
	img: '',  
  }, 
  {
    question: '/Test 16p Cuestionario 9 - 5  DíA 1-MÓDULO 3.  ARCHITECTING ON AWS/ What are the main characteristics of a monolithic application? Select one:',
    answers: [
      { text: 'a. Loosely coupled', correct: false,  expli:' ' },
      { text: 'b. Independently deployable', correct: false,  expli:' ' },
	    { text: 'c. User interface and business logic are combined on a single platform ', correct: true,  expli:' The correct answer is: User interface and business logic are combined on a single platform' },
      { text: 'd. Organized around business capabilities', correct: false,  expli:' ' }
    ],
	img: '',  
  }, 
  {
    question: '/Test 16p Cuestionario 9 - 6  DíA 1-MÓDULO 3.  ARCHITECTING ON AWS/ Using which component can you enable auto scaling for ECS containers? Select one:',
    answers: [
      { text: 'a. Service ', correct: true,  expli:'The correct answer is: Service ' },
      { text: 'b. Cluster', correct: false,  expli:' ' },
	    { text: 'c. Task', correct: false,  expli:' ' },
      { text: 'd. Image', correct: false,  expli:' ' }
    ],
	img: '',  
  }, 
  {
    question: '/Test 16p Cuestionario 9 - 7  DíA 1-MÓDULO 3.  ARCHITECTING ON AWS/ What is a container registry? Select one:',
    answers: [
      { text: 'a. A private storage location for container images ', correct: false,  expli:' ' },
      { text: 'b. A location to store and distribute container images', correct: true,  expli:' The correct answer is: A location to store and distribute container images' },
	    { text: 'c. A container Domain Name System (DNS) service that is used during the creation of public containers', correct: false,  expli:' ' },
      { text: 'd. A management service used to register containers to a cluster', correct: false,  expli:' ' }
    ],
	img: '',  
  }, 
  {
    question: '/Test 16p Cuestionario 9 - 8  DíA 1-MÓDULO 3.  ARCHITECTING ON AWS/ You are using CloudFormation to deploy test environments on the fly, and these environments include an RDS database. You want the database to go away on stack deletion, but the company policy is to keep the data for further analysis if needed. What should you do? Select one:',
    answers: [
      { text: 'a. Enable Termination Protection on the stack', correct: false,  expli:' ' },
      { text: 'b. Add a DeletionPolicy=Snapshot to the RDS resource', correct: true,  expli:' The correct answer is: Add a DeletionPolicy=Snapshot to the RDS resource' },
	    { text: 'c. Add a DeletionPolicy=Delete to the RDS resource', correct: false,  expli:' ' },
      { text: 'd. Add a DeletionPolicy=Retain to the RDS resource', correct: false,  expli:' ' }
    ],
	img: '',  
  }, 
  {
    question: '/Test 16p Cuestionario 9 - 9  DíA 1-MÓDULO 3.  ARCHITECTING ON AWS/ Which statements are correct? Select one or more than one:',
    answers: [
      { text: 'a. Kubernetes is highly extensible and has a large, vibrant ecosystem. ', correct: true,  expli:'correct  Kubernetes is highly extensible and has a large, vibrant ecosystem.' },
      { text: 'b. Kubernetes is a closed-source, proprietary system.', correct: false,  expli:' ' },
	    { text: 'c. Kubernetes is on-premises network-attached storage (NAS) solution.', correct: false,  expli:' ' },
      { text: 'd. Kubernetes is often combined with declarative configuration and automation. ', correct: true,  expli:'correct  Kubernetes is often combined with declarative configuration and automation.' }
    ],
	img: '',  
  }, 
  {
    question: '/Test 16p Cuestionario 9 - 10  DíA 1-MÓDULO 3.  ARCHITECTING ON AWS/ Which tool can be used to build container images locally? Select one:',
    answers: [
      { text: 'a. amazon build', correct: false,  expli:' ' },
      { text: 'b. aws build', correct: false,  expli:' ' },
	    { text: 'c. docker build ', correct: true,  expli:' The correct answer is: docker build' },
      { text: 'd. docker ps', correct: false,  expli:' ' }
    ],
	img: '',  
  }, 
  {
    question: '/Test 16p Cuestionario 9 - 11  DíA 1-MÓDULO 3.  ARCHITECTING ON AWS/ Which Kubernetes object represents containers that run on a cluster? Select one:',
    answers: [
      { text: 'a. Pod ', correct: true,  expli:' The correct answer is: Pod' },
      { text: 'b. Task', correct: false,  expli:' ' },
	    { text: 'c. Controller', correct: false,  expli:' ' },
      { text: 'd. Service', correct: false,  expli:' ' }
    ],
	img: '',  
  }, 
  {
    question: '/Test 16p Cuestionario 9 - 12  DíA 1-MÓDULO 3.  ARCHITECTING ON AWS/ Select the true statements about containers and virtual machines (VMs).  Select one or more than one:',
    answers: [
      { text: 'a. Containers and VMs do not use images for backup, restoration, and duplication of the application environment.', correct: false,  expli:' ' },
      { text: 'b. Containers and VMs both use images for backup, restoration, and duplication of the application environment. ', correct: true,  expli:'correct  Containers and VMs both use images for backup, restoration, and duplication of the application environment.' },
	    { text: 'c. Containers and VMs do not provide isolation for application environments.', correct: false,  expli:' ' },
      { text: 'd. Containers and VMs both enable multiple environments to exist within the same underlying hardware environment. ', correct: true,  expli:'correct  Containers and VMs both enable multiple environments to exist within the same underlying hardware environment.' },
      { text: 'e. Containers and VMs both provide isolation for application environments.', correct: true,  expli:'correct  Containers and VMs both provide isolation for application environments.' },
      { text: 'f. Containers and VMs both facilitate decoupling of the application environments from the underlying hardware.', correct: true,  expli:'correct  Containers and VMs both facilitate decoupling of the application environments from the underlying hardware.' },
      { text: 'g. Containers and VMs both use their own guest operating system per instantiation.', correct: false,  expli:' ' }
    ],
	img: '',  
  }, 
  {
    question: '/Test 16p Cuestionario 9 - 13  DíA 1-MÓDULO 3.  ARCHITECTING ON AWS/ Which networking mode does AWS Fargate support? Select one:',
    answers: [
      { text: 'a. host', correct: false,  expli:' ' },
      { text: 'b. docker-network ', correct: false,  expli:' ' },
	    { text: 'c. awsvpc', correct: true,  expli:' The correct answer is: awsvpc' },
      { text: 'd. bridge', correct: false,  expli:' ' }
    ],
	img: '',  
  }, 
  {
    question: '/Test 16p Cuestionario 9 - 14  DíA 1-MÓDULO 3.  ARCHITECTING ON AWS/ When using Amazon Elastic Container Service (Amazon ECS), each task definition can only have one container. Select one:',
    answers: [
      { text: 'a. Verdadero', correct: false,  expli:' ' },
      { text: 'b. Falso ', correct: true,  expli:' La respuesta correcta es Falso' }
    ],
	img: '',  
  }, 
  {
    question: '/Test 16p Cuestionario 9 - 15  DíA 1-MÓDULO 3.  ARCHITECTING ON AWS/ What is the name of the file that contains instructions on how to build a docker container? Select one:',
    answers: [
      { text: 'a. Docker', correct: false,  expli:' ' },
      { text: 'b. Dockerfile ', correct: true,  expli:' The correct answer is: Dockerfile' },
	    { text: 'c. buildspec.yaml', correct: false,  expli:' ' },
      { text: 'd. requirements.txt', correct: false,  expli:' ' }
    ],
	img: '',  
  }, 
  {
    question: '/Test 16p Cuestionario 9 - 16  DíA 1-MÓDULO 3.  ARCHITECTING ON AWS/ What CloudFormation feature can you use to detect changes made to your stack resources outside CloudFormation? Select one:',
    answers: [
      { text: 'a. Pseudo Parameters ', correct: false,  expli:' ' },
      { text: 'b. StackSet', correct: false,  expli:' ' },
	    { text: 'c. ChangeSets', correct: false,  expli:' ' },
      { text: 'd. CloudFormation Drift', correct: true,  expli:' The correct answer is: CloudFormation Drift' }
    ],
	img: '',  
  }, 
  {
    question: '/Test 20p Cuestionario 10 - 1  DíA 1-MÓDULO 3.  ARCHITECTING ON AWS/ Which of the following statements are true with respect to VPC? (choose multiple)',
    answers: [
      { text: 'a. A route with target “local” on the route table can be edited to restrict traffic within VPC. ', correct: false,  expli:' ' },
      { text: 'b. A subnet can have multiple route tables associated with it.', correct: false,  expli:' ' },
	    { text: 'c. Subnet’s IP CIDR block can be same as the VPC CIDR block. ', correct: true,  expli:' a correct answer is: Subnet’s IP CIDR block can be same as the VPC CIDR block.' },
      { text: 'd. A network ACL can be associated with multiple subnets.', correct: true,  expli:' A network ACL can be associated with multiple subnets.' }
    ],
	img: '',  
  }, 
  {
    question: '/Test 20p Cuestionario 10 - 2  DíA 1-MÓDULO 3.  ARCHITECTING ON AWS/ A user has created a VPC with public and private subnets using the VPC wizard. Which of the below mentioned statements is true in this scenario? Select one:',
    answers: [
      { text: 'a. AWS VPC will automatically create a NAT instance with the micro size', correct: false,  expli:' ' },
      { text: 'b. VPC bounds the main route table with a public subnet and a custom route table with a private subnet', correct: false,  expli:' ' },
	    { text: 'c. User has to manually create a NAT instance ', correct: false,  expli:' ' },
      { text: 'd. VPC bounds the main route table with a private subnet and a custom route table with a public subnet', correct: true,  expli:' La respuesta correcta es: VPC bounds the main route table with a private subnet and a custom route table with a public subnet' }
    ],
	img: '',  
  }, 
  {
    question: '/Test 20p Cuestionario 10 - 5  DíA 1-MÓDULO 3.  ARCHITECTING ON AWS/ You have successfully set up a VPC peering connection in your account between two VPCs – VPC A and VPC B, each in a different region. When you are trying to make a request from VPC A to VPC B, the request fails. Which of the following could be a reason? Select one:',
    answers: [
      { text: 'a. VPC A security group default outbound rules not allowing traffic to VPC B IP range.', correct: false,  expli:' ' },
      { text: 'b. Cross-region peering is not supported in AWS', correct: false,  expli:' ' },
	    { text: 'c. Routes not configured in route tables for peering connections. ', correct: true,  expli:' La respuesta correcta es: Routes not configured in route tables for peering connections.' },
      { text: 'd. CIDR blocks of both VPCs might be overlapping.', correct: false,  expli:' ' }
    ],
	img: '',  
  }, 
  {
    question: '/Test 20p Cuestionario 10 - 4  DíA 1-MÓDULO 3.  ARCHITECTING ON AWS/ A user has created a VPC with two subnets: one public and one private. The user is planning to run the patch update for the instances in the private subnet. How can the instances in the private subnet connect to the internet? Select one:',
    answers: [
      { text: 'a. The private subnet can never connect to the internet', correct: false,  expli:' ' },
      { text: 'b. Allow outbound traffic in the security group for port 80 to allow internet updates', correct: false,  expli:' ' },
	    { text: 'c. Use NAT with an elastic IP ', correct: true,  expli:' La respuesta correcta es: Use NAT with an elastic IP' },
      { text: 'd. Use the internet gateway with a private IP', correct: false,  expli:' ' }
    ],
	img: '',  
  }, 
  {
    question: '/Test 20p Cuestionario 10 - 5  DíA 1-MÓDULO 3.  ARCHITECTING ON AWS/ A company hosts a popular web application that connects to an Amazon RDS MySQL DB instance running in a private VPC subnet created with default ACL settings. The web servers must be accessible only to customers on an SSL connection and the database must only be accessible to web servers in a public subnet. Which solution meets these requirements without impacting other running applications? Select 2 answers from the options given below. Seleccione una o más de una:',
    answers: [
      { text: 'a. Create a network ACL on the DB subnet, allow MySQL port 3306 inbound for Web Serversand deny all outbound traffic. ', correct: false,  expli:' ' },
      { text: 'b. Create a network ACL on the Web Server’s subnets, allow HTTPS port 443 inbound andspecify the source as 0.0.0.0/0', correct: false,  expli:' ' },
	    { text: 'c. Create a Web Server security group that allows HTTPS port 443 inbound traffic from anywhere(0.0.0.0/0) and apply it to the Web Servers.', correct: true,  expli:' a correct answer is : Create a Web Server security group that allows HTTPS port 443 inbound traffic from anywhere(0.0.0.0/0) and apply it to the Web Servers.' },
      { text: 'd. Create a DB Server security group that allows MySQL port 3306 inbound and specify thesource as the Web Server security group.', correct: true,  expli:' a correct answer is : Create a DB Server security group that allows MySQL port 3306 inbound and specify thesource as the Web Server security group.' }
    ],
	img: '',  
  }, 
  {
    question: '/Test 20p Cuestionario 10 - 6  DíA 1-MÓDULO 3.  ARCHITECTING ON AWS/ A user has created a VPC with public and private subnets using the VPC Wizard. The VPC has CIDR 20.0.0.0/16. The private subnet uses CIDR 20.0.0.0/24. Which of the below mentioned entries are required in the main route table to allow the instances in VPC to communicate with each other? Select one:',
    answers: [
      { text: 'a. Destination : 20.0.0.0/24 and Target : VPC', correct: false,  expli:' ' },
      { text: 'b. Destination : 20.0.0.0/0 and Target : ALL', correct: false,  expli:' ' },
	    { text: 'c. Destination : 20.0.0.0/16 and Target : ALL', correct: false,  expli:' ' },
      { text: 'd. Destination : 20.0.0.0/16 and Target : Local', correct: true,  expli:' La respuesta correcta es: Destination : 20.0.0.0/16 and Target : Local' }
    ],
	img: '',  
  }, 
  {
    question: '/Test 20p Cuestionario 10 - 7  DíA 1-MÓDULO 3.  ARCHITECTING ON AWS/ A user has launched an EC2 instance and installed a website with the Apache webserver. The webserver is running but the user is not able to access the website from the Internet. What can be the possible reason for this failure? Select one:',
    answers: [
      { text: 'a. The instance is not configured with the proper key-pairs.', correct: false,  expli:' ' },
      { text: 'b. The Apache website cannot be accessed from the Internet.', correct: false,  expli:' ' },
	    { text: 'c. Instance is not configured with an elastic IP. ', correct: false,  expli:' ' },
      { text: 'd. The security group of the instance is not configured properly.', correct: true,  expli:' La respuesta correcta es: The security group of the instance is not configured properly.' }
    ],
	img: '',  
  }, 
  {
    question: '/Test 20p Cuestionario 10 - 8  DíA 1-MÓDULO 3.  ARCHITECTING ON AWS/ A fleet of EC2 instances running in a private subnet must connect to the Internet using the IPv6 protocol. What service should we configure to enable this connectivity? Select one:',
    answers: [
      { text: 'a. Connect the instances to Route 53', correct: false,  expli:' ' },
      { text: 'b. AWS Direct Connect', correct: false,  expli:' ' },
	    { text: 'c. An Egress-Only Internet Gateway ', correct: true,  expli:' La respuesta correcta es: An Egress-Only Internet Gateway' },
      { text: 'd. A NAT Instance', correct: false,  expli:' ' }
    ],
	img: '',  
  }, 
  {
    question: '/Test 20p Cuestionario 10 - 9  DíA 1-MÓDULO 3.  ARCHITECTING ON AWS/ A gaming company stores large size (terabytes to petabytes) of clickstream events data into their central S3 bucket. The company wants to analyze this clickstream data to generate business insight. Amazon Redshift, hosted securely in a private subnet of a VPC, is used for all data warehouse-related and analytical solutions. Using Amazon Redshift, the company wants to explore some solutions to securely run complex analytical queries on the clickstream data stored in S3 without transforming/copying or loading the data in the Redshift. As a Solutions Architect, which of the following AWS services would you recommend for this requirement, knowing that security and cost are two major priorities for the company? Select one:',
    answers: [
      { text: 'a. Use NAT Gateway to connect Amazon Redshift to the internet and access the S3 static website. Use Amazon Redshift Spectrum to run the query', correct: false,  expli:' ' },
      { text: 'b. Create a VPC endpoint to establish a secure connection between Amazon Redshift and the S3 central bucket and use Amazon Redshift Spectrum to run the query', correct: true,  expli:' La respuesta correcta es: Create a VPC endpoint to establish a secure connection between Amazon Redshift and the S3 central bucket and use Amazon Redshift Spectrum to run the query' },
	    { text: 'c. Create a VPC endpoint to establish a secure connection between Amazon Redshift and the S3 central bucket and use Amazon Athena to run the query ', correct: false,  expli:' ' },
      { text: 'd. Create Site-to-Site VPN to set up a secure connection between Amazon Redshift and the S3 central bucket and use Amazon Redshift Spectrum to run the query', correct: false,  expli:' ' }
    ],
	img: '',  
  }, 
  {
    question: '/Test 20p Cuestionario 10 - 10  DíA 1-MÓDULO 3.  ARCHITECTING ON AWS/ A company has a set of resources hosted in an AWS VPC. Having acquired another company with its own set of resources hosted in AWS, it is required to ensure that resources in the VPC of the parent company can access the resources in the VPC of the child company. How can this be accomplished? Select one:',
    answers: [
      { text: 'a. Use VPC Peering to peer both VPCs.', correct: true,  expli:' La respuesta correcta es: Use VPC Peering to peer both VPCs.' },
      { text: 'b. Use a VPN Connection to peer both VPCs.', correct: false,  expli:' ' },
	    { text: 'c. Establish a NAT Instance to establish communication across VPCs.', correct: false,  expli:' ' },
      { text: 'd. Establish a NAT Gateway to establish communication across VPCs.', correct: false,  expli:' ' }
    ],
	img: '',  
  }, 
  {
    question: '/Test 20p Cuestionario 10 - 11  DíA 1-MÓDULO 3.  ARCHITECTING ON AWS/ A user has created a VPC with a subnet and a security group. The user has launched an instance in that subnet and attached a public IP. The user is still unable to connect to the instance. The internet gateway has also been created. What can be the reason for the error? Select one:',
    answers: [
      { text: 'a. The internet gateway is not configured with the route table ', correct: true,  expli:' La respuesta correcta es: The internet gateway is not configured with the route table' },
      { text: 'b. The private IP is not present', correct: false,  expli:' ' },
	    { text: 'c. The outbound traffic on the security group is disabled', correct: false,  expli:' ' },
      { text: 'd. The internet gateway is not configured with the security group', correct: false,  expli:' ' }
    ],
	img: '',  
  }, 
  {
    question: '/Test 20p Cuestionario 10 - 12  DíA 1-MÓDULO 3.  ARCHITECTING ON AWS/ There is a requirement to get the IP addresses for resources accessed in a private subnet. Which of the following can be used to fulfill this purpose? Select one:',
    answers: [
      { text: 'a. Use CloudTrail ', correct: false,  expli:' ' },
      { text: 'b. Use CloudWatch metrics', correct: false,  expli:' ' },
	    { text: 'c. VPC Flow Logs', correct: true,  expli:' La respuesta correcta es: VPC Flow Logs' },
      { text: 'd. Trusted Advisor', correct: false,  expli:' ' }
    ],
	img: '',  
  }, 
  {
    question: '/Test 20p Cuestionario 10 - 13  DíA 1-MÓDULO 3.  ARCHITECTING ON AWS/ Which AWS Services is used to make VPC accessible from internet? Select one:',
    answers: [
      { text: 'a. VPC peering ', correct: false,  expli:' ' },
      { text: 'b. Transit Gateway', correct: false,  expli:' ' },
	    { text: 'c. Network Access control list', correct: false,  expli:' ' },
      { text: 'd. Internet Gateway ', correct: true,  expli:' La respuesta correcta es: Internet Gateway' }
    ],
	img: '',  
  }, 

  
  /* IMAGEN */
  

  {
    question: '/Test 20p Cuestionario 10 - 14  DíA 1-MÓDULO 3.  ARCHITECTING ON AWS/ A company needs to test its applications in 3 separate VPCs. A peering topology is configured with VPC-A peered with VPC-B and VPC-B with VPC-C. The development team wants to modify the process to release code directly from VPC-A to VPC-C. How can this be accomplished? Select one:',
    answers: [
      { text: 'a. You don’t have to do anything, as VPC-B is already connected with VPC-C, and the VPC-A will be able to connect to this one', correct: false,  expli:' ' },
      { text: 'b. Create a new VPC peering connection between VPC-A and VPC-C ', correct: true,  expli:' La respuesta correcta es: Create a new VPC peering connection between VPC-A and VPC-C' },
	    { text: 'c. Update VPC-As route table with an entry using the VPC peering as a target', correct: false,  expli:' ' },
      { text: 'd. Update VPC-Bs route table with peering targets for VPC-A and VPC-C and enable route propagation', correct: false,  expli:' ' }
    ],
	img: './aws/question14_c10.jpg',  
  },
    
  {
    question: '/Test 20p Cuestionario 10 - 15  DíA 1-MÓDULO 3.  ARCHITECTING ON AWS/ You need to design a VPC for a web-application consisting of an ELB a fleet of web application servers, and an RDS DB. The entire infrastructure must be distributed over 2 AZ. Which VPC configuration works while assuring the DB is not available from the Internet? Select one:',
    answers: [
      { text: 'a. Two Public Subnets for ELB, two private Subnet for the web-servers, and two private subnet for the RDS', correct: true,  expli:' La respuesta correcta es: Two Public Subnets for ELB, two private Subnet for the web-servers, and two private subnet for the RDS' },
      { text: 'b. One Public Subnet for ELB, two Private Subnets for the web-servers, and two private subnets for the RDS ', correct: false,  expli:' ' },
	    { text: 'c. Two Public Subnets for ELB, two Public Subnet for the web-servers, and two public subnets for the RDS', correct: false,  expli:' ' },
      { text: 'd. One Public Subnet for ELB, one Public Subnet for the web-servers, and one private subnet for the DB', correct: false,  expli:' ' }
    ],
	img: '',  
  }, 
  {
    question: '/Test 20p Cuestionario 10 - 16  DíA 1-MÓDULO 3.  ARCHITECTING ON AWS/ An application needs to access data in another AWS account in the same region. Which of the following can be used to ensure that the data can be accessed as required? Select one:',
    answers: [
      { text: 'a. Use VPC Peering between both accounts. ', correct: true,  expli:' La respuesta correcta es: Use VPC Peering between both accounts.' },
      { text: 'b. Establish a NAT instance between both accounts.', correct: false,  expli:' ' },
	    { text: 'c. Use a NAT Gateway between both accounts.', correct: false,  expli:' ' },
      { text: 'd. Use a VPN between both accounts.', correct: false,  expli:' ' }
    ],
	img: '',  
  }, 
  {
    question: '/Test 20p Cuestionario 10 - 17  DíA 1-MÓDULO 3.  ARCHITECTING ON AWS/ How many VPCs can an Internet Gateway be attached to at any given time? Select one:',
    answers: [
      { text: 'a. 1', correct: true,  expli:' La respuesta correcta es: 1' },
      { text: 'b. By default 1. But it can be attached to any VPC peered with its belonging VPC.', correct: false,  expli:' ' },
	    { text: 'c. 5 ', correct: false,  expli:' ' },
      { text: 'd. 2', correct: false,  expli:' ' }
    ],
	img: '',  
  }, 
  {
    question: '/Test 20p Cuestionario 10 - 18  DíA 1-MÓDULO 3.  ARCHITECTING ON AWS/ Your organization has an existing VPC setup and has a requirement to route any traffic going from VPC to AWS S3 bucket through AWS internal network. So they have created a VPC endpoint for S3 and configured to allow traffic for S3 buckets. The application you are developing involves sending traffic to AWS S3 bucket from VPC for which you planned to use a similar approach. You have created a new route table, added route to VPC endpoint and associated route table with your new subnet. However, when you are trying to send a request from EC2 to S3 bucket using AWS CLI, the request is getting failed with 403 access denied errors. What could be causing the failure? Select one:',
    answers: [
      { text: 'a. VPC endpoint might have a restrictive policy and does not contain the new S3 bucket. ', correct: true,  expli:' La respuesta correcta es: VPC endpoint might have a restrictive policy and does not contain the new S3 bucket.' },
      { text: 'b. AWS S3 bucket is in a different region than your VPC.', correct: false,  expli:' ' },
	    { text: 'c. EC2 security group outbound rules not allowing traffic to S3 prefix list.', correct: false,  expli:' ' },
      { text: 'd. S3 bucket CORS configuration does not have EC2 instances as the origin.', correct: false,  expli:' ' }
    ],
	img: '',  
  }, 
  {
    question: '/Test 20p Cuestionario 10 - 19  DíA 1-MÓDULO 3.  ARCHITECTING ON AWS/ A start-up firm has a corporate office in New York & a regional office in Washington & Chicago. These offices are interconnected over Internet links. Recently they have migrated a few application servers to EC2 instance launched in the AWS US-east-1 region. The Developer Team located at the corporate office requires secure access to these servers for initial testing & performance checks before go-live of the new application. Since the go-live date is approaching soon, the IT team is looking for quick connectivity to be established. As an AWS consultant, which link option will you suggest as a cost-effective & quick way to establish secure connectivity from on-premise to servers launched in AWS? Select one:',
    answers: [
      { text: 'a. Use AWS Direct Connect to establish IPSEC connectivity from On-premise to VGW', correct: false,  expli:' ' },
      { text: 'b. Use Hardware VPN over AWS Direct Connect to establish IPSEC connectivity from On-premise to VGW', correct: false,  expli:' ' },
	    { text: 'c. Use AWS Site-to-Site VPN to establish IPSEC VPN connectivity between VPC and the on-premises network ', correct: true,  expli:' La respuesta correcta es: Use AWS Site-to-Site VPN to establish IPSEC VPN connectivity between VPC and the on-premises network' },
      { text: 'd. Install a third party software VPN appliance from AWS Marketplace in the EC2 instance to create a VPN connection to the on-premises network', correct: false,  expli:' ' }
    ],
	img: '',  
  }, 
  {
    question: '/Test 20p Cuestionario 10 - 20  DíA 1-MÓDULO 3.  ARCHITECTING ON AWS/ Some Amazon EC2 instances in a VPC need to make API calls to Amazon DynamoDB. If we want to avoid using DynamoDB public endpoints (because we don’t want to use the Internet), what is the most EFFICIENT and secure method to accomplish it? Seleccione una o más de una:',
    answers: [
      { text: 'a. Create a VPC peering connection between the VPC and DynamoDB ', correct: false,  expli:' ' },
      { text: 'b. Create a gateway endpoint for DynamoDB ', correct: true,  expli:'a correct answer is : Create a gateway endpoint for DynamoDB ' },
	    { text: 'c. Create a route table entry for the endpoint', correct: false,  expli:' a correct answer is : Create a route table entry for the endpoint' },
      { text: 'd. Create an interface endpoint for DynamoDB ', correct: false,  expli:' ' },
      { text: 'e. Create a new private DynamoDB table that uses the endpoint', correct: false,  expli:' ' }
    ],
	img: '',  
  }, 
  {
    question: '/Test 10p Cuestionario 11 - 1  DíA 1-MÓDULO 3.  ARCHITECTING ON AWS/ You have some code that you would like to run occasionally and need to minimize costs. The completion time is typically under 10 minutes. Which solution is cost-effective and operationally efficient? Select one:',
    answers: [
      { text: 'a. Run the code using an AWS Lambda function ', correct: true,  expli:' La respuesta correcta es: Run the code using an AWS Lambda function' },
      { text: 'b. Run the code on an Amazon ECS task', correct: false,  expli:' ' },
	    { text: 'c. Run the code on an Amazon EC2 instance', correct: false,  expli:' ' },
      { text: 'd. Run the code using AWS Batch', correct: false,  expli:' ' }
    ],
	img: '',  
  }, 
  {
    question: '/Test 10p Cuestionario 11 - 2  DíA 1-MÓDULO 3.  ARCHITECTING ON AWS/ A company wants to transfer files into and out of Amazon Simple Storage Service (Amazon S3) storage by using AWS Transfer Family. Several users in the company need permissions to access a specific object storage bucket that hosts the files from AWS Transfer Family. What is the BEST way to provide the needed bucket-access permissions to these users? Select one:',
    answers: [
      { text: 'a. AWS Identity and Access Management (IAM) user', correct: false,  expli:' ' },
      { text: 'b. Access keys', correct: false,  expli:' ' },
	    { text: 'c. AWS Identity and Access Management (IAM) role ', correct: true,  expli:' La respuesta correcta es: AWS Identity and Access Management (IAM) role' },
      { text: 'd. AWS account root user', correct: false,  expli:' ' }
    ],
	img: '',  
  }, 
  {
    question: '/Test 10p Cuestionario 11 - 3  DíA 1-MÓDULO 3.  ARCHITECTING ON AWS/ Which type of architecture is the best fit for facilitating real-time data streaming? Select one:',
    answers: [
      { text: 'a. SaaS', correct: false,  expli:' ' },
      { text: 'b. Serverless ', correct: true,  expli:' La respuesta correcta es: Serverless' },
	    { text: 'c. Containers', correct: false,  expli:' ' },
      { text: 'd. Virtual Machines', correct: false,  expli:' ' }
    ],
	img: '',  
  }, 
  {
    question: '/Test 10p Cuestionario 11 - 4  DíA 1-MÓDULO 3.  ARCHITECTING ON AWS/ Which statements about the Amazon Kinesis Family are true? Seleccione una o más de una:',
    answers: [
      { text: 'a. Amazon Kinesis Data Analytics loads data streams into AWS databases.', correct: false,  expli:' ' },
      { text: 'b. Amazon Kinesis Data Analytics provides an option to author non-Structured Query Language (SQL) code to process and analyze streaming data. ', correct: false,  expli:' ' },
	    { text: 'c. Amazon Kinesis Data Streams stores data only in the JSON format.', correct: false,  expli:' ' },
      { text: 'd. The Amazon Kinesis Family can ingest a high volume of small bits of data that are being processed in real time. ', correct: true,  expli:'a correct answer is: The Amazon Kinesis Family can ingest a high volume of small bits of data that are being processed in real time.' },
      { text: 'e. By writing data consumers, customers can move data that is ingested into Amazon Kinesis Data Streams to an Amazon Simple Storage Service (Amazon S3) bucket with minimum modification.', correct: true,  expli:' a correct answer is: By writing data consumers, customers can move data that is ingested into Amazon Kinesis Data Streams to an Amazon Simple Storage Service (Amazon S3) bucket with minimum modification.' }
    ],
	img: '',  
  }, 
  {
    question: '/Test 10p Cuestionario 11 - 5  DíA 1-MÓDULO 3.  ARCHITECTING ON AWS/ Which service can be used for application authenthication? Select one:',
    answers: [
      { text: 'a. AWS X-Ray', correct: false,  expli:' ' },
      { text: 'b. Amazon S3', correct: false,  expli:' ' },
	    { text: 'c. Amazon Cognito ', correct: true,  expli:' La respuesta correcta es: Amazon Cognito' },
      { text: 'd. AWS AppSync', correct: false,  expli:' ' }
    ],
	img: '',  
  }, 
  {
    question: '/Test 10p Cuestionario 11 - 6  DíA 1-MÓDULO 3.  ARCHITECTING ON AWS/ How can you save cost when checking for messages on an Amazon SQS queue? Select one: ',
    answers: [
      { text: 'a. Use long polling ', correct: true,  expli:' La respuesta correcta es: Use long polling' },
      { text: 'b. Use a FIFO queue', correct: false,  expli:' ' },
	    { text: 'c. Use short polling', correct: false,  expli:' ' },
      { text: 'd. Set the ReceiveMessageWaitTime to 0', correct: false,  expli:' ' }
    ],
	img: '',  
  }, 
  {
    question: '/Test 10p Cuestionario 11 - 7  DíA 1-MÓDULO 3.  ARCHITECTING ON AWS/ CORS is configured in which Amazon service? Select one: ',
    answers: [
      { text: 'a. Amazon API Gateway ', correct: true,  expli:' La respuesta correcta es: Amazon API Gateway' },
      { text: 'b. Amazon S3', correct: false,  expli:' ' },
	    { text: 'c. AWS Lambda', correct: false,  expli:' ' },
      { text: 'd. Amazon CloudFront', correct: false,  expli:' ' }
    ],
	img: '',  
  }, 
  {
    question: '/Test 10p Cuestionario 11 - 8  DíA 1-MÓDULO 3.  ARCHITECTING ON AWS/ Which statement is true for the AWS Step Functions? Select one: ',
    answers: [
      { text: 'a. AWS Step functions are functions that work in steps', correct: false,  expli:' ' },
      { text: 'b. Each step is monitored and logged', correct: false,  expli:' ' },
	    { text: 'c. All three statements are true ', correct: true,  expli:' La respuesta correcta es: All three statements are true' },
      { text: 'd. It has built-in automatic retries should a step fail', correct: false,  expli:' ' }
    ],
	img: '',  
  }, 
  {
    question: '/Test 10p Cuestionario 11 - 9  DíA 1-MÓDULO 3.  ARCHITECTING ON AWS/ For which use case is serverless not a good fit? Select one: ',
    answers: [
      { text: 'a. Data streaming', correct: false,  expli:' ' },
      { text: 'b. Batch processing', correct: false,  expli:' ' },
	    { text: 'c. Long-running applications ', correct: true,  expli:' La respuesta correcta es: Long-running applications' },
      { text: 'd.  IoT', correct: false,  expli:' ' }
    ],
	img: '',  
  }, 
  {
    question: '/Test 10p Cuestionario 11 - 10  DíA 1-MÓDULO 3.  ARCHITECTING ON AWS/ How can you scale Amazon SQS? Select one: ',
    answers: [
      { text: 'a. Add more queues', correct: true,  expli:' La respuesta correcta es: Add more queues' },
      { text: 'b. Increase the maximum message size', correct: false,  expli:' ' },
	    { text: 'c. Use a mixture of queue types', correct: false,  expli:' ' },
      { text: 'd. Implement SQS Auto Scaling ', correct: false,  expli:' ' }
    ],
	img: '',  
  }, 
  {
    question: '/Test 10p Cuestionario 12 - 1  DíA 1-MÓDULO 3.  ARCHITECTING ON AWS/ Which routing policy should be used if you want to send the fastest response to your end user? Select one: ',
    answers: [
      { text: 'a. Geolocation Routing Policy ', correct: false,  expli:' ' },
      { text: 'b. Simple Routing Policy', correct: false,  expli:' ' },
	    { text: 'c. Multi-value Routing Policy', correct: false,  expli:' ' },
      { text: 'd. Latency-based Routing Policy', correct: true,  expli:' La respuesta correcta es: Latency-based Routing Policy' }
    ],
	img: '',  
  }, 
  {
    question: '/Test 10p Cuestionario 12 - 2  DíA 1-MÓDULO 3.  ARCHITECTING ON AWS/ Select the Routing Policy we can use if we want to setup a Primary domain and a secondary domain. Select one: ',
    answers: [
      { text: 'a. Failover Routing Policy ', correct: true,  expli:'La respuesta correcta es: Failover Routing Policy ' },
      { text: 'b. Latency-based Routing Policy', correct: false,  expli:' ' },
	    { text: 'c. Multi-value Routing Policy', correct: false,  expli:' ' },
      { text: 'd. Disaster Routing Policy', correct: false,  expli:' ' }
    ],
	img: '',  
  },   
  {
    question: '/Test 10p Cuestionario 12 - 3  DíA 1-MÓDULO 3.  ARCHITECTING ON AWS/ What are Nameservers used for? Seleccione una o más de una: ',
    answers: [
      { text: 'a. Nameservers help connect URLs with the IP address of web servers. ', correct: true,  expli:' a correct answer is :Nameservers help connect URLs with the IP address of web servers.' },
      { text: 'b. Nameservers are used as statements of Authority records. ', correct: false,  expli:' ' },
	    { text: 'c. A name server is a specialized server on the Internet that handles queries or questions from your local computer, about the location of a domain name’s various services ', correct: true,  expli:' a correct answer is :A name server is a specialized server on the Internet that handles queries or questions from your local computer, about the location of a domain name’s various services' },
      { text: 'd. Nameservers are used to maintain the Email server. ', correct: false,  expli:' ' }
    ],
	img: '',  
  }, 
  {
    question: '/Test 10p Cuestionario 12 - 4  DíA 1-MÓDULO 3.  ARCHITECTING ON AWS/ Which Status Code should be received by a Health Check in Route53 for an endpoint to be considered as Healthy? Select one: ',
    answers: [
      { text: 'a.  200 ', correct: true,  expli:' La respuesta correcta es: 200' },
      { text: 'b.  450', correct: false,  expli:' ' },
	    { text: 'c.  500', correct: false,  expli:' ' },
      { text: 'd.  403', correct: false,  expli:' ' }
    ],
	img: '',  
  },   
  {
    question: '/Test 10p Cuestionario 12 - 5  DíA 1-MÓDULO 3.  ARCHITECTING ON AWS/ Which Routing Policy is recommended when you want to serve your users with customized websites based on their location? Select one: ',
    answers: [
      { text: 'a. Latency-based Routing Policy', correct: false,  expli:' ' },
      { text: 'b. Simple Routing Policy', correct: false,  expli:' ' },
	    { text: 'c. GeoLocation Routing Policy', correct: true,  expli:' La respuesta correcta es: GeoLocation Routing Policy' },
      { text: 'd. GeoProximity Routing Policy ', correct: false,  expli:' ' }
    ],
	img: '',  
  }, 
  {
    question: '/Test 10p Cuestionario 12 - 6  DíA 1-MÓDULO 3.  ARCHITECTING ON AWS/ Select if the following statement is True or False: "We can have multiple IP addresses in a single A record for any Routing Policy". Select one: ',
    answers: [
      { text: 'a. True ', correct: true,  expli:' La respuesta correcta es True' },
      { text: 'b. False', correct: false,  expli:' ' }
    ],
	img: '',  
  },   
  {
    question: '/Test 10p Cuestionario 12 - 7  DíA 1-MÓDULO 3.  ARCHITECTING ON AWS/ Your company is utilising CloudFront to distribute its media content to multiple regions. The content is frequently accessed by users. As a cloud architect, which of the following options would help you improve the performance of the system? Select one: ',
    answers: [
      { text: 'a. Increase the cache expiration time. ', correct: true,  expli:' La respuesta correcta es: Increase the cache expiration time.' },
      { text: 'b. Change the origin location from an S3 bucket to an ELB.', correct: false,  expli:' ' },
	    { text: 'c. Create an “invalidation” for all your objects, and recache them.', correct: false,  expli:' ' },
      { text: 'd. Use a faster Internet connection.', correct: false,  expli:' ' }
    ],
	img: '',  
  }, 
  {
    question: '/Test 10p Cuestionario 12 - 8  DíA 1-MÓDULO 3.  ARCHITECTING ON AWS/ A company has an application that uses the S3 bucket as its data layer. As per the monitoring on the S3 bucket, it can be seen that the number of GET requests is 400 requests per second. The IT Operations team receives service requests about users getting HTTP 500 or 503 errors while accessing the application. What can be done to resolve these errors? Choose 2 answers from the options given below. Seleccione una o más de una: ',
    answers: [
      { text: 'a. Add random ness to the key names.', correct: true,  expli:' a correct answer is: Add random ness to the key names.' },
      { text: 'b. Enable Versioning for the S3 bucket.', correct: false,  expli:' ' },
	    { text: 'c. Add an ELB in front of the S3 bucket. ', correct: false,  expli:' ' },
      { text: 'd. Add a CloudFront distribution in front of the bucket. ', correct: true,  expli:' a correct answer is: Add a CloudFront distribution in front of the bucket.' }
    ],
	img: '',  
  },   
  {
    question: '/Test 10p Cuestionario 12 - 9  DíA 1-MÓDULO 3.  ARCHITECTING ON AWS/ To deliver content through Amazon CloudFront, you create a ... Select one: ',
    answers: [
      { text: 'a. Distribution ', correct: true,  expli:' La respuesta correcta es: Distribution' },
      { text: 'b. None of the above', correct: false,  expli:' ' },
	    { text: 'c. Distributing server', correct: false,  expli:' ' },
      { text: 'd. Distributor', correct: false,  expli:' ' }
    ],
	img: '',  
  }, 
  {
    question: '/Test 10p Cuestionario 12 - 10  DíA 1-MÓDULO 3.  ARCHITECTING ON AWS/ Which storage browser can be used as an interface for Amazon CloudFront? Select one: ',
    answers: [
      { text: 'a. Amazon Redshift', correct: false,  expli:' ' },
      { text: 'b. Amazon S3 ', correct: true,  expli:' La respuesta correcta es: Amazon S3' },
	    { text: 'c. AWS Storage Gateway', correct: false,  expli:' ' },
      { text: 'd. Amazon Glacier', correct: false,  expli:' ' }
    ],
	img: '',  
  },   
  {
    question: '/Test DíA 10-MÓDULO 3.  ARCHITECTING ON AWS/  What is a connection to a transit gateway called? ',
    answers: [
      { text: 'a.VPN ', correct: false,  expli:' ' },
      { text: 'b. Attachment', correct: true,  expli:'correct B  Attachment'},
	    { text: 'c. Route', correct: false,  expli:' ' },
      { text: 'd. VPC', correct: false,  expli:' ' }
    ],
	img: '',  
  }, 
  {
    question: '/Test DíA 10-MÓDULO 3.  ARCHITECTING ON AWS/  What are the components of an AWS Site-to-Site VPN connection? (Select TWO.)',
    answers: [
      { text: 'a. Customer gateway device', correct: true,  expli:' correct A Customer gateway device' },
      { text: 'b. Interface endpoint', correct: false,  expli:' ' },
	    { text: 'c. Virtual private gateway', correct: true,  expli:' correct C Virtual private gateway' },
      { text: 'd. VPC peering connection', correct: false,  expli:' ' },
      { text: 'e. Gateway endpoint ', correct: false,  expli:' ' }
    ],
	img: '',  
  }, 
  {
    question: '/Test DíA 10-MÓDULO 3.  ARCHITECTING ON AWS/  What is true of VPC peering connections? (Select TWO.)',
    answers: [
      { text: 'a. Connections are one-to-many.', correct: false,  expli:' ' },
      { text: 'b. Connections are one-to-one.', correct: true,  expli:' correct B Connections are one-to-one.' },
	    { text: 'c. Connections require a transit gateway. ', correct: false,  expli:' ' },
      { text: 'd. Connections can span accounts. ', correct: true,  expli:' correct D Connections can span accounts. ' },
      { text: 'e. Connections are transitive.', correct: false,  expli:' ' }
    ],
	img: '',  
  }, 
  {
    question: '/Test DíA 11-MÓDULO 3.  ARCHITECTING ON AWS/ Which type of Amazon SQS queue provides at-least-once delivery?',
    answers: [
      { text: 'a. FIFO queue ', correct: false,  expli:' ' },
      { text: 'b. Standard queue', correct: true,  expli:' correct B Standard queue' },
	    { text: 'c. Dead-letter queue ', correct: false,  expli:' ' },
      { text: 'd. Long polling  ', correct: false,  expli:' ' }
    ],
	img: '',  
  }, 
  {
    question: '/Test DíA 11-MÓDULO 3.  ARCHITECTING ON AWS/ What is an advantage of long polling compared to short polling?',
    answers: [
      { text: 'a. Long polling provides an immediate response from a ReceiveMes sage call. ', correct: false,  expli:' ' },
      { text: 'b. Long polling is more stable when using a single thread to poll multiple queues.', correct: false,  expli:' ' },
	    { text: 'c. Long polling reduces the cost of using Amazon SQS by reducing the number of empty responses and false empty responses. ', correct: true,  expli:' correct C Long polling reduces the cost of using Amazon SQS by reducing the number of empty responses and false empty responses. ' },
      { text: 'd. Long polling reduces cost by only sampling a subset of Amazon SQS servers.  ', correct: false,  expli:' ' }
    ],
	img: '',  
  }, 
  {
    question: '/Test DíA 11-MÓDULO 3.  ARCHITECTING ON AWS/ What is a feature of Amazon SNS?',
    answers: [
      { text: 'a. Amazon SNS exchanges messages through a polling model.', correct: false,  expli:' ' },
      { text: 'b. Amazon SNS can send messages to distributed components of applications without requiring each component to be concurrently available.', correct: false,  expli:' ' },
	    { text: 'c. Amazon SNS can push messages to multiple subscribers.', correct: true,  expli:' correct C Amazon SNS can push messages to multiple subscribers.' },
      { text: 'd. Amazon SNS keeps messages persistent. ', correct: false,  expli:' ' }
    ],
	img: '',  
  }, 
  {
    question: '/Test DíA 12-MÓDULO 3.  ARCHITECTING ON AWS/ What are the potential benefits of implementing a CloudFront distribution? (Select TWO.)',
    answers: [
      { text: 'a. Increased application security', correct: true,  expli:' correct A Increased application security' },
      { text: 'b. Two global static IP addresses', correct: false,  expli:' ' },
	    { text: 'c. Automatic redundancy for all application content', correct: false,  expli:' ' },
      { text: 'd. Reduced latency for access to application content', correct: true,  expli:' correct D Reduced latency for access to application content' },
      { text: 'e. On-premises data caching', correct: false,  expli:' ' }
    ],
	img: '',  
  }, 
  {
    question: '/Test DíA 12-MÓDULO 3.  ARCHITECTING ON AWS/ Which of the following services offer DDoS protection? (Select TWO.)',
    answers: [
      { text: 'a. AWS Outposts', correct: false,  expli:' ' },
      { text: 'b. Amazon EC2', correct: false,  expli:' ' },
	    { text: 'c. Network Load Balancer', correct: false,  expli:' ' },
      { text: 'd. AWS Shield', correct: true,  expli:' correct D AWS Shield' },
      { text: 'e. AWS WAF', correct: true,  expli:' correct E AWS WAF' }
    ],
	img: '',  
  }, 
  {
    question: '/Test DíA 12-MÓDULO 3.  ARCHITECTING ON AWS/  A network engineer wants to route 80 percent of web traffic to the ap-southeast-2 Region. The remaining 20 percent of traffic will be directed to the eu-west-1 Region. Which Route 53 routing policy is the best choice for this use case?',
    answers: [
      { text: 'a. Simple routing', correct: false,  expli:' ' },
      { text: 'b. Weighted routing', correct: true,  expli:' correct B Weighted routing ' },
	    { text: 'c. Geoproximity routing', correct: false,  expli:' ' },
      { text: 'd. Geolocation routing', correct: false,  expli:' ' },
      { text: 'e. Multivalue answer routing ', correct: false,  expli:' ' }
    ],
	img: '',  
  }, 
  {
    question: '/Test DíA 12-MÓDULO 3.  ARCHITECTING ON AWS/ What is a benefit of choosing Outposts servers when compared to an Outposts rack?',
    answers: [
      { text: 'a. More AWS services are available on Outposts servers ', correct: false,  expli:' ' },
      { text: 'b. Pool compute and storage capacity between multiple Outposts servers', correct: false,  expli:' ' },
	    { text: 'c. A Smaller-sized device can be placed in your own rack', correct: true,  expli:' correct C, A Smaller-sized device can be placed in your own rack' },
      { text: 'd. You don\'t need to host your Outposts servers in a data center', correct: false,  expli:' ' }
    ],
	img: '',  
  }, 
  {
    question: '/Test 32p Cuestionario 13 - 1  DíA 1-MÓDULO 3.  ARCHITECTING ON AWS/ A company needs to have a columnar structured database storage suitable to perform complex analytic queries against petabytes of structured data, Which of the following options can meet this requirement? Select one:  ',
    answers: [
      { text: 'a. Amazon RDS', correct: false,  expli:' ' },
      { text: 'b. Amazon Redshift ', correct: true,  expli:' La respuesta correcta es: Amazon Redshift' },
	    { text: 'c. DynamoDB', correct: false,  expli:' ' },
      { text: 'd. ElastiCache', correct: false,  expli:' ' }
    ],
	img: '',  
  }, 
  {
    question: '/Test 32p Cuestionario 13 - 2  DíA 1-MÓDULO 3.  ARCHITECTING ON AWS/ What architectural best practice aims to reduce the interdependencies between services? Select one:',
    answers: [
      { text: 'a. Services, Not Servers', correct: false,  expli:' ' },
      { text: 'b. Automation', correct: false,  expli:' ' },
	    { text: 'c. Removing Single Points of Failure', correct: false,  expli:' ' },
      { text: 'd. Loose Coupling ', correct: true,  expli:' La respuesta correcta es: Loose Coupling' }
    ],
	img: '',  
  }, 
  {
    question: '/Test 32p Cuestionario 13 - 3  DíA 1-MÓDULO 3.  ARCHITECTING ON AWS/ You have created an AWS Lambda function that will write data to a DynamoDB table. Which of the following must be in place to ensure that the Lambda function can interact with the DynamoDB table? Select one:',
    answers: [
      { text: 'a. Ensure the Access keys are embedded in the AWS Lambda function.', correct: false,  expli:' ' },
      { text: 'b. Ensure an IAM User is attached to the Lambda function which has the required DynamoDB privileges.', correct: false,  expli:' ' },
	    { text: 'c. Ensure an IAM Role is attached to the Lambda function which has the required DynamoDB privileges. ', correct: true,  expli:' La respuesta correcta es: Ensure an IAM Role is attached to the Lambda function which has the required DynamoDB privileges.' },
      { text: 'd. Ensure the IAM user password is embedded in the AWS Lambda function.', correct: false,  expli:' ' }
    ],
	img: '',  
  }, 
  {
    question: '/Test 32p Cuestionario 13 - 4  DíA 1-MÓDULO 3.  ARCHITECTING ON AWS/ Which feature of AWS allows you to deploy a new application for which the requirements may change over time? Select one: ',
    answers: [
      { text: 'a. High availability', correct: false,  expli:' ' },
      { text: 'b. Disposable resources', correct: false,  expli:' ' },
	    { text: 'c. Elasticity ', correct: true,  expli:' La respuesta correcta es: Elasticity' },
      { text: 'd. Fault tolerance', correct: false,  expli:' ' }
    ],
	img: '',  
  }, 
  {
    question: '/Test 32p Cuestionario 13 - 5  DíA 1-MÓDULO 3.  ARCHITECTING ON AWS/ What is the most cost-effective EC2 pricing option to use for a non-critical overnight workload? Select one:',
    answers: [
      { text: 'a. Spot', correct: true,  expli:' La respuesta correcta es: Spot' },
      { text: 'b. Reserved Instance', correct: false,  expli:' ' },
	    { text: 'c. Dedicated Host', correct: false,  expli:' ' },
      { text: 'd. On-Demand', correct: false,  expli:' ' }
    ],
	img: '',  
  }, 
  {
    question: '/Test 32p Cuestionario 13 - 6  DíA 1-MÓDULO 3.  ARCHITECTING ON AWS/ Which service allows you to run code as functions without needing to provision or manage servers? Select one:',
    answers: [
      { text: 'a. Amazon EC2', correct: false,  expli:' ' },
      { text: 'b. AWS Lambda ', correct: true,  expli:' La respuesta correcta es: AWS Lambda' },
	    { text: 'c. Amazon CodeDeploy', correct: false,  expli:' ' },
      { text: 'd. Amazon EKS', correct: false,  expli:' ' }
    ],
	img: '',  
  }, 
  {
    question: '/Test 32p Cuestionario 13 - 7  DíA 1-MÓDULO 3.  ARCHITECTING ON AWS/ Which of the statements below is accurate regarding Amazon S3 buckets? (choose 2) Seleccione una o más de una:',
    answers: [
      { text: 'a. Buckets are replicated globally', correct: false,  expli:' ' },
      { text: 'b. Bucket names must be unique globally ', correct: true,  expli:' a correct answer is: Bucket names must be unique globally' },
	    { text: 'c. Bucket names must be unique regionally', correct: false,  expli:' ' },
      { text: 'd. Buckets are region-specific', correct: true,  expli:' a correct answer is: Buckets are region-specific' },
      { text: 'e. Buckets can contain other buckets', correct: false,  expli:' ' }
    ],
	img: '',  
  }, 
  {
    question: '/Test 32p Cuestionario 13 - 8  DíA 1-MÓDULO 3.  ARCHITECTING ON AWS/ Your supervisor asks you to create a decoupled application whose process includes dependencies on EC2 instances where you would be using Polling Strategy to trigger messages once the defined criteria are fulfilled. Which of the following would you include in the architecture? Select one:',
    answers: [
      { text: 'a. An SNS topic as the messaging component between the Instances and servers', correct: false,  expli:' ' },
      { text: 'b. Route 53 resource records to route requests based on failure', correct: false,  expli:' ' },
	    { text: 'c. An SQS queue as the messaging component between the Instances and servers ', correct: true,  expli:' La respuesta correcta es: An SQS queue as the messaging component between the Instances and servers' },
      { text: 'd. An Elastic Load balancer to distribute requests to your EC2 Instance', correct: false,  expli:' ' }
    ],
	img: '',  
  }, 
  {
    question: '/Test 32p Cuestionario 13 - 9  DíA 1-MÓDULO 3.  ARCHITECTING ON AWS/ Which AWS service allows you to connect to storage from on-premise servers using standard file protocols? Select one:',
    answers: [
      { text: 'a. Amazon S3', correct: false,  expli:' ' },
      { text: 'b. Amazon Glacier', correct: false,  expli:' ' },
	    { text: 'c. Amazon EBS', correct: false,  expli:' ' },
      { text: 'd. Amazon EFS ', correct: true,  expli:' La respuesta correcta es: Amazon EFS' }
    ],
	img: '',  
  }, 
  {
    question: '/Test 32p Cuestionario 13 - 10  DíA 1-MÓDULO 3.  ARCHITECTING ON AWS/ Which database service is a NoSQL type of database that is fully managed? Select one:',
    answers: [
      { text: 'a. Amazon RDS', correct: false,  expli:' ' },
      { text: 'b. Amazon ElastiCache', correct: false,  expli:' ' },
	    { text: 'c. Amazon DynamoDB ', correct: true,  expli:' La respuesta correcta es: Amazon DynamoDB' },
      { text: 'd. Amazon RedShift', correct: false,  expli:' ' }
    ],
	img: '',  
  }, 
  {
    question: '/Test 32p Cuestionario 13 - 11  DíA 1-MÓDULO 3.  ARCHITECTING ON AWS/ What considerations are there when choosing which region to use? (choose 2) Seleccione una o más de una: ',
    answers: [
      { text: 'a. Data sovereignty ', correct: true,  expli:' a correct answer is: Data sovereignty' },
      { text: 'b. Latency ', correct: true,  expli:' a correct answer is: Latency' },
	    { text: 'c. Available storage capacity', correct: false,  expli:' ' },
      { text: 'd. Available compute capacity', correct: false,  expli:' ' },
      { text: 'e. Pricing in local currency', correct: false,  expli:' ' }
    ],
	img: '',  
  }, 
  {
    question: '/Test 32p Cuestionario 13 - 12  DíA 1-MÓDULO 3.  ARCHITECTING ON AWS/ Which items can be configured from within the VPC management console? (choose 2) Seleccione una o más de una:',
    answers: [
      { text: 'a. Regions', correct: false,  expli:' ' },
      { text: 'b. Auto Scaling', correct: false,  expli:' ' },
	    { text: 'c. Security Groups', correct: true,  expli:' a correct answer is: Security Groups' },
      { text: 'd. Subnets ', correct: true,  expli:'a correct answer is: Subnets ' },
      { text: 'e. Load Balancing', correct: false,  expli:' ' }
    ],
	img: '',  
  }, 
  {
    question: '/Test 32p Cuestionario 13 - 13  DíA 1-MÓDULO 3.  ARCHITECTING ON AWS/ Which AWS services are used for analytics? (choose 2) Seleccione una o más de una: ',
    answers: [
      { text: 'a. Amazon Kinesis  ', correct: true,  expli:' a correct answer is : Amazon Athena, Amazon Kinesis' },
      { text: 'b. Amazon Athena', correct: true,  expli:' a correct answer is : Amazon Athena, Amazon Kinesis' },
	    { text: 'c. Amazon ElastiCache', correct: false,  expli:' ' },
      { text: 'd. Amazon RDS', correct: false,  expli:' ' },
      { text: 'e.Amazon S3 ', correct: false,  expli:' ' }
    ],
	img: '',  
  }, 
  {
    question: '/Test 32p Cuestionario 13 - 14  DíA 1-MÓDULO 3.  ARCHITECTING ON AWS/ What advantages does deploying Amazon CloudFront provide? (choose 2) Seleccione una o más de una: ',
    answers: [
      { text: 'a. Provides serverless compute services ', correct: false,  expli:' ' },
      { text: 'b. Improved performance for end users', correct: true,  expli:'a correct answer is : Improved performance for end users ' },
	    { text: 'c. Reduced latency ', correct: true,  expli:' a correct answer is : Reduced latency' },
      { text: 'd. A private network link to the AWS cloud ', correct: false,  expli:' ' },
      { text: 'e. Automated deployment of resources', correct: false,  expli:' ' }
    ],
	img: '',  
  }, 
  {
    question: '/Test 32p Cuestionario 13 - 15  DíA 1-MÓDULO 3.  ARCHITECTING ON AWS/ You work for a large company having multiple applications which are very different from each other. These are built using different programming languages. How can you deploy these applications as quickly as possible? Select one: ',
    answers: [
      { text: 'a. Develop all the apps in a single Docker container and deploy using Elastic Beanstalk ', correct: false,  expli:' ' },
      { text: 'b. Develop each app in separate Docker containers and deploy using CloudFormation.', correct: false,  expli:' ' },
	    { text: 'c. Develop each app in a separate Docker container and deploy using Elastic Beanstalk ', correct: true,  expli:'La respuesta correcta es: Develop each app in a separate Docker container and deploy using Elastic Beanstalk ' },
      { text: 'd. Create a Lambda function deployment package consisting of code and any dependencies.. ', correct: false,  expli:' ' }
    ],
	img: '',  
  }, 
  {
    question: '/Test 32p Cuestionario 13 - 16  DíA 1-MÓDULO 3.  ARCHITECTING ON AWS/ Which service allows you to automatically expand and shrink your application in response to demand? Select one: ',
    answers: [
      { text: 'a. Amazon DynamoDB', correct: false,  expli:' ' },
      { text: 'b. AWS Auto Scaling  ', correct: true,  expli:' La respuesta correcta es: AWS Auto Scaling' },
	    { text: 'c. AWS ElastiCache', correct: false,  expli:' ' },
      { text: 'd. Amazon Elastic Load Balancing', correct: false,  expli:' ' }
    ],
	img: '',  
  }, 
  {
    question: '/Test 32p Cuestionario 13 - 17  DíA 1-MÓDULO 3.  ARCHITECTING ON AWS/ An application in AWS is currently running in the Singapore region. You have been asked to implement disaster recovery for the same. So, if the application goes down in the Singapore region, it has to be started in the Asia region. Your application relies on pre-built AMIs. As a part of your disaster recovery strategy, which of the below points would you consider? Select one: ',
    answers: [
      { text: 'a. Modify the image permissions and share the AMI to the Asia region.', correct: false,  expli:' ' },
      { text: 'b. Modify the image permissions to share the AMI with another account, then set the default region to the backup region.', correct: false,  expli:' ' },
	    { text: 'c. Nothing, because all AMIs by default are available in any region as long as they are created within the same account.', correct: false,  expli:' ' },
      { text: 'd. Copy the AMI from the Singapore region to the Asia region. Modify the Auto Scaling groups in the backup region to use the new AMI ID in the backup region.  ', correct: true,  expli:'La respuesta correcta es: Copy the AMI from the Singapore region to the Asia region. Modify the Auto Scaling groups in the backup region to use the new AMI ID in the backup region. ' }
    ],
	img: '',  
  }, 
  {
    question: '/Test 32p Cuestionario 13 - 18  DíA 1-MÓDULO 3.  ARCHITECTING ON AWS/ Identify the services that have a global (rather than regional) scope? (choose 2) Seleccione una o más de una: ',
    answers: [
      { text: 'a. Amazon CloudFront ', correct: true,  expli:' a correct answer is : Amazon CloudFront' },
      { text: 'b. Amazon Route 53 ', correct: true,  expli:' a correct answer is : Amazon Route 53' },
	    { text: 'c. Amazon EC2 ', correct: false,  expli:' ' },
      { text: 'd. Amazon S3', correct: false,  expli:' ' },
      { text: 'e.AWS Lambda ', correct: false,  expli:' ' }
    ],
	img: '',  
  }, 
  {
    question: '/Test 32p Cuestionario 13 - 19  DíA 1-MÓDULO 3.  ARCHITECTING ON AWS/ You need to ensure that instances in a private subnet can access the Internet. The solution should be highly available and ensure less maintenance overhead. Which of the following would ideally fit this requirement? Select one: ',
    answers: [
      { text: 'a. Host the NAT Instance in the public subnet.', correct: false,  expli:' ' },
      { text: 'b. Host the NAT Gateway in the private subnet.', correct: false,  expli:' ' },
	    { text: 'c. Host the NAT Instance in the private subnet.', correct: false,  expli:' ' },
      { text: 'd. Host the NAT Gateway in the public subnet. ', correct: true,  expli:'La respuesta correcta es: Host the NAT Gateway in the public subnet. ' }
    ],
	img: '',  
  }, 
  {
    question: '/Test 32p Cuestionario 13 - 20  DíA 1-MÓDULO 3.  ARCHITECTING ON AWS/ Which service can you use to provision a preconfigured server with little to no AWS experience? Select one: ',
    answers: [
      { text: 'a. AWS Lambda', correct: false,  expli:' ' },
      { text: 'b. Amazon Lightsail', correct: true,  expli:'La respuesta correcta es: Amazon Lightsail' },
	    { text: 'c. Amazon EC2', correct: false,  expli:' ' },
      { text: 'd. Amazon Elastic Beanstalk ', correct: false,  expli:' ' }
    ],
	img: '',  
  }, 
  {
    question: '/Test 32p Cuestionario 13 - 21  DíA 1-MÓDULO 3.  ARCHITECTING ON AWS/ Your company is planning on using Route 53 as the DNS provider. There is a need to ensure that the company’s domain name points to an existing CloudFront distribution. How can this be achieved? Select one: ',
    answers: [
      { text: 'a. Create a Non-Alias Record which points to the CloudFront distribution.', correct: false,  expli:' ' },
      { text: 'b. Create a host record which points to the CloudFront distribution.', correct: false,  expli:' ' },
	    { text: 'c. Create a CNAME record which points to the CloudFront distribution. ', correct: false,  expli:' ' },
      { text: 'd. Create an Alias record which points to the CloudFront distribution.', correct: true,  expli:' La respuesta correcta es: Create an Alias record which points to the CloudFront distribution.' }
    ],
	img: '',  
  }, 
  {
    question: '/Test 32p Cuestionario 13 - 22  DíA 1-MÓDULO 3.  ARCHITECTING ON AWS/ A company currently hosts their architecture in the US region. They now need to duplicate this architecture to the Europe region and extend the application hosted on this architecture to the new region. In order to ensure that users across the globe get the same seamless experience from either setups, what among the following needs to be done? Select one: ',
    answers: [
      { text: 'a. Create a Classic Elastic Load Balancer setup to route traffic to both locations.', correct: true,  expli:' a correct answer is : Create a Classic Elastic Load Balancer setup to route traffic to both locations.' },
      { text: 'b. Create a Geolocation Route 53 Policy to route the policy based on the location. ', correct: true,  expli:' a correct answer is : Create a Geolocation Route 53 Policy to route the policy based on the location ' },
	    { text: 'c. Create an Application Elastic Load Balancer setup to route traffic to both locations.', correct: false,  expli:' ' },
      { text: 'd. Create a weighted Route 53 policy to route the policy based on the weightage for eachlocation.', correct: false,  expli:' ' }
    ],
	img: '',  
  }, 
  {
    question: '/Test 32p Cuestionario 13 - 23  DíA 1-MÓDULO 3.  ARCHITECTING ON AWS/ Which AWS service can you use to install a third-party database? Select one: ',
    answers: [
      { text: 'a. Amazon DynamoDB', correct: false,  expli:' ' },
      { text: 'b. Amazon EMR', correct: false,  expli:' ' },
	    { text: 'c. Amazon EC2', correct: true,  expli:' La respuesta correcta es: Amazon EC2' },
      { text: 'd. Amazon RDS ', correct: false,  expli:' ' }
    ],
	img: '',  
  }, 
  {
    question: '/Test 32p Cuestionario 13 - 24  DíA 1-MÓDULO 3.  ARCHITECTING ON AWS/ Under the AWS shared responsibility model what is the customer responsible for? (choose 2) Seleccione una o más de una: ',
    answers: [
      { text: 'a. Physical security of the data center', correct: false,  expli:' ' },
      { text: 'b. Replacement and disposal of disk drives ', correct: false,  expli:' ' },
	    { text: 'c. Encryption of customer data ', correct: true,  expli:' a correct answer is: Encryption of customer data' },
      { text: 'd. Configuration of security groups ', correct: true,  expli:' a correct answer is: Configuration of security groups ' },
      { text: 'e. Patch management of infrastructure', correct: false,  expli:' ' }
    ],
	img: '',  
  }, 
  {
    question: '/Test 32p Cuestionario 13 - 25  DíA 1-MÓDULO 3.  ARCHITECTING ON AWS/ You are building a large-scale confidential documentation web server on AWS and all of its documentation will be stored on S3. One of the requirements is that it should not be publicly accessible from S3 directly, and CloudFront would be needed to accomplish this. Which of the methods listed below would satisfy the outlined requirements? Choose an answer from the options below. Select one: ',
    answers: [
      { text: 'a. Create individual policies for each bucket the documents are stored in, and grant access only to CloudFront in these policies.', correct: false,  expli:' ' },
      { text: 'b. Create an Origin Access Identity (OAI) for CloudFront and grant access to the objects in your S3 bucket to that OAI. ', correct: true,  expli:'La respuesta correcta es: Create an Origin Access Identity (OAI) for CloudFront and grant access to the objects in your S3 bucket to that OAI. ' },
	    { text: 'c. Create an S3 bucket policy that lists the CloudFront distribution ID as the Principal and the target bucket as the Amazon Resource Name (ARN).', correct: false,  expli:' ' },
      { text: 'd. Create an Identity and Access Management (IAM) user for CloudFront and grant access to the objects in your S3 bucket to that IAM User.', correct: false,  expli:' ' }
    ],
	img: '',  
  }, 
  {
    question: '/Test 32p Cuestionario 13 - 26  DíA 1-MÓDULO 3.  ARCHITECTING ON AWS/ A company wants to deploy docker containers to the AWS Cloud. They also want a highly scalable service which can help manage the orchestration of these containers. Which of the following would be ideal for such a requirement? Select one: ',
    answers: [
      { text: 'a. Use SQS to orchestrate the messages between docker containers.', correct: false,  expli:' ' },
      { text: 'b. Use the Amazon Elastic Container Service for Kubernetes. ', correct: true,  expli:'La respuesta correcta es: Use the Amazon Elastic Container Service for Kubernetes. ' },
	    { text: 'c. Install a custom orchestration tool on EC2 Instances.', correct: false,  expli:' ' },
      { text: 'd. Use AWS Lambda functions to embed the logic for container orchestration.', correct: false,  expli:' ' }
    ],
	img: '',  
  }, 
  {
    question: '/Test 32p Cuestionario 13 - 27  DíA 1-MÓDULO 3.  ARCHITECTING ON AWS/ What method can you use to take a backup of an Amazon EC2 instance using AWS tools? Select one: ',
    answers: [
      { text: 'a. Take a snapshot to capture the point-in-time state of the instance ', correct: true,  expli:' La respuesta correcta es: Take a snapshot to capture the point-in-time state of the instance' },
      { text: 'b. Take full and incremental file-level backups using the backup console ', correct: false,  expli:' ' },
	    { text: 'c. Use Cross Region Replication (CRR) to copy the instance to another region', correct: false,  expli:' ' },
      { text: 'd. Take application-consistent backups using the EC2 API', correct: false,  expli:' ' }
    ],
	img: '',  
  }, 
  {
    question: '/Test 32p Cuestionario 13 - 28  DíA 1-MÓDULO 3.  ARCHITECTING ON AWS/ Which service records API activity on your account and delivers log files to an Amazon S3 bucket? Select one: ',
    answers: [
      { text: 'a. Amazon S3 Event Notifications', correct: false,  expli:' ' },
      { text: 'b. Amazon CloudWatch', correct: false,  expli:' ' },
	    { text: 'c. Amazon CloudWatch Logs', correct: false,  expli:' ' },
      { text: 'd. Amazon CloudTrail ', correct: true,  expli:'La respuesta correcta es: Amazon CloudTrail ' }
    ],
	img: '',  
  }, 
  {
    question: '/Test 32p Cuestionario 13 - 29  DíA 1-MÓDULO 3.  ARCHITECTING ON AWS/ You plan to deploy a dockerised application in an AWS ECS cluster. As the application gets configuration files from an S3 bucket, the ECS containers should have the AmazonS3ReadOnlyAccess permission. What is the correct method to configure the IAM permission? Select one: ',
    answers: [
      { text: 'a. Modify the user data of ECS instances to assume an IAM role that has the AmazonS3ReadOnlyAccess permission.', correct: false,  expli:' ' },
      { text: 'b. Attach the AmazonS3ReadOnlyAccess policy to the ECS container instance IAM role. Attach this role when creating the ECS cluster ', correct: true,  expli:'La respuesta correcta es: Attach the AmazonS3ReadOnlyAccess policy to the ECS container instance IAM role. Attach this role when creating the ECS cluster ' },
	    { text: 'c. Add an environment to the ECS cluster configuration to allow the S3 read only access.', correct: false,  expli:' ' },
      { text: 'd. Add the AmazonS3ReadOnlyAccess permission to the IAM entity that creates the ECS cluster.', correct: false,  expli:' ' }
    ],
	img: '',  
  }, 
  {
    question: '/Test 32p Cuestionario 13 - 30  DíA 1-MÓDULO 3.  ARCHITECTING ON AWS/ You have a set of Docker images that you use for building containers. You want to start using the Elastic Container Service and utilize the Docker images. You need a place to store these Docker images. Which of the following can be used for this purpose? Select one: ',
    answers: [
      { text: 'a. Use the ECR Service to store the Docker images. ', correct: true,  expli:'La respuesta correcta es: Use the ECR Service to store the Docker images. ' },
      { text: 'b. Use AWS DynamoDB to store the Docker images.', correct: false,  expli:' ' },
	    { text: 'c. Use AWS RDS to store the Docker images.', correct: false,  expli:' ' },
      { text: 'd. Use EC2 Instances with EBS Volumes to store the Docker images.', correct: false,  expli:' ' }
    ],
	img: '',  
  }, 
  {
    question: '/Test 32p Cuestionario 13 - 31  DíA 1-MÓDULO 3.  ARCHITECTING ON AWS/ Which service can be used to track the CPU usage of an EC2 instance? Select one: ',
    answers: [
      { text: 'a. Amazon CloudTrail', correct: false,  expli:' ' },
      { text: 'b. Amazon CloudFront', correct: false,  expli:' ' },
	    { text: 'c. Amazon CloudWatch ', correct: true,  expli:' La respuesta correcta es: Amazon CloudWatch' },
      { text: 'd. Amazon CloudFormation', correct: false,  expli:' ' }
    ],
	img: '',  
  }, 
  {
    question: '/Test 32p Cuestionario 13 - 32  DíA 1-MÓDULO 3.  ARCHITECTING ON AWS/ For which services does Amazon not charge customers? (choose 2) Seleccione una o más de una: ',
    answers: [
      { text: 'a. Amazon S3', correct: false,  expli:' ' },
      { text: 'b. Amazon VPC ', correct: true,  expli:' a correct answer is : Amazon VPC ' },
	    { text: 'c. Amazon SNS', correct: false,  expli:' ' },
      { text: 'd. Amazon EBS', correct: false,  expli:' ' },
      { text: 'e. Amazon CloudFormation ', correct: true,  expli:' a correct answer is : Amazon CloudFormation' }
    ],
	img: '',  
  }, 
  {
    question: '/Test 32p Cuestionario 14 1/ An organization is planning to migrate from an on-premises data center to an AWS environment that spans multiple Availability Zones. A migration engineer has been tasked to plan how to transfer the home directories and other shared network attached storage from the data center to AWS. The migration design should support connections from multiple Amazon EC2 instances running the Linux operating system to this common shared storage platform. What storage option best fits their design? Seleccione una:',
    answers: [
      { text: 'a. Transfer the files to Amazon EFS and mount that file system to the EC2 instances. ', correct: true,  expli:' La respuesta correcta es: Transfer the files to Amazon EFS and mount that file system to the EC2 instances.' },
      { text: 'b. Transfer the files to the EC2 Instance Store attached to the EC2 instances.', correct: false,  expli:' ' },
	    { text: 'c. Transfer the files to Amazon S3 and access that data from the EC2 instances.', correct: false,  expli:' ' },
      { text: 'd. Transfer the files to one EBS volume and mount that volume to the EC2 instances.', correct: false,  expli:' ' }
    ],
	img: '',  
  }, 
  {
    question: '/Test 32p Cuestionario 14 2/ A company has a web application in which customers can log in and read near-real-time status updates about their orders. The company hosts the application on Amazon EC2 instances and is expanding the application from the eu-west-1 Region into the us-east-1 Region. The application relies on an Amazon RDS for MySQL database. The company already has provisioned the necessary EC2 instances in the new Region. The company needs to deploy the application in us-east-1 with the least possible change to the application. The company also needs fast, local database queries in both Regions. Which modification of the database will meet these requirements?  Seleccione una:',
    answers: [
      { text: 'a. Migrate the RDS database to an Amazon DynamoDB table. Create global tables for us-east-1. ', correct: false,  expli:' ' },
      { text: 'b. Migrate the RDS database to an Amazon Aurora global database. Add a secondary cluster in us-east-1.', correct: true,  expli:'La respuesta correcta es: Migrate the RDS database to an Amazon Aurora global database. Add a secondary cluster in us-east-1.'},
	    { text: 'c. Migrate the RDS database to an Amazon Aurora Serverless database. Configure automatic scaling in us-east-1.', correct: false,  expli:' ' },
      { text: 'd. Place an accelerator from AWS Global Accelerator in front of the RDS database to reduce the network latency from us-east-1.', correct: false,  expli:' ' }
    ],
	img: '',  
  }, 
  {
    question: '/Test 32p Cuestionario 14 3/ A startup company is looking for a solution to cost-effectively run and access microservices without the operational overhead of managing infrastructure. The solution needs to be able scale quickly to accommodate rapid changes in the volume of requests and protect against common DDoS attacks. What is the MOST cost-effective solution that meets these requirements? Seleccione una: ',
    answers: [
      { text: 'a. Run the microservices in containers using AWS Elastic Beanstalk. ', correct: false,  expli:' ' },
      { text: 'b. Run the microservices on Amazon EC2 instances in an Auto Scaling group.', correct: false,  expli:' ' },
	    { text: 'c. Run the microservices in AWS Lambda behind an Amazon API Gateway.', correct: true,  expli:'La respuesta correcta es: Run the microservices in AWS Lambda behind an Amazon API Gateway. ' },
      { text: 'd. Run the microservices in containers using Amazon Elastic Container Service (Amazon ECS) backed by EC2 instances. ', correct: false,  expli:' ' }
    ],
	img: '',  
  }, 
  {
    question: '/Test 32p Cuestionario 14 4/ A data processing facility wants to move a group of Microsoft Windows servers to the AWS Cloud. Theses servers require access to a shared file system that can integrate with the facility\'s existing Active Directory infrastructure for file and folder permissions. The solution needs to provide seamless support for shared files with AWS and on-premises servers and allow the environment to be highly available. The chosen solution should provide added security by supporting encryption at rest and in transit. Which storage solution would meet these requirements?  Seleccione una: ',
    answers: [
      { text: 'a. An Amazon FSx for the Windows File Server file system joined to the existing Active Directory domain ', correct: true,  expli:'La respuesta correcta es: An Amazon FSx for the Windows File Server file system joined to the existing Active Directory domain ' },
      { text: 'b. An Amazon S3 File Gateway joined to the existing Active Directory domain', correct: false,  expli:' ' },
	    { text: 'c. An Amazon S3 bucket mounted on Amazon EC2 instances in multiple Availability Zones running Windows Server', correct: false,  expli:' ' },
      { text: 'd. n Amazon Elastic File System (Amazon EFS) file system joined to an AWS Managed Microsoft AD domain', correct: false,  expli:' ' }
    ],
	img: '',  
  }, 
  {
    question: '/Test 32p Cuestionario 14 5/ A company has developed an application that processes photos and videos. When users upload photos and videos, a job processes the files. The job can take up to 1 hour to process long videos. The company is using Amazon EC2 On-Demand Instances to run web servers and processing jobs. The web layer and the processing layer have instances that run in an Auto Scaling group behind an Application Load Balancer. During peak hours, users report that the application is slow and that the application does not process some requests at all. During evening hours, the systems are idle. What should a solutions architect do so that the application will process all jobs in the MOST cost-effective manner?  Seleccione una: ',
    answers: [
      { text: 'a. Use a larger instance size in the Auto Scaling groups of the web layer and the processing layer.', correct: false,  expli:' ' },
      { text: 'b. Use Spot Instances for the Auto Scaling groups of the web layer and the processing layer.', correct: false,  expli:' ' },
	    { text: 'c. Use AWS Lambda functions instead of EC2 instances and Auto Scaling groups. Increase the service quota so that sufficient concurrent functions can run at the same time.', correct: false,  expli:' ' },
      { text: 'd.Use an Amazon Simple Queue Service (Amazon SQS) standard queue between the web layer and the processing layer. Use a custom queue metric to scale the Auto Scaling group in the processing layer.  ', correct: true,  expli:' La respuesta correcta es: Use an Amazon Simple Queue Service (Amazon SQS) standard queue between the web layer and the processing layer. Use a custom queue metric to scale the Auto Scaling group in the processing layer.' }
    ],
	img: '',  
  }, 
  {
    question: '/Test 32p Cuestionario 14 6/ A Solutions Architect has been tasked with creating a data store location that will be able to handle different file formats of unknown sizes. It is required that this data be highly available and protected from being accidentally deleted. What solution meets the requirements and is the MOST cost-effective? Seleccione una: ',
    answers: [
      { text: 'a. Deploy a database using Amazon RDS and configure a Multi-AZ deployment for that database.', correct: false,  expli:' ' },
      { text: 'b. Deploy an Amazon S3 bucket and enable Object Versioning. ', correct: true,  expli:' La respuesta correcta es: Deploy an Amazon S3 bucket and enable Object Versioning.' },
	    { text: 'c. Deploy an Amazon DynamoDB table and enable Global Tables.', correct: false,  expli:' ' },
      { text: 'd. Deploy an Amazon S3 bucket and enable Cross-Region Replication.', correct: false,  expli:' ' }
    ],
	img: '',  
  }, 
  {
    question: '/Test 32p Cuestionario 14 7/ A company uses AWS Organizations. The company recently acquired a new business unit and invited the new unit’s existing account to the company’s organization. The organization uses a deny list SCP in the root of the organization and all accounts are members of a single OU named Production. The administrators of the new business unit discovered that they are unable to access AWS Database Migration Service (DMS) to complete an in-progress migration. Which option will temporarily allow administrators to access AWS DMS and complete the migration project? Seleccione una: ',
    answers: [
      { text: 'a. Create a temporary OU named Staging for the new account. Apply an SCP to the Staging OU to allow AWS DMS actions. Move the new account to the Production OU when the migration project is complete. ', correct: false,  expli:' ' },
      { text: 'b. Create a temporary OU named Staging for the new account. Apply an SCP to the Staging OU to allow AWS DMS actions. Move the organization\'s deny list SCP to the Production OU. Move the new account to the Production OU when adjustments to AWS DMS are complete.', correct: true,  expli:' La respuesta correcta es: Create a temporary OU named Staging for the new account. Apply an SCP to the Staging OU to allow AWS DMS actions. Move the organization\'s deny list SCP to the Production OU. Move the new account to the Production OU when adjustments to AWS DMS are complete.' },
	    { text: 'c. Remove the organization\'s root SCPs that limit access to AWS DMS. Create an SCP that allows AWS DMS actions and apply the SCP to the Production OU.', correct: false,  expli:' ' },
      { text: 'd. Convert the organization\'s root SCPs from deny list SCPs to allow list SCPs to allow the required services only. Temporarily apply an SCP to the organization\'s root that allows AWS DMS actions for principals only in the new account.', correct: false,  expli:' ' }
    ],
	img: '',  
  }, 
  {
    question: '/Test 32p Cuestionario 14 8/ A company is building a distributed application, which will send sensor IoT data-- including weather conditions and wind speed from wind turbines--to the AWS Cloud for further processing. Because the nature of the data is spiky, the application needs to be able to scale. It is important to store the streaming data in a key-value database and then send it over to a centralized data lake, where it can be transformed, analyzed, and combined with diverse organizational datasets to derive meaningful insights and make predictions. Which combination of solutions would accomplish the business need with minimal operational overhead? (Select TWO.) Seleccione una o más de una: ',
    answers: [
      { text: 'a. Use Amazon DynamoDB to store the IoT sensor data, and enable DynamoDB Streams.  ', correct: true,  expli:' una respuesta correcta es: Use Amazon DynamoDB to store the IoT sensor data, and enable DynamoDB Streams.' },
      { text: 'b. Use Amazon Kinesis to deliver streaming data to Amazon Redshift, and enable Amazon Redshift Spectrum.  ', correct: false,  expli:' ' },
	    { text: 'c. Use Amazon DocumentDB to store IoT sensor data.', correct: false,  expli:' ' },
      { text: 'd. Write AWS Lambda functions to deliver streaming data to Amazon S3.', correct: false,  expli:' ' },
      { text: 'e. Configure Amazon Kinesis to deliver streaming data to an Amazon S3 data lake.', correct: true,  expli:' una respuesta correcta es: Configure Amazon Kinesis to deliver streaming data to an Amazon S3 data lake.' }
    ],
	img: '',  
  }, 
  {
    question: '/Test 32p Cuestionario 14 9/ A client has created a website (www.example.com), with an Application Load Balancer in a public subnet. The load balancer targets an application hosted on EC2 instances in private subnets, which rely on an Amazon Aurora PostgreSQL-Compatible Edition DB instance in separate private subnets. When testing the website, static content from the EC2 instance is displayed, but any content driven by database queries fails to load. What should the administrator check? Seleccione una: ',
    answers: [
      { text: 'a. Check if the security group of the database subnet allows inbound traffic from the EC2 subnets.  ', correct: true,  expli:' La respuesta correcta es: Check if the security group of the database subnet allows inbound traffic from the EC2 subnets' },
      { text: 'b. Check that the route table for the database subnets includes a default route to the internet gateway for the VPC.', correct: false,  expli:' ' },
	    { text: 'c. Check the network access control list (network ACL) of the application subnets for an outbound allow statement.', correct: false,  expli:' ' },
      { text: 'd. Check the Amazon Route 53 CNAME record to ensure that www.example.com points to the top-level domain (example.com). ', correct: false,  expli:' ' }
    ],
	img: '',  
  }, 
  {
    question: '/Test 32p Cuestionario 14 10/ A hospital client is migrating from another cloud provider to AWS and is looking for advice on modernizing as they migrate. They have containerized applications that run on tablets. During spikes caused by increases in patient visits, the communications from the applications to the central database occasionally fail. As a result, the client currently has the applications try to write to the central database once, and if that write fails, it writes to a dedicated application PostgreSQL database run by the hospital IT team on premises. Each of those PostgreSQL databases then sends batch information on to the central database. The client is asking for recommendations for migrating or refactoring the database write process to decrease operational overhead. What should the solutions architect recommend? (Select TWO.)  Seleccione una o más de una:',
    answers: [
      { text: 'a. Refactor the applications to use Amazon Simple Queue Service and eliminate the local PostgreSQL databases.', correct: true,  expli:' una respuesta correcta es: Refactor the applications to use Amazon Simple Queue Service and eliminate the local PostgreSQL databases.' },
      { text: 'b. Migrate the local databases to Aurora Serverless for PostgreSQL. ', correct: true,  expli:'una respuesta correcta es:   Migrate the local databases to Aurora Serverless for PostgreSQL.' },
	    { text: 'c. Refactor the central database to add an Amazon ElastiCache lazy loading cache in front of the database. ', correct: false,  expli:' ' },
      { text: 'd. Migrate the containerized applications to AWS Fargate.', correct: false,  expli:' ' },
      { text: 'e. Migrate the PostgreSQL databases to an RDS instance with a read replica that replaces each of the local databases. ', correct: false,  expli:' ' }
    ],
	img: '',  
  }, 
  {
    question: '/Test 32p Cuestionario 14 11/ A company is developing an application that runs on Amazon EC2 instances in a private subnet. The EC2 instances use a NAT gateway to access the internet. A solutions architect must provide a secure option so that developers can log in to the instances. Which solution meets these requirements MOST cost-effectively? Seleccione una: ',
    answers: [
      { text: 'a. Configure a bastion host in a public subnet to log in to the EC2 instances in a private subnet. ', correct: false,  expli:' ' },
      { text: 'b. Configure AWS Systems Manager Session Manager for the EC2 instances to enable login.', correct:true,  expli:' La respuesta correcta es: Configure AWS Systems Manager Session Manager for the EC2 instances to enable login.' },
	    { text: 'c. Use the existing NAT gateway to log in to the EC2 instances in a private subnet. ', correct: false,  expli:' ' },
      { text: 'd. Configure AWS Site-to-Site VPN to log in directly to the EC2 instances.', correct: false,  expli:' ' }
    ],
	img: '',  
  }, 
  {
    question: '/Test 32p Cuestionario 14 12/ A solutions architect must create a disaster recovery (DR) solution for a company\'s business-critical applications. The DR site must reside in a different AWS Region than the primary site. The solution requires a recovery point objective (RPO) in seconds and a recovery time objective (RTO) in minutes. The solution also requires the deployment of a completely functional, but scaled-down version of the applications. Which DR strategy will meet these requirements? Seleccione una: ',
    answers: [
      { text: 'a. Pilot light', correct: false,  expli:' ' },
      { text: 'b. Multi-site active-active', correct: false,  expli:' ' },
	    { text: 'c. Backup and restore', correct: false,  expli:' ' },
      { text: 'd. Warm standby', correct: true,  expli:'La respuesta correcta es: Warm standby ' }
    ],
	img: '',  
  }, 
  {
    question: '/Test 32p Cuestionario 14 13/ A solutions architect has been given a large number of video files to upload to an Amazon S3 bucket. The file sizes are 100–500 MB. The solutions architect also wants to easily resume failed upload attempts. How should the solutions architect perform the uploads in the LEAST amount of time? Seleccione una: ',
    answers: [
      { text: 'a. Upload the files with SFTP and the AWS Transfer Family. ', correct: false,  expli:' ' },
      { text: 'b. From the Amazon S3 console, select the S3 bucket. Upload the S3 bucket, and drag and drop items into the bucket. ', correct: false,  expli:' ' },
	    { text: 'c. Split each file into 5-MB parts. Upload the individual parts normally and use S3 multipart upload to merge the parts into a complete object.', correct: false,  expli:' ' },
      { text: 'd. Using the AWS CLI, copy individual objects into the S3 bucket with the aws s3 cp command.', correct: true,  expli:' La respuesta correcta es: Using the AWS CLI, copy individual objects into the S3 bucket with the aws s3 cp command.' }
    ],
	img: '',  
  }, 
  {
    question: '/Test 32p Cuestionario 14 14/ An API receives a high volume of sensor data. The data is written to a queue before being processed to produce trend analysis and forecasting reports. With the current architecture, some data records are being received and processed more than once. How can a solutions architect modify the architecture to ensure that duplicate records are not processed?  Seleccione una: ',
    answers: [
      { text: 'a. Configure the API to send the records to Amazon Simple Notification Service (Amazon SNS).', correct: false,  expli:' ' },
      { text: 'b. Configure the API to send the records to an Amazon Simple Queue Service (Amazon SQS) FIFO queue.  ', correct: true,  expli:' La respuesta correcta es: Configure the API to send the records to an Amazon Simple Queue Service (Amazon SQS) FIFO queue.' },
	    { text: 'c. Configure the API to send the records to Amazon Kinesis Data Firehose.', correct: false,  expli:' ' },
      { text: 'd. Configure the API to send the records to Amazon Kinesis Data Streams.', correct: false,  expli:' ' }
    ],
	img: '',  
  }, 
  {
    question: '/Test 32p Cuestionario 14 15/ A company is deploying an environment for a new data processing application. This application will be frequently accessed by 20 different departments across the globe seeking to run analytics. The company plans to charge each department for the cost of that department\'s access. Which solution will meet these requirements with the LEAST effort? Seleccione una: ',
    answers: [
      { text: 'a. Amazon Athena with workgroups set up for each department. Each department will query via the workgroup tagged for their team in the billing console. ', correct: true,  expli:'La respuesta correcta es: Amazon Athena with workgroups set up for each department. Each department will query via the workgroup tagged for their team in the billing console. ' },
      { text: 'b. Amazon Redshift, with clusters set up for each department. Each department will query the cluster tagged for their team in the billing console.  ', correct: false,  expli:' ' },
	    { text: 'c. Amazon Aurora with global databases. Each department will query a database in a different Region, and the Region is tagged in the billing console.', correct: false,  expli:' ' },
      { text: 'd. PostgreSQL on Amazon RDS, with read replicas for each department. Each department will query the read replica tagged for their team in the billing console.', correct: false,  expli:' ' }
    ],
	img: '',  
  }, 
  {
    question: '/Test 32p Cuestionario 14 16/ A gaming company is experiencing exponential growth. On multiple occasions, customers have been unable to access resources. To keep up with the increased demand, Management is considering deploying a cloud-based solution. The company is looking for a solution that can match the on-premises resilience of multiple data centers, and is robust enough to withstand the increased growth activity. Which configuration should a Solutions Architect implement to deliver the desired results?  Seleccione una: ',
    answers: [
      { text: 'a. A VPC configured with an ELB Application Load Balancer targeting an EC2 Auto Scaling group consisting of Amazon EC2 instances spanning two AWS Regions', correct: false,  expli:' ' },
      { text: 'b. A VPC configured with an ELB Application Load Balancer targeting an EC2 Auto Scaling group consisting of Amazon EC2 instances in one Availability Zone ', correct: false,  expli:' ' },
	    { text: 'c. Multiple Amazon EC2 instances configured within peered VPCs across two Availability Zones ', correct: false,  expli:' ' },
      { text: 'd. A VPC configured with an ELB Network Load Balancer targeting an EC2 Auto Scaling group consisting of Amazon EC2 instances spanning two Availability Zones', correct: true,  expli:'La respuesta correcta es: A VPC configured with an ELB Network Load Balancer targeting an EC2 Auto Scaling group consisting of Amazon EC2 instances spanning two Availability Zones ' }
    ],
	img: '',  
  }, 
  {
    question: '/Test 32p Cuestionario 14 17/ A large international company has a management account in AWS Organizations, and over 50 individual accounts for each country they operate in. Each of the country accounts has least four VPCs set up for functional divisions. There is a high amount of trust across the accounts, and communication among all of the VPCs should be allowed. Each of the individual VPCs throughout the entire global organization will need to access an account and VPC that provide shared services to all the other accounts. How can the member accounts access the shared services VPC with the LEAST operational overhead? Seleccione una: ',
    answers: [
      { text: 'a. Create a VPN connection between each of the VPCs and the shared service VPC.', correct: false,  expli:' ' },
      { text: 'b. Create a peering connection between each of the VPCs and the shared services VPC. ', correct: false,  expli:' ' },
	    { text: 'c. Create a Network Load Balancer across the Availability Zones in the shared services VPC. Create service consumer roles in IAM, and set endpoint connection acceptance to automatically accept. Create consumer endpoints in each division VPC and point to the Network Load Balancer.', correct: true,  expli:' La respuesta correcta es: Create a Network Load Balancer across the Availability Zones in the shared services VPC. Create service consumer roles in IAM, and set endpoint connection acceptance to automatically accept. Create consumer endpoints in each division VPC and point to the Network Load Balancer.' },
      { text: 'd. Create an Application Load Balancer, with a target of the private IP address of the shared services VPC. Add a Certification Authority Authorization (CAA) record for the Application Load Balancer to Amazon Route 53. Point all requests for shared services in the routing tables of the VPCs to the CAA record.', correct: false,  expli:' ' }
    ],
	img: '',  
  }, 
  {
    question: '/Test 32p Cuestionario 14 18/ A company is designing a human genome application using multiple Amazon EC2 Linux instances. The high performance computing (HPC) application requires low latency and high performance network communication between the instances. Which solution provides the LOWEST latency between the instances? Seleccione una: ',
    answers: [
      { text: 'a. Launch the EC2 instances in a spread placement group. ', correct: false,  expli:' ' },
      { text: 'b. Launch the EC2 instances in an Auto Scaling group spanning multiple Regions.', correct: false,  expli:' ' },
	    { text: 'c. Launch the EC2 instances in an Auto Scaling group spanning multiple Availability Zones within a Region.', correct: false,  expli:' ' },
      { text: 'd. Launch the EC2 instances in a cluster placement group. ', correct: true,  expli:' La respuesta correcta es: Launch the EC2 instances in a cluster placement group.' }
    ],
	img: '',  
  }, 
  {
    question: '/Test 32p Cuestionario 14 19/ A company is deploying a production portal application on AWS. The database tier runs on a MySQL database. The company requires a highly available database solution that maximizes ease of management. How can the company meet these requirements? Seleccione una: ',
    answers: [
      { text: 'a. Use Amazon DynamoDB with an Amazon DynamoDB Accelerator (DAX) cluster. Create periodic on-demand backups.', correct: false,  expli:' ' },
      { text: 'b. Use Amazon RDS with a Single-AZ deployment. Schedule periodic database snapshots. ', correct: false,  expli:' ' },
	    { text: 'c. Use Amazon RDS with a Multi-AZ deployment. Schedule periodic database snapshots.  ', correct: true,  expli:' La respuesta correcta es: Use Amazon RDS with a Multi-AZ deployment. Schedule periodic database snapshots.' },
      { text: 'd. Deploy the database on multiple Amazon EC2 instances that are backed by Amazon Elastic Block Store (Amazon EBS) across multiple Availability Zones. Schedule periodic EBS snapshots.', correct: false,  expli:' ' }
    ],
	img: '',  
  }, 
  {
    question: '/Test 32p Cuestionario 14 20/ A solutions architect has been tasked with designing a three-tier application for deployment in AWS. There will be a web tier as the frontend, a backend application tier for data processing, and a database that will be hosted on Amazon RDS. The application frontend will be distributed to end users by CloudFront. Following best practices, it is decided that there should not be any point-to-point dependencies between the different layers of the infrastructure. How many Elastic Load Balancing load balancers should the architect deploy in the architecture so that this application\'s design follows best practices?  Seleccione una: ',
    answers: [
      { text: 'a. Three load balancers. One public load balancer would direct traffic to the web tier. One private load balancer would direct traffic to the application tier. Another private load balancer would direct traffic to the Amazon RDS database.', correct: false,  expli:' ' },
      { text: 'b. Zero. Use the load balancer that is automatically enabled when CloudFront is deployed. ', correct: false,  expli:' ' },
	    { text: 'c. Two load balancers. One public load balancer would direct traffic to the web tier, and one private load balancer would direct traffic to the application tier.', correct: true,  expli:' La respuesta correcta es: Two load balancers. One public load balancer would direct traffic to the web tier, and one private load balancer would direct traffic to the application tier.' },
      { text: 'd. One load balancer. This load balancer would be between the web tier and the application tier. ', correct: false,  expli:' ' }
    ],
	img: '',  
  }, 
  {
    question: '/Test 32p Cuestionario 14 21/ A SysOps administrator is looking into a way to automate the deployment of new SSL/TLS certificates to their web servers, and a centralized way to track and manage the deployed certificates. Which AWS service can the administrator use to fulfill the above-mentioned needs? Seleccione una: ',
    answers: [
      { text: 'a. Configure AWS Systems Manager Run Command', correct: false,  expli:' ' },
      { text: 'b. AWS Systems Manager Parameter Store ', correct: false,  expli:' ' },
	    { text: 'c. AWS Certificate Manager ', correct: true,  expli:'La respuesta correcta es: AWS Certificate Manager ' },
      { text: 'd. AWS Key Management Service ', correct: false,  expli:' ' }
    ],
	img: '',  
  }, 
  {
    question: '/Test 32p Cuestionario 14 22/ A Solutions Architect must secure the network traffic for two applications running on separate Amazon EC2 instances in the same subnet. The applications are called Application A and Application B. Application A requires that inbound HTTP requests be allowed and all other inbound traffic be blocked. Application B requires that inbound HTTPS traffic be allowed and all other inbound traffic be blocked, including HTTP traffic. What should the Solutions Architect use to meet these requirements? Seleccione una: ',
    answers: [
      { text: 'a. Configure the network connectivity with route tables.', correct: false,  expli:' ' },
      { text: 'b. Configure the access with network access control lists (network ACLs).', correct: false,  expli:' ' },
	    { text: 'c. Configure the access with security groups.  ', correct: true,  expli:' La respuesta correcta es: Configure the access with security groups.' },
      { text: 'd. Configure the network connectivity with VPC peering.', correct: false,  expli:' ' }
    ],
	img: '',  
  }, 
  {
    question: '/Test 32p Cuestionario 14 23/ A solutions architect needs to design a secure environment for AWS resources that are being deployed to Amazon EC2 instances in a VPC. The solution should support for a three-tier architecture consisting of web servers, application servers, and a database cluster. The VPC needs to allow resources in the web tier to be accessible from the internet with only the HTTPS protocol. Which combination of actions would meet these requirements? (Select TWO.) Seleccione una o más de una: ',
    answers: [
      { text: 'a. Create a web server security group that allows HTTPS requests from the internet. Create an application server security group that allows requests from the web security group only. Create a database cluster security group that allows TCP connections from the application security group on the database port only. ', correct: true,  expli:' una respuesta correcta es: Create a web server security group that allows HTTPS requests from the internet. Create an application server security group that allows requests from the web security group only. Create a database cluster security group that allows TCP connections from the application security group on the database port only.' },
      { text: 'b. Create a web server security group that allows all traffic from the internet. Create an application server security group that allows requests from only the Amazon API Gateway on the application port. Create a database cluster security group that allows TCP connections from the application security group on the database port only.', correct: false,  expli:' ' },
	    { text: 'c. Attach a virtual private gateway to the VPC. Create public subnets for the web and application tiers. Create private subnets for the database tier.', correct: false,  expli:' ' },
      { text: 'd. Attach an internet gateway to the VPC. Create public subnets for the web tier. Create private subnets for the application and database tiers.', correct: true,  expli:'  una respuesta correcta es: Attach an internet gateway to the VPC. Create public subnets for the web tier. Create private subnets for the application and database tiers. ' },
      { text: 'e. Attach Amazon API Gateway to the VPC. Create private subnets for the web, application, and database tiers.', correct: false,  expli:' ' }
    ],
	img: '',  
  }, 
  {
    question: '/Test 32p Cuestionario 14 24/ A company is migrating its on-premises application to Amazon Web Services and refactoring its design. The design will consist of frontend Amazon EC2 instances that receive requests, backend EC2 instances that process the requests, and a message queuing service to address decoupling the application. The Solutions Architect has been informed that a key aspect of the application is that requests are processed in the order in which they are received. Which AWS service should the Solutions Architect to decouple the application? Seleccione una: ',
    answers: [
      { text: 'a. Amazon Kinesis', correct: false,  expli:' ' },
      { text: 'b. Amazon Simple Queue Service (Amazon SQS) standard queue', correct: false,  expli:' ' },
	    { text: 'c. Amazon Simple Notification Service (Amazon SNS)', correct: false,  expli:' ' },
      { text: 'd. Amazon Simple Queue Service (Amazon SQS) FIFO queue  ', correct: true,  expli:'La respuesta correcta es: Amazon Simple Queue Service (Amazon SQS) FIFO queue ' }
    ],
	img: '',  
  }, 
  {
    question: '/Test 32p Cuestionario 14 25/ A company requires operating system permissions on a relational database server. What should a solutions architect suggest as a configuration for a highly available database architecture?  Seleccione una: ',
    answers: [
      { text: 'a. Multiple Amazon EC2 instances in a replication configuration that uses a placement group', correct: false,  expli:' ' },
      { text: 'b. Multiple Amazon EC2 instances in a database replication configuration that uses two Availability Zones ', correct: true,  expli:'La respuesta correcta es: Multiple Amazon EC2 instances in a database replication configuration that uses two Availability Zones ' },
	    { text: 'c. A database installed on a single Amazon EC2 instance in an Availability Zone', correct: false,  expli:' ' },
      { text: 'd. Amazon RDS in a Multi-AZ configuration with Provisioned IOPS', correct: false,  expli:' ' }
    ],
	img: '',  
  }, 
  {
    question: '/Test 32p Cuestionario 14 26/ A financial services company is migrating its multi-tier web application to AWS. The application architecture consists of a fleet of web servers, application servers, and an Oracle database. The company must have full control over the database\'s underlying operating system, and the database must be highly available. Which approach should a solutions architect use for the database tier to meet these requirements? Seleccione una: ',
    answers: [
      { text: 'a. Migrate to Amazon EC2 instances in a single Availability Zone. Install Oracle Database and configure the instances to operate as a cluster.', correct: false,  expli:' ' },
      { text: 'b. Migrate the database to an Amazon RDS for Oracle DB Single-AZ DB instance.', correct: false,  expli:' ' },
	    { text: 'c. Migrate to Amazon EC2 instances in two Availability Zones. Install Oracle Database and configure the instances to operate as a cluster. ', correct: true,  expli:'La respuesta correcta es: Migrate to Amazon EC2 instances in two Availability Zones. Install Oracle Database and configure the instances to operate as a cluster ' },
      { text: 'd. Migrate the database to an Amazon RDS for Oracle Multi-AZ DB instance.', correct: false,  expli:' ' }
    ],
	img: '',  
  }, 
  {
    question: '/Test 32p Cuestionario 14 27/ A company\'s application allows users to upload image files to an Amazon S3 bucket. These files are accessed frequently for the first 30 days. After 30 days, these files are rarely accessed, but need to be durably stored and available immediately upon request. A solutions architect is tasked with configuring a lifecycle policy that minimizes the overall cost while meeting the application requirements. Which action will accomplish this?  Seleccione una: ',
    answers: [
      { text: 'a. Configure a lifecycle policy to move the files to S3 Glacier after 30 days.', correct: false,  expli:' ' },
      { text: 'b. Configure a lifecycle policy to move the files to S3 Standard-Infrequent Access (S3 Standard-IA) after 30 days. ', correct: true,  expli:'La respuesta correcta es: Configure a lifecycle policy to move the files to S3 Standard-Infrequent Access (S3 Standard-IA) after 30 days. ' },
	    { text: 'c. Configure a lifecycle policy to move the files to S3 One Zone-Infrequent Access (S3 One Zone-IA) after 30 days.  ', correct: false,  expli:' ' },
      { text: 'd. Configure a lifecycle policy to move the files to S3 Glacier Deep Archive after 30 days.', correct: false,  expli:' ' }
    ],
	img: '',  
  }, 
  {
    question: '/Test 32p Cuestionario 14 28/ After reviewing the cost optimization checks in AWS Trusted Advisor, a team finds that it has 10,000 Amazon Elastic Block Store (Amazon EBS) snapshots in its account that are more than 30 days old. The team has determined that it needs to implement better governance for the lifecycle of its resources. Which actions should the team take to automate the lifecycle management of the EBS snapshots with the LEAST effort? (Select TWO.)  Seleccione una o más de una: ',
    answers: [
      { text: 'a. Use Amazon Data Lifecycle Manager (Amazon DLM).', correct: true,  expli:' una respuesta correcta es:  Use Amazon Data Lifecycle Manager (Amazon DLM).' },
      { text: 'b. Create and schedule a backup plan with AWS Backup. ', correct: true,  expli:' una respuesta correcta es: Create and schedule a backup plan with AWS Backup.' },
	    { text: 'c. Schedule and run backups in AWS Systems Manager.', correct: false,  expli:' ' },
      { text: 'd. Use a scheduled event in Amazon EventBridge (Amazon CloudWatch Events) and invoke AWS Step Functions to manage the snapshots.', correct: false,  expli:' ' },
      { text: 'e. Copy the EBS snapshots to Amazon S3, and then create lifecycle configurations in the S3 bucket.', correct: false,  expli:' ' }
    ],
	img: '',  
  }, 
  {
    question: '/Test 32p Cuestionario 14 29/ A company is using an Amazon S3 bucket to store archived data for audits. The company needs long-term storage for the data. The data is rarely accessed and must be available for retrieval the next business day. After a quarterly review, the company wants to reduce the storage cost for the S3 bucket. A solutions architect must recommend the most cost-effective solution to store the archived data. Which solution will meet these requirements? Seleccione una:',
    answers: [
      { text: 'a. Store the data in another S3 bucket in a different AWS Region.', correct: false,  expli:' ' },
      { text: 'b. Store the data on an Amazon EC2 instance that uses Amazon Elastic Block Store (Amazon EBS).', correct: false,  expli:' ' },
	    { text: 'c. Store the data in S3 Glacier. ', correct: true,  expli:'La respuesta correcta es: Store the data in S3 Glacier.' },
      { text: 'd. Use an S3 Lifecycle configuration rule to move the data to S3 Standard-Infrequent Access (S3 Standard-IA).', correct: false,  expli:' ' }
    ],
	img: '',  
  }, 
  {
    question: '/Test 32p Cuestionario 14 30/ A company needs to implement a secure data encryption solution to meet regulatory requirements. The solution must provide security and durability in generating, storing, and controlling cryptographic data keys. Which action should be taken to provide the MOST secure solution? Seleccione una: ',
    answers: [
      { text: 'a. Use AWS Key Management Service (AWS KMS) to generate cryptographic keys and import the keys to AWS Certificate Manager. Use IAM policies to control access to the keys.', correct: false,  expli:' ' },
      { text: 'b. Use OpenSSL to generate the cryptographic keys and upload the keys to an Amazon S3 bucket with encryption enabled. Apply AWS Key Management Service (AWS KMS) key policies to control access to the keys.', correct: false,  expli:' ' },
	    { text: 'c. Use a third-party solution from AWS Marketplace to generate the cryptographic keys and store them on encrypted instance store volumes. Use IAM policies to control access to the encryption key APIs.', correct: false,  expli:' ' },
      { text: 'd. Use AWS Key Management Service (AWS KMS) to generate AWS KMS keys and data keys. Use AWS KMS key policies to control access to the KMS keys. ', correct: true,  expli:' La respuesta correcta es: Use AWS Key Management Service (AWS KMS) to generate AWS KMS keys and data keys. Use AWS KMS key policies to control access to the KMS keys.' }
    ],
	img: '',  
  }, 
  {
    question: '/Test 32p Cuestionario 14 31/ The CIO of a company is concerned about the security of the account root user of their AWS account. How can the CIO ensure that the AWS account follows the best practices for logging in securely? (Select TWO.)  Seleccione una o más de una: ',
    answers: [
      { text: 'a. Enforce the use of complex passwords for member account root user logins. ', correct: true,  expli:' una respuesta correcta es :Enforce the use of complex passwords for member account root user logins.' },
      { text: 'b. Enforce the account root user to assume a role to access the root user\'s own resources.', correct: false,  expli:' ' },
	    { text: 'c. Enforce the use of MFA for the account root user logins. ', correct: false,  expli:' una respuesta correcta es : Enforce the use of MFA for the account root user logins.' },
      { text: 'd. Enforce the deletion of the AWS account so that it cannot be used.', correct: false,  expli:' ' },
      { text: 'e. Enforce the use of an access key ID and secret access key for the account root user logins.', correct: false,  expli:' ' }
    ],
	img: '',  
  }, 
  {
    question: '/Test 32p Cuestionario 14 32/ A Solutions Architect notices an abnormal amount of network traffic coming from an Amazon EC2 instance. The traffic is determined to be malicious and the destination needs to be determined. What tool can the Solutions Architect use to identify the destination of the malicious network traffic? Seleccione una: ',
    answers: [
      { text: 'a. Filter the logs from Amazon CloudWatch.', correct: false,  expli:' ' },
      { text: 'b. Consult the AWS Personal Health Dashboard.', correct: false,  expli:' ' },
	    { text: 'c. Enable AWS CloudTrail and filter the logs.  ', correct: false,  expli:' ' },
      { text: 'd. Enable VPC Flow Logs and filter the logs.', correct: true,  expli:'La respuesta correcta es: Enable VPC Flow Logs and filter the logs. ' }
    ],
	img: '',  
  }, 
  {
    question: '/Exam Prep 1 - 65p - 1 / You are using DynamoDB to host a discussion forum website on AWS topics (S3, VPC, ELB….). Users can subscribe to notification whenever there is a new discussion thread or post on topics they have chosen. For example user Smith has chosen to be notified for (RDS, EC2, ECS). How can you achieve this? Seleccione una: ',
    answers: [
      { text: 'a. Use Cloudtrail with DynamoDB stream to capture the new post or topic record insertion in the table, trigger a Lambda to query the list of users subscribed to that discussion topic then it will send notification to subscribed users through SNS.', correct: false,  expli:' ' },
      { text: 'b. Use Lambda with DynamoDB stream to capture the new post or topic record insertion in the table, function will have logic to query the list of users subscribed to that discussion topic then it will send notification to subscribed users through SNS. ', correct: true,  expli:'La respuesta correcta es: Use Lambda with DynamoDB stream to capture the new post or topic record insertion in the table, function will have logic to query the list of users subscribed to that discussion topic then it will send notification to subscribed users through SNS. <br>'+
      ' Respuesta correcta AWS Documentation Reference: https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/Streams.Lambda.html <br>'+
      ' Amazon DynamoDB is integrated with AWS Lambda so that you can create triggers—pieces of code that automatically respond to events in DynamoDB Streams. With triggers, you can build applications that react to data modifications in DynamoDB tables.<br>'+
      ' If you enable DynamoDB Streams on a table, you can associate the stream Amazon Resource Name (ARN) with an AWS Lambda function that you write. Immediately after an item in the table is modified, a new record appears in the table\'s stream. AWS Lambda polls the stream and invokes your Lambda function synchronously when it detects new stream records. <br>'+
      ' The Lambda function can perform any actions you specify, such as sending a notification or initiating a workflow. '},
	    { text: 'c. Use Cloudwatch with DynamoDB stream to capture the new post or topic record insertion in the table, trigger a Lambda to query the list of users subscribed to that discussion topic then it will send notification to subscribed users through SNS.', correct: false,  expli:' ' },
      { text: 'd. Use a scheduled job running in an EC2 server to continuously read the DynamoDB table and send the notification to subscribed users through SNS.', correct: false,  expli:' ' }
    ],
	img: '',  
  }, 
  {
    question: '/Exam Prep 1 - 65p - 2 / What is a fan out scenario? Seleccione una:  ',
    answers: [
      { text: 'a. Message is sent to a SQS queue and then replicated and pushed to multiple Amazon SNS topics.', correct: false,  expli:' ' },
      { text: 'b. A publisher sends same message to multiple SNS topics or SQS queues', correct: true,  expli:' La respuesta correcta es: A publisher sends same message to multiple SNS topics or SQS queues <br>'+
      '  AWS Documentation Reference: https://docs.aws.amazon.com/sns/latest/dg/sns-common-scenarios.html The fanout scenario is when an Amazon SNS message is sent to a topic and then replicated and pushed to multiple Amazon SQS queues, HTTP endpoints, or email addresses. This allows for parallel asynchronous processing.' },
	    { text: 'c. Message is sent to a SQS queue and then replicated and pushed to multiple Amazon SQS queues.', correct: false,  expli:' ' },
      { text: 'd. Amazon SNS message is sent to a topic and then replicated and pushed to multiple Amazon SQS queues, HTTP endpoints, or email addresses. ', correct: false,  expli:' ' }
    ],
	img: '',  
  }, 
  {
    question: '/Exam Prep 1 - 65p - 3 / You are the solution architect for a global financial services company providing banking and stock market trading to its customers. Because of compliance and regulatory reasons the application must be hosted in respective country of the users. For example a U.S citizen request must be routed to application hosted in US-East region and for a European Union user it must be routed to application hosted in EU-Central region. Which routing policy you will configure in the Route 53 to achieve this requirement? Seleccione una:',
    answers: [
      { text: 'a. User Profile Routing', correct: false,  expli:' ' },
      { text: 'b. Geolocation Routing ', correct: true,  expli:' La respuesta correcta es: Geolocation Routing. <br> AWS Documentation Reference: https://docs.aws.amazon.com/Route53/latest/DeveloperGuide/routing-policy.html Since the requirement here is routing based on ‘location’ of the user, the appropriate routing policy will be Geolocation Routing. Geoproximity routing policy is used when you want to route traffic based on the location of your resources and, optionally, shift traffic from resources in one location to resources in another.' },
	    { text: 'c. User Location Routing', correct: false,  expli:' ' },
      { text: 'd. Geoproximity Routing', correct: false,  expli:' ' }
    ],
	img: '',  
  }, 
  {
    question: '/Exam Prep 1 - 65p - 4 / You run an online photo editing website for two type of members: free members and fee paying premium members. The set of editing requests and photos is placed asynchronously in a SQS queue which is then process by worked EC2 instances in an auto scaling group. The architecture has two SQS queues, one for premium members and one for free members editing task. You have on-demand EC2 instances in an auto scale group to process the messages in the premium members queue and spot instances for processing the message from free member queue. At times spot instances are terminated by AWS. What will happen to messages which are in-process by those terminated instances? Seleccione una:',
    answers: [
      { text: 'a. The message will be deleted by SQS.', correct: false,  expli:' ' },
      { text: 'b. The message will be visible in the queue after the visibility time is over and picked up for processing by other live spot instance. ', correct: true,  expli:' La respuesta correcta es: The message will be visible in the queue after the visibility time is over and picked up for processing by other live spot instance. '+
      ' AWS Documentation Reference: https://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/sqs-visibility-timeout.html '+
' When a consumer receives and processes a message from a queue, the message remains in the queue. To prevent other consumers from processing the message again, Amazon SQS sets a visibility timeout, a period of time during which Amazon SQS prevents other consumers from receiving and processing the message. '+
' Amazon SQS doesn\'t automatically delete the message. Thus, the consumer must delete the message from the queue after receiving and processing it. '+
' In the given scenario as the processing is terminated before completion, the consumer program didn’t deleted the message from the queue. Hence it will be visible again in the queue for other spot instance to receive it after the visibility time is over. ' },
	    { text: 'c. The message will be visible immediately in the queue and picked up for processing by other live spot instance.', correct: false,  expli:' ' },
      { text: 'd. The message will be deleted by the terminated instance and will not appear in the queue.', correct: false,  expli:' ' }
    ],
	img: '',  
  }, 
  {
    question: '/Exam Prep 1 - 65p - 5 / How can you ensure that the load balancer stops sending requests to instances that are deregistering or unhealthy while keeping the existing session connection open so as to complete the in-flight requests to these instances ? Seleccione una:',
    answers: [
      { text: 'a. Programmatically keep sending requests to the same instance till session completes.', correct: false,  expli:' ' },
      { text: 'b. Enable sticky sessions. ', correct: false,  expli:' ' },
	    { text: 'c. Enable connection draining.', correct: true,  expli:' La respuesta correcta es: Enable connection draining' +
      ' AWS Documentation Reference: https://aws.amazon.com/about-aws/whats-new/2014/03/20/elastic-load-balancing-supports-connection-draining/ '+
' https://aws.amazon.com/blogs/aws/elb-connection-draining-remove-instances-from-service-with-care/ '+
' When you enable Connection Draining on a load balancer, any back-end instances that you deregister will complete requests that are in progress before deregistration. '+
' Likewise, if a back-end instance fails health checks, the load balancer will not send any new requests to the unhealthy instance but will allow existing requests to complete. '+
' This means that you can perform maintenance such as deploying software upgrades or replacing back-end instances without impacting your customers’ experience. '+
' Connection Draining is also integrated with Auto Scaling, making it even easier to manage the capacity behind your load balancer. '+
' When Connection Draining is enabled, Auto Scaling will wait for outstanding requests to complete before terminating instances. '},
      { text: 'd. All of the above.', correct: false,  expli:' ' }
    ],
	img: '',  
  }, 
  {
    question: '/Exam Prep 1 - 65p - 6 / A new user is unable to access any AWS services, what is the most likely explanation? Seleccione una: ',
    answers: [
      { text: 'a. The services are currently unavailable', correct: false,  expli:' ' },
      { text: 'b. The user needs to login with a key pair', correct: false,  expli:' ' },
	    { text: 'c. The default limit for user logons has been reached', correct: false,  expli:' ' },
      { text: 'd. By default, new users are created without access to any AWS services ', correct: true,  expli:' La respuesta correcta es: By default, new users are created without access to any AWS services • By default, new users are created with NO access to any AWS services – they can only login to the AWS console' }
    ],
	img: '',  
  }, 
  {
    question: '/Exam Prep 1 - 65p - 7 / Which of the following are AWS recommended best practices in relation to IAM? (choose 2) Seleccione una o más de una:',
    answers: [
      { text: 'a. Embed access keys in application code', correct: false,  expli:' ' },
      { text: 'b. Assign permissions to users', correct: false,  expli:' ' },
	    { text: 'c. Enable MFA for all users ', correct: false,  expli:' ' },
      { text: 'd. Create individual IAM users', correct: true,  expli:' una respuesta correcta es : Create individual IAM users, Grant least privileg • AWS recommend creating individual IAM users and assigning the least privileges necessary for them to perform their rolee' },
      { text: 'e. Grant least privilege ', correct:true,  expli:'una respuesta correcta es : Create individual IAM users, Grant least privilege  • You should use groups to assign permissions to IAM users, should avoid embedding access keys in application code, and should enable MFA for privileged users (not everyone)' }
    ],
	img: '',  
  }, 
  {
    question: '/Exam Prep 1 - 65p - 8 / Which configuration changes are associated with scaling vertically? (choose 2) Seleccione una o más de una:',
    answers: [
      { text: 'a. Adding additional EC2 instances through Auto Scaling', correct: false,  expli:' ' },
      { text: 'b. Adding a larger capacity hard drive to a server ', correct: true,  expli:' una respuesta correcta es : Adding a larger capacity hard drive to a server' },
	    { text: 'c. Adding additional hard drives to a storage array', correct: false,  expli:' ' },
      { text: 'd. Changing an EC2 instance to a type that has more CPU and RAM', correct: true,  expli:' una respuesta correcta es : Changing an EC2 instance to a type that has more CPU and RAM '+
      '• Scaling vertically takes place through an increase in the specifications of an individual resource (e.g., upgrading a server with a larger hard drive or a faster CPU). On Amazon EC2, this can easily be achieved by stopping an instance and resizing it to an instance type that has more RAM, CPU, IO, or networking capabilities'+
      '• Scaling horizontally takes place through an increase in the number of resources (e.g., adding more hard drives to a storage array or adding more servers to support an application)' },
      { text: 'e. Distributed processing', correct: false,  expli:' ' }
    ],
	img: '',  
  }, 
  {
    question: '/Exam Prep 1 - 65p - 9 / You are migrating your on premise Windows-based custom build .Net applications to AWS cloud platform using Lift-and-Shift strategy. These applications require shared file storage provided by Windows-based file systems (NTFS) and that uses the SMB protocol. Which AWS services you will use? Choose 2. Seleccione una o más de una:',
    answers: [
      { text: 'a. EC2', correct: true,  expli:'una respuesta correcta es : EC2 ' },
      { text: 'b. EBS', correct: false,  expli:' ' },
	    { text: 'c. Lambda', correct: false,  expli:' ' },
      { text: 'd. FSx for Windows File Server', correct: true,  expli:' una respuesta correcta es : FSx for Windows File Server '+ 
      ' EC2 instance with windows based AMI along with Amazon FSx for Windows File Server to provide the environment similar to on-premise '+
' AWS Documentation Reference: https://aws.amazon.com/fsx/windows/'+
' Amazon FSx is built on Windows Server and provides you with the native Windows file system features and performance that your applications need from a file store. '+
' By providing fully managed native Windows file shares with features like Microsoft AD integration and automatic backups, you can easily migrate Windows-based applications to AWS. '+
' Amazon FSx supports Windows-native file system features such as Access Control Lists (ACLs), shadow copies, and user quotas to help you move your applications to AWS with minimal disruption. '+
' Amazon FSx provides NTFS file systems that can be accessed from up to thousands of compute instances using the SMB protocol. '+
' Amazon FSx works with Microsoft Active Directory (AD) to easily integrate your file system with your Windows environments. '},
      { text: 'e. EFS ', correct: false,  expli:' ' }
    ],
	img: '',  
  }, 
  {
    question: '/Exam Prep 1 - 65p - 10 / Which AWS service lets you monitor the HTTP and HTTPS requests that are forwarded to an Amazon API Gateway, Amazon CloudFront or an Application Load Balancer and gives you control over which traffic to allow or block to your web applications by defining customizable web security rules? Seleccione una: ',
    answers: [
      { text: 'a. AWS Cloudtrail', correct: false,  expli:' ' },
      { text: 'b. AWS WAF ', correct: true,  expli:' La respuesta correcta es: AWS WAF . AWS Documentation Reference: https://aws.amazon.com/waf/ '+
    ' AWS WAF is a web application firewall that lets you monitor the HTTP and HTTPS requests that are forwarded to an Amazon API Gateway, Amazon CloudFront or an Application Load Balancer. '+
    ' AWS WAF gives you control over which traffic to allow or block to your web applications by defining customizable web security rules. ' },
	    { text: 'c. AWS Shield', correct: false,  expli:' ' },
      { text: 'd. AWS Cloudwatch', correct: false,  expli:' ' }
    ],
	img: '',  
  }, 
  {
    question: '/Exam Prep 1 - 65p - 11 / What are two ways an AWS customer can reduce their monthly spend? (choose 2) Seleccione una o más de una: ',
    answers: [
      { text: 'a. Turn off resources that are not being used ', correct: true,  expli:' una respuesta correcta es : Turn off resources that are not being used' },
      { text: 'b. Be efficient with usage of Security Groups', correct: false,  expli:' ' },
	    { text: 'c. Reduce the amount of data ingress charges', correct: false,  expli:' ' },
      { text: 'd. Reserve capacity where suitable ', correct: true,  expli:' una respuesta correcta es :  Reserve capacity where suitable'+
      ' • Turning of resources that are not used can reduce spend. You can also use reserved instances to reduce the monthly spend at the expense of having to lock into a 1 or 3-year contract - good for stable workloads '+
      ' • You don\'t pay for power, security groups, or data ingress to the AWS cloud so these answers are all incorrect '},
      { text: 'e. Use more power efficient instance types', correct: false,  expli:' ' }
    ],
	img: '',  
  }, 
  {
    question: '/Exam Prep 1 - 65p - 12 / John hosts his personal blog website as static website on S3. The bucket name he uses to store his website files is ‘west-bucket’ in ‘us-west-2’ region. The photos are uploaded under the main bucket folder using the S3 console. What is the url of john’s static website? Seleccione una: ',
    answers: [
      { text: 'a. http://s3-us-west-2.amazonaws.com/west-bucket ', correct: false,  expli:' ' },
      { text: 'b. http://west-bucket.s3-us-west-2.amazonaws.com/', correct: false,  expli:' ' },
	    { text: 'c. http://s3-website-us-west-2.amazonaws.com/west-bucket', correct: false,  expli:' ' },
      { text: 'd. http://west-bucket.s3-website-us-west-2.amazonaws.com/', correct: true,  expli:' La respuesta correcta es: http://west-bucket.s3-website-us-west-2.amazonaws.com/' +
      ' AWS Documentation Reference links: '+
' https://docs.aws.amazon.com/AmazonS3/latest/dev/WebsiteHosting.html '+
' https://docs.aws.amazon.com/AmazonS3/latest/dev/WebsiteEndpoints.html '+
' https://docs.aws.amazon.com/general/latest/gr/rande.html#s3_website_region_endpoints '+
' After configuring a S3 bucket for website hosting, website content are uploaded to the bucket. '+
' The bucket must have public read access. The website is then available at the AWS Region-specific website endpoint of the bucket, which is in one of the following formats: '+
' <bucket-name>.s3-website-<AWS-region>.amazonaws.com '+
' <bucket-name>.s3-website. <AWS-region>.amazonaws.com '+
' Which format is used for the endpoint depends on what Region the bucket is in. '+
' In the given scenario the website endpoint for us-west-2 regions is '+
' ‘s3-website-us-west-2.amazonaws.com’ therefore the url for the website will be '+
' http://west-bucket.s3-website-us-west-2.amazonaws.com/ '}
    ],
	img: '',  
  }, 
  {
    question: '/Exam Prep 1 - 65p - 13 / Which AWS service you will use for real time analytics of streaming data such as IoT telemetry data, application logs, and website clickstreams? Seleccione una:',
    answers: [
      { text: 'a. Amazon Kinesis ', correct: true,  expli:' La respuesta correcta es: Amazon Kinesis. AWS Documentation Reference: https://aws.amazon.com/big-data/datalakes-and-analytics/'+
    ' For real-time analytics, Amazon Kinesis makes it easy to collect, process and analyze streaming data such as IoT telemetry data, application logs, and website clickstreams.'+
    ' This enable you to process, and analyze data as it arrives in your data lake, and respond in real-time instead of having to wait until all your data is collected before the processing can begin.' },
      { text: 'b. Amazon Athena', correct: false,  expli:' ' },
	    { text: 'c. Amazon Elasticsearch Service', correct: false,  expli:' ' },
      { text: 'd. Amazon QuickSight', correct: false,  expli:' ' }
    ],
	img: '',  
  }, 
  {
    question: '/Exam Prep 1 - 65p - 14 / How can an organization assess applications for vulnerabilities and deviations from best practice? Seleccione una:',
    answers: [
      { text: 'a. Use AWS Inspector ', correct: true,  expli:' La respuesta correcta es: Use AWS Inspector'+ 
      ' • Inspector is an automated security assessment service that helps improve the security and compliance of applications deployed on AWS. Inspector automatically assesses applications for vulnerabilities or deviations from best practices '+
      ' • AWS Artifact is your go-to, central resource for compliance-related information that matters to you • AWS Shield is a managed Distributed Denial of Service (DDoS) protection service • AWS WAF is a web application firewall '},
      { text: 'b. Use AWS Artifact', correct: false,  expli:' ' },
	    { text: 'c. Use AWS WAF', correct: false,  expli:' ' },
      { text: 'd. Use AWS Shield', correct: false,  expli:' ' }
    ],
	img: '',  
  }, 
  {
    question: '/Exam Prep 1 - 65p - 15 / You are the architect of a payment gateway provider and anticipating a fivefold increase in traffic in the upcoming shopping season. You are using RDS with MySQL as database engine. During load testing you notice a decrease in query performance with increase in traffic. Which of the following options you could do immediately to increase database performance? Seleccione una: ',
    answers: [
      { text: 'a. Instead of MySQL use Oracle or SQL Server.', correct: false,  expli:' ' },
      { text: 'b. Use Read Replicas and redirect read queries to those replicas.', correct: true,  expli:' La respuesta correcta es: Use Read Replicas and redirect read queries to those replicas. Multi-AZ deployment doesn’t improve performance.' },
	    { text: 'c. Use Multi-AZ deployment option to increase read and write performance.', correct: false,  expli:' ' },
      { text: 'd. Instead of MySQL use DynamoDB.', correct: false,  expli:' ' }
    ],
	img: '',  
  }, 
  {
    question: '/Exam Prep 1 - 65p - 16 / Considering the rules of IPv4 subnetting, how many IP addresses are reserved given the following network 192.168.130.130/28? Seleccione una: ',
    answers: [
      { text: 'a. 4', correct: false,  expli:' ' },
      { text: 'b. 2', correct: false,  expli:' ' },
	    { text: 'c. 3', correct: false,  expli:' ' },
      { text: 'd. 5', correct: true,  expli:' La respuesta correcta es: 5. AWS Documentation Reference: https://docs.aws.amazon.com/vpc/latest/userguide/VPC_Subnets.html#vpc-sizing-ipv4 The first four IP addresses and the last IP address in each subnet CIDR block are not available for you to use, and cannot be assigned to an instance.' }
    ],
	img: '',  
  }, 
  {
    question: '/Exam Prep 1 - 65p - 17 /  Which of the following statements is incorrect as the suitable scenario for using ENI vs EN vs EFA? Seleccione una: ',
    answers: [
      { text: 'a. Use ENI when you need to accelerate High Performance Computing and machine learning application.', correct: true,  expli:' La respuesta correcta es: Use ENI when you need to accelerate High Performance Computing and machine learning application.' },
      { text: 'b. Use ENI when you need basic networking and want to create a separate management network at low cost.', correct: false,  expli:' ' },
	    { text: 'c. Use EN (Enhanced Networking) when you need speeds between 10GBps and 100 GBps with high throughput.', correct: false,  expli:' ' },
      { text: 'd. Use EFA when you need to accelerate High Performance Computing and machine learning application. ', correct: false,  expli:' ' }
    ],
	img: '',  
  }, 
  {
    question: '/Exam Prep 1 - 65p - 18 / Which AWS service enables developers to manage and synchronize mobile app data in real time across devices and users, but still allows the data to be accessed and altered when the mobile device is in an offline state? Seleccione una: ',
    answers: [
      { text: 'a. AWS DataSync', correct: false,  expli:' ' },
      { text: 'b. Amazon API Gateway', correct: false,  expli:' ' },
	    { text: 'c. AWS AppSync ', correct: true,  expli:' La respuesta correcta es: AWS AppSync. AWS Documentation Reference: https://aws.amazon.com/appsync/faqs/ '+
' AWS AppSync is a service that enables developers to manage and synchronize mobile app data in real time across devices and users, but still allows the data to be accessed and altered when the mobile device is in an offline state.'+
' The service further allows developers to optimize the user experience by selecting which data is automatically synchronized to each user\'s device when changes are made, minimizing storage and bandwidth requirements, with a query language called GraphQL.'+
' Using these capabilities, developers can, in minutes, build real time collaborative experiences spanning browsers, mobile apps, Alexa skills, and IoT devices that remain usable when network connectivity is lost.'},
      { text: 'd. Amazon Cognito', correct: false,  expli:' ' }
    ],
	img: '',  
  }, 
  {
    question: '/Exam Prep 1 - 65p - 19 / Which Amazon EBS volume type you will use for 1-Streaming workloads requiring consistent, fast throughput at a low price 2-Big data or Data warehouses 3-Log processing Seleccione una: ',
    answers: [
      { text: 'a. Cold HDD (sc1)', correct: false,  expli:' ' },
      { text: 'b. General Purpose SSD (gp2)', correct: false,  expli:' ' },
	    { text: 'c. Throughput Optimized HDD (st1) ', correct: true,  expli:' La respuesta correcta es: Throughput Optimized HDD (st1) AWS Documentation Reference: https://docs.aws.amazon.com/en_pv/AWSEC2/latest/UserGuide/EBSVolumeTypes.html' },
      { text: 'd. Provisioned IOPS SSD (io1)', correct: false,  expli:' ' }
    ],
	img: '',  
  }, 
  {
    question: '/Exam Prep 1 - 65p - 20 / You have a photo upload application and use S3 to store the uploaded images. After an image is uploaded you want to create a thumbnail version of it. Which of the following option will be most scalable and cost effective? Seleccione una:',
    answers: [
      { text: 'a. S3 posts new image upload event notification as JSON to a SNS topic from which a fleet of EC2 servers will process the image.', correct: false,  expli:' ' },
      { text: 'b. Create a Lambda function that Amazon S3 can invoke when objects are created. Then, the Lambda function can read the image object from the source bucket and create a thumbnail image target bucket  ', correct: true,  expli:' La respuesta correcta es: Create a Lambda function that Amazon S3 can invoke when objects are created. Then, the Lambda function can read the image object from the source bucket and create a thumbnail image target bucket. '+
    ' Lambda function can be configured as S3 event notification target. AWS Documentation Reference: https://aws.amazon.com/lambda/ ' +
    ' AWS Lambda lets you run code without provisioning or managing servers. You pay only for the compute time you consume - there is no charge when your code is not running. '+
    ' Just upload your code and Lambda takes care of everything required to run and scale your code with high availability.' },
	    { text: 'c. S3 posts new image upload event notification as JSON to a SQS queue from which a fleet of EC2 servers will process the image.', correct: false,  expli:' ' },
      { text: 'd. Have a fleet of EC2 instances running a program which continuously reads the most latest object uploaded in S3 and converts into thumbnail.', correct: false,  expli:' ' }
    ],
	img: '',  
  }, 
  {
    question: '/Exam Prep 1 - 65p - 21 / Which AWS service you will use to direct your users to application based on their geographic location, application health, and weights that you can configure. You also want to use static IP addresses that are globally unique for your application so that there is no need to update clients as your application scales. Your application has Application Load Balancers. Seleccione una: ',
    answers: [
      { text: 'a. CloudFront', correct: false,  expli:' ' },
      { text: 'b. Global Accelerator', correct: true,  expli:' La respuesta correcta es: Global Accelerator'+
      'None of the other options provide static ip address. AWS Documentation Reference: '+
      'https://aws.amazon.com/global-accelerator/features/'+
      'https://aws.amazon.com/blogs/aws/new-aws-global-accelerator-for-availability-and-performance/'+
      'AWS Global Accelerator uses AWS’s vast, highly available and congestion-free global network to direct internet traffic from your users to your applications running in AWS regions. '+
      'With AWS Global Accelerator, your users are directed to your workload based on their geographic location, application health, and weights that you can configure. '+
      'AWS Global Accelerator also allocates static Anycast IP addresses that are globally unique for your application and do not change, thus removing the need to update clients as your application scales. ' },
	    { text: 'c. Application Load Balancer', correct: false,  expli:' ' },
      { text: 'd. Route53 ', correct: false,  expli:' ' }
    ],
	img: '',  
  }, 
  {
    question: '/Exam Prep 1 - 65p - 22 / You have developed your own blog website ‘www.mycloudblogs.com’ in which you write about AWS, Cloud and Digital topics. It also has other features of discussion forums and ability for the user to take mock tests. You have deployed it in a VPC, web server on EC2 instances with Auto Scaling group and an Application Load Balancer (ALB) in the front. The domain name ‘www.mycloudblogs.com’ will be pointing to the ALB. You are also using Route 53 to manage DNS Which record types will you create in Route 53 assuming you have configured your VPC and ALB to route only IPv4 traffic? Seleccione una:',
    answers: [
      { text: 'a. ‘A’ Non Alias record with Alias Target as the ALB', correct: false,  expli:' ' },
      { text: 'b. ‘A’ Alias record with Alias Target as the ALB', correct: true,  expli:'La respuesta correcta es:  ‘A’ Alias record with Alias Target as the ALB '+
      'AWS Documentation Reference: As it is mentioned that VPC and ALB routes only IPv4 traffic and not IPv6, option A and D is not applicable as AAAA record type is for IPv6 addresses.'+
'Option is incorrect because a Non Alias A record type should map to an ip address. In this case the ip address of ALB can change over time.'+
'https://docs.aws.amazon.com/Route53/latest/DeveloperGuide/routing-to-elb-load-balancer.html'+
'https://docs.aws.amazon.com/Route53/latest/DeveloperGuide/resource-record-sets-choosing-alias-non-alias.html'+
'https://docs.aws.amazon.com/Route53/latest/DeveloperGuide/ResourceRecordTypes.html#CNAMEFormat'+
'Amazon Route 53 alias records provide a Route 53–specific extension to DNS functionality. Alias records lets you route traffic to selected AWS resources, such as ALB, CloudFront distributions and Amazon S3 buckets.'+
'To route domain traffic to an ELB load balancer, use Amazon Route 53 to create an alias record that points to your load balancer. An alias record is a Route 53 extension to DNS.'+
'When you use an alias record to route traffic to an AWS resource, Route 53 automatically recognizes changes in the resource. For example, suppose an alias record for ‘www.mycloudblogs.com’ points to an ELB load balancer at lb1-1234.us-east-2.elb.amazonaws.com.'+
'If the IP address of the load balancer changes, Route 53 automatically starts to respond to DNS queries using the new IP address.'+
'It\'s similar to a CNAME record, but you can create an alias record both for the root domain, mycloudblogs.com, and for subdomains, such as www. mycloudblogs.com. '+
'E is not correct because the DNS protocol does not allow you to create a CNAME record for the top node of a DNS namespace, also known as the zone apex. For example, if you register the DNS name mycloudblogs.com, the zone apex is mycloudblogs.com. '+
'You cannot create a CNAME record for mycloudblogs.com, but you can create CNAME records for www. mycloudblogs.com and so on.'},
	    { text: 'c. CNAME record with Alias Target as the ALB ', correct: false,  expli:' ' },
      { text: 'd. ‘AAAA’ Non Alias record with Alias Target as the ALB', correct: false,  expli:' ' },
      { text: 'e. ‘AAAA’ Alias record with Alias Target as the ALB', correct: false,  expli:' ' }
    ],
	img: '',  
  }, 
  {
    question: '/Exam Prep 1 - 65p - 23 / You have a web app that provides video transcoding services. The videos uploaded by the users are first stored in a S3 bucket where you have configured "An object created event" notification to a SQS queue. There are fleet of EC2 instances which picks up the videos from the queue and places it in another S3 bucket after transcoding the file. These consumer fleet of EC2 instance also has dynamic auto scaling policy based on custom metric backlog per instance. Which type of EC2 instances you will use which will be most cost effective given that you don’t have defined duration in which you have to complete the transcoding for an uploaded file? Seleccione una',
    answers: [
      { text: 'a. Reserved Instances', correct: false,  expli:' ' },
      { text: 'b. On-demand Instances', correct: false,  expli:' ' },
	    { text: 'c. Spot Instances ', correct: true,  expli:' La respuesta correcta es: Spot Instances. '+
      'Since ‘cost’ is the most important criteria, spot instances pricing provides least pricing compared to other purchasing options. '+
'AWS Documentation Reference: https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/using-spot-instances.html '+
'A Spot Instance is an unused EC2 instance that is available for less than the On-Demand price. Because Spot Instances enable you to request unused EC2 instances at steep discounts, you can lower your Amazon EC2 costs significantly. '+
'Spot Instances are a cost-effective choice if you can be flexible about when your applications run and if your applications can be interrupted. '},
      { text: 'd. Saving plans Instances', correct: false,  expli:' ' }
    ],
	img: '',  
  }, 
  {
    question: '/Exam Prep 1 - 65p - 24 / Your company is planning to use WordPress hosted on AWS for corporate website. You are planning to run your WordPress site using an auto scaling group of Amazon EC2 instances and database layer on Amazon RDS Aurora. Which Amazon service you should use to store shared, unstructured WordPress data like php files, config themes, plugin etc. This storage service should be accessible by multiple WordPress EC2 instances. Seleccione una: ',
    answers: [
      { text: 'a. Amazon EFS ', correct: true,  expli:' La respuesta correcta es: Amazon EFS. '+
      'AWS Documentation Reference: Web serving & content management https://aws.amazon.com/efs/ '+
'Amazon EFS provides a durable, high throughput file system for content management systems and web serving applications that store and serve information for a range of applications like websites, online publications, and archives. '+
'Amazon EFS provides secure access for thousands of connections for Amazon EC2 instances and on-premises servers simultaneously using a traditional file permissions model, file locking capabilities, and hierarchical directory structure via the NFSv4 protocol. '},
      { text: 'b. Amazon EBS', correct: false,  expli:' ' },
	    { text: 'c. Amazon S3', correct: false,  expli:' ' },
      { text: 'd. Amazon RDS', correct: false,  expli:' ' }
    ],
	img: '',  
  }, 
  {
    question: '/Exam Prep 1 - 65p - 25 / Your company has headquarter in Los Angeles CA and have deployed their internal applications in US-West region. They are going to open a new office in Frankfurt Germany and are planning to transfer few employees as well. To comply with European regulations some of the applications will be replicated in a new AWS account created in EU-Central region. How will you manage the IAM users and roles being used by employees who will be transferred to Frankfurt? Seleccione una:',
    answers: [
      { text: 'a. IAM roles is a global service, users are region specific. You don’t need to create new roles but will need to create new users for EU-Central region.', correct: false,  expli:' ' },
      { text: 'b. You will need to create new IAM users and roles for EU-Central region.', correct: false,  expli:' ' },
	    { text: 'c. IAM users is a global service, roles are region specific. You don’t need to create new users but will need to create new roles for EU-Central region.', correct: false,  expli:' ' },
      { text: 'd. IAM is a global service, users and roles are not region specific. You don’t need to create new one for EU-Central region. ', correct: true,  expli:'La respuesta correcta es: IAM is a global service, users and roles are not region specific. You don’t need to create new one for EU-Central region. ' }
    ],
	img: '',  
  }, 
  {
    question: '/Exam Prep 1 - 65p - 26 / Which load balancer you should use if you need extreme performance and static IP is needed for your application? Seleccione una: ',
    answers: [
      { text: 'a. Application Load Balancers ', correct: false,  expli:' ' },
      { text: 'b. Database Load Balancers', correct: false,  expli:' ' },
	    { text: 'c. Classic Load Balancers', correct: false,  expli:' ' },
      { text: 'd. Network Load Balancers', correct: true,  expli:' La respuesta correcta es: Network Load Balancers. (need extreme performance and static IP)' }
    ],
	img: '',  
  }, 
  {
    question: '/Exam Prep 1 - 65p - 27 / Which service provides visibility into user activity by recording actions taken on your account? Seleccione una:',
    answers: [
      { text: 'a. Amazon CloudHSM', correct: false,  expli:' ' },
      { text: 'b. Amazon CloudFormation', correct: false,  expli:' ' },
	    { text: 'c. Amazon CloudWatch', correct: false,  expli:' ' },
      { text: 'd. Amazon CloudTrail ', correct: true,  expli:' La respuesta correcta es: Amazon CloudTrail.' +
      '• CloudTrail is a web service that records activity made on your account and delivers log files to an Amazon S3 bucket '+
'• CloudTrail is for auditing (CloudWatch is for performance monitoring) '+
'• CloudFormation is used for deploying infrastructure through code '+
'• CloudHSM is a hardware security module for generating, managing and storing encryption keys '}
    ],
	img: '',  
  }, 
  {
    question: '/Exam Prep 1 - 65p - 28 / You are using Amazon SQS in your ecommerce application to send order confirmation email asynchronously. You have created a program which polls the SQS queue frequently for new order message and then sends the email after fetching new order message from the queue. You observe that at times the program is getting empty response to the ReceiveMessage request. What should you do to eliminate empty responses to reduce cost? Seleccione una:',
    answers: [
      { text: 'a. Make wait time for the ReceiveMessage API action is greater than 0 to effect short polling.', correct: true,  expli:' La respuesta correcta es: Make wait time for the ReceiveMessage API action is greater than 0 to effect short polling. <br>'+ 
      'AWS Documentation Reference: https://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/sqs-delay-queues.html <br>'+
      'When the wait time for the ReceiveMessage API action is greater than 0, long polling is in effect. Long polling helps reduce the cost of using Amazon SQS by eliminating the number of empty responses (when there are no messages available for a ReceiveMessage request) and false empty responses (when messages are available but aren\'t included in a response). <br>'+
      'Long polling offers the following benefits: <br>'+
      'Eliminate empty responses by allowing Amazon SQS to wait until a message is available in a queue before sending a response. Unless the connection times out, the response to the ReceiveMessage request contains at least one of the available messages, up to the maximum number of messages specified in the ReceiveMessage action. <br>'+
      'Eliminate false empty responses by querying all—rather than a subset of—Amazon SQS servers <br>' },
      { text: 'b. Increase the duration of visibility timeout value to higher number.', correct: false,  expli:' ' },
	    { text: 'c. Make wait time for the ReceiveMessage API action is greater than 0 to effect long polling.', correct: false,  expli:' ' },
      { text: 'd. Create a delay queue.', correct: false,  expli:' ' }
    ],
	img: '',  
  }, 
  {
    question: '/Exam Prep 1 - 65p - 29 / Which of the following compliance programs allows the AWS environment to process, maintain, and store protected health information? Seleccione una:',
    answers: [
      { text: 'a. SOC 1', correct: false,  expli:' ' },
      { text: 'b. HIPAA ', correct: true,  expli:' La respuesta correcta es: HIPAA. • AWS enables covered entities and their business associates subject to the U.S. Health Insurance Portability and Accountability Act of 1996 (HIPAA) to use the secure AWS environment to process, maintain, and store protected health information' },
	    { text: 'c. PCI DSS', correct: false,  expli:' ' },
      { text: 'd. ISO 27001', correct: false,  expli:' ' }
    ],
	img: '',  
  }, 
  {
    question: '/Exam Prep 1 - 65p - 30 / You are creating proof of concept web application and want to quickly deploy and manage applications in the AWS Cloud without having to learn about the infrastructure that runs those applications. You don’t want to handle the details of capacity provisioning, load balancing, scaling, and application health monitoring. Which AWS services you should leverage? Seleccione una:',
    answers: [
      { text: 'a. AWS Elastic Beanstalk ', correct: true,  expli:' La respuesta correcta es: AWS Elastic Beanstalk <br>'+
      'AWS Documentation Reference: https://docs.aws.amazon.com/elasticbeanstalk/latest/dg/Welcome.html <br>'+
'With Elastic Beanstalk, you can quickly deploy and manage applications in the AWS Cloud without having to learn about the infrastructure that runs those applications.  <br>'+
'Elastic Beanstalk reduces management complexity without restricting choice or control.  <br>'+
'You simply upload your application, and Elastic Beanstalk automatically handles the details of capacity provisioning, load balancing, scaling, and application health monitoring. <br>'},
      { text: 'b. Lambda, ELB, Auto Scaling, CloudFormation', correct: false,  expli:' ' },
	    { text: 'c. EC2, ELB, Auto Scaling', correct: false,  expli:' ' },
      { text: 'd. Lambda, ELB, Auto Scaling', correct: false,  expli:' ' },
      { text: 'e. EC2, S3, ELB, Auto Scaling', correct: false,  expli:' ' }
    ],
	img: '',  
  }, 
  {
    question: '/Exam Prep 1 - 65p - 31 / Which AWS security service uses machine learning to automatically discover, classify, and protect sensitive data such as personally identifiable information (PII) or intellectual property. Seleccione una:',
    answers: [
      { text: 'a. AWS Shield', correct: false,  expli:' ' },
      { text: 'b. Amazon GuardDuty', correct: false,  expli:' ' },
	    { text: 'c. Amazon Macie ', correct: true,  expli:' La respuesta correcta es: Amazon Macie. <br>'+
      'AWS Documentation Reference: https://aws.amazon.com/macie/ <br>'+
'Amazon Macie is a security service that uses machine learning to automatically discover, classify, and protect sensitive data in AWS.  <br>'+
'Amazon Macie recognizes sensitive data such as personally identifiable information (PII) or intellectual property, and provides you with dashboards and alerts that give visibility into how this data is being accessed or moved.  <br>'+
'The fully managed service continuously monitors data access activity for anomalies, and generates detailed alerts when it detects risk of unauthorized access or inadvertent data leaks.  <br>'+
'The Amazon Macie service supports Amazon S3 and AWS CloudTrail management API and S3 object-level events for the buckets and prefixes enrolled with Amazon Macie. <br>'},
      { text: 'd. AWS WAF', correct: false,  expli:' ' }
    ],
	img: '',  
  }, 
  {
    question: '/Exam Prep 1 - 65p - 32 / You are developing a mobile application that will enable user to login using their userids in Facebook, Amazon and Google. In the cloud backend you will have Serverless architecture. For backend application data storage you want to use a RDBMS database. What is the minimum set of AWS services you will need for your mobile application and backend cloud application? Seleccione una:',
    answers: [
      { text: 'a. Lambda, Cognito, API Gateway, DynamoDB', correct: false,  expli:' ' },
      { text: 'b. Lambda, Fargate, API Gateway, DynamoDB', correct: false,  expli:' ' },
	    { text: 'c. Lambda, Cognito, API Gateway, Aurora Serverless', correct: true,  expli:' La respuesta correcta es: Lambda, Cognito, API Gateway, Aurora Serverless. AWS Documentation Reference: <br>'+
'https://aws.amazon.com/blogs/compute/secure-api-access-with-amazon-cognito-federated-identities-amazon-cognito-user-pools-and-amazon-api-gateway/ <br>'+
'As it is mentioned that you need RDBMS therefore Aurora Serverless service , for Serverless backend design you will be using Lambda , Cognito is the service you will need for federated user authentication from Facebook/Google/Amazon and API gateway as custom API to your code running in AWS Lambda and also for calling the Lambda code from your API.  <br>'+
'API Gateway can invoke AWS Lambda code in your account. <br>'+
'You don’t need DynamoDB as the design doesn’t require NoSQL database nor Elastic Beanstalk which is appropriate for a web application deployment. <br>'+
'https://aws.amazon.com/rds/aurora/serverless/ <br>'+
'Amazon Aurora Serverless is an on-demand, auto-scaling configuration for Amazon Aurora (MySQL-compatible and PostgreSQL-compatible editions), where the database will automatically start up, shut down, and scale capacity up or down based on your application\'s needs. <br>'},
      { text: 'd. Elastic Beanstalk, Cognito, API Gateway, Aurora ', correct: false,  expli:' ' }
    ],
	img: '',  
  }, 
  {
    question: '/Exam Prep 1 - 65p - 33 / What is Recovery Time Objective (RTO)? Seleccione una: ',
    answers: [
      { text: 'a. The time it takes after a disruption to restore a business process to its service level, as defined by the operational level agreement (OLA). ', correct: true,  expli:' La respuesta correcta es: The time it takes after a disruption to restore a business process to its service level, as defined by the operational level agreement (OLA).' },
      { text: 'b. The time it takes after a disruption to restore a database to its service level, as defined by the operational level agreement (OLA).', correct: false,  expli:' ' },
	    { text: 'c. The acceptable amount of data loss measured in time.', correct: false,  expli:' ' },
      { text: 'd. The acceptable amount of performance loss measured in time.', correct: false,  expli:' ' }
    ],
	img: '',  
  }, 
  {
    question: '/Exam Prep 1 - 65p - 34 / You need to implement a hosted queue for storing messages in transit between application servers. Which service should you use? Seleccione una:',
    answers: [
      { text: 'a. Amazon SWF', correct: false,  expli:' ' },
      { text: 'b. Amazon DynamoDB', correct: false,  expli:' ' },
	    { text: 'c. Amazon SNS', correct: false,  expli:' ' },
      { text: 'd. Amazon SQS ', correct: true,  expli:' La respuesta correcta es: Amazon SQS. <br>'+
      '• Amazon Simple Queue Service (Amazon SQS) is a web service that gives you access to message queues that store messages waiting to be processed. SQS offers a reliable, highly-scalable, hosted queue for storing messages in transit between computers. SQS is used for distributed/decoupled application <br>'+
'• Amazon SWF helps developers build, run, and scale background jobs that have parallel or sequential steps <br>'+
'• Amazon Simple Notification Service (SNS) is a highly available, durable, secure, fully managed pub/sub messaging service that enables you to decouple microservices, distributed systems, and serverless applications <br>'+
'• Amazon DynamoDB is a nonrelational database that delivers reliable performance at any scale <br>' }
    ],
	img: '',  
  }, 
  {
    question: '/Exam Prep 1 - 65p - 35 / Which items should be included in a TCO analysis comparing on-premise to AWS Cloud? (choose 2) Seleccione una o más de una: ',
    answers: [
      { text: 'a. Operating system patching', correct: false,  expli:' ' },
      { text: 'b. Firewall management', correct: false,  expli:' ' },
	    { text: 'c. Compute hardware ', correct: true,  expli:' una respuesta correcta es : Compute hardware. ' },
      { text: 'd. Data center security', correct: true,  expli:' una respuesta correcta es :  Data center security.  <br>'+
'Explanation: <br>'+ 
'• You need to identify the items that have a cost on-premise and that will be rolled into the service in the cloud. Compute hardware costs and data center security costs will be rolled in the service cost in the cloud so you need to include them in the model so you can really understand the true TCO on-premise vs. the cloud <br>'+
'• Firewall management, application licensing and operating system patching need to be paid for on-premise and in the cloud so there is little difference <br>'+
'References: <br>'+
'• https://media.amazonwebservices.com/AWS_TCO_Web_Applications.pdf <br>'},
      { text: 'e. Application licensing ', correct: false,  expli:' ' }
    ],
	img: '',  
  }, 
  {
    question: '/Exam Prep 1 - 65p - 36 / Which of the following services does Amazon Route 53 provide? (choose 2) Seleccione una o más de una: ',
    answers: [
      { text: 'a. Domain Name Service (DNS) ', correct: true,  expli:' una respuesta correcta es : Domain Name Service (DNS)' },
      { text: 'b. Domain registration ', correct: true,  expli:' una respuesta correcta es : Domain registration. Route 53 services include domain registration, DNS, health checking (availability monitoring) and traffic management ' },
	    { text: 'c. Load balancing', correct: false,  expli:' ' },
      { text: 'd. Route tables', correct: false,  expli:' ' },
      { text: 'e. Auto Scaling', correct: false,  expli:' ' }
    ],
	img: '',  
  }, 
  {
    question: '/Exam Prep 1 - 65p - 37 / At which layers of the OSI model do the different types of Elastic Load Balancers operate? (choose 2) Seleccione una o más de una: ',
    answers: [
      { text: 'a. Application Load Balancer at layer 4', correct: false,  expli:' ' },
      { text: 'b. Network Load Balancer at layer 4', correct: true,  expli:'una respuesta correcta es : Network Load Balancer at layer 4. • Network Load Balancer (NLB) – layer 4 load balancer that routes connections based on IP protocol data' },
	    { text: 'c. Network Load Balancer at layer 3 ', correct: false,  expli:' ' },
      { text: 'd. Classic Load Balancer at layer 3', correct: false,  expli:' • Classic Load Balancer (CLB) – this is the oldest of the three and provides basic load balancing at both layer 4 and layer 7' },
      { text: 'e. Application Load Balancer at layer 7 ', correct: true,  expli:' una respuesta correcta es : Application Load Balancer at layer 7. • Application Load Balancer (ALB) – layer 7 load balancer that routes connections based on the content of the request' }
    ],
	img: '',  
  }, 
  {
    question: '/Exam Prep 1 - 65p - 38 / A law firm has an internal tablet/mobile application used by employees to download large word documents in their devices for offline review. These document’s size are in the range of 10-20 MB. The employees save the document in local device storage, edit it in offline mode and then use the feature in app to upload file to cloud storage. Most of the time users are expected to be in area of high mobile bandwidth of LTE or WIFI but some time they may be in area using a slow speed network (EDGE) or 3G with lots of fluctuations. The files are stored in AWS S3 buckets. What approach should the architect recommend for file upload in application? Seleccione una:',
    answers: [
      { text: 'a. Use Amazon S3 Transfer Acceleration to upload the files', correct: false,  expli:' ' },
      { text: 'b. Use Single PUT operation to upload the files to S3 ', correct: false,  expli:' ' },
	    { text: 'c. Use Multipart upload to upload the files to S3', correct: true,  expli:' La respuesta correcta es: Use Multipart upload to upload the files to S3. <br>'+ 
      'The key point to consider here is file size in the range of 10-20 MB and upload resiliency in low speed network. <br>'+
      'A is feasible as you can upload up to 5 GB object size in one PUT operation to S3 bucket. But using single put operation may not be suitable in low bandwidth scenario. <br>'+
      'Correct answer: to use multipart upload api to upload the files to S3. If you\'re uploading over a spotty network, multipart uploading increases resiliency to network errors by avoiding upload restarts. Multipart upload can be used for file sizes greater than 5 MB. <br>'},
      { text: 'd. Use Single POST operation to upload the files to S3', correct: false,  expli:' ' }
    ],
	img: '',  
  }, 
  {
    question: '/Exam Prep 1 - 65p - 39 / You have three VPCs A, B, C. How many peer connection you need to configure so all the VPCs can access the resource of one another? Seleccione una:',
    answers: [
      { text: 'a. Two peer configuration. A-B and B-C peer configuration needs to be done. A-C transitive peering configuration will be automatically done.', correct: false,  expli:' ' },
      { text: 'b. Three peer configuration. A-B, B-C and C-A.', correct: true,  expli:' La respuesta correcta es: Three peer configuration. A-B, B-C and C-A. <br>'+ 
      'wrong because transitive peering connection is not supported. <br>'+ 
      'AWS Documentation Reference: Three VPCs Peered Together <br>'+ 
      'https://docs.aws.amazon.com/vpc/latest/peering/peering-configurations-full-access.html <br>' },
	    { text: 'c. Two peer configuration. A-C and B-C peer configuration needs to be done. A-B transitive peering configuration will be automatically done.', correct: false,  expli:' ' },
      { text: 'd. None of the above. ', correct: false,  expli:' ' }
    ],
	img: '',  
  }, 
  {
    question: '/Exam Prep 1 - 65p - 40 / What features does Amazon RDS provide to deliver scalability, availability and durability? (choose 2) Seleccione una o más de una:',
    answers: [
      { text: 'a. Read Replicas ', correct: true,  expli:' una respuesta correcta es : Read Replicas.' },
      { text: 'b. Clustering', correct: false,  expli:' ' },
	    { text: 'c. DB mirroring', correct: false,  expli:' ' },
      { text: 'd. Multi-AZ ', correct: true,  expli:' una respuesta correcta es : Multi-AZ.  <br>'+
      '• Multi-AZ RDS creates a replica in another AZ and synchronously replicates to it (DR only) <br>'+ 
      '• Read replicas are used for read heavy DBs and replication is asynchronous <br>'+ 
      '• DB mirroring, multi-subnet and clustering are not options provided by RDS <br>' },
      { text: 'e. Multi-Subnet', correct: false,  expli:' ' }
    ],
	img: '',  
  }, 
  {
    question: '/Exam Prep 1 - 65p - 41 / Which strategy KMS uses to encrypt data and also protect your encryption key? Seleccione una: ',
    answers: [
      { text: 'a. Encryption Context', correct: false,  expli:' ' },
      { text: 'b. Envelope Encryption', correct: true,  expli:' La respuesta correcta es: Envelope Encryption. <br>'+  
      'AWS Documentation Reference: https://docs.aws.amazon.com/kms/latest/developerguide/concepts.html#enveloping. <br>'+ 
      'When you encrypt your data, your data is protected, but you have to protect your encryption key. One strategy is to encrypt it. <br>'+  
      'Envelope encryption is the practice of encrypting plaintext data with a data key, and then encrypting the data key under another key. <br>' },
	    { text: 'c. Symmetric keys ', correct: false,  expli:' ' },
      { text: 'd. Asymmetric keys', correct: false,  expli:' ' }
    ],
	img: '',  
  }, 
  {
    question: '/Exam Prep 1 - 65p - 42 / You have developed a web application and plan to deploy it in your VPC in us-west region. Your VPC has three subnets mapped to three availability zones: us-west-1a, us-west-1b, us-west-1c.  <br>'+  
    'Your application requires in normal scenario nine servers but can run on a minimum 66 percent capacity. How many web server instances should you deploy in each of three AZ so that you can meet the above availability requirements in a cost effective way? Seleccione una:',
    answers: [
      { text: 'a. Six in us-west-1a, six in us-west-1b, six in us-west-1c.', correct: false,  expli:' ' },
      { text: 'b. Three in us-west-1a, three in us-west-1b, three in us-west-1c. ', correct: true,  expli:' La respuesta correcta es: Three in us-west-1a, three in us-west-1b, three in us-west-1c.  <br>'+  
      'The key criteria is to deploy minimum servers to meet the fault tolerance requirement of availability of at least six servers (66% of total 9) when on AZ goes down and also meeting requirement of at least nine servers for normal scenario.' },
	    { text: 'c. Four in us-west-1a, four in us-west-1b, four in us-west-1c.', correct: false,  expli:' ' },
      { text: 'd. Two in us-west-1a, two in us-west-1b, four in us-west-1c.', correct: false,  expli:' ' }
    ],
	img: '',  
  }, 
  {
    question: '/Exam Prep 1 - 65p - 43 / A company is planning to migrate some resources into the cloud. What factors need to be considered when determining the cost of the AWS Cloud? (choose 2) Seleccione una o más de una:',
    answers: [
      { text: 'a. The number of servers migrated into EC2 ', correct: true,  expli:'una respuesta correcta es: The number of servers migrated into EC2.' },
      { text: 'b. The amount of ingress data per month', correct: false,  expli:' ' },
	    { text: 'c. The number of VPCs created', correct: false,  expli:' ' },
      { text: 'd. The amount of egress data per month ', correct: true,  expli:' una respuesta correcta es: The amount of egress data per month. • AWS charge for EC2 instances and data egress. There are no charges for VPCs, IAM users or data ingress' },
      { text: 'e. The number of IAM users created', correct: false,  expli:' ' }
    ],
	img: '',  
  }, 
  {
    question: '/Exam Prep 1 - 65p - 44 / Which AWS service gives you centralized control over the encryption keys used to protect your data? Seleccione una: ',
    answers: [
      { text: 'a. AWS STS', correct: false,  expli:' ' },
      { text: 'b. AWS KMS ', correct: true,  expli:' La respuesta correcta es: AWS KMS' },
	    { text: 'c. AWS DMS', correct: false,  expli:' ' },
      { text: 'd. Amazon EBS', correct: false,  expli:' ' }
    ],
	img: '',  
  }, 
  {
    question: '/Exam Prep 1 - 65p - 45 / Which of the facts below are accurate in relation to AWS Regions? (choose 2) Seleccione una o más de una: ',
    answers: [
      { text: 'a. Each region is designed to be completely isolated from the other Amazon Regions', correct: true,  expli:' una respuesta correcta es : Each region is designed to be completely isolated from the other Amazon Regions' },
      { text: 'b. Each region consists of a collection of VPCs', correct: false,  expli:' ' },
	    { text: 'c. Regions are Content Delivery Network (CDN) endpoints for CloudFront', correct: false,  expli:' ' },
      { text: 'd. Each region consists of 2 or more availability zones ', correct: true,  expli:' una respuesta correcta es : Each region consists of 2 or more availability zones.  <br>'+ 
      '• A region is not a collection of VPCs, it is composed of at least 2 AZs. VPCs exist within accounts on a per region basis <br>'+ 
      '• Availability Zones (not regions) have direct, low-latency, high throughput and redundant network connections between each other <br>'+ 
      '• Edge locations are (not regions) are Content Delivery Network (CDN) endpoints for CloudFront <br>'},
      { text: 'e. Regions have direct, low-latency, high throughput and redundant network connections between each other ', correct: false,  expli:' ' }
    ],
	img: '',  
  }, 
  {
    question: '/Exam Prep 1 - 65p - 46 / What are two ways of connecting to an Amazon VPC from an on-premise data center? Seleccione una o más de una:',
    answers: [
      { text: 'a. VPC Router', correct: false,  expli:' ' },
      { text: 'b. Internet Gateway ', correct: false,  expli:' ' },
	    { text: 'c. Direct Connect ', correct: true,  expli:' una respuesta correcta es : Direct Connect. • AWS Direct Connect is a network service that provides an alternative to using the Internet to connect a customer’s on-premise sites to AWS' },
      { text: 'd. VPN CloudHub', correct: true,  expli:' una respuesta correcta es : VPN CloudHub • You can connect from your on-premise data center to a VPC via Direct Connect or VPN CloudHub  <br>'+  
      '• If you have multiple VPN connections, you can provide secure communication between sites using the AWS VPN CloudHub.  <br>'+  
      '• Internet gateways and VPC routers are components of a VPC and are not used for connecting from external locations ' },
      { text: 'e. VPC Peering', correct: false,  expli:' ' }
    ],
	img: '',  
  }, 
  {
    question: '/Exam Prep 1 - 65p - 47 /  Your company is migrating two existing applications to AWS. Application portfolio has one internet application which will be accessed by its customers and one intranet application which will be accessed only by employees from corporate network. Your plan is to create one VPC and deploy each application instances individually in a separate subnet. You also want to ensure that whole design is fault tolerant and services should not be hampered in case one of AWS AZ goes down? How many minimum subnets should you create? Seleccione una:',
    answers: [
      { text: 'a. 2 subnets', correct: false,  expli:' ' },
      { text: 'b. 6 subnets', correct: false,  expli:' ' },
	    { text: 'c. 1 subnets', correct: false,  expli:' ' },
      { text: 'd. 4 subnets ', correct: true,  expli:' La respuesta correcta es: 4 subnets. <br>'+
      'Key considerations are: <br>'+  
    'VPC is mapped to one region but can span AZs <br>'+  
    'A subnet is mapped to on AZ in VPC’s region <br>'+  
    'Both the application will be inside the same VPC but in different subnet of their own. <br>'+  
    'To achieve fault tolerance in case one AZ goes down, each application should have one instances in two subnets which are mapped to two different AZs. <br>'+  
    'For example if you are deploying INTERNETApp and INTRANETApp by creating a VPC in us-east-1 region. Your network topology can be. <br>'+  
    'Subnet1, us-east-1a AZ having INTERNETApp instance. <br>'+  
    'Subnet2, us-east-1b AZ having INTERNETApp instance. <br>'+  
    'Subnet3 us-east-1c AZ having INTRANETApp instance. <br>'+  
    'Subnet4, us-east-1d AZ having INTRANETApp instance. <br>'+  
    'This ensures that in case one AZ goes down, user request can be served by instance in subnet mapped to other active AZ. <br>'}
    ],
	img: '',  
  }, 
  {
    question: '/Exam Prep 1 - 65p - 48 / An organization would like to run managed desktops on the AWS cloud using the Windows 10 operating system. Which service can deliver these requirements? Seleccione una:',
    answers: [
      { text: 'a. Amazon does not provide desktop services', correct: false,  expli:' ' },
      { text: 'b. Amazon Workspaces ', correct: true,  expli:' La respuesta correcta es: Amazon Workspaces. <br>'+ 
      '• Amazon WorkSpaces is a managed desktop computing service running on the AWS cloud <br>'+  
'• WorkSpaces allows customers to easily provision cloud-based desktops that allow end-users to access documents and applications <br>'+  
'• WorkSpaces offers bundles that come with a Windows 7 or Windows 10 desktop experience, powered by Windows Server 2008 R2 and Windows Server 2016 respectively. <br>'},
	    { text: 'c. Amazon SWF', correct: false,  expli:' ' },
      { text: 'd. Amazon EC2', correct: false,  expli:' ' }
    ],
	img: '',  
  }, 
  {
    question: '/Exam Prep 1 - 65p - 49 / Soma is founder of an Artificial Intelligence product start up. Upon starting the company, she created her own AWS account and used AWS products by herself. Then as company expanded she hired developers, admins, testers, managers, and system administrators.  <br>'+  
    'Using AWS account root user credentials she created a user for herself called Soma, and a group called Admins. She added user Soma to group Admins. She also created groups called Developers, Testers, Managers and SysAdmins. She created users for each of her employees, and puts the users in their respective groups.  <br>'+  
    'What IAM best practice she should follow so that she can easily apply any account-wide permissions to all users in the AWS account? Seleccione una:',
    answers: [
      { text: 'a. Create a customer managed policy and attach to each user.', correct: false,  expli:' ' },
      { text: 'b. She should create a group called AllUsers and add all users to that group so that she can easily apply any account-wide permissions to all users in the AWS account.', correct: true,  expli:' La respuesta correcta es: She should create a group called AllUsers and add all users to that group so that she can easily apply any account-wide permissions to all users in the AWS account. <br>'+  
      'She should create a group called AllUsers and attach every user to that group so that she can easily apply any account-wide permissions to all users in the AWS account. ' },
	    { text: 'c. Any account wide permission can be updated in each of the group’s permission (Developers, Testers, Managers and SysAdmins) are attached to.', correct: false,  expli:' ' },
      { text: 'd. Create a customer managed policy and attach to each group. ', correct: false,  expli:' ' }
    ],
	img: '',  
  }, 
  {
    question: '/Exam Prep 1 - 65p - 50 / You need to ensure you have the right amount of compute available to service demand. Which AWS service can automatically scale the number of EC2 instances for your application? Seleccione una:',
    answers: [
      { text: 'a. Amazon Elasticache', correct: false,  expli:' ' },
      { text: 'b. Amazon Elastic Load Balancer', correct: false,  expli:' ' },
	    { text: 'c. AWS Auto Scaling ', correct: true,  expli:' La respuesta correcta es: AWS Auto Scaling. <br>'+  
      '• Auto Scaling automates the process of adding (scaling up) OR removing (scaling down) EC2 instances based on the traffic demand for your application. <br>'+ 
      '• ELB automatically distributes incoming application traffic across multiple targets, such as Amazon EC2 instances, containers, and IP addresses. <br>'+ 
      '• Amazon Redshift is a fast, scalable data warehouse that makes it simple and cost-effective to analyze all your data across your data warehouse and data lake. <br>'+ 
      '• Amazon ElastiCache offers fully managed Redis and Memcached <br>'},
      { text: 'd. AWS RedShift', correct: false,  expli:' ' }
    ],
	img: '',  
  }, 
  {
    question: '/Exam Prep 1 - 65p - 51 / A building construction company’s architects use CAD software installed in their workstation to design architecture blueprints. These blueprint files are very large. The company started using S3 and AWS Storage gateway for file storage and back up. After a while as number of users increased after rolling it out across different global office locations, it was found that transferring/fetching large data files speed was slow. What should they do to decrease the amount of time required to transfer data in a cost effective way? Seleccione una:',
    answers: [
      { text: 'a. Increase the bandwidth with your Internet service provider.', correct: false,  expli:' ' },
      { text: 'b. Create VPN connection with AWS resources.', correct: false,  expli:' ' },
	    { text: 'c. Use AWS Transit Gateway to connect with AWS resources. ', correct: false,  expli:' ' },
      { text: 'd. Use AWS Direct Connect to connect with AWS resources.', correct: true,  expli:' La respuesta correcta es: Use AWS Direct Connect to connect with AWS resources. <br>'+   
      'AWS Documentation Reference: https://aws.amazon.com/directconnect/features/?nc=sn&loc=2 <br>'+  
'Transferring large data sets over the Internet can be time consuming and expensive. <br>'+  
'When you use the cloud, you can find that transferring large data sets can be slow because your business critical network traffic is contending for bandwidth with your other Internet usage. <br>'+  
 'To decrease the amount of time required to transfer your data, you could increase the bandwidth to your Internet service provider, which frequently requires a costly contract renewal and a minimum commitment. <br>'+  
 'With AWS Direct Connect, you can transfer your business critical data directly from your datacenter, office, or colocation environment into and from AWS bypassing your Internet service provider and removing network congestion. <br>'+  
 'Further, AWS Direct Connect’s simple pay as-you-go pricing, and no minimum commitment means you pay only for the network ports you use and the data you transfer over the connection, which can greatly reduce your networking costs. <br>'}
    ],
	img: '',  
  }, 
  {
    question: '/Exam Prep 1 - 65p - 52 / Which AWS database service will you choose for Online Analytical Processing (OLAP)? Seleccione una:',
    answers: [
      { text: 'a. Amazon Redshift', correct: true,  expli:' La respuesta correcta es: Amazon Redshift' },
      { text: 'b. Amazon Glacier', correct: false,  expli:' ' },
	    { text: 'c. Amazon DynamoDB', correct: false,  expli:' ' },
      { text: 'd. Amazon RDS', correct: false,  expli:' ' }
    ],
	img: '',  
  }, 
  {
    question: '/Exam Prep 1 - 65p - 53 / Which AWS service provides elastic web-scale cloud computing allowing you to deploy operating system instances? Seleccione una: ',
    answers: [
      { text: 'a. AWS Lambda', correct: false,  expli:' ' },
      { text: 'b. Amazon EBS', correct: false,  expli:' ' },
	    { text: 'c. Amazon EC2 ', correct: true,  expli:' La respuesta correcta es: Amazon EC2 <br>'+ 
      '• Amazon EC2 provides elastic web-scale computing in the cloud allowing you to deploy Windows and Linux <br>'+  
'• AWS Lambda lets you run code without provisioning or managing server operating systems <br>'+  
'• Amazon Elastic Block Store (Amazon EBS) provides persistent block storage volumes for use with Amazon EC2instances in the AWS Cloud <br>'+  
'• Amazon Relational Database Service (Amazon RDS) makes it easy to set up, operate, and scale a relational database in the cloud <br>'},
      { text: 'd. Amazon RDS', correct: false,  expli:' ' }
    ],
	img: '',  
  }, 
  {
    question: '/Exam Prep 1 - 65p - 54 / Which services are involved with security? (choose 2) Seleccione una o más de una:',
    answers: [
      { text: 'a. AWS DMS ', correct: false,  expli:' • AWS Database Migration Service and Server Migration Service are used for migration' },
      { text: 'b. AWS KMS ', correct: true,  expli:' una respuesta correcta es : AWS KMS AWS Key Management Service gives you centralized control over the encryption keys used to protect your data' },
	    { text: 'c. Amazon ELB', correct: false,  expli:' Amazon Elastic Load Balancing is used for distributing incoming connections to pools of EC2 instances' },
      { text: 'd. AWS CloudHSM ', correct: true,  expli:' una respuesta correcta es : AWS CloudHSM. AWS CloudHSM is a cloud-based hardware security module (HSM) that enables you to easily generate and use your own encryption keys on the AWS Cloud' },
      { text: 'e. AWS SMS', correct: false,  expli:' ' }
    ],
	img: '',  
  }, 
  {
    question: '/Exam Prep 1 - 65p - 55 / How can you apply metadata to an EC2 instance that categorizes it according to its purpose, owner or environment? Seleccione una:',
    answers: [
      { text: 'a. Tags ', correct: true,  expli:' La respuesta correcta es: Tags. • A tag is a label that you assign to an AWS resource. Each tag consists of a key and an optional value, both of which you define. Tags enable you to categorize your AWS resources in different ways, for example, by purpose, owner, or environment' },
      { text: 'b. Stickers', correct: false,  expli:' ' },
	    { text: 'c. Labels', correct: false,  expli:' ' },
      { text: 'd. Hostname', correct: false,  expli:' ' }
    ],
	img: '',  
  }, 
  {
    question: '/Exam Prep 1 - 65p - 56 / At what level is a Network ACL applied? Seleccione una: ',
    answers: [
      { text: 'a. Availability Zone level', correct: false,  expli:' ' },
      { text: 'b. Region level', correct: false,  expli:' ' },
	    { text: 'c. Instance level', correct: false,  expli:' ' },
      { text: 'd. Subnet level ', correct: true,  expli:' La respuesta correcta es: Subnet level. • Network Access Control Lists (ACLs) provide a firewall/security layer at the subnet level • Security Groups provide a firewall/security layer at the instance level' }
    ],
	img: '',  
  }, 
  {
    question: '/Exam Prep 1 - 65p - 57 / Which of the below is Amazon\'s proprietary RDS database? Seleccione una:',
    answers: [
      { text: 'a. MariaDB', correct: false,  expli:' MariaDB and MySQL can be used on RDS but they are not Amazon proprietary'},
      { text: 'b. Aurora ', correct: true,  expli:' La respuesta correcta es: Aurora, Aurora is Amazon’s proprietary database' },
	    { text: 'c. DynamoDB', correct: false,  expli:' DynamoDB is an Amazon proprietary DB but it is not an RDS DB' },
      { text: 'd. MySQL', correct: false,  expli:' ' }
    ],
	img: '',  
  }, 
  {
    question: '/Exam Prep 1 - 65p - 58 / You have a corporate intranet web application that required 500GB of block storage at 1000 IOPS throughout the day apart from 40 minutes at night when you run a schedule batch process to generate reports during which you require 3000 IOPS. Which Amazon EBS volume will be cost effective? Seleccione una: ',
    answers: [
      { text: 'a. Cold HDD (sc1)', correct: false,  expli:' ' },
      { text: 'b. General Purpose SSD (gp2)', correct: true,  expli:' La respuesta correcta es: General Purpose SSD (gp2)  <br>'+ 
      'General Purpose SSD (gp2) volumes offer between a minimum of 100 IOPS (at 33.33 GiB and below) and a maximum of 16,000 IOPS (at 5,334 GiB and above), baseline performance scales linearly at 3 IOPS per GiB of volume size.  <br>'+ 
      'When your volume requires more than the baseline performance I/O level, it draws on I/O credits in the credit balance to burst to the required performance level, up to a maximum of 3,000 IOPS. When your volume uses fewer I/O credits than it earns in a second, unused I/O credits are added to the I/O credit balance.  <br>'+ 
      'Each volume receives an initial I/O credit balance of 5.4 million I/O credits, which is enough to sustain the maximum burst performance of 3,000 IOPS for 30 minutes. <br>'+ 
      'The 500 GB gp2 storage will have baseline performance of 500*3 = 1500 IOPS. As the volume uses fewer I/O credits of 1000 IPS than it earns 1500 IOPS in a second, unused I/O credits are added to the I/O credit balance. <br>'+ 
      'When your volume requires 3000 IOPS which is more than the baseline performance I/O level of 1500 IOPS, it draws on I/O credits in the credit balance to burst to the required performance level <br>'+ 
      'AWS Documentation Reference: General Purpose SSD (gp2) Volumes: I/O Credits and Burst Performance <br>'+ 
      'https://docs.aws.amazon.com/en_pv/AWSEC2/latest/UserGuide/EBSVolumeTypes.html <br>' },
	    { text: 'c. Throughput Optimized HDD (st1)', correct: false,  expli:' ' },
      { text: 'd. Provisioned IOPS SSD (io1)', correct: false,  expli:' ' }
    ],
	img: '',  
  }, 
  {
    question: '/Exam Prep 1 - 65p - 59 / Which tool can be used to create and manage a selection of AWS services that are approved for use on AWS? Seleccione una:',
    answers: [
      { text: 'a. AWS Service Catalog ', correct: true,  expli:' La respuesta correcta es: AWS Service Catalog.  <br>'+
      '• AWS Service Catalog allows organizations to create and manage catalogs of IT services that are approved for use on AWS. These IT services can include everything from virtual machine images, servers, software, and databases to complete multi-tier application architectures <br>'+
      '• AWS OpsWorks is a configuration management service that provides managed instances of Chef and Puppet <br>'+
      '• Amazon Cloud Directory enables you to build flexible cloud-native directories for organizing hierarchies of data along multiple dimensions <br>'+
      '• AWS Organizations offers policy-based management for multiple AWS accounts <br>'},
      { text: 'b. Amazon Cloud Directory', correct: false,  expli:' ' },
	    { text: 'c. AWS Organizations', correct: false,  expli:' ' },
      { text: 'd. AWS OpsWorks', correct: false,  expli:' ' }
    ],
	img: '',  
  }, 
  {
    question: '/Exam Prep 1 - 65p - 60 / You are a solution architect for a multinational company which wants to migrate all their existing applications to AWS cloud platform. They want to create separate AWS account based on each country where they have regional headquarters. They also want to centrally manage billing; control access, compliance, and security; and share resources across AWS accounts. If you want to define your own custom multi-account environment with advanced governance and management capabilities which AWS service you will use? Seleccione una: ',
    answers: [
      { text: 'a. AWS Organizations ', correct: true,  expli:' La respuesta correcta es: AWS Organizations <br>'+ 
      'AWS Documentation Reference: https://aws.amazon.com/organizations/ <br>'+
      'AWS Organizations helps you centrally govern your environment as you grow and scale your workloads on AWS.  <br>'+
      'Whether you are a growing startup or a large enterprise, Organizations helps you to centrally manage billing; control access, compliance, and security; and share resources across your AWS accounts. <br>'},
      { text: 'b. AWS Service Catalog', correct: false,  expli:' ' },
	    { text: 'c. AWS System Manager', correct: false,  expli:' ' },
      { text: 'd. AWS Control Tower', correct: false,  expli:' ' }
    ],
	img: '',  
  }, 
  {
    question: '/Exam Prep 1 - 65p - 61 / What is an example of using loose coupling when designing an information system? Seleccione una:',
    answers: [
      { text: 'a. Monolithic application architecture', correct: false,  expli:' ' },
      { text: 'b. Proprietary interfaces', correct: false,  expli:' ' },
	    { text: 'c. Synchronous replication', correct: false,  expli:' ' },
      { text: 'd. DNS name usage ', correct: true,  expli:' La respuesta correcta es: DNS name usage. <br>'+ 
      '• DNS names are used for service discovery. In loose coupling disparate resources must have a way of discovering each other without prior knowledge of the network topology <br>'+ 
      '• Asynchronous integration rather than synchronous replication is recommended so an interaction does not require an immediate response <br>'+ 
      '• You should use standard, technology-agnostic interfaces rather than proprietary interfaces where possible <br>'+ 
      '• A monolithic application architecture is not an example of loose coupling <br>' }
    ],
	img: '',  
  }, 
  {
    question: '/Exam Prep 1 - 65p - 62 / Which AWS service can be used to run Docker containers? Seleccione una: ',
    answers: [
      { text: 'a. AWS Lambda', correct: false,  expli:' ' },
      { text: 'b. Amazon ECS ', correct: true,  expli:' La respuesta correcta es: Amazon ECS. <br>'+ 
      '• Amazon Elastic Container Service (ECS) is a highly scalable, high performance container management service that supports Docker containers and allows you to easily run applications on a managed cluster of Amazon EC2 instances <br>'+
      '• AWS Lambda is a serverless technology that lets you run code in response to events as functions <br>'+
      '• Amazon Elastic Container Registry (ECR) is a fully-managed Docker container registry that makes it easy for developers to store, manage, and deploy Docker container images <br>'+
      '• Amazon Machine Images (AMI) store configuration information for Amazon EC2 instances <br>'},
	    { text: 'c. Amazon AMI', correct: false,  expli:' ' },
      { text: 'd. Amazon ECR', correct: false,  expli:' ' }
    ],
	img: '',  
  }, 
  {
    question: '/Exam Prep 1 - 65p - 63 / To optimize pricing or ensure capacity is available reservations can be applied to which of the following services? (choose 2) Seleccione una o más de una:',
    answers: [
      { text: 'a. Amazon S3 ', correct: false,  expli:' ' },
      { text: 'b. Amazon EC2 ', correct: true,  expli:' una respuesta correcta es : Amazon EC2' },
	    { text: 'c. Amazon EBS', correct: false,  expli:' ' },
      { text: 'd. Amazon RDS', correct: true,  expli:' una respuesta correcta es : Amazon RDS' },
      { text: 'e. AWS Lambda', correct: false,  expli:' ' }
    ],
	img: '',  
  }, 
  {
    question: '/Exam Prep 1 - 65p - 64 / You are solution architect for a Stock Trading web application provider company. Financial regulation mandates them to keep the trading data for five years.  From analysis of past internal and customer access behavior you are certain that data more than two year old is unlikely to be accessed, data less than two year old but more than six months old is infrequently accessed. Any data less than six months old will need to have faster access.  Currently 150 TB data are stored in in-premise data storage which company is planning to move to AWS cloud storage to save cost. Which is the most cost effective option? Seleccione una: ',
    answers: [
      { text: 'a. Store the data on Amazon S3 with lifecycle policy that change the storage class from Standard to Standard-IA in six months, from Standard-IA to Glacier in two year and expiration in five years. ', correct: true,  expli:' La respuesta correcta es: Store the data on Amazon S3 with lifecycle policy that change the storage class from Standard to Standard-IA in six months, from Standard-IA to Glacier in two year and expiration in five years. <br>'+  
      'AWS Documentation Reference: https://docs.aws.amazon.com/AmazonS3/latest/dev/how-to-set-lifecycle-configuration-intro.html <br>'+ 
      'Based on the requirement S3 is the most cost effective storage giving different storage options based on the accessibility and life duration time based requirements. Hence C and D is not correct.  <br>'+ 
      'You didn’t need Redshift data warehouse to store for this requirement.  <br>'+ 
      'EBS provides block storage and is specifically meant for EC2 (Elastic Computing Cloud) instances and is not accessible unless mounted to one <br>'+ 
      'S3 lifecycle rules are applied based on object creation date.  <br>'},
      { text: 'b. Store all the data in Redshift data warehouse', correct: false,  expli:' ' },
	    { text: 'c. Store the data on Amazon S3 with lifecycle policy that change the storage class from Standard to Standard-IA in six months, from Standard-IA to Glacier in 1.5 years and expiration in 3.5 years.', correct: false,  expli:' ' },
      { text: 'd. Store all the data in EBS general purpose volume attached to EC2 cheapest instance', correct: false,  expli:' ' }
    ],
	img: '',  
  }, 
  {
    question: '/Exam Prep 1 - 65p - 65 / How can a security compliance officer retrieve AWS compliance documentation such as a SOC 2 report? Seleccione una: ',
    answers: [
      { text: 'a. Using AWS Trusted Advisor', correct: false,  expli:' ' },
      { text: 'b. Using the AWS Personal Health Dashboard', correct: false,  expli:' ' },
	    { text: 'c. Using AWS Artifact', correct: true,  expli:' La respuesta correcta es: Using AWS Artifact. <br>'+  
      'Explanation: <br>'+ 
      '• AWS Artifact, available in the console, is a self-service audit artifact retrieval portal that provides our customers with on-demand access to AWS’ compliance documentation and AWS agreements <br>'+ 
      '• You can use AWS Artifact Reports to download AWS security and compliance documents, such as AWS ISO certifications, Payment Card Industry (PCI), and System and Organization Control (SOC) reports <br>'+ 
      '• AWS Trusted Advisor is an online resource to help you reduce cost, increase performance, and improve security by optimizing your AWS environment <br>'+ 
      '• Inspector is an automated security assessment service that helps improve the security and compliance of applications deployed on AWS <br>'+ 
      '• AWS Personal Health Dashboard provides alerts and remediation guidance when AWS is experiencing events that may impact you <br>'+ 
      'References: <br>'+ 
      '• https://aws.amazon.com/artifact/ <br>'},
      { text: 'd. Using AWS Inspector', correct: false,  expli:' ' }
    ],
	img: '',  
  }, 
  {
    question: '/Exam Prep 2 - 65p - 1 / A popular social network is hosted in AWS and is using a DynamoDB table as its database. There is a requirement to implement a follow feature where users can subscribe to certain updates made by a particular user and be notified via email. Which of the following is the most suitable solution that you should implement to meet the requirement? Seleccione una: ',
    answers: [
      { text: 'a. Create a Lambda function that uses DynamoDB Streams Kinesis Adapter which will fetch data from the DynamoDB Streams endpoint. Set up an SNS Topic that will notify the subscribers via email when there is an update made by a particular user. ', correct: false,  expli:' ' },
      { text: 'b. Enable DynamoDB Stream and create an AWS Lambda trigger, as well as the IAM role which contains all of the permissions that the Lambda function will need at runtime. The data from the stream record will be processed by the Lambda function which will then publish a message to SNS Topic that will notify the subscribers via email.', correct: true,  expli:' La respuesta correcta es: Enable DynamoDB Stream and create an AWS Lambda trigger, as well as the IAM role which contains all of the permissions that the Lambda function will need at runtime. The data from the stream record will be processed by the Lambda function which will then publish a message to SNS Topic that will notify the subscribers via email.'+ 
      'A DynamoDB stream is an ordered flow of information about changes to items in an Amazon DynamoDB table. When you enable a stream on a table, DynamoDB captures information about every modification to data items in the table. <br>'+
'Whenever an application creates, updates, or deletes items in the table, DynamoDB Streams writes a stream record with the primary key attribute(s) of the items that were modified. A stream record contains information about a data modification to a single item in a DynamoDB table. You can configure the stream so that the stream records capture additional information, such as the "before" and "after" images of modified items. <br>'+
'Amazon DynamoDB is integrated with AWS Lambda so that you can create triggers—pieces of code that automatically respond to events in DynamoDB Streams. With triggers, you can build applications that react to data modifications in DynamoDB tables. <br>'+
'If you enable DynamoDB Streams on a table, you can associate the stream ARN with a Lambda function that you write. Immediately after an item in the table is modified, a new record appears in the table\'s stream. AWS Lambda polls the stream and invokes your Lambda function synchronously when it detects new stream records. The Lambda function can perform any actions you specify, such as sending a notification or initiating a workflow. Hence, the correct answer in this scenario is Option 4. <br>'+
'Option 1 is incorrect because although this is a valid solution, it is missing a vital step which is to enable DynamoDB Streams. With the DynamoDB Streams Kinesis Adapter in place, you can begin developing applications via the KCL interface, with the API calls seamlessly directed at the DynamoDB Streams endpoint. Remember that the DynamoDB Stream feature is not enabled by default. <br>'+
'Option 2 is incorrect because just like Option 1, you have to manually enable DynamoDB Streams first before you can use its endpoint. <br>'+
'Option 3 is incorrect because the DynamoDB Accelerator (DAX) feature is primarily used to significantly improve the in-memory read performance of your database, and not to capture the time-ordered sequence of item-level modifications. You should use DynamoDB Streams in this scenario instead. <br>'+
'References: <br>'+
'https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/Streams.html <br>'+
'https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/Streams.Lambda.Tutorial.html <br>'},
	    { text: 'c. Using the Kinesis Client Library (KCL), write an application that leverages on DynamoDB Streams Kinesis Adapter that will fetch data from the DynamoDB Streams endpoint. When there are updates made by a particular user, notify the subscribers via email using SNS.', correct: false,  expli:' ' },
      { text: 'd. Set up a DAX cluster to access the source DynamoDB table. Create a new DynamoDB trigger and a Lambda function. For every update made in the user data, the trigger will send data to the Lambda function which will then notify the subscribers via email using SNS.', correct: false,  expli:' ' }
    ],
	img: '',  
  },  
  {
    question: '/Exam Prep 2 - 65p - 2 / You are working for a software company that has moved a legacy application from an on-premises data center to the cloud. The legacy application requires a static IP address hard-coded into the backend, which blocks you from using an Application Load Balancer. ',
    answers: [
      { text: 'a. Use Cloudfront with a custom origin pointed to your on-premises network where the web application is deployed.', correct: false,  expli:' ' },
      { text: 'b. Postpone the deployment until you have fully converted the application to work with the ELB and Auto Scaling. ', correct: false,  expli:' ' },
	    { text: 'c. Write a script that checks the health of the EC2 instance. If the instance stops responding, the script will switch the elastic IP address to a standby EC2 instance. ', correct: true,  expli:' una respuesta correcta es : Write a script that checks the health of the EC2 instance. If the instance stops responding, the script will switch the elastic IP address to a standby EC2 instance.'+ 
      'Which steps would you take to apply high availability and fault tolerance to this application without ELB? (Choose 2) Seleccione una o más de una: <br>'+
'For this scenario, it is best to set up a self-monitoring EC2 instance with a virtual IP Address. You can use an Elastic IP and then write a custom script that checks the health of the EC2 instance and if the instance stops responding, the script will switch the Elastic IP address to a standby EC2 instance. <br>'+
'A custom script enables one Amazon Elastic Compute Cloud (EC2) instance to monitor another Amazon EC2 instance and take over a private "virtual" IP address on instance failure. When used with two instances, the script enables a High Availability scenario where instances monitor each other and take over a shared virtual IP address if the other instance fails. It could easily be modified to run on a third-party monitoring or witness server to perform the VIP swapping on behalf of the two monitored nodes. <br>'+
'Option 3 is incorrect because you don\'t have to postpone your deployment as you have the option to set up a self-monitoring EC2 instance with an EIP address. <br>'+
'Option 4 is incorrect as even though the Auto Scaling group provides high availability and scalability, it still depends on ELB which is not available in this scenario. Take note that you need to have a static IP address which can be in the form of an Elastic IP. Although an Auto Scaling group can scale out if one of the EC2 instances became unhealthy, you still cannot directly assign an EIP to an Auto Scaling group. In addition, you are only limited to use EC2 instance status checks for your Auto Scaling group if you do not have an ELB which can provide you the actual health check of your application (using its port), and not just the health of the EC2 instance. <br>'+
'Option 5 is incorrect because although this option is feasible, the goal of the company is to move the application to the cloud and not to continue using its on-premises resources. <br>'+
'References: <br>'+
'https://aws.amazon.com/articles/leveraging-multiple-ip-addresses-for-virtual-ip-address-fail-over-in-6-simple-steps <br>'+
'https://aws.amazon.com/blogs/apn/amazon-vpc-for-on-premises-network-engineers-part-two/ <br>' },
      { text: 'd. Assign an Elastic IP address to the instance.', correct: true,  expli:' una respuesta correcta es :Assign an Elastic IP address to the instance.' },
      { text: 'e. Launch the instance using Auto Scaling which will deploy the instance again if it becomes unhealthy.', correct: false,  expli:' ' }
    ],
	img: '',  
  },  
  {
    question: '/Exam Prep 2 - 65p - 3 / A company\'s application runs on Amazon EC2 instances behind an Application Load Balancer (ALB). The instances run in an Amazon EC2 Auto Scaling group across multiple Availability Zones. On the first day of every month at midnight, the application becomes much slower when the month-end financial calculation batch executes. This causes the CPU utilization of the EC2 instances to immediately peak to 100%, which disrupts the application. What should a solutions architect recommend to ensure the application is able to handle the workload and avoid downtime? Seleccione una:',
    answers: [
      { text: 'a. Configure an Amazon CloudFront distribution in front of the ALB.', correct: false,  expli:' ' },
      { text: 'b. Configure an EC2 Auto Scaling scheduled scaling policy based on the monthly schedule. ', correct: true,  expli:' La respuesta correcta es: Configure an EC2 Auto Scaling scheduled scaling policy based on the monthly schedule.' +
      'Scheduled Scaling for Amazon EC2 Auto Scaling <br>'+
'Scheduled scaling allows you to set your own scaling schedule. For example, let\'s say that every week the traffic <br>'+
'to your web application starts to increase on <br>'+
'Wednesday, remains high on Thursday, and starts to decrease on Friday. You can plan your scaling actions based <br>'+
'on the predictable traffic patterns of your web application. Scaling actions are performed automatically as a <br>'+
'function of time and date. <br>'+
'Reference: <br>'+
'https://docs.aws.amazon.com/autoscaling/ec2/userguide/schedule_time.html <br>'},
	    { text: 'c. Configure Amazon ElastiCache to remove some of the workload from the EC2 instances', correct: false,  expli:' ' },
      { text: 'd. Configure an EC2 Auto Scaling simple scaling policy based on CPU utilization.', correct: false,  expli:' ' }
    ],
	img: '',  
  },  
  {
    question: '/Exam Prep 2 - 65p - 4 / You have triggered the creation of a snapshot of your EBS volume attached to an Instance Store-backed EC2 Instance and is currently on-going. At this point, what are the things that the EBS volume can or cannot do? Seleccione una:',
    answers: [
      { text: 'a. The volume can be used in write-only mode while the snapshot is in progress.', correct: false,  expli:' ' },
      { text: 'b. The volume cannot be used until the snapshot completes.', correct: false,  expli:' ' },
	    { text: 'c. The volume can be used as normal while the snapshot is in progress. ', correct: true,  expli:' La respuesta correcta es: The volume can be used as normal while the snapshot is in progress.' +
      'EBS snapshots occur asynchronously which makes option 1 the correct answer. This means that the point-in-time snapshot is created immediately, but the status of the snapshot is pending until the snapshot is complete (when all of the modified blocks have been transferred to Amazon S3), which can take several hours for large initial snapshots or subsequent snapshots where many blocks have changed. While it is completing, an in-progress snapshot is not affected by ongoing reads and writes to the volume hence, you can still use the volume. <br>'+
'Option 2, 3 and 4 are incorrect because you will still be able to perform normal read and write operations on your EBS volume even while a snapshot is ongoing. Although you can take a snapshot of a volume while a previous snapshot of that volume is in the pending status, having multiple pending snapshots of a volume may result in reduced volume performance until the snapshots complete. <br>'+
'Reference: <br>'+
'https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ebs-creating-snapshot.html <br>'},
      { text: 'd. The volume can be used in read-only mode while the snapshot is in progress.', correct: false,  expli:' ' }
    ],
	img: '',  
  },  
    {
    question: '/Exam Prep 2 - 65p - 5 / You are working for a large pharmaceutical company that has resources hosted on both their on-premises network and in AWS cloud. They want all of their Software Architects to access resources on both environments using their on-premises credentials, which is stored in Active Directory. In this scenario, which of the following can be used to fulfill this requirement? Seleccione una:',
    answers: [
      { text: 'a. Use Web Identity Federation', correct: false,  expli:' ' },
      { text: 'b. Use SAML Federation ', correct: true,  expli:' La respuesta correcta es: Use SAML Federation' +
      'Since the company is using Microsoft Active Directory which implements Security Assertion Markup Language (SAML), you can set up a SAML-Based Federation for API Access to your AWS cloud. In this way, you can easily connect to AWS using the login credentials of your on-premises network. <br>'+
'AWS supports identity federation with SAML 2.0, an open standard that many identity providers (IdPs) use. This feature enables federated single sign-on (SSO), so users can log into the AWS Management Console or call the AWS APIs without you having to create an IAM user for everyone in your organization. By using SAML, you can simplify the process of configuring federation with AWS, because you can use the IdP\'s service instead of writing custom identity proxy code. <br>'+
'Option 1 is incorrect because web identity federation is primarily used to let users sign in via a well-known external identity provider (IdP), such as Login with Amazon, Facebook, Google. It does not utilize Active Directory. <br>'+
'Option 3 is incorrect because the situation requires you to use the existing credentials stored in their Active Directory, and not user accounts that will be generated by IAM. <br>'+
'Option 4 is incorrect because the AWS VPC lets you provision a logically isolated section of the AWS Cloud where you can launch AWS resources in a virtual network that you define. This has nothing to do with user authentication or Active Directory. <br>'+
'Reference: <br>'+
'http://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles_providers_saml.html <br>'},
	    { text: 'c. Use IAM users', correct: false,  expli:' ' },
      { text: 'd. Use AWS VPC', correct: false,  expli:' ' }
    ],
	img: '',  
  },  
    {
    question: '/Exam Prep 2 - 65p - 6 / A company captures clickstream data from multiple websites and analyzes it using batch processing. The data is loaded nightly into Amazon Redshift and is consumed by business analysts. The company wants to move towards near-real-time data processing for timely insights. The solution should process the streaming data with minimal effort and operational overhead. Which combination of AWS services are MOST cost-effective for this solution? (Choose two.) Seleccione una o más de una: ',
    answers: [
      { text: 'a. Amazon Kinesis Data Streams ', correct: false,  expli:' ' },
      { text: 'b. Amazon Kinesis Data Firehose', correct: true,  expli:' una respuesta correcta es : Amazon Kinesis Data Firehose' },
	    { text: 'c. Amazon Kinesis Data Analytics ', correct: true,  expli:' una respuesta correcta es : Amazon Kinesis Data Analytics' +
      'Kinesis Data Streams and Kinesis Client Library (KCL) ג "Data from the data source can be continuously captured <br>'+
'and streamed in near real-time using Kinesis <br>'+
'Data Streams. With the Kinesis Client Library (KCL), you can build your own application that can preprocess the <br>'+
'streaming data as they arrive and emit the data for generating incremental views and downstream analysis. <br>'+
'Kinesis Data Analytics ג "€This service provides the easiest way to process the data that is streaming through <br>'+
'Kinesis Data Stream or Kinesis Data Firehose using SQL. This enables customers to gain actionable insight in near <br>'+
'real-time from the incremental stream before storing it in Amazon S3. <br>'+
'Reference: https://d1.awsstatic.com/whitepapers/lambda-architecure-on-for-batch-aws.pdf <br>'},
      { text: 'd. AWS Lambda', correct: false,  expli:' ' },
      { text: 'e. Amazon EC2', correct: false,  expli:' ' }
    ],
	img: '',  
  },  
    {
    question: '/Exam Prep 2 - 65p - 7 / A company built a food ordering application that captures user data and stores it for future analysis. The applicationג\'s static front end is deployed on an Amazon EC2 instance. The front-end application sends the requests to the backend application running on separate EC2 instance. The backend application then stores the data in Amazon RDS. What should a solutions architect do to decouple the architecture and make it scalable? Seleccione una:',
    answers: [
      { text: 'a. Use Amazon S3 to serve the front-end application and write requests to an Amazon Simple Notification Service (Amazon SNS) topic. Subscribe Amazon EC2 instances to the HTTP/HTTPS endpoint of the topic, and process and store the data in Amazon RDS.', correct: false,  expli:' ' },
      { text: 'b. Use Amazon S3 to serve the static front-end application and send requests to Amazon API Gateway, which writes the requests to an Amazon SQS queue. Place the backend instances in an Auto Scaling group, and scale based on the queue depth to process and store the data in Amazon RDS. ', correct: true,  expli:' La respuesta correcta es: Use Amazon S3 to serve the static front-end application and send requests to Amazon API Gateway, which writes the requests to an Amazon SQS queue. Place the backend instances in an Auto Scaling group, and scale based on the queue depth to process and store the data in Amazon RDS.' },
	    { text: 'c. Use an EC2 instance to serve the front end and write requests to an Amazon SQS queue. Place the backend instance in an Auto Scaling group, and scale based on the queue depth to process and store the data in Amazon RDS.', correct: false,  expli:' ' },
      { text: 'd. Use Amazon S3 to serve the front-end application, which sends requests to Amazon EC2 to execute the backend application. The backend application will process and store the data in Amazon RDS.', correct: false,  expli:' ' }
    ],
	img: '',  
  },  
    {
    question: '/Exam Prep 2 - 65p - 8 / A suite of web applications is composed of several different Auto Scaling group of EC2 instances which is configured with default settings and then deployed across three Availability Zones. There is an Application Load Balancer that forwards the request to the respective target group on the URL path. The scale-in policy has been triggered due to the low number of incoming traffic to the application. Which EC2 instance will be the first one to be terminated by your Auto Scaling group? Seleccione una:',
    answers: [
      { text: 'a. The EC2 instance which has been running for the longest time', correct: false,  expli:' ' },
      { text: 'b. The EC2 instance which belongs to an Auto Scaling group with the oldest launch configuration', correct: true,  expli:' La respuesta correcta es: The EC2 instance which belongs to an Auto Scaling group with the oldest launch configuration' +
      'The default termination policy is designed to help ensure that your network architecture spans Availability Zones evenly. With the default termination policy, the behavior of the Auto Scaling group is as follows: <br>'+
'1. If there are instances in multiple Availability Zones, choose the Availability Zone with the most instances and at least one instance that is not protected from scale in. If there is more than one Availability Zone with this number of instances, choose the Availability Zone with the instances that use the oldest launch configuration. <br>'+
'2. Determine which unprotected instances in the selected Availability Zone use the oldest launch configuration. If there is one such instance, terminate it. <br>'+
'3. If there are multiple instances to terminate based on the above criteria, determine which unprotected instances are closest to the next billing hour. (This helps you maximize the use of your EC2 instances and manage your Amazon EC2 usage costs.) If there is one such instance, terminate it. <br>'+
'4. If there is more than one unprotected instance closest to the next billing hour, choose one of these instances at random. <br>'+
'The following flow diagram illustrates how the default termination policy works: <br>'+
'Reference: <br>'+
'https://docs.aws.amazon.com/autoscaling/ec2/userguide/as-instance-termination.html#default-termination-policy <br>' },
	    { text: 'c. The instance will be randomly selected by the Auto Scaling group', correct: false,  expli:' ' },
      { text: 'd. The EC2 instance which has the least number of user sessions', correct: false,  expli:' ' }
    ],
	img: './aws/question8_exam2_65p.png',  
  },  
  /*imagen*/
    {
    question: '/Exam Prep 2 - 65p - 9 / A solutions architect is designing a solution where users will be directed to a backup static error page if the primary website is unavailable. The primary website DNS records are hosted in Amazon Route 53 where their domain is pointing to an Application Load Balancer (ALB). Which configuration should the solutions architect use to meet the companyגTM€s needs while minimizing changes and infrastructure overhead? Seleccione una: ',
    answers: [
      { text: 'a. Update the Route 53 record to use a latency-based routing policy. Add the backup static error page hosted within an Amazon S3 bucket to the record so the traffic is sent to the most responsive endpoints.', correct: false,  expli:' ' },
      { text: 'b. Point a Route 53 alias record to an Amazon CloudFront distribution with the ALB as one of its origins. Then, create custom error pages for the distribution.', correct: false,  expli:' ' },
	    { text: 'c. Set up a Route 53 active-passive failover configuration. Direct traffic to a static error page hosted within an Amazon S3 bucket when Route 53 health checks determine that the ALB endpoint is unhealthy. ', correct: true,  expli:' La respuesta correcta es: Set up a Route 53 active-passive failover configuration. Direct traffic to a static error page hosted within an Amazon S3 bucket when Route 53 health checks determine that the ALB endpoint is unhealthy.' +
      'Active-passive failover  <br>'+
'Use an active-passive failover configuration when you want a primary resource or group of resources to be available the majority of the time and you want a secondary resource or group of resources to be on standby in case all the primary resources become unavailable. When responding to queries, Route 53 includes only the healthy primary resources. If all the primary resources are unhealthy, Route 53 begins to include only the healthy secondary resources in response to DNS queries. <br>'+
'To create an active-passive failover configuration with one primary record and one secondary record, you just create the records and specify Failover for the routing policy. When the primary resource is healthy, Route 53 responds to DNS queries using the primary record. When the primary resource is unhealthy, Route 53 responds to DNS queries using the secondary record. <br>'+
'How Amazon Route 53 averts cascading failures <br>'+
'As a first defense against cascading failures, each request routing algorithm (such as weighted and failover) has a mode of last resort. In this special mode, when all records are considered unhealthy, the Route 53 algorithm reverts to considering all records healthy. <br>'+
'For example, if all instances of an application, on several hosts, are rejecting health check requests, Route 53 DNS servers will choose an answer anyway and return it rather than returning no DNS answer or returning an NXDOMAIN (non-existent domain) response. An application can respond to users but still fail health checks, so this provides some protection against misconfiguration. <br>'+
'Similarly, if an application is overloaded, and one out of three endpoints fails its health checks, so that it\'s excluded from Route 53 DNS responses, Route 53 distributes responses between the two remaining endpoints. <br>'+
'If the remaining endpoints are unable to handle the additional load and they fail, Route 53 reverts to distributing requests to all three endpoints. <br>'+
'Reference: <br>'+
'https://docs.aws.amazon.com/Route53/latest/DeveloperGuide/dns-failover-types.html <br>'+
'https://docs.aws.amazon.com/Route53/latest/DeveloperGuide/dns-failover-problems.html <br>' },
      { text: 'd. Set up a Route 53 active-active configuration with the ALB and an Amazon EC2 instance hosting a static error page as endpoints. Route 53 will only send requests to the instance if the health checks fail for the ALB.', correct: false,  expli:' ' }
    ],
	img: '',  
  },  
    {
    question: '/Exam Prep 2 - 65p - 10 / A tech company has a CRM application hosted on an Auto Scaling group of On-Demand EC2 instances. The application is extensively used during office hours from 9 in the morning till 5 in the afternoon. Their users are complaining that the performance of the application is slow during the start of the day but then works normally after a couple of hours. Which of the following can be done to ensure that the application works properly at the beginning of the day? Seleccione una:',
    answers: [
      { text: 'a. Configure a Dynamic scaling policy for the Auto Scaling group to launch new instances based on the Memory utilization.', correct: false,  expli:' ' },
      { text: 'b. Set up an Application Load Balancer (ALB) to your architecture to ensure that the traffic is properly distributed on the instances.', correct: false,  expli:' ' },
	    { text: 'c. Configure a Dynamic scaling policy for the Auto Scaling group to launch new instances based on the CPU utilization. ', correct: false,  expli:' ' },
      { text: 'd. Configure a Scheduled scaling policy for the Auto Scaling group to launch new instances before the start of the day', correct: true,  expli:' La respuesta correcta es: Configure a Scheduled scaling policy for the Auto Scaling group to launch new instances before the start of the day' +
      'Scaling based on a schedule allows you to scale your application in response to predictable load changes. For example, every week the traffic to your web application starts to increase on Wednesday, remains high on Thursday, and starts to decrease on Friday. You can plan your scaling activities based on the predictable traffic patterns of your web application. <br>'+
'To configure your Auto Scaling group to scale based on a schedule, you create a scheduled action. The scheduled action tells Amazon EC2 Auto Scaling to perform a scaling action at specified times. To create a scheduled scaling action, you specify the start time when the scaling action should take effect, and the new minimum, maximum, and desired sizes for the scaling action. At the specified time, Amazon EC2 Auto Scaling updates the group with the values for minimum, maximum, and desired size specified by the scaling action. You can create scheduled actions for scaling one time only or for scaling on a recurring schedule. <br>'+
'Option 3 is the correct answer. You need to configure a Scheduled scaling policy. This will ensure that the instances are already scaled up and ready before the start of the day since this is when the application is used the most. <br>'+
'Options 1 and 2 are incorrect because although this is a valid solution, it is still better to configure a Scheduled scaling policy as you already know the exact peak hours of your application. By the time either the CPU or Memory hits a peak, the application already has performance issues, so you need to ensure the scaling is done beforehand using a Scheduled scaling policy. <br>'+
'Option 4 is incorrect. Although the Application load balancer can also balance the traffic, it cannot increase the instances based on demand. <br>'+
'Reference: <br>'+
'https://docs.aws.amazon.com/autoscaling/ec2/userguide/schedule_time.html <br>'}
    ],
	img: '',  
  },  
    {
    question: '/Exam Prep 2 - 65p - 11 / A Solutions Architect is designing an online medical system in AWS which will store sensitive Personally Identifiable Information (PII) of the users in an Amazon S3 bucket. Both the master keys and the unencrypted data should never be sent to AWS to comply with the strict compliance and regulatory requirements of the company. Which S3 encryption technique should the Architect use? Seleccione una:',
    answers: [
      { text: 'a. Use S3 client-side encryption with a KMS-managed customer master key.', correct: false,  expli:' ' },
      { text: 'b. Use S3 client-side encryption with a client-side master key. ', correct: true,  expli:' La respuesta correcta es: Use S3 client-side encryption with a client-side master key.' + 
      'Client-side encryption is the act of encrypting data before sending it to Amazon S3. To enable client-side encryption, you have the following options: <br>'+
'- Use an AWS KMS-managed customer master key. <br>'+
'- Use a client-side master key. <br>'+
'When using an AWS KMS-managed customer master key to enable client-side data encryption, you provide an AWS KMS customer master key ID (CMK ID) to AWS. On the other hand, when you use client-side master key for client-side data encryption, your client-side master keys and your unencrypted data are never sent to AWS. It\'s important that you safely manage your encryption keys because if you lose them, you can\'t decrypt your data. <br>'+
'This is how client-side encryption using client-side master key works: <br>'+
'When uploading an object - You provide a client-side master key to the Amazon S3 encryption client. The client uses the master key only to encrypt the data encryption key that it generates randomly. The process works like this: <br>'+
'1. The Amazon S3 encryption client generates a one-time-use symmetric key (also known as a data encryption key or data key) locally. It uses the data key to encrypt the data of a single Amazon S3 object. The client generates a separate data key for each object. <br>'+
'2. The client encrypts the data encryption key using the master key that you provide. The client uploads the encrypted data key and its material description as part of the object metadata. The client uses the material description to determine which client-side master key to use for decryption. <br>'+
'3. The client uploads the encrypted data to Amazon S3 and saves the encrypted data key as object metadata (x-amz-meta-x-amz-key) in Amazon S3. <br>'+

'When downloading an object - The client downloads the encrypted object from Amazon S3. Using the material description from the object\'s metadata, the client determines which master key to use to decrypt the data key. The client uses that master key to decrypt the data key and then uses the data key to decrypt the object. <br>'+
'Hence, the correct answer is Option 2. <br>'+
'Option 1 is incorrect because in client-side encryption with a KMS-managed customer master key, you provide an AWS KMS customer master key ID (CMK ID) to AWS. The scenario clearly indicates that both the master keys and the unencrypted data should never be sent to AWS. <br>'+
'Option 3 is incorrect because the scenario mentioned that the unencrypted data should never be sent to AWS, which means that you have to use client-side encryption in order to encrypt the data first before sending to AWS. In this way, you can ensure that there is no unencrypted data being uploaded to AWS. In addition, the master key used by Server-Side Encryption with AWS KMS–Managed Keys (SSE-KMS) is uploaded and managed by AWS, which directly violates the requirement of not uploading the master key. <br>'+
'Option 4 is incorrect because just as mentioned in Option 3, you have to use client-side encryption in this scenario instead of server-side encryption. For the S3 server-side encryption with customer-provided key (SSE-C), you actually provide the encryption key as part of your request to upload the object to S3. Using this key, Amazon S3 manages both the encryption (as it writes to disks) and decryption (when you access your objects). <br>'+

'References: <br>'+
'https://docs.aws.amazon.com/AmazonS3/latest/dev/UsingEncryption.html <br>'+
'https://docs.aws.amazon.com/AmazonS3/latest/dev/UsingClientSideEncryption.html <br>' },
	    { text: 'c. Use S3 server-side encryption with a KMS managed key', correct: false,  expli:' ' },
      { text: 'd. Use S3 server-side encryption with customer provided key.', correct: false,  expli:' ' }
    ],
	img: '',  
  },  
    {
    question: '/Exam Prep 2 - 65p - 12/ A startup based in Australia is deploying a new two-tier web application in AWS. The Australian company wants to store their most frequently used data in an in-memory data store to improve the retrieval and response time of their web application. Which of the following is the most suitable service to be used for this requirement? Seleccione una:',
    answers: [
      { text: 'a. DynamoDB', correct: false,  expli:' ' },
      { text: 'b. Amazon ElastiCache ', correct: true,  expli:' La respuesta correcta es: Amazon ElastiCache' +
      'Amazon ElastiCache is a web service that makes it easy to deploy, operate, and scale an in-memory data store or cache in the cloud. The service improves the performance of web applications by allowing you to retrieve information from fast, managed, in-memory data stores, instead of relying entirely on slower disk-based databases. <br>'+
'Option 1 is incorrect because DynamoDB is primarily used as a NoSQL database which supports both document and key-value store models. ElastiCache is a more suitable service to use than DynamoDB, if you need an in-memory data store. <br>'+
'Option 2 is incorrect because RDS is mainly used as a relational database and not as a data storage for frequently used data. <br>'+
'Option 4 is incorrect because Redshift is a data warehouse service and is not suitable to be used as an in-memory data store. <br>'+
'References: <br>'+
'https://aws.amazon.com/elasticache/ <br>'+
'https://aws.amazon.com/products/databases/ <br>'},
	    { text: 'c. Amazon RDS', correct: false,  expli:' ' },
      { text: 'd. Amazon Redshift', correct: false,  expli:' ' }
    ],
	img: '',  
  },  
    {
    question: '/Exam Prep 2 - 65p - 13 / You are trying to establish an SSH connection to a newly created Amazon EC2 instance using the PuTTY tool. However, you are getting the following error message: Error: No supported authentication methods available What steps should you take to fix this issue? (Choose 2) Seleccione una o más de una:',
    answers: [
      { text: 'a. Verify that you are connecting with the appropriate user name for your AMI such as ec2-user for Linux AMI, centos for Centos AMI or admin for Debian AMI ', correct: true,  expli:' una respuesta correcta es: Verify that you are connecting with the appropriate user name for your AMI such as ec2-user for Linux AMI, centos for Centos AMI or admin for Debian AMI' },
      { text: 'b. Verify that your IAM user policy has permission to launch Amazon EC2 instances.', correct: false,  expli:' ' },
	    { text: 'c. Verify that you have waited at least 1 hour after the EC2 instance was created before connecting via SSH.', correct: false,  expli:' ' },
      { text: 'd. Verify if your private key (.pem) file has been correctly converted to the format recognized by PuTTY (.ppk).', correct: true,  expli:' una respuesta correcta es:Verify if your private key (.pem) file has been correctly converted to the format recognized by PuTTY (.ppk).' + 
      'If you use PuTTY to connect to your instance via SSH and get either of the following errors, Error: Server refused our key or Error: No supported authentication methods available, verify that you are connecting with the appropriate user name for your AMI. Enter the user name in the User name box in the PuTTY Configuration window. <br>'+
'The appropriate user names are as follows: <br>'+
'• -For an Amazon Linux AMI, the user name is ec2-user. <br>'+
'• -For a RHEL AMI, the user name is ec2-user or root. <br>'+
'• -For an Ubuntu AMI, the user name is ubuntu or root. <br>'+
'• -For a Centos AMI, the user name is centos. <br>'+
'• -For a Debian AMI, the user name is admin or root. <br>'+
'• -For a Fedora AMI, the user name is ec2-user. <br>'+
'• -For a SUSE AMI, the user name is ec2-user or root. <br>'+
'• -Otherwise, if ec2-user and root don\'t work, check with the AMI provider. <br>'+

'You should also verify that your private key (.pem) file has been correctly converted to the format recognized by PuTTY (.ppk). <br>'+
'Options 2 and 4 are incorrect because both an IAM user and IAM role policy have nothing to do with this issue. <br>'+
'Option 5 is incorrect because you don\'t need to wait an hour in order to connect to a new EC2 instance as you can immediately connect to it once it is created. <br>'+

'Reference: <br>'+
'https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/TroubleshootingInstancesConnecting.html#TroubleshootingInstancesConnectingPuTTY <br>'},
      { text: 'e. Verify that the Amazon EC2 Instance was launched with the proper IAM role. ', correct: false,  expli:' ' }
    ],
	img: '',  
  },  
    {
    question: '/Exam Prep 2 - 65p - 14 / An Amazon EC2 administrator created the following policy associated with an IAM group containing several users: What is the effect of this policy?  Seleccione una:',
    answers: [
      { text: 'a. Users can terminate an EC2 instance in the us-east-1 Region when the user\'s source IP is 10.100.100.254.', correct: true,  expli:' La respuesta correcta es: Users can terminate an EC2 instance in the us-east-1 Region when the user\'s source IP is 10.100.100.254.' },
      { text: 'b. Users cannot terminate an EC2 instance in the us-east-1 Region when the userגTM€s source IP is 10.100.100.254.', correct: false,  expli:' ' },
	    { text: 'c. Users can terminate an EC2 instance with the IP address 10.100.100.1 in the us-east-1 Region. ', correct: false,  expli:' ' },
      { text: 'd. Users can terminate an EC2 instance in any AWS Region except us-east-1', correct: false,  expli:' ' }
    ],
	img: './aws/question14_exam2_65p.png',  
  },  
  /*imagen*/
    {
    question: '/Exam Prep 2 - 65p - 15 / You have a web application deployed in AWS which is currently running in the eu-central-1 region. You have an Auto Scaling group of On-Demand EC2 instances which are using pre-built AMIs. Your manager instructed you to implement disaster recovery for your system so in the event that the application goes down in the eu-central-1 region, a new instance can be started in the us-west-2 region. As part of your disaster recovery plan, which of the following should you take into consideration? Seleccione una:',
    answers: [
      { text: 'a. Copy the AMI from the eu-central-1 region to the us-west-2 region. Afterwards, create a new Auto Scaling group in the us-west-2 region to use this new AMI ID. ', correct: true,  expli:' La respuesta correcta es: Copy the AMI from the eu-central-1 region to the us-west-2 region. Afterwards, create a new Auto Scaling group in the us-west-2 region to use this new AMI ID.' +
      'In this scenario, the EC2 instances you are currently using depends on a pre-built AMI. This AMI is not accessible to another region hence, you have to copy it to the us-west-2 region to properly establish your disaster recovery instance. <br>'+
'You can copy an Amazon Machine Image (AMI) within or across an AWS region using the AWS Management Console, the AWS command line tools or SDKs, or the Amazon EC2 API, all of which support the CopyImage action. You can copy both Amazon EBS-backed AMIs and instance store-backed AMIs. You can copy encrypted AMIs and AMIs with encrypted snapshots. <br>'+
'Options 1 and 3 are incorrect because the AMI does not have a Network Access Control nor a Share functionality. <br>'+
'Option 4 is incorrect as you can use a unique or pre-built AMI to a specific region only. <br>'+

'Reference: <br>'+
'http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/CopyingAMIs.html <br>' },
      { text: 'b. In the AMI dashboard, add the us-west-2 region to the Network Access Control List which contains the regions that are allowed to use the AMI.', correct: false,  expli:' ' },
	    { text: 'c. Share the AMI to the us-west-2 region.', correct: false,  expli:' ' },
      { text: 'd. None. AMIs can be used in any region hence, there is no problem using it in the us-west-2 region.', correct: false,  expli:' ' }
    ],
	img: '',  
  },  
    {
    question: '/Exam Prep 2 - 65p - 16 / You are deploying an Interactive Voice Response (IVR) telephony system in your cloud architecture that interacts with callers, gathers information, and routes calls to the appropriate recipients in your company. The system will be composed of an Auto Scaling group of EC2 instances, an Application Load Balancer, and an RDS instance in a Multi-AZ Deployments configuration. To protect the confidential data of your customers, you have to ensure that your RDS database can only be accessed using the profile credentials specific to your EC2 instances via an authentication token. As the Solutions Architect of the company, which of the following should you do to meet the above requirement? Seleccione una: ',
    answers: [
      { text: 'a. Configure SSL in your application to encrypt the database connection to RDS.', correct: false,  expli:' ' },
      { text: 'b. Enable the IAM DB Authentication.', correct: true,  expli:' La respuesta correcta es: Enable the IAM DB Authentication.' + 
      'You can authenticate to your DB instance using AWS Identity and Access Management (IAM) database authentication. IAM database authentication works with MySQL and PostgreSQL. With this authentication method, you don\'t need to use a password when you connect to a DB instance. Instead, you use an authentication token. <br>'+
'An authentication token is a unique string of characters that Amazon RDS generates on request. Authentication tokens are generated using AWS Signature Version 4. Each token has a lifetime of 15 minutes. You don\'t need to store user credentials in the database, because authentication is managed externally using IAM. You can also still use standard database authentication. <br>'+
'IAM database authentication provides the following benefits: <br>'+
'• Network traffic to and from the database is encrypted using Secure Sockets Layer (SSL). <br>'+
'• You can use IAM to centrally manage access to your database resources, instead of managing access individually on each DB instance. <br>'+
'• For applications running on Amazon EC2, you can use profile credentials specific to your EC2 instance to access your database instead of a password, for greater security <br>'+
'Hence, Option 1 is the correct answer based on the above reference. <br>'+
'Option 2 is incorrect because an SSL connection is not using an authentication token from IAM. Although configuring SSL to your application can improve the security of your data in flight, it is still not a suitable option to use in this scenario. <br>'+
'Option 3 is incorrect because although you can create and assign an IAM Role to your EC2 instances, you still need to configure your RDS to use IAM DB Authentication. <br>'+
'Option 4 is incorrect because you have to use IAM DB Authentication for this scenario, and not a combination of an IAM and STS. Although STS is used to send temporary tokens for authentication, this is not a compatible use case for RDS. <br>'+
'Reference: <br>'+
'https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/UsingWithRDS.IAMDBAuth.html <br>'},
	    { text: 'c. Create an IAM Role and assign it to your EC2 instances which will grant exclusive access to your RDS instance.', correct: false,  expli:' ' },
      { text: 'd. Use a combination of IAM and STS to restrict access to your RDS instance via a temporary token ', correct: false,  expli:' ' }
    ],
	img: '',  
  },  
    {
    question: '/Exam Prep 2 - 65p - 17 / You are a Solutions Architect for a leading Enterprise Resource Planning (ERP) solutions provider and you are instructed to design and set up the architecture of your ERP application in AWS. Your manager instructed you to avoid using fully-managed AWS services and instead, only use specific services which allows you to access the underlying operating system for the resource. This is to allow the company to have a much better control of the underlying resources that their systems are using in the AWS cloud. Which of the following services should you choose to satisfy this requirement? (Choose 2) Seleccione una o más de una:',
    answers: [
      { text: 'a. Amazon EMR ', correct: true,  expli:' una respuesta correcta es : Amazon EMR ' },
      { text: 'b. DynamoDB', correct: false,  expli:' ' },
	    { text: 'c. Amazon Neptune', correct: false,  expli:' ' },
      { text: 'd. Amazon Athena', correct: false,  expli:' ' },
      { text: 'e. Amazon EC2 ', correct: true,  expli:' una respuesta correcta es : Amazon EC2' +
      'Amazon EC2 provides you access to the operating system of the instance that you created. <br>'+
'Amazon EMR provides you a managed Hadoop framework that makes it easy, fast, and cost-effective to process vast amounts of data across dynamically scalable Amazon EC2 instances. You can access the operating system of these EC2 instances that were created by Amazon EMR. <br>'+
'Options 1, 4 and 5 are incorrect as these are managed services, which means that AWS manages the underlying operating system and other server configurations that these databases use. <br>'+
'References: <br>'+
'https://aws.amazon.com/ec2/ <br>'+
'https://aws.amazon.com/emr/ <br>'}
    ],
	img: '',  
  },  
    {
    question: '/Exam Prep 2 - 65p - 18 / A popular mobile game uses CloudFront, Lambda, and DynamoDB for its backend services. The player data is persisted on a DynamoDB table and the static assets are distributed by CloudFront. However, there are a lot of complaints that saving and retrieving player information is taking a lot of time. To improve the game\'s performance, which AWS service can you use to reduce DynamoDB response times from milliseconds to microseconds? Seleccione una:',
    answers: [
      { text: 'a. AWS Device Farm', correct: false,  expli:' ' },
      { text: 'b. Amazon DynamoDB Accelerator (DAX) ', correct: true,  expli:' La respuesta correcta es: Amazon DynamoDB Accelerator (DAX) <br>'+
      'Amazon DynamoDB Accelerator (DAX) is a fully managed, highly available, in-memory cache that can reduce Amazon DynamoDB response times from milliseconds to microseconds, even at millions of requests per second. <br>'+
'Option 1 is incorrect because although you may use ElastiCache as your database cache, it will not reduce the DynamoDB response time from milliseconds to microseconds as compared with DynamoDB DAX. <br>'+
'Option 2 is incorrect because AWS Device Farm is an app testing service that lets you test and interact with your Android, iOS, and web apps on many devices at once, or reproduce issues on a device in real time. <br>'+
'Option 3 is incorrect because DynamoDB Auto Scaling is primarily used to automate capacity management for your tables and global secondary indexes. <br>'+
'References: <br>'+
'https://aws.amazon.com/dynamodb/dax <br>'},
	    { text: 'c. Amazon ElastiCache', correct: false,  expli:' ' },
      { text: 'd. DynamoDB Auto Scaling', correct: false,  expli:' ' }
    ],
	img: '',  
  },  
    {
    question: '/Exam Prep 2 - 65p - 19 / Your cloud architecture is composed of Linux and Windows EC2 instances which process high volumes of financial data 24 hours a day, 7 days a week. To ensure high availability of your systems, you are required to monitor the memory and disk utilization of all of your instances. Which of the following is the most suitable monitoring solution to implement? Seleccione una:',
    answers: [
      { text: 'a. Use Amazon Inspector and install the Inspector agent to all of your EC2 instances.', correct: false,  expli:' ' },
      { text: 'b. Enable the Enhanced Monitoring option in EC2 and install CloudWatch agent to all of your EC2 instances to be able to view the memory and disk utilization in the CloudWatch dashboard. ', correct: false,  expli:' ' },
	    { text: 'c. Install the CloudWatch agent to all of your EC2 instances which gathers the memory and disk utilization data. View the custom metrics in the Amazon CloudWatch console.', correct: true,  expli:' La respuesta correcta es: Install the CloudWatch agent to all of your EC2 instances which gathers the memory and disk utilization data. View the custom metrics in the Amazon CloudWatch console. <br>'+
      'CloudWatch has available Amazon EC2 Metrics for you to use for monitoring CPU utilization, Network utilization, Disk performance, and Disk Reads/Writes. In case that you need to monitor the below items, you need to prepare a custom metric using a Perl or other shell script, as there are no ready to use metrics for these: <br>'+
'Memory utilization <br>'+
'disk swap utilization <br>'+
'disk space utilization <br>'+
'page file utilization <br>'+
'log collection <br>'+
'Take note that there is a multi-platform CloudWatch agent which can be installed on both Linux and Windows-based instances. You can use a single agent to collect both system metrics and log files from Amazon EC2 instances and on-premises servers. This agent supports both Windows Server and Linux and enables you to select the metrics to be collected, including sub-resource metrics such as per-CPU core. It is recommended that you use the new agent instead of the older monitoring scripts to collect metrics and logs. <br>'+

'Option 1 is incorrect because, by default, CloudWatch does not automatically provide memory and disk utilization metrics of your instances. You have to set up custom CloudWatch metrics to monitor the memory, disk swap, disk space and page file utilization of your instances. <br>'+
'Option 3 is incorrect because Enhanced Monitoring is a feature of RDS and not of CloudWatch. <br>'+
'Option 4 is incorrect because Amazon Inspector is an automated security assessment service that helps you test the network accessibility of your Amazon EC2 instances and the security state of your applications running on the instances. It does not provide a custom metric to track the memory and disk utilization of each and every EC2 instance in your VPC. <br>'+

'References: <br>'+
'https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/monitoring_ec2.html <br>'+
'https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/mon-scripts.html#using_put_script <br>' },
      { text: 'd. Use the default CloudWatch configuration to your EC2 instances where the memory and disk utilization metrics are already available. Install the AWS Systems Manager (SSM) Agent to all of your EC2 instances.', correct: false,  expli:' ' }
    ],
	img: '',  
  },  
    {
    question: '/Exam Prep 2 - 65p - 20 / You are building a new data analytics application in AWS which will be deployed in an Auto Scaling group of On-Demand EC2 instances and a MongoDB database. It is expected that the database will have high-throughput workloads performing small, random I/O operations. As the Solutions Architect, you are required to properly set up and launch the required resources in AWS. Which of the following is the most suitable EBS type to use for your database? Seleccione una:',
    answers: [
      { text: 'a. Provisioned IOPS SSD (io1) ', correct: true,  expli:' La respuesta correcta es: Provisioned IOPS SSD (io1) <br>'+ 
      'On a given volume configuration, certain I/O characteristics drive the performance behavior for your EBS volumes. SSD-backed volumes, such as General Purpose SSD (gp2) and Provisioned IOPS SSD (io1), deliver consistent performance whether an I/O operation is random or sequential. HDD-backed volumes like Throughput Optimized HDD (st1) and Cold HDD (sc1) deliver optimal performance only when I/O operations are large and sequential.<br>'+
'In the exam, always consider the difference between SSD and HDD as shown on the table below. This will allow you to easily eliminate specific EBS-types in the options which are not SSD or not HDD, depending on whether the question asks for a storage type which has small, random I/O operations or large, sequential I/O operations.<br>'+
'Provisioned IOPS SSD (io1) volumes are designed to meet the needs of I/O-intensive workloads, particularly database workloads, that are sensitive to storage performance and consistency. Unlike gp2, which uses a bucket and credit model to calculate performance, an io1 volume allows you to specify a consistent IOPS rate when you create the volume, and Amazon EBS delivers within 10 percent of the provisioned IOPS performance 99.9 percent of the time over a given year.<br>'+
'Option 1 is incorrect because although General Purpose is a type of SSD that can handle small, random I/O operations, the Provisioned IOPS SSD volumes are much more suitable to meet the needs of I/O-intensive database workloads such as MongoDB, Oracle, MySQL, and many others.<br>'+
'Options 3 and 4 are incorrect because HDD volumes (such as Throughput Optimized HDD and Cold HDD volumes) are more suitable for workloads with large, sequential I/O operations instead of small, random I/O operations.<br>'+

'Reference:<br>'+
'https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/EBSVolumeTypes.html#EBSVolumeTypes_piops <br>'+
'https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ebs-io-characteristics.html <br>'},
      { text: 'b. Cold HDD (sc1)', correct: false,  expli:' ' },
	    { text: 'c. Throughput Optimized HDD (st1)', correct: false,  expli:' ' },
      { text: 'd. General Purpose SSD (gp2)', correct: false,  expli:' ' }
    ],
	img: './aws/question20_exam2_65p.png',  
  },  
    {
    question: '/Exam Prep 2 - 65p - 21 / A company is developing an ecommerce application that will consist of a load-balanced front end, a container-based application, and a relational database. A solutions architect needs to create a highly available solution that operates with as little manual intervention as possible. Which solutions meet these requirements? (Choose two.) Seleccione una o más de una:',
    answers: [
      { text: 'a. Create an Amazon RDS DB instance in Multi-AZ mode.', correct: true,  expli:'una respuesta correcta es : Create an Amazon RDS DB instance in Multi-AZ mode. ' },
      { text: 'b. Create an Amazon RDS DB instance and one or more replicas in another Availability Zone.', correct: false,  expli:' ' },
	    { text: 'c. Create an Amazon Elastic Container Service (Amazon ECS) cluster with a Fargate launch type to handle the dynamic application load. ', correct: false,  expli:' ' },
      { text: 'd. Create an Amazon Elastic Container Service (Amazon ECS) cluster with an Amazon EC2 launch type to handle the dynamic application load.', correct: true,  expli:'una respuesta correcta es :  Create an Amazon Elastic Container Service (Amazon ECS) cluster with an Amazon EC2 launch type to handle the dynamic application load.' },
      { text: 'e. Create an Amazon EC2 instance-based Docker cluster to handle the dynamic application load.', correct: false,  expli:' ' }
    ],
	img: '',  
  },  
    {
    question: '/Exam Prep 2 - 65p - 22 / You are using a combination of API Gateway and Lambda for the web services of your online web portal that is being accessed by hundreds of thousands of clients each day. Your company will be announcing a new revolutionary product and it is expected that your web portal will receive a massive number of visitors all around the globe. How can you protect your backend systems and applications from traffic spikes? Seleccione una:',
    answers: [
      { text: 'a. Use throttling limits in API Gateway.', correct: true,  expli:'La respuesta correcta es: Use throttling limits in API Gateway. <br>'+
      'Amazon API Gateway provides throttling at multiple levels including global and by a service call. Throttling limits can be set for standard rates and bursts. For example, API owners can set a rate limit of 1,000 requests per second for a specific method in their REST APIs, and also configure Amazon API Gateway to handle a burst of 2,000 requests per second for a few seconds. <br>'+
'Amazon API Gateway tracks the number of requests per second. Any requests over the limit will receive a 429 HTTP response. The client SDKs generated by Amazon API Gateway retry calls automatically when met with this response. <br>'+
'Option 2 is incorrect because although it can scale using AWS Edge locations, you still need to configure the throttling to further manage the bursts of your APIs. <br>'+
'Option 3 is incorrect because API Gateway is a fully managed service and hence, you do not have access to its underlying resources. <br>'+
'Option 4 is incorrect because RDS has Multi-AZ and Read Replica capabilities, and not API Gateway. <br>'+

'Reference: <br>'+
'https://aws.amazon.com/api-gateway/faqs/#Throttling_and_Caching <br>' },
      { text: 'b. Deploy Multi-AZ in API Gateway with Read Replica ', correct: false,  expli:' ' },
	    { text: 'c. API Gateway will automatically scale and handle massive traffic spikes so you do not have to do anything. ', correct: false,  expli:' ' },
      { text: 'd. Manually upgrade the EC2 instances being used by API Gateway ', correct: false,  expli:' ' }
    ],
	img: '',  
  },  
    {
    question: '/Exam Prep 2 - 65p - 23 / You are tasked to host a web application in a new VPC with private and public subnets. In order to do this, you will need to deploy a new MySQL database server and a fleet of EC2 instances to host the application. In which subnet should you launch the new database server into? Seleccione una: ',
    answers: [
      { text: 'a. Ideally be launched outside the Amazon VPC ', correct: false,  expli:' ' },
      { text: 'b. The private subnet', correct: true,  expli:' La respuesta correcta es: The private subnet  <br>'+ 
      'In an ideal and secure VPC architecture, you launch the web servers or elastic load balancers in the public subnet and the database servers in the private subnet. <br>'+

'Option 1 is incorrect because if you launch your database server in the public subnet, it will be publicly accessible all over the Internet which has a higher security risk. <br>'+
'Option 2 is correct because it is more secure to launch your database in the private subnet to prevent other external and unauthorized users to access or attack your system. <br>'+
'Option 3 is incorrect since only the private subnet is the correct answer if you want to secure your database from external traffic. <br>'+
'Option 4 is incorrect as there is no need to launch it outside the VPC. Having it run in a private subnet should address the security and networking concerns of your database. <br>'+

'Reference: <br>'+
'https://docs.aws.amazon.com/AmazonVPC/latest/UserGuide/VPC_Scenario2.html <br>' },
	    { text: 'c. The public subnet', correct: false,  expli:' ' },
      { text: 'd. Either public or private subnet', correct: false,  expli:' ' }
    ],
	img: '',  
  },  
    {
    question: '/Exam Prep 2 - 65p - 24 / An engineering firm has an application that stores all the data in Amazon S3 buckets. The developer team has developed a new application that would start processing if there is any modification to the objects stored in these Amazon S3 buckets. The developer team is looking for a quick and reliable solution to get notifications from Amazon S3 for any updates to the objects. The proposed solution should be scalable and efficient to be used with all future deployments. The notifications should be specific to the new application and its associated objects, but not for all objects in the S3 bucket. What solution can be designed to get the required notifications for the Developer team? Seleccione una:',
    answers: [
      { text: 'a. Use Amazon S3 Event Notifications with Amazon EventBridge ', correct: true,  expli:'La respuesta correcta es: Use Amazon S3 Event Notifications with Amazon EventBridge <br>'+ 
      'Amazon EventBridge can be used to build applications that start processing after any changes to the objects stored in Amazon S3 buckets. All Amazon S3 event notifications are directly sent to Amazon EventBridge in a reliable and quick way. Amazon EventBridge provides additional benefits such as  <br>'+ 
'Advance Filtering: This helps to match object parameters which can be used to get only specific notifications.  <br>'+ 
'Multiple Destinations: Amazon EventBridge can be used forward event notifications to multiple destinations.  <br>'+ 
'Fast, Reliable Invocation: Amazon EventBridge provides a fast and reliable way to forward notifications without additional custom codes.   <br>'+ 
'Option B is incorrect as using AWS Lambda would require additional codes to be developed to process event notifications sent to a new application. This would not be an efficient solution.  <br>'+ 
'Option C is incorrect as this would require additional logic to be built in the new application to pull notifications from the Amazon SQS queue. This would not be a scalable solution.  <br>'+ 
'Option D is incorrect as this would require custom logic to be built to use Amazon SNS notifications. This would not be a scalable solution.  <br>'+ 
'For more information on S3 notifications with Amazon EventBridge, refer to the following URL,  <br>'+ 
'https://aws.amazon.com/blogs/aws/new-use-amazon-s3-event-notifications-with-amazon-eventbridge/  <br>' },
      { text: 'b. Use Amazon S3 Event Notifications with AWS Lambda', correct: false,  expli:' ' },
	    { text: 'c. Use Amazon S3 Event Notifications with Amazon SQS queue', correct: false,  expli:' ' },
      { text: 'd. Use Amazon S3 Event Notifications with the Amazon SNS', correct: false,  expli:' ' }
    ],
	img: '',  
  },  
    {
    question: '/Exam Prep 2 - 65p - 25 / You have a requirement to make sure that an On-Demand EC2 instance can only be accessed from this IP address (110.238.98.71) via an SSH connection. Which configuration below will satisfy this requirement? Seleccione una:',
    answers: [
      { text: 'a. Security Group Inbound Rule: Protocol – TCP. Port Range – 22, Source 110.238.98.71/0', correct: false,  expli:' ' },
      { text: 'b. Security Group Inbound Rule: Protocol – UDP, Port Range – 22, Source 110.238.98.71/32', correct: false,  expli:' ' },
	    { text: 'c. Security Group Inbound Rule: Protocol – UDP, Port Range – 22, Source 110.238.98.71/0', correct: false,  expli:' ' },
      { text: 'd. Security Group Inbound Rule: Protocol – TCP. Port Range – 22, Source 110.238.98.71/32', correct: true,  expli:'La respuesta correcta es: Security Group Inbound Rule: Protocol – TCP. Port Range – 22, Source 110.238.98.71/32  <br>'+ 
      'The SSH protocol uses TCP and port 22. Hence, Options 2 and 4 are incorrect as they are using UDP. Options 1 and 3 have one major difference and that is their CIDR block <br>'+ 
      'The requirement is to only allow the individual IP of the client and not the entire network. Therefore, the proper CIDR notation should be used. The /32 denotes one IP address and the /0 refers to the entire network. That is why Option 3 is incorrect as it allowed the entire network instead of a single IP. <br>'+ 
      'References: <br>'+ 
      'https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/using-network-security.html#security-group-rules <br>'
 }
    ],
	img: '',  
  },  
    {
    question: '/Exam Prep 2 - 65p - 26 / You are an AWS Solutions Architect designing an online analytics application that uses Redshift Cluster for its data warehouse. Which service will allow you to monitor all API calls to your Redshift instance and can also provide secured data for auditing and compliance purposes? Seleccione una:',
    answers: [
      { text: 'a. AWS X-Ray ', correct: false,  expli:' ' },
      { text: 'b. CloudWatch', correct: false,  expli:' ' },
	    { text: 'c. CloudTrail for security logs ', correct: true,  expli:'La respuesta correcta es: CloudTrail for security logs   <br>'+  
      'AWS CloudTrail is a service that enables governance, compliance, operational auditing, and risk auditing of your AWS account. With CloudTrail, you can log, continuously monitor, and retain account activity related to actions across your AWS infrastructure.  <br>'+ 
'CloudTrail provides event history of your AWS account activity, including actions taken through the AWS Management Console, AWS SDKs, command line tools, API calls, and other AWS services. This event history simplifies security analysis, resource change tracking, and troubleshooting.  <br>'+ 
'Option 2 is incorrect because although CloudWatch is also a monitoring service, it cannot track the API calls to your AWS resources.  <br>'+ 
'Option 3 is incorrect because AWS X-Ray is not a suitable service to use to track each API call to your AWS resources. It just helps you debug and analyze your microservices applications with request tracing so you can find the root cause of issues and performance.  <br>'+ 
'Option 4 is incorrect because Redshift Spectrum is not a monitoring service but rather a feature of Amazon Redshift that enables you to query and analyze all of your data in Amazon S3 using the open data formats you already use, with no data loading or transformations needed.  <br>'+ 

'Reference:  <br>'+ 
'https://aws.amazon.com/cloudtrail/  <br>' },
      { text: 'd. Redshift Spectrum', correct: false,  expli:' ' }
    ],
	img: '',  
  },  
    {
    question: '/Exam Prep 2 - 65p - 27 / In your AWS VPC, you need to add a new subnet that will allow you to host a total of 20 EC2 instances. Which of the following IPv4 CIDR block can you use for this scenario? Seleccione una:',
    answers: [
      { text: 'a. 172.0.0.0/28 ', correct: false,  expli:' ' },
      { text: 'b. 172.0.0.0/29', correct: false,  expli:' ' },
	    { text: 'c. 172.0.0.0/27 ', correct: true,  expli:' La respuesta correcta es: 172.0.0.0/27  <br>'+  
      'To calculate the total number of IP addresses of a given CIDR Block, you simply need to follow the 2 easy steps below. Let\'s say you have a CIDR block /27: <br>'+ 
'1. Subtract 32 with the mask number : (32 - 27) = 5 <br>'+ 
'2. Raise the number 2 to the power of the answer in Step #1 : 2^ 5 = (2 * 2 * 2 * 2 * 2) = 32 <br>'+ 
'The answer to Step #2 is the total number of IP addresses available in the given CIDR netmask. Don\'t forget that in AWS, the first 4 IP addresses and the last IP address in each subnet CIDR block are not available for you to use, and cannot be assigned to an instance. In addition, you can always associate a netmask of /27 which also has the same number of usable IP addresses (27) to help you with your exam. <br>'+ 
'Option 1 is the correct answer because the CIDR block of 172.0.0.0/27, with a netmask of /27, has an equivalent of 27 usable IP addresses. Take note that a netmask of /27 originally provides you with 32 IP addresses but in AWS, there are 5 IP addresses that are reserved which you cannot use. The first 4 IP addresses and the last IP address in each subnet CIDR block are not available in your VPC which means that you have to always subtract 5 IP addresses, hence 32 - 5 = 27. <br>'+ 
'Option 2 is incorrect as a netmask of /28 only supports 16 IP Addresses. <br>'+ 
'Options 3 and 4 are incorrect as the only allowed block size is between a /28 netmask and /16 netmask. <br>'+ 
'To add a CIDR block to your VPC, the following rules apply: <br>'+ 
'• -The allowed block size is between a /28 netmask and /16 netmask. <br>'+ 
'• -The CIDR block must not overlap with any existing CIDR block that\'s associated with the VPC. <br>'+ 
'• -You cannot increase or decrease the size of an existing CIDR block. <br>'+ 
'• -You have a limit on the number of CIDR blocks you can associate with a VPC and the number of routes you can add to a route table. You cannot associate a CIDR block if this results in you exceeding your limits. <br>'+ 
'• -The CIDR block must not be the same or larger than the CIDR range of a route in any of the VPC route tables. For example, if you have a route with a destination of 10.0.0.0/24 to a virtual private gateway, you cannot associate a CIDR block of the same range or larger. However, you can associate a CIDR block of 10.0.0.0/25 or smaller. <br>'+ 
'• -The first four IP addresses and the last IP address in each subnet CIDR block are not available for you to use, and cannot be assigned to an instance.  <br>'+ 

'Reference: <br>'+ 
'http://docs.aws.amazon.com/AmazonVPC/latest/UserGuide/VPC_Subnets.html <br>'},
      { text: 'd. 172.0.0.0/30', correct: false,  expli:' ' }
    ],
	img: '',  
  },  
    {
    question: '/Exam Prep 2 - 65p - 28 / A Solutions Architect is working for a company which has multiple VPCs in various AWS regions. The Architect is assigned to set up a logging system which will track all of the changes made to their AWS resources in all regions, including the configurations made in IAM, CloudFront, AWS WAF, and Route 53. In order to pass the compliance requirements, the solution must ensure the security, integrity, and durability of the log data. It should also provide an event history of all API calls made in AWS Management Console and AWS CLI.  Which of the following solutions is the best fit for this scenario? Seleccione una:',
    answers: [
      { text: 'a. Set up a new CloudWatch trail in a new S3 bucket using the AWS CLI and also pass both the --is-multi-region-trail and --include-global-service-events parameters then encrypt log files using KMS encryption. Apply Multi Factor Authentication (MFA) Delete on the S3 bucket and ensure that only authorized users can access the logs by configuring the bucket policies.', correct: false,  expli:' ' },
      { text: 'b. Set up a new CloudTrail trail in a new S3 bucket using the AWS CLI and also pass both the --is-multi-region-trail and --include-global-service-events parameters then encrypt log files using KMS encryption. Apply Multi Factor Authentication (MFA) Delete on the S3 bucket and ensure that only authorized users can access the logs by configuring the bucket policies.', correct: true,  expli:' La respuesta correcta es: Set up a new CloudTrail trail in a new S3 bucket using the AWS CLI and also pass both the --is-multi-region-trail and --include-global-service-events parameters then encrypt log files using KMS encryption. Apply Multi Factor Authentication (MFA) Delete on the S3 bucket and ensure that only authorized users can access the logs by configuring the bucket policies.  <br>'+ 
      'An event in CloudTrail is the record of an activity in an AWS account. This activity can be an action taken by a user, role, or service that is monitorable by CloudTrail. CloudTrail events provide a history of both API and non-API account activity made through the AWS Management Console, AWS SDKs, command line tools, and other AWS services. There are two types of events that can be logged in CloudTrail: management events and data events. By default, trails log management events, but not data events. <br>'+ 
      'A trail can be applied to all regions or a single region. As a best practice, create a trail that applies to all regions in the AWS partition in which you are working. This is the default setting when you create a trail in the CloudTrail console. <br>'+ 
      'For most services, events are recorded in the region where the action occurred. For global services such as AWS Identity and Access Management (IAM), AWS STS, Amazon CloudFront, and Route 53, events are delivered to any trail that includes global services, and are logged as occurring in US East (N. Virginia) Region. <br>'+ 
      'In this scenario, the company requires a secure and durable logging solution that will track all of the activities of all AWS resources on all regions. CloudWatch can be used for this case with multi-region trail enabled. However, CloudWatch will only cover the activities of the regional services (EC2, S3, RDS etc.) and not for global services such as IAM, CloudFront, AWS WAF, and Route 53. <br>'+ 
      'Option 1 is correct because it provides security, integrity, and durability to your log data and in addition, it has the -include-global-service-events parameter enabled which will also include activity from global services such as IAM, Route 53, AWS WAF, and CloudFront. <br>'+ 
      'Option 2 is incorrect because you need to use CloudTrail instead of CloudWatch. <br>'+ 
      'Option 3 is incorrect because you need to use CloudTrail instead of CloudWatch. In addition, the --include-global-service-events parameter is also missing in this setup. <br>'+ 
      'Option 4 is incorrect because the --is-multi-region-trail is not enough as you also need to add the --include-global-service-events parameter. Plus, you cannot enable the Global Service Events using the CloudTrail console but by using AWS CLI. <br>'+ 

      'References: <br>'+ 
      'https://docs.aws.amazon.com/awscloudtrail/latest/userguide/cloudtrail-concepts.html#cloudtrail-concepts-global-service-events <br>'+ 
      'http://docs.aws.amazon.com/IAM/latest/UserGuide/cloudtrail-integration.html <br>'+ 
      'https://docs.aws.amazon.com/awscloudtrail/latest/userguide/cloudtrail-create-and-update-a-trail-by-using-the-aws-cli.html <br>' },
	    { text: 'c. Set up a new CloudTrail trail in a new S3 bucket using the AWS CLI and also pass the --is-multi-region-trail parameter then encrypt log files using KMS encryption. Apply Multi Factor Authentication (MFA) Delete on the S3 bucket and ensure that only authorized users can access the logs by configuring the bucket policies.', correct: false,  expli:' ' },
      { text: 'd. Set up a new CloudWatch trail in a new S3 bucket using the CloudTrail console and also pass the --is-multi-region-trail parameter then encrypt log files using KMS encryption. Apply Multi Factor Authentication (MFA) Delete on the S3 bucket and ensure that only authorized users can access the logs by configuring the bucket policies.', correct: false,  expli:' ' }
    ],
	img: '',  
  },  
    {
    question: '/Exam Prep 2 - 65p - 29 / An online cryptocurrency exchange platform is hosted in AWS which uses ECS Cluster and RDS in Multi-AZ Deployments configuration. The application is heavily using the RDS instance to process complex read and write database operations. To maintain the reliability, availability, and performance of your systems, you have to closely monitor how the different processes or threads on a DB instance use the CPU, including the percentage of the CPU bandwidth and total memory consumed by each process. Which of the following is the most suitable solution to properly monitor your database? Seleccione una:',
    answers: [
      { text: 'a. Create a script that collects and publishes custom metrics to CloudWatch, which tracks the real-time CPU Utilization of the RDS instance, and then set up a custom CloudWatch dashboard to view the metrics. ', correct: false,  expli:' ' },
      { text: 'b. Check the CPU% and MEM% metrics which are readily available in the Amazon RDS console that shows the percentage of the CPU bandwidth and total memory consumed by each database process of your RDS instance.', correct: false,  expli:' ' },
	    { text: 'c. Use Amazon CloudWatch to monitor the CPU Utilization of your database. ', correct: false,  expli:' ' },
      { text: 'd. Enable Enhanced Monitoring in RDS. ', correct: true,  expli:'La respuesta correcta es: Enable Enhanced Monitoring in RDS.  <br>'+ 
      'Amazon RDS provides metrics in real time for the operating system (OS) that your DB instance runs on. You can view the metrics for your DB instance using the console, or consume the Enhanced Monitoring JSON output from CloudWatch Logs in a monitoring system of your choice. By default, Enhanced Monitoring metrics are stored in the CloudWatch Logs for 30 days. To modify the amount of time the metrics are stored in the CloudWatch Logs, change the retention for the RDSOSMetrics log group in the CloudWatch console. <br>'+ 
'Take note that there are certain differences between CloudWatch and Enhanced Monitoring Metrics. CloudWatch gathers metrics about CPU utilization from the hypervisor for a DB instance, and Enhanced Monitoring gathers its metrics from an agent on the instance. As a result, you might find differences between the measurements, because the hypervisor layer performs a small amount of work. Hence, Option 3 is the correct answer in this specific scenario. <br>'+ 
'The differences can be greater if your DB instances use smaller instance classes, because then there are likely more virtual machines (VMs) that are managed by the hypervisor layer on a single physical instance. Enhanced Monitoring metrics are useful when you want to see how different processes or threads on a DB instance use the CPU. <br>'+ 
'Option 1 is incorrect because although you can use Amazon CloudWatch to monitor the CPU Utilization of your database instance, it does not provide the percentage of the CPU bandwidth and total memory consumed by each database process in your RDS instance. Take note that CloudWatch gathers metrics about CPU utilization from the hypervisor for a DB instance while RDS Enhanced Monitoring gathers its metrics from an agent on the instance. <br>'+ 
'Option 2 is incorrect because although you can use Amazon CloudWatch Logs and CloudWatch dashboard to monitor the CPU Utilization of the database instance, using CloudWatch alone is still not enough to get the specific percentage of the CPU bandwidth and total memory consumed by each database processes. The data provided by CloudWatch is not as detailed as compared with the Enhanced Monitoring feature in RDS. Take note as well that you do not have direct access to the instances/servers of your RDS database instance, unlike with your EC2 instances where you can install a CloudWatch agent or a custom script to get CPU and memory utilization of your instance. <br>'+ 
'Option 4 is incorrect because the CPU% and MEM% metrics are not readily available in the Amazon RDS console, which is contrary to what is being stated in this option. <br>'+ 
'References: <br>'+ 
'https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_Monitoring.OS.html#USER_Monitoring.OS.CloudWatchLogs <br>'+ 
'https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/MonitoringOverview.html#monitoring-cloudwatch <br>' }
    ],
	img: '',  
  },  
    {
    question: '/Exam Prep 2 - 65p - 30 / You have launched a new enterprise application with a web server and a database. You are using a large EC2 Instance with one 500 GB EBS volume to host a relational database. Upon checking the performance, it shows that write throughput to the database needs to be improved. Which of the following is the most suitable configuration to help you achieve this requirement? (Choose 2) Seleccione una o más de una: ',
    answers: [
      { text: 'a. Increase the size of the EC2 Instance ', correct: true,  expli:'una respuesta correcta es: Increase the size of the EC2 Instance ' },
      { text: 'b. Set up a standard RAID 0 configuration with two EBS Volumes ', correct: true,  expli:' una respuesta correcta es: Set up a standard RAID 0 configuration with two EBS Volumes <br>'+  
      'The goal here is to increase the write performance of the database hosted in an EC2 instance. You can achieve this by either setting up a standard RAID 0 configuration or simply by increasing the size of the EC2 instance. <br>'+ 
'Some EC2 instance types can drive more I/O throughput than what you can provision for a single EBS volume. You can join multiple gp2, io1, st1, or sc1 volumes together in a RAID 0 configuration to use the available bandwidth for these instances. <br>'+ 
'With Amazon EBS, you can use any of the standard RAID configurations that you can use with a traditional bare metal server, as long as that particular RAID configuration is supported by the operating system for your instance. This is because all RAID is accomplished at the software level. For greater I/O performance than you can achieve with a single volume, RAID 0 can stripe multiple volumes together; for on-instance redundancy, RAID 1 can mirror two volumes together. <br>'+ 
'Take note that HVM AMIs are required to take advantage of enhanced networking and GPU processing. In order to pass through instructions to specialized network and GPU devices, the OS needs to be able to have access to the native hardware platform which the HVM virtualization provides. <br>'+ 
'Option 2 is incorrect because although the Enhanced Networking feature can provide higher I/O performance and lower CPU utilization to your EC2 instance, you have to use an HVM AMI instead of PV AMI. <br>'+ 
'Option 3 is incorrect because the main use case for RAID 1 is to provide mirroring, redundancy, and fault-tolerance. RAID 0 is a more suitable option for providing faster read and write operations, compared with RAID 1. <br>'+ 
'Option 4 is incorrect because the placement groups feature is primarily used for inter-instance communication. <br>'+ 
'References: <br>'+ 
'https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/raid-config.html <br>'+ 
'https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/EBSPerformance.html <br>'+ 
'https://aws.amazon.com/ec2/features/#enhanced-networking <br>' },
	    { text: 'c. Re-launch the instance with a Paravirtual (PV) AMI and enable Enhanced Networking ', correct: false,  expli:' ' },
      { text: 'd. Set up the EC2 instance in a placement group', correct: false,  expli:' ' },
      { text: 'e. Use a standard RAID 1 configuration with two EBS Volumes', correct: false,  expli:' ' }
    ],
	img: '',  
  },  
    {
    question: '/Exam Prep 2 - 65p - 31 / You are working as a Solutions Architect for a government project in which they are building an online portal to allow people to pay their taxes and claim their tax refunds online. Due to the confidentiality of data, the security policy requires that the application hosted in EC2 encrypts the data first before writing it to the disk for storage. In this scenario, which service would you use to meet this requirement? Seleccione una:',
    answers: [
      { text: 'a. Elastic File System (EFS)', correct: false,  expli:' ' },
      { text: 'b. Security Token Service', correct: false,  expli:' ' },
	    { text: 'c. EBS encryption', correct: false,  expli:' ' },
      { text: 'd. AWS KMS API ', correct: true,  expli:' La respuesta correcta es: AWS KMS API  <br>'+ 
      'AWS Key Management Service (AWS KMS) is a managed service that makes it easy for you to create and control the encryption keys used to encrypt your data. The master keys that you create in AWS KMS are protected by FIPS 140-2 validated cryptographic modules. AWS KMS is integrated with most other AWS services that encrypt your data with encryption keys that you manage. AWS KMS is also integrated with AWS CloudTrail to provide encryption key usage logs to help meet your auditing, regulatory and compliance needs. <br>'+ 
'The scenario mentions that you have to encrypt the data before writing it to disk for storage. What this means is that you will have to temporarily store the data in memory and not persist it on the disk, then encrypt it on the fly before finally storing it. The end result would be an encrypted data in your disk EBS Volume, and the EBS Encryption would be the secondary layer of protection/encryption for your sensitive data. <br>'+ 
'You can configure your application to use the KMS API to encrypt all data before saving it to disk. Hence, Option 4 is the correct answer. <br>'+ 
'Option 1 is incorrect because AWS Security Token Service (STS) is a web service that enables you to request temporary, limited-privilege credentials for AWS Identity and Access Management (IAM) users or for users that you authenticate (federated users). It is not used for encrypting data unlike KMS. <br>'+ 
'Option 2 is incorrect because although EBS encryption provides additional security for the EBS volumes, the application could not use this service to encrypt or decrypt each individual data that it writes on the disk. It is better to use KMS API instead to automatically encrypt the data before saving it to disk for maximum security, rather than after. <br>'+ 
'Option 3 is incorrect because EFS is a storage service and does not provide encryption services unlike KMS API. <br>'+ 
'References: <br>'+ 
'https://docs.aws.amazon.com/kms/latest/developerguide/programming-top.html <br>'+ 
'https://docs.aws.amazon.com/kms/latest/developerguide/concepts.html#data-keys <br>' }
    ],
	img: '',  
  },  
    {
    question: '/Exam Prep 2 - 65p - 32 / You have identified a series of DDoS attacks while monitoring your VPC. As the Solutions Architect, you are responsible in fortifying your current cloud infrastructure to protect the data of your clients. Which of the following is the most suitable solution to mitigate these kinds of attacks? Seleccione una:',
    answers: [
      { text: 'a. Set up a web application firewall using AWS WAF to filter, monitor, and block HTTP traffic.', correct: false,  expli:' ' },
      { text: 'b. A combination of Security Groups and Network Access Control Lists to only allow authorized traffic to access your VPC. ', correct: false,  expli:' ' },
	    { text: 'c. Use AWS Shield to detect and mitigate DDoS attacks. ', correct: true,  expli:'La respuesta correcta es: Use AWS Shield to detect and mitigate DDoS attacks.  <br>'+ 
      'For higher levels of protection against attacks targeting your applications running on Amazon Elastic Compute Cloud (EC2), Elastic Load Balancing(ELB), Amazon CloudFront, and Amazon Route 53 resources, you can subscribe to AWS Shield Advanced. In addition to the network and transport layer protections that come with Standard, AWS Shield Advanced provides additional detection and mitigation against large and sophisticated DDoS attacks, near real-time visibility into attacks, and integration with AWS WAF, a web application firewall. <br>'+ 
'AWS Shield Advanced also gives you 24x7 access to the AWS DDoS Response Team (DRT) and protection against DDoS related spikes in your Amazon Elastic Compute Cloud (EC2), Elastic Load Balancing(ELB), Amazon CloudFront, and Amazon Route 53 charges. <br>'+ 
'Option 2 is incorrect because the AWS Firewall Manager is mainly used to simplify your AWS WAF administration and maintenance tasks across multiple accounts and resources. It does not protect your VPC against DDoS attacks. <br>'+ 
'Option 3 is incorrect because even though AWS WAF can help you block common attack patterns to your VPC such as SQL injection or cross-site scripting, this is still not enough to withstand DDoS attacks. It is better to use AWS Shield in this scenario. <br>'+ 
'Option 4 is incorrect because although using a combination of Security Groups and NACLs are valid to provide security to your VPC, this is not enough to mitigate a DDoS attack. You should use AWS Shield for better security protection. <br>'+ 
'References: <br>'+ 
'https://d1.awsstatic.com/whitepapers/Security/DDoS_White_Paper.pdf <br>'+ 
'https://aws.amazon.com/shield/ <br>' },
      { text: 'd. Using the AWS Firewall Manager, set up a security layer that will prevent SYN floods, UDP reflection attacks and other DDoS attacks.', correct: false,  expli:' ' }
    ],
	img: '',  
  },  
    {
    question: '/Exam Prep 2 - 65p - 33 / In a government agency that you are working for, you have been assigned to put confidential tax documents on AWS cloud. However, there is a concern from a security perspective on what can be put on AWS. What are the features in AWS that can ensure data security for your confidential documents? (Choose 2)  Seleccione una o más de una:',
    answers: [
      { text: 'a. EBS On-Premises Data Encryption', correct: false,  expli:' ' },
      { text: 'b. S3 Client-Side Encryption ', correct: true,  expli:'una respuesta correcta es :  S3 Client-Side Encryption' },
	    { text: 'c. S3 Server-Side Encryption', correct: true,  expli:'una respuesta correcta es : S3 Server-Side Encryption  <br>'+ 
      'You can secure the privacy of your data in AWS, both at rest and in-transit, through encryption. If your data is stored in EBS Volumes, you can enable EBS Encryption and if it is stored on Amazon S3, you can enable client-side and server-side encryption. <br>'+ 
'Option 4 is incorrect as public data sets are designed to be publicly accessible. <br>'+ 
'Options 1 and 5 are incorrect as there is no such thing as On-Premises Data Encryption for S3 and EBS as these services are in the AWS cloud and not on your on-premises network. <br>'+ 
'References: <br>'+ 
'https://docs.aws.amazon.com/AmazonS3/latest/dev/UsingEncryption.html <br>'+ 
'https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/EBSEncryption.html <br>'+ 
'https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/using-public-data-sets.html <br>'},
      { text: 'd. S3 On-Premises Data Encryption  ', correct: false,  expli:' ' },
      { text: 'e. Public Data Set Volume Encryption', correct: false,  expli:' ' }
    ],
	img: '',  
  },  
    {
    question: '/Exam Prep 2 - 65p - 34 / In the VPC that you are managing, it has one EC2 instance that has its data stored in an instance store. The instance was shut down by a 2nd level support staff over the weekend to save costs. When you arrived in the office the next Monday, you noticed that all data are lost and are no longer available on the EC2 instance. What might be the cause of this? Seleccione una:',
    answers: [
      { text: 'a. The EC2 instance has been hacked.', correct: false,  expli:' ' },
      { text: 'b. The EC2 instance was using EBS-backed root volumes hence, the data will be erased when the instance is terminated.', correct: false,  expli:' ' },
	    { text: 'c. AWS automatically erased the data due to a virus found on the EC2 instance.', correct: false,  expli:' ' },
      { text: 'd. The EC2 instance was using an instance store hence, data will be erased when the instance is stopped or terminated. . ', correct: true,  expli:'La respuesta correcta es: The EC2 instance was using an instance store hence, data will be erased when the instance is stopped or terminated  <br>'+ 
      'Since you are using an EC2 instance with an Instance store, its data is ephemeral which means that it will be erased once the instance is stopped or terminated. You may argue that the instance was only shut down but remember that the Operating system shutdown commands always terminate an instance store-backed instance. That is why the right answer is Option 1. <br>'+ 
'The data in an instance store persists only during the lifetime of its associated instance. If an instance reboots (intentionally or unintentionally), data in the instance store persists. However, data in the instance store is lost under any of the following circumstances: <br>'+ 
'- The underlying disk drive fails <br>'+ 
'- The instance stops <br>'+ 
'- The instance terminates <br>'+ 
'Therefore, do not rely on instance store for valuable, long-term data. Instead, use more durable data storage, such as Amazon S3, Amazon EBS, or Amazon EFS. When you stop or terminate an instance, every block of storage in the instance store is reset. Hence, your data cannot be accessed through the instance store of another instance. <br>'+ 
'If you create an AMI from an instance, the data on its instance store volumes aren\'t preserved and aren\'t present on the instance store volumes of the instances that you launch from the AMI. You can specify instance store volumes for an instance only when you launch it. You can\'t detach an instance store volume from one instance and attach it to a different instance. <br>'+ 
'Option 2 is incorrect because the data will persist if you use an EBS-backed root volume. <br>'+ 
'Option 3 is incorrect because based on the AWS Shared Responsibility model, AWS will only manage the underlying resources that the services are using and not your actual data. Hence, it is highly unlikely that AWS will automatically erase your data due to a virus. <br>'+ 
'Option 4 is incorrect because although it is remotely possible that someone got hold of your AWS security credentials and deletes your data, this reason is still far fetched and quite unlikely to happen. Based on the given scenario, the stopping of the instance is one key attribute which we can link to its use of Instance Store volumes. <br>'+ 
'References: <br>'+ 
'https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ec2-instance-lifecycle.html <br>'+ 
'https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/Storage.html <br>' }
    ],
	img: '',  
  },  
    {
    question: '/Exam Prep 2 - 65p - 35 / You are working as a Solutions Architect for a technology company which is in the process of migrating their applications to AWS. One of their systems requires a database that can scale globally and can handle frequent schema changes. It should also provide low-latency response to high-traffic queries. Which is the most suitable database solution to use to achieve this requirement? Seleccione una:',
    answers: [
      { text: 'a. Redshift', correct: false,  expli:' ' },
      { text: 'b. An Amazon Aurora database with Read Replicas', correct: false,  expli:' ' },
	    { text: 'c. An Amazon RDS instance in Multi-AZ Deployments configuration', correct: false,  expli:' ' },
      { text: 'd. Amazon DynamoDB ', correct: true,  expli:'La respuesta correcta es: Amazon DynamoDB  <br>'+ 
      'Before we proceed in answering this question, we must first be clear with the actual definition of a "schema". Basically, the english definition of a schema is: a representation of a plan or theory in the form of an outline or model. <br>'+ 
'Just think of a schema as the "structure" or a "model" of your data in your database. Since the scenario requires that the schema, or the structure of your data, changes frequently, then you have to pick a database which provides a non-rigid and flexible way of adding or removing new types of data. This is a classic example of choosing between a relational database and non-relational (NoSQL) database. <br>'+ 

'A relational database is known for having a rigid schema, with a lot of constraints and limits as to which (and what type of ) data can be inserted or not. It is primarily used for scenarios where you have to support complex queries which fetch data across a number of tables. It is best for scenarios where you have complex table relationships but for use cases where you need to have a flexible schema, this is not a suitable database to use. <br>'+ 
'For NoSQL, it is not as rigid as a relational database because you can easily add or remove rows or elements in your table/collection entry. It also has a more flexible schema because it can store complex hierarchical data within a single item which, unlike a relational database, does not entail changing multiple related tables. Hence, the best answer to be used here is a NoSQL database, like DynamoDB. When your business requires a low-latency response to high-traffic queries, taking advantage of a NoSQL system generally makes technical and economic sense. <br>'+ 
'Amazon DynamoDB helps solve the problems that limit the relational system scalability by avoiding them. In DynamoDB, you design your schema specifically to make the most common and important queries as fast and as inexpensive as possible. Your data structures are tailored to the specific requirements of your business use cases. <br>'+ 
'Remember that a relational database system does not scale well for the following reasons: <br>'+ 
'-It normalizes data and stores it on multiple tables that require multiple queries to write to disk. <br>'+ 
'-It generally incurs the performance costs of an ACID-compliant transaction system. <br>'+ 
'-It uses expensive joins to reassemble required views of query results. <br>'+ 

'For DynamoDB, it scales well due to these reasons: <br>'+ 
'-Its schema flexibility lets DynamoDB store complex hierarchical data within a single item. DynamoDB is not a totally schemaless database since the very definition of a schema is just the model or structure of your data. <br>'+ 
'-Composite key design lets it store related items close together on the same table. <br>'+ 

'Options 1 and 3 are incorrect because both of them are a type of relational database. <br>'+ 
'Option 4 is incorrect because Redshift is primarily used for OLAP systems. <br>'+ 

'References: <br>'+ 
'https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/bp-general-nosql-design.html <br>'+ 
'https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/bp-relational-modeling.html <br>'+ 
'https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/SQLtoNoSQL.html <br>' }
    ],
	img: '',  
  },  
    {
    question: '/Exam Prep 2 - 65p - 36 / A company runs a multi-tier web application that hosts news content. The application runs on Amazon EC2 instances behind an Application Load Balancer. The instances run in an EC2 Auto Scaling group across multiple Availability Zones and use an Amazon Aurora database. A solutions architect needs to make the application more resilient to periodic increases in request rates. Which architecture should the solutions architect implement? (Choose two.) Seleccione una o más de una: ',
    answers: [
      { text: 'a. Add AWS Global Accelerator. ', correct: false,  expli:' ' },
      { text: 'b. Add an Amazon CloudFront distribution in front of the Application Load Balancer.', correct: true,  expli:'una respuesta correcta es :Add an Amazon CloudFront distribution in front of the Application Load Balancer. ' },
	    { text: 'c. Add Aurora Replica. ', correct: true,  expli:'una respuesta correcta es : Add Aurora Replica.  <br>'+ 
      'AWS Global Accelerator - Acceleration for latency-sensitive applications Many applications, especially in areas such as gaming, media, mobile apps, and financials, require very low latency for a great user experience. To improve the user experience, Global Accelerator directs user traffic to the application endpoint that is nearest to the client, which reduces internet latency and jitter. Global Accelerator routes traffic to the closest edge location by using Anycast, and then routes it to the closest regional endpoint over the AWS global network. Global Accelerator quickly reacts to changes in network performance to improve your users\'s application performance. <br>'+ 
      'Amazon CloudFront - Amazon CloudFront is a fast content delivery network (CDN) service that securely delivers data, videos, applications, and APIs to customers globally with low latency, high transfer speeds, all within a developerfriendly environment. <br>'+ 
      'Reference: https://docs.aws.amazon.com/global-accelerator/latest/dg/introduction-benefits-of-migrating.html <br>' },
      { text: 'd. Add AWS Direct Connect.', correct: false,  expli:' ' },
      { text: 'e. Add AWS Shield', correct: false,  expli:' ' }
    ],
	img: '',  
  },  
    {
    question: '/Exam Prep 2 - 65p - 37 / A solutions architect is optimizing a website for an upcoming musical event. Videos of the performances will be streamed in real time and then will be available on demand. The event is expected to attract a global online audience. Which service will improve the performance of both the real-time and on-demand steaming? Seleccione una:',
    answers: [
      { text: 'a. Amazon Route S3', correct: false,  expli:' ' },
      { text: 'b. Amazon CloudFront', correct: true,  expli:' La respuesta correcta es: Amazon CloudFront. <br> Reference: https://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/on-demand-streaming-video.html' },
	    { text: 'c. Amazon S3 Transfer Acceleration ', correct: false,  expli:' ' },
      { text: 'd. AWS Global Accelerator', correct: false,  expli:' ' }
    ],
	img: '',  
  },  
    {
    question: '/Exam Prep 2 - 65p - 38 / There are a lot of outages in the Availability Zone of your RDS database instance to the point that you have lost access to the database. What could you do to prevent losing access to your database in case that this event happens again? Seleccione una: ',
    answers: [
      { text: 'a. Enabled Multi-AZ failover ', correct: true,  expli:' La respuesta correcta es: Enabled Multi-AZ failover <br>'+  
      'Amazon RDS Multi-AZ deployments provide enhanced availability and durability for Database (DB) Instances, making them a natural fit for production database workloads. For this scenario, option 2 is correct. When you provision a Multi-AZ DB Instance, Amazon RDS automatically creates a primary DB Instance and synchronously replicates the data to a standby instance in a different Availability Zone (AZ). Each AZ runs on its own physically distinct, independent infrastructure, and is engineered to be highly reliable.  <br>'+ 
      'In case of an infrastructure failure, Amazon RDS performs an automatic failover to the standby (or to a read replica in the case of Amazon Aurora), so that you can resume database operations as soon as the failover is complete.  <br>'+ 
      'In option 1, creating a snapshot allows you to have a backup of your database, but it does not provide immediate availability in case of AZ failure. So this is incorrect.  <br>'+ 
      'For option 3, increasing database instance size is not a solution for this problem. Doing this action addresses the need to upgrade your compute capacity but does not solve the requirement of providing access to your database even in the event of a loss of one of the Availability Zones.  <br>'+ 
      'Option 4 is incorrect because read replicas provide enhanced performance for read-heavy database workloads. Although you can promote a read replica, its asynchronous replication might not provide you the latest version of your database.  <br>'+ 
      'Reference:  <br>'+ 
      'https://aws.amazon.com/rds/details/multi-az/  <br>'},
      { text: 'b. Increase the database instance size ', correct: false,  expli:' ' },
	    { text: 'c. Create a read replica', correct: false,  expli:' ' },
      { text: 'd. Make a snapshot of the database', correct: false,  expli:' ' }
    ],
	img: './aws/question38_exam2_65p.png',  
  },  
    {
    question: '/Exam Prep 2 - 65p - 39 / The company that you are working for has a highly available architecture consisting of an elastic load balancer and several EC2 instances configured with auto-scaling in three Availability Zones. You want to monitor your EC2 instances based on a particular metric, which is not readily available in CloudWatch. Which of the following is a custom metric in CloudWatch which you have to manually set up? Seleccione una:',
    answers: [
      { text: 'a. CPU Utilization of an EC2 instance', correct: false,  expli:' ' },
      { text: 'b. Network packets out of an EC2 instance', correct: false,  expli:' ' },
	    { text: 'c. Disk Reads activity of an EC2 instance', correct: false,  expli:' ' },
      { text: 'd. Memory Utilization of an EC2 instance ', correct: true,  expli:' La respuesta correcta es: Memory Utilization of an EC2 instance   <br>'+ 
      'CloudWatch has available Amazon EC2 Metrics for you to use for monitoring. CPU Utilization identifies the processing power required to run an application upon a selected instance. Network Utilization identifies the volume of incoming and outgoing network traffic to a single instance. Disk Reads metric is used to determine the volume of the data the application reads from the hard disk of the instance. This can be used to determine the speed of the application. However, there are certain metrics that are not readily available in CloudWatch such as memory utilization, disk space utilization, and many others which can be collected by setting up a custom metric.  <br>'+ 
      'You need to prepare a custom metric using CloudWatch Monitoring Scripts which is written in Perl. You can also install CloudWatch Agent to collect more system-level metrics from Amazon EC2 instances. Here\'s the list of custom metrics that you can set up:  <br>'+ 
      '- Memory utilization  <br>'+ 
      '- Disk swap utilization  <br>'+ 
      '- Disk space utilization  <br>'+ 
      '- Page file utilization  <br>'+ 
      '- Log collection  <br>'+ 
      'References:   <br>'+ 
      'https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/monitoring_ec2.html  <br>'+ 
      'https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/mon-scripts.html#using_put_script  <br>' }
    ],
	img: '',  
  },  
    {
    question: '/Exam Prep 2 - 65p - 40 / You are leading a software development team which uses serverless computing with AWS Lambda to build and run applications without having to set up or manage servers. You have a Lambda function that connects to a MongoDB Atlas, which is a popular Database as a Service (DBaaS) platform and also uses a third party API to fetch certain data for your application. You instructed one of your junior developers to create the environment variables for the MongoDB database hostname, username, and password as well as the API credentials that will be used by the Lambda function for DEV, SIT, UAT and PROD environments. Considering that the Lambda function is storing sensitive database and API credentials, how can you secure these information to prevent other developers in your team, or anyone, from seeing these credentials in plain text? Select the best option that provides the maximum security. Seleccione una: ',
    answers: [
      { text: 'a. Enable SSL encryption that leverages on AWS CloudHSM to store and encrypt the sensitive information.', correct: false,  expli:' ' },
      { text: 'b. There is no need to do anything because, by default, AWS Lambda already encrypts the environment variables using the AWS Key Management Service.', correct: false,  expli:' ' },
	    { text: 'c. Create a new KMS key and use it to enable encryption helpers that leverage on AWS Key Management Service to store and encrypt the sensitive information. ', correct: true,  expli:' La respuesta correcta es: Create a new KMS key and use it to enable encryption helpers that leverage on AWS Key Management Service to store and encrypt the sensitive information. <br>'+  
      'When you create or update Lambda functions that use environment variables, AWS Lambda encrypts them using the AWS Key Management Service. When your Lambda function is invoked, those values are decrypted and made available to the Lambda code. <br>'+ 
      'The first time you create or update Lambda functions that use environment variables in a region, a default service key is created for you automatically within AWS KMS. This key is used to encrypt environment variables. However, if you wish to use encryption helpers and use KMS to encrypt environment variables after your Lambda function is created, you must create your own AWS KMS key and choose it instead of the default key. The default key will give errors when chosen. Creating your own key gives you more flexibility, including the ability to create, rotate, disable, and define access controls, and to audit the encryption keys used to protect your data. <br>'+ 
      'Option 1 is incorrect because although Lambda encrypts the environment variables in your function by default, the sensitive information would still be visible to other users who have access to the Lambda console. This is because Lambda uses a default KMS key to encrypt the variables, which is usually accessible by other users. The best option in this scenario is to use encryption helpers to secure your environment variables. <br>'+ 
      'Option 2 is also incorrect since enabling SSL would encrypt data only when in-transit. Your other teams would still be able to view the plaintext at-rest. Use AWS KMS instead. <br>'+ 
      'Option 3 is incorrect since, as mentioned, Lambda does provide encryption functionality of environment variables. <br>'+ 
      'References: <br>'+ 
      'https://docs.aws.amazon.com/lambda/latest/dg/env_variables.html#env_encrypt <br>'+ 
      'https://docs.aws.amazon.com/lambda/latest/dg/tutorial-env_console.html <br>'},
      { text: 'd. AWS Lambda does not provide encryption for the environment variables. Deploy your code to an EC2 instance instead.', correct: false,  expli:' ' }
    ],
	img: '',  
  },  
    {
    question: '/Exam Prep 2 - 65p - 41 / A telecommunications company is planning to give AWS Console access to developers. Company policy mandates the use of identity federation and role-based access control. Currently, the roles are already assigned using groups in the corporate Active Directory. In this scenario, what combination of the following services can provide developers access to the AWS console? (Choose 2) Seleccione una o más de una: ',
    answers: [
      { text: 'a. IAM Groups', correct: false,  expli:' ' },
      { text: 'b. AWS Directory Service Simple AD ', correct: false,  expli:' ' },
	    { text: 'c. Lambda', correct: false,  expli:' ' },
      { text: 'd. AWS Directory Service AD Connector', correct: true,  expli:' una respuesta correcta es : AWS Directory Service AD Connector  <br>'+ 
      'Considering that the company is using a corporate Active Directory, it is best to use AWS Directory Service AD Connector for easier integration. In addition, since the roles are already assigned using groups in the corporate Active Directory, it would be better to also use IAM Roles. Take note that you can assign an IAM Role to the users or groups from your Active Directory once it is integrated with your VPC via the AWS Directory Service AD Connector. <br>'+ 
      'AWS Directory Service provides multiple ways to use Amazon Cloud Directory and Microsoft Active Directory (AD) with other AWS services. Directories store information about users, groups, and devices, and administrators use them to manage access to information and resources. AWS Directory Service provides multiple directory choices for customers who want to use existing Microsoft AD or Lightweight Directory Access Protocol (LDAP)–aware applications in the cloud. It also offers those same choices to developers who need a directory to manage users, groups, devices, and access. <br>'+ 
      'Option 2 is incorrect because the AWS Directory Service Simple AD just provides a subset of the features offered by AWS Managed Microsoft AD, including the ability to manage user accounts and group memberships, create and apply group policies, securely connect to Amazon EC2 instances, and provide Kerberos-based single sign-on (SSO). In this scenario, the more suitable component to use is the AD Connector since it is a directory gateway with which you can redirect directory requests to your on-premises Microsoft Active Directory. <br>'+ 
      'Option 3 is incorrect because an IAM group is just a collection of IAM users. Groups let you specify permissions for multiple users, which can make it easier to manage the permissions for those users. In this scenario, the more suitable one to use is IAM Roles in order for permissions to create AWS Directory Service resources. <br>'+ 
      'Option 5 is incorrect because Lambda is primarily used for serverless computing. <br>'+ 
      'Reference: <br>'+ 
      'https://aws.amazon.com/blogs/security/how-to-connect-your-on-premises-active-directory-to-aws-using-ad-connector/ <br>'},
      { text: 'e. IAM Roles ', correct: false,  expli:' una respuesta correcta es : IAM Roles' }
    ],
	img: '',  
  },  
    {
    question: '/Exam Prep 2 - 65p - 42 / You have a new joiner in your organization. You have provisioned an IAM user for the new employee in AWS however, the user is not able to perform any actions. What could be the reason for this? Seleccione una: ',
    answers: [
      { text: 'a. IAM users are created by default with partial permissions', correct: false,  expli:' ' },
      { text: 'b. You need to wait for 24 hours for the new IAM user to have access.', correct: false,  expli:' ' },
	    { text: 'c. IAM users are created by default with full permissions', correct: false,  expli:' ' },
      { text: 'd. IAM users are created by default with no permissions ', correct: true,  expli:' La respuesta correcta es: IAM users are created by default with no permissions   <br>'+ 
      'The reason for this issue is that IAM users are created with no permissions by default. That means that when you created the new IAM user, you might not provisioned any permissions to the user. Hence, option 3 is correct and conversely, options 1 and 2 are wrong.  <br>'+ 
      'Option 4 is incorrect because provisions are applied immediately, and not after 24 hours.  <br>'+ 
      'The IAM user might need to make API calls or use the AWS CLI or the Tools for Windows PowerShell. In that case, create an access key (an access key ID and a secret access key) for that user. This is called Programmatic access.  <br>'+ 
      'If the user needs to access AWS resources from the AWS Management Console, create a password and provide it to the user.  <br>'+ 
      'Reference:  <br>'+ 
      'https://aws.amazon.com/iam/details/manage-users/  <br>'}
    ],
	img: '',  
  },  
    {
    question: '/Exam Prep 2 - 65p - 43 / There was an incident in your production environment where the user data stored in the S3 bucket has been accidentally deleted by one of the Junior DevOps Engineers. The issue was escalated to your manager and after a few days, you were instructed to improve the security and protection of your AWS resources. What combination of the following options will protect the S3 objects in your bucket from both accidental deletion and overwriting? (Choose 2) Seleccione una o más de una: ',
    answers: [
      { text: 'a. Disallow S3 Delete using an IAM bucket policy ', correct: false,  expli:' ' },
      { text: 'b. Enable Multi-Factor Authentication Delete', correct: true,  expli:' una respuesta correcta es: Enable Multi-Factor Authentication Delete' },
	    { text: 'c. Enable Versioning ', correct: true,  expli:' una respuesta correcta es: Enable Versioning  <br>'+ 
      'By using Versioning and enabling MFA (Multi-Factor Authentication) Delete, you can secure and recover your S3 objects from accidental deletion or overwrite. <br>'+ 
      'Versioning is a means of keeping multiple variants of an object in the same bucket. Versioning-enabled buckets enable you to recover objects from accidental deletion or overwrite. You can use versioning to preserve, retrieve, and restore every version of every object stored in your Amazon S3 bucket. With versioning, you can easily recover from both unintended user actions and application failures. <br>'+ 
      'You can also optionally add another layer of security by configuring a bucket to enable MFA (Multi-Factor Authentication) Delete, which requires additional authentication for either of the following operations: <br>'+ 
      '- Change the versioning state of your bucket <br>'+ 
      '- Permanently delete an object version <br>'+ 

      'MFA Delete requires two forms of authentication together: <br>'+ 
      '- Your security credentials <br>'+ 
      '- The concatenation of a valid serial number, a space, and the six-digit code displayed on an approved authentication device <br>'+ 

      'Option 2 is incorrect since a pre-signed URL gives access to the object identified in the URL. Pre-signed URLs are useful when customers perform an object upload to your S3 bucket, but does not help in preventing accidental deletes. <br>'+ 
      'Option 3 is incorrect since you still want users to be able to delete objects in the bucket, and you just want to prevent accidental deletions. Disallowing S3 Delete using an IAM bucket policy will restrict all delete operations to your bucket. <br>'+ 
      'Option 4 is incorrect since S3 intelligent tiering does not help in this situation. <br>'+ 

      'Reference: <br>'+ 
      'https://docs.aws.amazon.com/AmazonS3/latest/dev/Versioning.html <br>'},
      { text: 'd. Provide access to S3 data strictly through pre-signed URL only', correct: false,  expli:' ' },
      { text: 'e. Enable Amazon S3 Intelligent-Tiering', correct: false,  expli:' ' }
    ],
	img: '',  
  },  
    {
    question: '/Exam Prep 2 - 65p - 44 / There are many clients complaining that the online trading application of an investment bank is always down. Your manager instructed you to re-design the architecture of the application to prevent the unnecessary service interruptions. To ensure high availability, you set up the application to use an ELB to distribute the incoming requests across an auto-scaled group of EC2 instances in two single Availability Zones. In this scenario, what happens when an EC2 instance behind an ELB fails a health check? Seleccione una:',
    answers: [
      { text: 'a. The EC2 instance is replaced automatically by the ELB.', correct: false,  expli:' ' },
      { text: 'b. The EC2 instance gets quarantined by the ELB for root cause analysis.', correct: false,  expli:' ' },
	    { text: 'c. The ELB stops sending traffic to the EC2 instance ', correct: true,  expli:' La respuesta correcta es: The ELB stops sending traffic to the EC2 instance  <br>'+ 
      'In this scenario, the load balancer will route the incoming requests only to the healthy instances. When the load balancer determines that an instance is unhealthy, it stops routing requests to that instance. The load balancer resumes routing requests to the instance when it has been restored to a healthy state. <br>'+ 
      'There are two ways of checking the status of your EC2 instances: <br>'+ 
      '1. Via the Auto Scaling group <br>'+ 
      '2. Via the ELB health checks <br>'+ 
      'The default health checks for an Auto Scaling group are EC2 status checks only. If an instance fails these status checks, the Auto Scaling group considers the instance unhealthy and replaces. If you attached one or more load balancers or target groups to your Auto Scaling group, the group does not, by default, consider an instance unhealthy and replace it if it fails the load balancer health checks. <br>'+ 
      'However, you can optionally configure the Auto Scaling group to use Elastic Load Balancing health checks. This ensures that the group can determine an instance\'s health based on additional tests provided by the load balancer. The load balancer periodically sends pings, attempts connections, or sends requests to test the EC2 instances. These tests are called health checks. <br>'+ 
      'If you configure the Auto Scaling group to use Elastic Load Balancing health checks, it considers the instance unhealthy if it fails either the EC2 status checks or the load balancer health checks. If you attach multiple load balancers to an Auto Scaling group, all of them must report that the instance is healthy in order for it to consider the instance healthy. If one load balancer reports an instance as unhealthy, the Auto Scaling group replaces the instance, even if other load balancers report it as healthy. <br>'+ 
      'References: <br>'+ 
      'https://docs.aws.amazon.com/elasticloadbalancing/latest/classic/elb-healthchecks.html <br>'+ 
      'https://docs.aws.amazon.com/autoscaling/ec2/userguide/as-add-elb-healthcheck.html <br>' },
      { text: 'd. The EC2 instance gets terminated automatically by the ELB.', correct: false,  expli:' ' }
    ],
	img: '',  
  },  
    {
    question: '/Exam Prep 2 - 65p - 45 / An application that records weather data every minute is deployed in a fleet of Spot EC2 instances and uses a MySQL RDS database instance. Currently, there is only one RDS instance running in one Availability Zone. You plan to improve the database to ensure high availability by synchronous data replication to another RDS instance. Which of the following performs synchronous data replication in RDS? Seleccione una:',
    answers: [
      { text: 'a. CloudFront running as a Multi-AZ deployment', correct: false,  expli:' ' },
      { text: 'b. RDS DB instance running as a Multi-AZ deployment', correct: true,  expli:'La respuesta correcta es: RDS DB instance running as a Multi-AZ deployment  <br>'+ 
      'When you create or modify your DB instance to run as a Multi-AZ deployment, Amazon RDS automatically provisions and maintains a synchronous standby replica in a different Availability Zone. Updates to your DB Instance are synchronously replicated across Availability Zones to the standby in order to keep both in sync and protect your latest database updates against DB instance failure. <br>'+ 
      'Option 2 is incorrect as a Read Replica provides an asynchronous replication instead of synchronous. <br>'+ 
      'Options 3 and 4 are incorrect as both DynamoDB and CloudFront do not have a Read Replica feature. <br>'+ 
      'Reference: <br>'+ 
      'https://aws.amazon.com/rds/details/multi-az/ <br>'},
	    { text: 'c. RDS Read Replica ', correct: false,  expli:' ' },
      { text: 'd. DynamoDB Read Replica', correct: false,  expli:' ' }
    ],
	img: '',  
  },  
    {
    question: '/Exam Prep 2 - 65p - 46 / A content management system (CMS) is hosted on a fleet of auto-scaled, On-Demand EC2 instances which use Amazon Aurora as its database. Currently, the system stores the file documents that the users uploaded in one of the attached EBS Volumes. Your manager noticed that the system performance is quite slow and he has instructed you to improve the architecture of the system. In this scenario, what will you do to implement a scalable, high throughput POSIX-compliant file system? Seleccione una:',
    answers: [
      { text: 'a. Create an S3 bucket and use this as the storage for the CMS.', correct: false,  expli:' ' },
      { text: 'b. Upgrade your existing EBS volumes to Provisioned IOPS SSD Volumes', correct: false,  expli:' ' },
	    { text: 'c. Use ElastiCache', correct: false,  expli:' ' },
      { text: 'd. Use EFS ', correct: true,  expli:' La respuesta correcta es: Use EFS.  <br>'+ 
      'A content management system (CMS) is hosted on a fleet of auto-scaled, On-Demand EC2 instances which use Amazon Aurora as its database. Currently, the system stores the file documents that the users uploaded in one of the attached EBS Volumes. Your manager noticed that the system performance is quite slow and he has instructed you to improve the architecture of the system. <br>'+ 
      'In this scenario, what will you do to implement a scalable, high throughput POSIX-compliant file system? <br>'+ 
      '• Create an S3 bucket and use this as the storage for the CMS <br>'+ 
      '• Use EFS (Correct) <br>'+ 
      '•Upgrade your existing EBS volumes to Provisioned IOPS SSD Volumes <br>'+ 
      '•Use ElastiCache <br>'+ 
      'Explanation <br>'+ 
      'Amazon Elastic File System (Amazon EFS) provides simple, scalable, elastic file storage for use with AWS Cloud services and on-premises resources. When mounted on Amazon EC2 instances, an Amazon EFS file system provides a standard file system interface and file system access semantics, allowing you to seamlessly integrate Amazon EFS with your existing applications and tools. Multiple Amazon EC2 instances can access an Amazon EFS file system at the same time, allowing Amazon EFS to provide a common data source for workloads and applications running on more than one Amazon EC2 instance. <br>'+ 
      'This particular scenario tests your understanding of EBS, EFS, and S3. In this scenario, there is a fleet of On-Demand EC2 instances that stores file documents from the users to one of the attached EBS Volumes. The system performance is quite slow because the architecture doesn\'t provide the EC2 instances a parallel shared access to the file documents. <br>'+ 
      'Remember that an EBS Volume can be attached to one EC2 instance at a time, hence, no other EC2 instance can connect to that EBS Provisioned IOPS Volume. Take note as well that the type of storage needed here is a "file storage" which means that S3 (Option 1) is not the best service to use because it is mainly used for "object storage", and S3 does not provide the notion of "folders" too. This is why Option 2 is the correct answer. <br>'+ 
      'Option 3 is incorrect because the scenario requires you to set up a scalable, high throughput storage system that will allow concurrent access from multiple EC2 instances. This is clearly not possible in EBS, even with Provisioned IOPS SSD Volumes. You have to use EFS instead. <br>'+ 
      'Option 4 is incorrect because ElastiCache is an in-memory data store that improves the performance of your applications, which is not what you need since it is not a file storage. <br>'+ 
      'Reference: <br>'+ 
      'https://aws.amazon.com/efs/ <br>'}
    ],
	img: '',  
  },  
    {
    question: '/Exam Prep 2 - 65p - 47 / You are a newly-hired Solutions Architect in a leading utilities provider, which is in the process of migrating their applications to AWS. You created an EBS-Backed EC2 instance with ephemeral0 and ephemeral1 instance store volumes attached to host a web application that fetches and stores data from a web API service. If this instance is stopped, what will happen to the data on the ephemeral store volumes? Seleccione una: ',
    answers: [
      { text: 'a. Data is automatically saved as an EBS snapshot.', correct: false,  expli:' ' },
      { text: 'b. Data is automatically saved in an EBS volume.', correct: false,  expli:' ' },
	    { text: 'c. Data is unavailable until the instance is restarted.', correct: false,  expli:' ' },
      { text: 'd. Data will be deleted. ', correct: true,  expli:'La respuesta correcta es: Data will be deleted.  <br>'+ 
      'The virtual devices for instance store volumes are named as ephemeral[0-23]. Instance types that support one instance store volume have ephemeral0. Instance types that support two instance store volumes have ephemeral0 and ephemeral1, and so on until ephemeral23. <br>'+ 
      'The data in an instance store persists only during the lifetime of its associated instance. If an instance reboots (intentionally or unintentionally), data in the instance store persists. However, data in the instance store is lost under the following circumstances: <br>'+ 
      '- The underlying disk drive fails <br>'+ 
      '- The instance stops <br>'+ 
      '- The instance terminates <br>'+ 
      'Hence, Option 3 is the correct answer. <br>'+ 
      'Option 1 is incorrect since instance store volumes and EBS volumes are two different storage types. An Amazon EBS volume is a durable, block-level storage device that you can attach to a single EC2 instance. An instance store provides temporary block-level storage and is located on disks that are physically attached to the host computer. No automatic backup will be performed. <br>'+ 
      'Option 2 is incorrect because once you stop an instance, the data in the ephemeral instance store volumes will be gone. <br>'+ 
      'Option 4 is incorrect because like Option 2, instance store volumes and EBS volumes are two different storage devices. There is no automated snapshot that will be created. <br>'+ 
      'Reference: <br>'+ 
      'http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/InstanceStorage.html?shortFooter=true#instance-store-lifetime <br>' }
    ],
	img: '',  
  },  
    {
    question: '/Exam Prep 2 - 65p - 48 / A Docker application, which is running on an Amazon ECS cluster behind a load balancer, is heavily using DynamoDB. You are instructed to improve the database performance by distributing the workload evenly and using the provisioned throughput efficiently. Which of the following would you consider to implement for your DynamoDB table? Seleccione una: ',
    answers: [
      { text: 'a. Use partition keys with high-cardinality attributes, which have a large number of distinct values for each item.', correct: true,  expli:' La respuesta correcta es: Use partition keys with high-cardinality attributes, which have a large number of distinct values for each item. <br>'+ 
      'The partition key portion of a table\'s primary key determines the logical partitions in which a table\'s data is stored. This in turn affects the underlying physical partitions. Provisioned I/O capacity for the table is divided evenly among these physical partitions. Therefore a partition key design that doesn\'t distribute I/O requests evenly can create "hot" partitions that result in throttling and use your provisioned I/O capacity inefficiently. <br>'+
      'The optimal usage of a table\'s provisioned throughput depends not only on the workload patterns of individual items, but also on the partition-key design. This doesn\'t mean that you must access all partition key values to achieve an efficient throughput level, or even that the percentage of accessed partition key values must be high. It does mean that the more distinct partition key values that your workload accesses, the more those requests will be spread across the partitioned space. In general, you will use your provisioned throughput more efficiently as the ratio of partition key values accessed to the total number of partition key values increases. <br>'+
      'One example for this is the use of partition keys with high-cardinality attributes, which have a large number of distinct values for each item. Hence, Option 2 is the correct answer. <br>'+
      'Option 1 is incorrect because instead of reducing the number of partition keys in your DynamoDB table, you should actually add more to improve its performance to distribute the I/O requests evenly and not avoid "hot" partitions. <br>'+
      'Option 3 is incorrect because this is the exact opposite of the correct answer. Remember that the more distinct partition key values your workload accesses, the more those requests will be spread across the partitioned space. Conversely, the less distinct partition key values, the less evenly spread it would be across the partitioned space, which effectively slows the performance. <br>'+
      'Option 4 is incorrect because, just like Option 2, a composite primary key will provide more partition for the table and in turn, improves the performance. Hence, it should be used and not avoided. <br>'+
      'References: <br>'+
      'https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/bp-partition-key-uniform-load.html <br>'+
      'https://aws.amazon.com/blogs/database/choosing-the-right-dynamodb-partition-key/ <br>' },
      { text: 'b. Use partition keys with low-cardinality attributes, which have a few number of distinct values for each item. ', correct: false,  expli:' ' },
	    { text: 'c. Reduce the number of partition keys in the DynamoDB table.', correct: false,  expli:' ' },
      { text: 'd. Avoid using a composite primary key, which is composed of a partition key and a sort key.', correct: false,  expli:' ' }
    ],
	img: '',  
  },  
    {
    question: '/Exam Prep 2 - 65p - 49 / You have a new e-commerce web application written in Angular framework which is deployed to a fleet of EC2 instances behind an Application Load Balancer. You configured the load balancer to perform health checks on these EC2 instances. What will happen if one of these EC2 instances failed the health checks? Seleccione una:',
    answers: [
      { text: 'a. The EC2 instance gets quarantined by the Application Load Balancer for root cause analysis.', correct: false,  expli:' ' },
      { text: 'b. The Application Load Balancer stops sending traffic to the instance that failed its health check. ', correct: true,  expli:'La respuesta correcta es: The Application Load Balancer stops sending traffic to the instance that failed its health check.  <br>'+
      'In case that one of the EC2 instances failed a health check, the Application Load Balancer stops sending traffic to that instance. <br>'+
      'Your Application Load Balancer periodically sends requests to its registered targets to test their status. These tests are called health checks. Each load balancer node routes requests only to the healthy targets in the enabled Availability Zones for the load balancer. Each load balancer node checks the health of each target, using the health check settings for the target group with which the target is registered. After your target is registered, it must pass one health check to be considered healthy. After each health check is completed, the load balancer node closes the connection that was established for the health check. <br>'+
      'Reference: <br>'+
      'http://docs.aws.amazon.com/elasticloadbalancing/latest/classic/elb-healthchecks.html <br>' },
	    { text: 'c. The EC2 instance gets terminated automatically by the Application Load Balancer. ', correct: false,  expli:' ' },
      { text: 'd. The EC2 instance is replaced automatically by the Application Load Balancer.', correct: false,  expli:' ' }
    ],
	img: '',  
  },  
    {
    question: '/Exam Prep 2 - 65p - 50 / You are a Solutions Architect of a bank, designing various CloudFormation templates for a new online trading platform that your department will build. How much does it cost to use CloudFormation templates? Seleccione una:',
    answers: [
      { text: 'a. There is no additional charge for AWS CloudFormation. You only pay for the AWS resources that are created. ', correct: true,  expli:' La respuesta correcta es: There is no additional charge for AWS CloudFormation. You only pay for the AWS resources that are created. <br>'+ 
      'There is no additional charge for AWS CloudFormation. You only pay for the AWS resources that are created (e.g. Amazon EC2 instances, Elastic Load Balancing load balancers, etc.) <br>'+ 
      'Reference: https://aws.amazon.com/cloudformation/faqs/ <br>' },
      { text: 'b. The cost is based on the size of the template.', correct: false,  expli:' ' },
	    { text: 'c. The cost is based on the file size of the template.', correct: false,  expli:' ' },
      { text: 'd. It is charged per hour.', correct: false,  expli:' ' }
    ],
	img: '',  
  },  
    {
    question: '/Exam Prep 2 - 65p - 51 / You have one security group associated with 10 On-Demand EC2 instances. You then modified the security group to allow all inbound SSH traffic and then right after that, you created two new EC2 instances in the same security group. When will the changes be applied to the EC2 instances? Seleccione una: ',
    answers: [
      { text: 'a. Immediately to the new instances only.', correct: false,  expli:' ' },
      { text: 'b. The changes will apply to all 12 instances after an hour when the propagation is complete.', correct: false,  expli:' ' },
	    { text: 'c. Immediately to all 12 instances in the security group. ', correct: true,  expli:' La respuesta correcta es: Immediately to all 12 instances in the security group. <br>'+
      'A security group acts as a virtual firewall for your instance to control inbound and outbound traffic. When you launch an instance in a VPC, you can assign up to five security groups to the instance. Security groups act at the instance level, not the subnet level. Therefore, each instance in a subnet in your VPC could be assigned to a different set of security groups. If you don\'t specify a particular group at launch time, the instance is automatically assigned to the default security group for the VPC. <br>'+
      'Option 1 is correct. When you add or remove rules, those changes are automatically applied to all instances to which you\'ve assigned the security group. Since the first 10 instances are already assigned to the security group, you can SSH into them immediately after the change. After adding the two new instances to the security group, you should be able to SSH into them as well since the change was made beforehand. <br>'+
      'Options 2 and 3 are incorrect because the changes will be applied to all EC2 instances and not just to the new or old set of instances. <br>'+
      'Option 4 is incorrect because you don\'t have to wait for an hour for the changes to be applied to your security group since the changes will be immediately reflected. <br>'+
      'Reference: <br>'+
      'http://docs.aws.amazon.com/AmazonVPC/latest/UserGuide/VPC_SecurityGroups.html <br>'},
      { text: 'd. Immediately to the new instances, but not for the old ones which must be restarted before the changes take effect.', correct: false,  expli:' ' }
    ],
	img: '',  
  },  
    {
    question: '/Exam Prep 2 - 65p - 52 / You are working as a Solutions Architect in a top software development company in Silicon Valley. The company has multiple applications hosted in their VPC. While you are monitoring the system, you noticed that multiple port scans are coming in from a specific IP address block which are trying to connect to several AWS resources inside your VPC. The internal security team has requested that all offending IP addresses be denied for the next 24 hours for security purposes. Which of the following is the best method to quickly and temporarily deny access from the specified IP addresses? Seleccione una: ',
    answers: [
      { text: 'a. Create a policy in IAM to deny access from the IP Address block.', correct: false,  expli:' ' },
      { text: 'b. Configure the firewall in the operating system of the EC2 instances to deny access from the IP address block.', correct: false,  expli:' ' },
	    { text: 'c. Modify the Network Access Control List associated with all public subnets in the VPC to deny access from the IP Address block. ', correct: true,  expli:' La respuesta correcta es: Modify the Network Access Control List associated with all public subnets in the VPC to deny access from the IP Address block. <br>'+
      'To control the traffic coming in and out of your VPC network, you can use the network access control list (ACL). It is an optional layer of security for your VPC that acts as a firewall for controlling traffic in and out of one or more subnets. This is the best solution among other options as you can easily add and remove the restriction in a matter of minutes. <br>'+
      'Option 1 is incorrect as an IAM policy does not control the inbound and outbound traffic of your VPC. <br>'+
      'Option 3 is incorrect as although a Security Group acts as a firewall, it will only control both inbound and outbound traffic at the instance level and not on the whole VPC. <br>'+
      'Option 4 is incorrect because adding a firewall in the underlying operating system of the EC2 instance is not enough; the attacker can just connect to other AWS resources since the network access control list still allows them to do so. <br>'+
      'Reference: <br>'+
      'http://docs.aws.amazon.com/AmazonVPC/latest/UserGuide/VPC_ACLs.html <br>'},
      { text: 'd. Add a rule in the Security Group of the EC2 instances to deny access from the IP Address block.', correct: false,  expli:' ' }
    ],
	img: '',  
  },  
    {
    question: '/Exam Prep 2 - 65p - 53 / You are working as a Solutions Architect in a new startup that provides storage for high-quality photos which are infrequently accessed by the users. To make the architecture cost-effective, you designed the cloud service to use an S3 One Zone-Infrequent Access (S3 One Zone-IA) storage type for free users and an S3 Standard-Infrequent Access (S3 Standard-IA) storage type for premium users. When your manager found out about this, he asked you about the trade-offs of using S3 One Zone-IA instead of the S3 Standard-IA. What will you say to your manager? (Choose 2) Seleccione una o más de una:',
    answers: [
      { text: 'a. Unlike other Amazon object storage classes, which store data in a minimum of three Availability Zones (AZs), S3 One Zone-IA stores data in two AZs only. Hence the name, One Zone-IA since the data replication is skipped in one Availability Zone.', correct: false,  expli:' ' },
      { text: 'b. Unlike other Amazon object storage classes, which store data in a minimum of three Availability Zones (AZs), S3 One Zone-IA stores data in a single AZ. ', correct:true,  expli:' una respuesta correcta es :  Unlike other Amazon object storage classes, which store data in a minimum of three Availability Zones (AZs), S3 One Zone-IA stores data in a single AZ.' },
	    { text: 'c. Storing data in S3 One Zone-IA costs less than storing it in S3 Standard-IA.', correct: true,  expli:' una respuesta correcta es : Storing data in S3 One Zone-IA costs less than storing it in S3 Standard-IA. <br>'+
      'Amazon S3 One Zone-Infrequent Access (S3 One Zone-IA) is an Amazon S3 storage class for data that is accessed less frequently but requires rapid access when needed. Unlike other Amazon object storage classes, which store data in a minimum of three Availability Zones (AZs), S3 One Zone-IA stores data in a single AZ. Because of this, storing data in S3 One Zone-IA costs 20% less than storing it in S3 Standard-IA. S3 One Zone-IA is ideal for customers who want a lower cost option for infrequently accessed data but do not require the availability and resilience of S3 Standard or S3 Standard-IA storage. It’s a good choice, for example, for storing secondary backup copies of on-premises data or easily re-creatable data, or for storage used as an S3 Cross-Region Replication target from another AWS Region. <br>'+
      'S3 One Zone-IA offers the same high durability, high throughput, and low latency of Amazon S3 Standard and S3 Standard-IA, with a low per GB storage price and per GB retrieval fee. The S3 One Zone-IA storage class is set at the object level and can exist in the same bucket as S3 Standard and S3 Standard-IA, allowing you to use S3 Lifecycle Policies to automatically transition objects between storage classes without any application changes. <br>'+
      'Key Features: <br>'+
      '• Same low latency and high throughput performance of S3 Standard and S3 Standard-IA <br>'+
      '• Designed for durability of 99.999999999% of objects in a single Availability Zone, but data will be lost in the event of Availability Zone destruction <br>'+
      '• Designed for 99.5% availability over a given year <br>'+
      '• Backed with the Amazon S3 Service Level Agreement for availability <br>'+
      '• Supports SSL for data in transit and encryption of data at rest <br>'+
      '• Lifecycle management for automatic migration of objects <br>'+
      'Remember that since the S3 One Zone-IA stores data in a single AWS Availability Zone, data stored in this storage class will be lost in the event of Availability Zone destruction. <br>'+
      'Reference: <br>'+
      'https://aws.amazon.com/s3/storage-classes/#Amazon_S3_One_Zone-Infrequent_Access <br>'},
      { text: 'd. S3 One Zone-IA offers lower durability and low throughput compared with Amazon S3 Standard and S3 Standard-IA which is why it has a low per GB storage price and per GB retrieval fee.', correct: false,  expli:' ' },
      { text: 'e. Storing data in S3 One Zone-IA costs more than storing it in S3 Standard-IA but provides more durability.', correct: false,  expli:' ' }
    ],
	img: '',  
  },  
    {
    question: '/Exam Prep 2 - 65p - 54 / A media company has an Amazon ECS Cluster, which uses the Fargate launch type, to host its news website. The database credentials should be supplied using environment variables, to comply with strict security compliance. As the Solutions Architect, you have to ensure that the credentials are secure and that they cannot be viewed in plaintext on the cluster itself. Which of the following is the most suitable solution in this scenario that you can implement with minimal effort? Seleccione una:  ',
    answers: [
      { text: 'a. In the ECS task definition file of the ECS Cluster, store the database credentials using Docker Secrets to centrally manage these sensitive data and securely transmit it to only those containers that need access to it. Secrets are encrypted during transit and at rest. A given secret is only accessible to those services which have been granted explicit access to it via IAM Role, and only while those service tasks are running. ', correct: false,  expli:' ' },
      { text: 'b. Use the AWS Secrets Manager to store the database credentials and then encrypt them using AWS KMS. Create a resource-based policy for your Amazon ECS task execution role and reference it with your task definition which allows access to both KMS and AWS Secrets Manager. Within your container definition, specify secrets with the name of the environment variable to set in the container and the full ARN of the Secrets Manager secret which contains the sensitive data, to present to the container.', correct: false,  expli:' ' },
	    { text: 'c. Use the AWS Systems Manager Parameter Store to keep the database credentials and then encrypt them using AWS KMS. Create an IAM Role for your Amazon ECS task execution role and reference it with your task definition, which allows access to both KMS and the Parameter Store. Within your container definition, specify secrets with the name of the environment variable to set in the container and the full ARN of the Systems Manager Parameter Store parameter containing the sensitive data to present to the container.', correct: true,  expli:' La respuesta correcta es: Use the AWS Systems Manager Parameter Store to keep the database credentials and then encrypt them using AWS KMS. Create an IAM Role for your Amazon ECS task execution role and reference it with your task definition, which allows access to both KMS and the Parameter Store. Within your container definition, specify secrets with the name of the environment variable to set in the container and the full ARN of the Systems Manager Parameter Store parameter containing the sensitive data to present to the container. <br>'+ 
      'Amazon ECS enables you to inject sensitive data into your containers by storing your sensitive data in either AWS Secrets Manager secrets or AWS Systems Manager Parameter Store parameters and then referencing them in your container definition. This feature is supported by tasks using both the EC2 and Fargate launch types. <br>'+
      'Secrets can be exposed to a container in the following ways: <br>'+
      '- To inject sensitive data into your containers as environment variables, use the secrets container definition parameter. <br>'+
      '- To reference sensitive information in the log configuration of a container, use the secretOptions container definition parameter. <br>'+
      'Within your container definition, specify secrets with the name of the environment variable to set in the container and the full ARN of either the Secrets Manager secret or Systems Manager Parameter Store parameter containing the sensitive data to present to the container. The parameter that you reference can be from a different Region than the container using it, but must be from within the same account. Hence, Option 4 is the correct answer. <br>'+
      'Option 1 is incorrect because although you can use Docker Secrets to secure the sensitive database credentials, this feature is only applicable in Docker Swarm. In AWS, the recommended way to secure sensitive data is either through the use of Secrets Manager or Systems Manager Parameter Store. <br>'+
      'Option 2 is incorrect because although the solution may work, it is not recommended to store sensitive credentials in S3. This entails a lot of overhead and manual configuration steps which can be simplified by simply using the Secrets Manager or Systems Manager Parameter Store. <br>'+
      'Option 3 is incorrect because although the use of Secrets Manager in securing sensitive data in ECS is valid, using an IAM Role is a more suitable choice over a resource-based policy for the Amazon ECS task execution role. <br>'+
      'References: <br>'+
      'https://docs.aws.amazon.com/AmazonECS/latest/developerguide/specifying-sensitive-data.html <br>'+
      'https://aws.amazon.com/blogs/mt/the-right-way-to-store-secrets-using-parameter-store/ <br>'},
      { text: 'd. Store the database credentials in the ECS task definition file of the ECS Cluster and encrypt it with KMS. Store the task definition JSON file in a private S3 bucket and ensure that HTTPS is enabled on the bucket to encrypt the data in-flight. Create an IAM role to the ECS task definition script that allows access to the specific S3 bucket and then pass the --cli-input-json parameter when calling the ECS register-task-definition. Reference the task definition JSON file in the S3 bucket which contains the database credentials.', correct: false,  expli:' ' }
    ],
	img: '',  
  },  
    {
    question: '/Exam Prep 2 - 65p - 55 / A solutions architect is designing a high performance computing (HPC) workload on Amazon EC2. The EC2 instances need to communicate to each other frequently and require network performance with low latency and high throughput. Which EC2 configuration meets these requirements? Seleccione una: ',
    answers: [
      { text: 'a. Launch the EC2 instances in a spread placement group in one Availability Zone.', correct: false,  expli:' ' },
      { text: 'b. Launch the EC2 instances in an Auto Scaling group spanning multiple Availability Zones.', correct: false,  expli:' ' },
	    { text: 'c. Launch the EC2 instances in a cluster placement group in one Availability Zone. ', correct: true,  expli:' La respuesta correcta es: Launch the EC2 instances in a cluster placement group in one Availability Zone. <br>'+
      'Placement groups - <br>'+
      'When you launch a new EC2 instance, the EC2 service attempts to place the instance in such a way that all of your instances are spread out across underlying hardware to minimize correlated failures.  <br>'+
      'You can use placement groups to influence the placement of a group of interdependent instances to meet the needs of your workload.  <br>'+
      'Depending on the type of workload. <br>'+
      'Cluster ג "€packs instances close together inside an Availability Zone. This strategy enables workloads to achieve the low-latency network performance necessary for tightly-coupled node-to-node communication that is typical of HPC applications. <br>'+
      'Reference: <br>'+
      'https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/placement-groups.html <br>'},
      { text: 'd. Launch the EC2 instances in an Auto Scaling group in two Regions and peer the VPCs.', correct: false,  expli:' ' }
    ],
	img: '',  
  },  
    {
    question: '/Exam Prep 2 - 65p - 56 / A company has a legacy application that processes data in two parts. The second part of the process takes longer than the first, so the company has decided to rewrite the application as two microservices running on Amazon ECS that can scale independently. How should a solutions architect integrate the microservices? Seleccione una: ',
    answers: [
      { text: 'a. Implement code in microservice 1 to send data to an Amazon SQS queue. Implement code in microservice 2 to process messages from the queue. ', correct: true,  expli:' La respuesta correcta es: Implement code in microservice 1 to send data to an Amazon SQS queue. Implement code in microservice 2 to process messages from the queue.' },
      { text: 'b. Implement code in microservice 1 to send data to Amazon Kinesis Data Firehose. Implement code in microservice 2 to read from Kinesis Data Firehose.', correct: false,  expli:' ' },
	    { text: 'c. Implement code in microservice 1 to publish data to an Amazon SNS topic. Implement code in microservice 2 to subscribe to this topic.', correct: false,  expli:' ' },
      { text: 'd. Implement code in microservice 1 to send data to an Amazon S3 bucket. Use S3 event notifications to invoke microservice 2.', correct: false,  expli:' ' }
    ],
	img: '',  
  },  
    {
    question: '/Exam Prep 2 - 65p - 57 / You are designing a multi-tier web application architecture that consists of a fleet of EC2 instances and an Oracle relational database server. It is required that the database is highly available and that you have full control over its underlying operating system. Which AWS service will you use for your database tier? Seleccione una: ',
    answers: [
      { text: 'a. Amazon EC2 instances with data replication in one Availability Zone', correct: false,  expli:' ' },
      { text: 'b. Amazon RDS with Multi-AZ deployments', correct: false,  expli:' ' },
	    { text: 'c. Amazon RDS', correct: false,  expli:' ' },
      { text: 'd. Amazon EC2 instances with data replication between two different Availability Zones ', correct: true,  expli:' La respuesta correcta es: Amazon EC2 instances with data replication between two different Availability Zones  <br>'+
      'To achieve this requirement, you can deploy your Oracle database to Amazon EC2 instances with data replication between two different Availability Zones. Hence, option 4 is the correct answer. The deployment of this architecture can easily be achieved by using Cloudformation and Quick Start. Please refer to the reference link for information.  <br>'+
      'The Quick Start deploys the Oracle primary database (using the preconfigured, general-purpose starter database from Oracle) on an Amazon EC2 instance in the first Availability Zone. It then sets up a second EC2 instance in a second Availability Zone, copies the primary database to the second instance by using the DUPLICATE command, and configures Oracle Data Guard.  <br>'+
      'Options 1 and 2 are incorrect because the scenario requires you to have access to the underlying operating system of the database server. Remember that Amazon RDS is a managed database service, which means that Amazon is the one that manages the underlying operating system of the database instance and not you.  <br>'+
      'Option 3 is incorrect since deploying to just one Availability Zone (AZ) will not make the database tier highly available. If that AZ went down, your database will be unavailable.  <br>'+
      'References:  <br>'+
      'https://aws.amazon.com/quickstart/  <br>'+
      'https://docs.aws.amazon.com/quickstart/latest/oracle-database/architecture.html  <br>'+
      'http://docs.aws.amazon.com/dms/latest/userguide/CHAP_Introduction.ReplicationInstance.html  <br>'}
    ],
	img: '',  
  },  
    {
    question: '/Exam Prep 2 - 65p - 58 / A traffic monitoring and reporting application uses Kinesis to accept real-time data. In order to process and store the data, they used Amazon Kinesis Data Firehose to load the streaming data to various AWS resources. Which of the following services can you load streaming data into? Seleccione una: ',
    answers: [
      { text: 'a. Amazon Redshift Spectrum', correct: false,  expli:' ' },
      { text: 'b. Amazon Elasticsearch Service', correct: true,  expli:' La respuesta correcta es: Amazon Elasticsearch Service. <br>'+
      'Amazon Kinesis Data Firehose is the easiest way to load streaming data into data stores and analytics tools. It can capture, transform, and load streaming data into Amazon S3, Amazon Redshift, Amazon Elasticsearch Service, and Splunk, enabling near real-time analytics with existing business intelligence tools and dashboards you’re already using today. <br>'+
      'It is a fully managed service that automatically scales to match the throughput of your data and requires no ongoing administration. It can also batch, compress, and encrypt the data before loading it, minimizing the amount of storage used at the destination and increasing security. <br>'+
      'Options 1 and 2 are incorrect because Amazon S3 Select is just a feature of Amazon S3. Likewise, Redshift Spectrum is also just a feature of Amazon Redshift. Although Amazon Kinesis Data Firehose can load streaming data to both Amazon S3 and Amazon Redshift, it does not directly load the data to S3 Select and Redshift Spectrum. <br>'+
      'S3 Select is an Amazon S3 feature that makes it easy to retrieve specific data from the contents of an object using simple SQL expressions without having to retrieve the entire object. Amazon Redshift Spectrum is a feature of Amazon Redshift that enables you to run queries against exabytes of unstructured data in Amazon S3 with no loading or ETL required. <br>'+
      'Option 4 is incorrect because Amazon Kinesis Data Firehose cannot load streaming data to Athena. <br>'+
      'Reference: <br>'+
      'https://aws.amazon.com/kinesis/data-firehose/ <br>'},
	    { text: 'c. Amazon S3 Select ', correct: false,  expli:' ' },
      { text: 'd. Amazon Athena', correct: false,  expli:' ' }
    ],
	img: '',  
  },  
    {
    question: '/Exam Prep 2 - 65p - 59 / You have a web application hosted in EC2 that consumes messages from an SQS queue and is integrated with SNS to send out an email to you once the process is complete. You received 5 orders but after a few hours, you saw more than 20 email notifications in your inbox. Which of the following could be the possible culprit for this issue? Seleccione una: ',
    answers: [
      { text: 'a. The web application is set to short polling so some messages are not being picked up', correct: false,  expli:' ' },
      { text: 'b. The web application is set for long polling so the messages are being sent twice.', correct: false,  expli:' ' },
	    { text: 'c. The web application is not deleting the messages in the SQS queue after it has processed them. ', correct: true,  expli:' La respuesta correcta es: The web application is not deleting the messages in the SQS queue after it has processed them. <br>'+
      'Always remember that the messages in the SQS queue will continue to exist even after the EC2 instance has processed it, until you delete that message. You have to ensure that you delete the message after processing to prevent the message from being received and processed again once the visibility timeout expires. <br>'+
      'There are three main parts in a distributed messaging system: <br>'+
      '1. The components of your distributed system (EC2 instances) <br>'+
      '2. Your queue (distributed on Amazon SQS servers) <br>'+
      '3. Messages in the queue. <br>'+
      'You can set up a system which has several components that send messages to the queue and receive messages from the queue. The queue redundantly stores the messages across multiple Amazon SQS servers. <br>'+
      'Refer to the third step of the SQS Message Lifecycle: <br>'+
      '1. Component 1 sends Message A to a queue, and the message is distributed across the Amazon SQS servers redundantly. <br>'+
      '2. When Component 2 is ready to process a message, it consumes messages from the queue, and Message A is returned. While Message A is being processed, it remains in the queue and isn\'t returned to subsequent receive requests for the duration of the visibility timeout. <br>'+
      '3. Component 2 deletes Message A from the queue to prevent the message from being received and processed again once the visibility timeout expires. <br>'+
      'Option 1 is incorrect because long polling helps reduce the cost of using SQS by eliminating the number of empty responses (when there are no messages available for a ReceiveMessage request) and false empty responses (when messages are available but aren\'t included in a response). Messages being sent twice in an SQS queue configured with long polling is quite unlikely. <br>'+
      'Option 3 is incorrect since you are receiving emails from SNS where messages are certainly being processed. Following the scenario, messages not being picked up won\'t result into 20 messages being sent to your inbox. <br>'+
      'Option 4 is incorrect because not having the correct permissions would have resulted in a different response. The scenario says that messages were properly processed but there were over 20 messages that were sent, hence, there is no problem with the accessing the queue. <br>'+
      'References: <br>'+
      'https://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/sqs-message-lifecycle.html <br>'+
      'https://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/sqs-basic-architecture.html <br>'},
      { text: 'd. The web application does not have permission to consume messages in the SQS queue.', correct: false,  expli:' ' }
    ],
	img: '',  
  },  
    {
    question: '/Exam Prep 2 - 65p - 60 / You have launched a travel photo sharing website using Amazon S3 to serve high-quality photos to visitors of your website. After a few days, you found out that there are other travel websites linking and using your photos. This resulted in financial losses for your business. What is an effective method to mitigate this issue? Seleccione una: ',
    answers: [
      { text: 'a. Store photos on an Amazon EBS volume of the web server.', correct: false,  expli:' ' },
      { text: 'b. Block the IP addresses of the offending websites using NACL.', correct: false,  expli:' ' },
	    { text: 'c. Configure your S3 bucket to remove public read access and use pre-signed URLs with expiry dates. ', correct: true,  expli:' La respuesta correcta es: Configure your S3 bucket to remove public read access and use pre-signed URLs with expiry dates. <br>'+
      'In Amazon S3, all objects are private by default. Only the object owner has permission to access these objects. However, the object owner can optionally share objects with others by creating a pre-signed URL, using their own security credentials, to grant time-limited permission to download the objects. <br>'+
      'When you create a pre-signed URL for your object, you must provide your security credentials, specify a bucket name, an object key, specify the HTTP method (GET to download the object) and expiration date and time. The pre-signed URLs are valid only for the specified duration. <br>'+
      'Anyone who receives the pre-signed URL can then access the object. For example, if you have a video in your bucket and both the bucket and the object are private, you can share the video with others by generating a pre-signed URL. <br>'+
      'Option 2 is incorrect. CloudFront is a content delivery network service that speeds up delivery of content to your customers. <br>'+
      'Option 3 is also incorrect. Blocking IP address using NACLs is not a very efficient method because a quick change in IP address would easily bypass this configuration. <br>'+
      'Option 4 is also incorrect. You cannot serve objects directly from an EBS volume, which needs to be attached to an EC2 instance. EBS volumes also do not provide the same durability as compared to S3. <br>'+
      'Reference: <br>'+
      'https://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/private-content-signed-urls.html <br>' },
      { text: 'd. Use CloudFront distributions for your photos.', correct: false,  expli:' ' }
    ],
	img: '',  
  },  
    {
    question: '/Exam Prep 2 - 65p - 61 / You are a Solutions Architect working for a major telecommunications company in Europe. You deployed an On-Demand EC2 instance that is transferring large amounts of data to an Amazon S3 bucket in the same region. Your manager is worried about infrastructure cost considering the vast amounts of data being transferred to the bucket. What will you say to justify this architecture? Seleccione una: ',
    answers: [
      { text: 'a. Transferring data from an EC2 instance to an S3 bucket in the same region has a 50% discount based on the AWS Pricing.', correct: false,  expli:' ' },
      { text: 'b. Transferring data from an EC2 instance to an S3 bucket in the same region has no cost at all. ', correct: true,  expli:' La respuesta correcta es: Transferring data from an EC2 instance to an S3 bucket in the same region has no cost at all. <br>'+
      'Transferring data from an EC2 instance to Amazon S3, Amazon Glacier, Amazon DynamoDB, Amazon SES, Amazon SQS, or Amazon SimpleDB in the same AWS Region has no cost at all. Refer to the Amazon EC2 Pricing on the link below for reference. <br>'+
      'Options 1 and 4 are incorrect since an On-Demand instance costs more than a Spot instance. <br>'+
      'Option 3 is incorrect as there is no such thing as 50% discount when transferring data from an EC2 instance to an S3 bucket in the same region. <br>'+
      'Reference: <br>'+
      'https://aws.amazon.com/ec2/pricing/on-demand/#Data_Transfer <br>' },
	    { text: 'c. You are only using an On-Demand EC2 instance which is exactly the same price as Spot EC2 instance, launched by a persistent Spot request.', correct: false,  expli:' ' },
      { text: 'd. You are only using an On-Demand EC2 instance so the cost will be lower than a Spot instance.', correct: false,  expli:' ' }
    ],
	img: '',  
  },  
    {
    question: '/Exam Prep 2 - 65p - 62 / You founded a tech startup that provides online training and software development courses to various students across the globe. Your team has developed an online portal in AWS where the students can log into and access the courses they are subscribed to. Since you are in the early phases of the startup and the funding is still hard to come by, which service can help you manage the budgets for all your AWS resources? Seleccione una: ',
    answers: [
      { text: 'a. Cost Explorer', correct: false,  expli:' ' },
      { text: 'b. Cost Allocation Tags', correct: false,  expli:' ' },
	    { text: 'c. AWS Budgets ', correct: true,  expli:' La respuesta correcta es: AWS Budgets.  <br>'+
      'AWS Budgets gives you the ability to set custom budgets that alert you when your costs or usage exceed (or are forecasted to exceed) your budgeted amount. <br>'+
      'Budgets can be tracked at the monthly, quarterly, or yearly level, and you can customize the start and end dates. You can further refine your budget to track costs associated with multiple dimensions, such as AWS service, linked account, tag, and others. Budget alerts can be sent via email and/or Amazon Simple Notification Service (SNS) topic. <br>'+
      'You can also use AWS Budgets to set a custom reservation utilization target and receive alerts when your utilization drops below the threshold you define. RI utilization alerts support Amazon EC2, Amazon RDS, Amazon Redshift, and Amazon ElastiCache reservations. <br>'+
      'Budgets can be created and tracked from the AWS Budgets dashboard or via the Budgets API. <br>'+
      'Option 1 is incorrect because the Cost Explorer only helps you visualize and manage your AWS costs and usages over time. It offers a set of reports you can view data with for up to the last 13 months, forecast how much you\'re likely to spend for the next three months, and get recommendations for what Reserved Instances to purchase. You use Cost Explorer to identify areas that need further inquiry and see trends to understand your costs. <br>'+
      'Option 2 is incorrect because Cost Allocation Tags only eases the organization of your resource costs on your cost allocation report, to make it easier for you to categorize and track your AWS costs. <br>'+
      'Option 4 is incorrect because the payment history option only provides a location where you can view the monthly invoices you receive from AWS. If your account isn\'t past due, the Payment History page shows only previous invoices and payment status. <br>'+
      'Reference: <br>'+
      'https://aws.amazon.com/aws-cost-management/aws-budgets/ <br>'},
      { text: 'd. Payment History', correct: false,  expli:' ' }
    ],
	img: '',  
  },  
    {
    question: '/Exam Prep 2 - 65p - 63 / A Forex trading platform, which frequently processes and stores global financial data every minute, is hosted in your on-premises data center and uses an Oracle database. Due to a recent cooling problem in their data center, the company urgently needs to migrate their infrastructure to AWS to improve the performance of their applications. As the Solutions Architect, you are responsible in ensuring that the database is properly migrated and should remain available in case of database server failure in the future. Which of the following is the most suitable solution to meet the requirement? Seleccione una: ',
    answers: [
      { text: 'a. Migrate your Oracle data to Amazon Aurora by converting the database schema using AWS Schema Conversion Tool and AWS Database Migration Service.', correct: false,  expli:' ' },
      { text: 'b. Launch an Oracle database instance in RDS with Recovery Manager (RMAN) enabled.', correct: false,  expli:' ' },
	    { text: 'c. Launch an Oracle Real Application Clusters (RAC) in RDS. ', correct: false,  expli:' ' },
      { text: 'd. Create an Oracle database in RDS with Multi-AZ deployments.', correct: true,  expli:' La respuesta correcta es: Create an Oracle database in RDS with Multi-AZ deployments. <br>'+
      'Amazon RDS Multi-AZ deployments provide enhanced availability and durability for Database (DB) Instances, making them a natural fit for production database workloads. When you provision a Multi-AZ DB Instance, Amazon RDS automatically creates a primary DB Instance and synchronously replicates the data to a standby instance in a different Availability Zone (AZ). Each AZ runs on its own physically distinct, independent infrastructure, and is engineered to be highly reliable. <br>'+
      'In case of an infrastructure failure, Amazon RDS performs an automatic failover to the standby (or to a read replica in the case of Amazon Aurora), so that you can resume database operations as soon as the failover is complete. Since the endpoint for your DB Instance remains the same after a failover, your application can resume database operation without the need for manual administrative intervention. <br>'+
      'In this scenario, the best RDS configuration to use is an Oracle database in RDS with Multi-AZ deployments to ensure high availability even if the primary database instance goes down. Hence, Option 3 is the correct answer. <br>'+
      'Options 1 and 2 are incorrect because Oracle RMAN and RAC are not supported in RDS. <br>'+
      'Option 4 is incorrect because although this solution is feasible, it takes time to migrate your Oracle database to Aurora which is not acceptable. Based on this option, the Aurora database does not have a Read Replica and is not configured as an Amazon Aurora DB cluster, which could have improved the availability of the database. <br>'+
      'References: <br>'+
      'https://aws.amazon.com/rds/details/multi-az/ <br>'+
      'https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/Concepts.MultiAZ.html <br>'}
    ],
	img: './aws/question63_exam2_65p.png',  
  },  
  /*imagen*/
    {
    question: '/Exam Prep 2 - 65p - 64 / A solutions architect is designing a system to analyze the performance of financial markets while the markets are closed. The system will run a series of compute- intensive jobs for 4 hours every night. The time to complete the compute jobs is expected to remain constant, and jobs cannot be interrupted once started. Once completed, the system is expected to run for a minimum of 1 year. Which type of Amazon EC2 instances should be used to reduce the cost of the system? Seleccione una:',
    answers: [
      { text: 'a. Standard Reserved Instances', correct: false,  expli:' ' },
      { text: 'b. Scheduled Reserved Instances ', correct: true,  expli:' La respuesta correcta es: Scheduled Reserved Instances. <br> Reference: https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ec2-scheduled-instances.html' },
	    { text: 'c. On-Demand Instances', correct: false,  expli:' ' },
      { text: 'd. Spot Instances', correct: false,  expli:' ' }
    ],
	img: '',  
  },  
    {
    question: '/Exam Prep 2 - 65p - 65 / A web application is using CloudFront to distribute their images, videos, and other static contents stored in their S3 bucket to its users around the world. The company has recently introduced a new member-only access to some of its high quality media files. There is a requirement to provide access to multiple private media files only to their paying subscribers without having to change their current URLs. Which of the following is the most suitable solution that you should implement to satisfy this requirement? Seleccione una: ',
    answers: [
      { text: 'a. Configure your CloudFront distribution to use Field-Level Encryption to protect your private data and only allow access to members.', correct: false,  expli:' ' },
      { text: 'b. Create a Signed URL with a custom policy which only allows the members to see the private files. ', correct: false,  expli:' ' },
	    { text: 'c. Configure your CloudFront distribution to use Match Viewer as its Origin Protocol Policy which will automatically match the user request. This will allow access to the private content if the request is a paying member and deny it if it is not a member.', correct: false,  expli:' ' },
      { text: 'd. Use Signed Cookies to control who can access the private files in your CloudFront distribution by modifying your application to determine whether a user should have access to your content. For members, send the required Set-Cookie headers to the viewer which will unlock the content only to them.', correct: true,  expli:' La respuesta correcta es: Use Signed Cookies to control who can access the private files in your CloudFront distribution by modifying your application to determine whether a user should have access to your content. For members, send the required Set-Cookie headers to the viewer which will unlock the content only to them. <br>'+ 
      'CloudFront signed URLs and signed cookies provide the same basic functionality: they allow you to control who can access your content. If you want to serve private content through CloudFront and you\'re trying to decide whether to use signed URLs or signed cookies, consider the following: <br>'+
      'Use signed URLs for the following cases: <br>'+
      '• You want to use an RTMP distribution. Signed cookies aren\'t supported for RTMP distributions. <br>'+
      '• You want to restrict access to individual files, for example, an installation download for your application. <br>'+
      '• Your users are using a client (for example, a custom HTTP client) that doesn\'t support cookies. <br>'+
      'Use signed cookies for the following cases: <br>'+
      '• You want to provide access to multiple restricted files, for example, all of the files for a video in HLS format or all of the files in the subscribers\' area of a website. <br>'+
      '• You don\'t want to change your current URLs. <br>'+
      'Hence, the correct answer to this scenario is Option 4. <br>'+
      'Option 1 is incorrect because a Match Viewer is an Origin Protocol Policy which configures CloudFront to communicate with your origin using HTTP or HTTPS, depending on the protocol of the viewer request. CloudFront caches the object only once even if viewers make requests using both HTTP and HTTPS protocols. <br>'+
      'Option 2 is incorrect because Signed URLs are primarily used for providing access to individual files, as shown on the above explanation. In addition, the scenario explicitly says that they don\'t want to change their current URLs which is why implementing Signed Cookies is more suitable than Signed URL. <br>'+
      'Option 3 is incorrect because Field-Level Encryption only allows you to securely upload user-submitted sensitive information to your web servers. It does not provide access to download multiple private files. <br>'+
      'Reference: <br>'+
      'https://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/private-content-choosing-signed-urls-cookies.html <br>'+
      'https://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/private-content-signed-cookies.html <br>'}
    ],
	img: '',  
  },  
  {
    question: '/Explicación antes de Exam 2/ In what ways does Amazon S3 object storage differ from block and file storage? (Select TWO.) ',
    answers: [
      { text: 'a. Amazon S3 allows storing an unlimited number of objects.', correct: true,  expli:' correct A Amazon S3 allows storing an unlimited number of objects.' },
      { text: 'b. Objects are immutable - the only way to change a single byte is to replace the object.', correct: true,  expli:' correct B Objects are immutable - the only way to change a single byte is to replace the object.' },
	    { text: 'c. Objects  are replicated across Availability Zenes ', correct: false,  expli:' Objects  are replicated across Availability Zenes (S3 IA objects can be1 AZ only)' },
      { text: 'd. Objects are replicated across all regions ', correct: false,  expli:' Objects are replicated across all regions (Objects may be replicated across AZs within a single region but not across all regions).' }
    ],
	img: '',  
  },   
  {
    question: '/Explicación antes de Exam 2/ Which of the following are features of Amazon EBS? (Select TWO.) ',
    answers: [
      { text: 'a. Data stored on Amazon EBS is automatically replicated within an Availability Zone.', correct: true,  expli:' correct A Data stored on Amazon EBS is automatically replicated within an Availability Zone.' },
      { text: 'b. Amazon EBS data is automatically backed up to tape.', correct: false,  expli:' ' },
	    { text: 'c. Amazon EBS volumes can be encrypted.', correct: true,  expli:' correct C Amazon EBS volumes can be encrypted. ' },
      { text: 'd. Amazon EBS volumes can be attached to more then one instance in the same AZ.', correct: false,  expli:' ' }
    ],
	img: '',  
  },   
  {
    question: '/Explicación antes de Exam 2/ Which use case is ideal for Amazon RDS database engines? (Select TWO) ',
    answers: [
      { text: 'a. Complex transactions', correct: false,  expli:' ' },
      { text: 'b. Sharding', correct: false,  expli:' ' },
	    { text: 'c. Simple GET/PUT requests and queries', correct: false,  expli:' ' },
      { text: 'd. A medium to high query/write rate', correct: true,  expli:' correct D, A medium to high query/write rate' },
      { text: 'e. RDBMS customization', correct: false,  expli:' ' }
    ],
	img: '',  
  },   
  {
    question: '/Explicación antes de Exam 2/ Which AWS database service is best suited for non-relational databases?',
    answers: [
    { text: 'a. Amazon Redshift ', correct: false,  expli:' Amazon Redshift (ldeal for running big queries against large datasets)' },
      { text: 'b. Amazon RDS ', correct: false,  expli:' Amazon RDS (Amazon RDS is a structured relational database)' },
	    { text: 'c. Amazon Glacier ', correct: false,  expli:' Amazon Glacier (Amazon Glacier is not a database service)' },
      { text: 'd. Amazon DynamoDB', correct: true,  expli:' correct D, Amazon DynamoDB' }
    ],
	img: '',  
  },   
  {
    question: '/Explicación antes de Exam 2/ An application requires a relational database with an initial storage capacity of 4 TB. The database will grow by 10 GB every day. To support traffic, at least four read replicas is required to handle reads. Which option will meet these requirements?',
    answers: [
      { text: 'a. DynamoDB', correct: false,  expli:' DynamoDB (NoSQL service, not a relational DB)' },
      { text: 'b. Amazon S3', correct: false,  expli:' Amazon S3 (Object storage, not a relational DB)' },
	    { text: 'c. Amazon Aurora', correct: true,  expli:' correct C ,Amazon Aurora' },
      { text: 'd. Amazon Redshift', correct: false,  expli:' Amazon Redshift (Does not support read replicas and does not automaticaly scale)' }
    ],
	img: '',  
  },     
  {
    question: '/Explicación antes de Exam 2/ Which ot the following objects are good candidates to store in a cache? (Select THREE.) ',
    answers: [
      { text: 'a. Session state', correct: true,  expli:'correct A  Session state' },
      { text: 'b. Shopping cart', correct: true,  expli:'correct B  Shopping cart ' },
	    { text: 'c. Product catalog', correct: true,  expli:'correct C Product catalog ' },
      { text: 'd. Bank account balance ', correct: false,  expli:' Bank account balance (it is critical that this data is accurate and updated)' }
    ],
	img: '',  
  },  
  {
    question: '/Explicación antes de Exam 2/ Which of the following cache engines are supported by Amazon ElastiCache? (Select TWO.) ',
    answers: [
      { text: 'a. MySQL', correct: false,  expli:' ' },
      { text: 'b. Memcached', correct: true,  expli:' correct B Memcached' },
	    { text: 'c. Redis', correct: true,  expli:' correct C Redis' },
      { text: 'd. Couchbase', correct: false,  expli:' ' }
    ],
	img: '',  
  },  
  {
    question: '/Explicación antes de Exam 2/ Which services work together to enable auto scaling of Amazon EC2 instances? ',
    answers: [
      { text: 'a. Amazon EC2 Auto Scaling and Elastic Load Balancer ', correct: false,  expli:' ' },
      { text: 'b. Amazon EC2 Auto Scaling and CloudWatch', correct: false,  expli:' ' },
	    { text: 'c. Amazon EC2 Auto Scaling, Elastic Load Balancer and CloudWatch', correct: true,  expli:' correct C Amazon EC2 Auto Scaling, Elastic Load Balancer and CloudWatch' },
      { text: 'd. Amazon EC2 Elastic Load Balancer and CloudWatch', correct: false,  expli:' ' },
      { text: 'e. Amazon EC2 Auto Scaling ', correct: false,  expli:' ' }
    ],
	img: '',  
  },  
  {
    question: '/Explicación antes de Exam 2/ A radio station runs a contest where every day at noon they make an announcement that generates an immediate spike in traffiC that requires 8 Amazon ECz instances to process. All other times the web site requires 2 EC2 instances. Which is the most cost effective way to meet these requirements?',
    answers: [
      { text: 'a. Create an Auto Scaling group with a minimum capacity of 2 and scale up based on CPU utilization', correct: false,  expli:'Create an Auto Scaling group with a minimum capacity of 2 and scale up based on CPU utilization (delay in launching instances) ' },
      { text: 'b. Create an Auto Scaling group with a minimun capacity of 8 at all times ', correct: false,  expli:' Create an Auto Scaling group with a minimun capacity of 8 at all times  (overprovisioned)' },
	    { text: 'c. Create an Auto Scaling group with a minimum capacity of 2 and set a schedule to scale up at 11:40 am', correct: true,  expli:'correct C Create an Auto Scaling group with a minimum capacity of 2 and set a schedule to scale up at 11:40 am' },
      { text: 'd. Create an Auto Scaling group with a minimum capacity of 2 and scale up based upon memory utilization ', correct: false,  expli:' Create an Auto Scaling group with a minimum capacity of 2 and scale up based upon memory utilization (not a native CloudWatch event)' }
    ],
	img: '',  
  },   
  {
    question: '/Explicación antes de Exam 2/ Which of the following are characteristicS of Amazon EC2 Auto Scaling on AWS? (Select THREE.) ',
    answers: [
      { text: 'a. Sends traffics to healthy instances ', correct: false,  expli:'  Sends traffics to healthy instances (Amazon Elastic Load Balancer)' },
      { text: 'b. Responds to changing conditions by adding or terminating Amazon EC2 instances', correct: true,  expli:' correct B Responds to changing conditions by adding or terminating Amazon EC2 instances' },
	    { text: 'c. Collects and tracks metrics and sets alarms ', correct: false,  expli:' Collects and tracks metrics and sets alarms ( Amazon CloudWatch)' },
      { text: 'd. Dellivers push notifications. ', correct: false,  expli:'Dellivers push notifications. (Amazon SNS) ' },
      { text: 'e. Launches instances from a specified Amazon Machine Image (AMI)', correct: true,  expli:' correct E Launches instances from a specified Amazon Machine Image (AMI)' },
      { text: 'f. Enforces a minimum number of running Amazon EC2 instances.', correct: true,  expli:' correct F Enforces a minimum number of running Amazon EC2 instances.' }
    ],
	img: '',  
  },  
  {
    question: '/Explicación antes de Exam 2/ To monitor CPU utilization on your RDS DB instance you set up a CloudWatch alarm with a threshold of 70% over 3 periods of 5 minutes. If CPU utilization goes up to 80%o for 10 minutes how many alarms will you receive?',
    answers: [
      { text: 'a. Zero', correct: true,  expli:' correct A Zero ' },
      { text: 'b. One', correct: false,  expli:' ' },
	    { text: 'c. Two', correct: false,  expli:' ' },
      { text: 'd. Three', correct: false,  expli:' ' }
    ],
	img: '',  
  },  
  {
    question: '/Explicación antes de Exam 2/ You are responsible for a web application running on Amazon ECZ instances. You want to track the number of 404 errors that users see in the application. Which of the following options can you use to do this?',
    answers: [
      { text: 'a. Use Amazon VPC Flow Logs ', correct: false,  expli:' Use Amazon VPC Flow Logs (Amazon VPC Flow Logs capture layer 3 and 4 IP-level logs and do not capture layer 7 HTTP 404 errors)' },
      { text: 'b. Use Amazon CloudWatch metrics. ', correct: false,  expli:' Use Amazon CloudWatch metrics. (Amazon CloudWatch Metrics do not capture 404 errors by default)' },
	    { text: 'c. Use Amazon CloudWatch Logs to get the web server logs from the EC2 instances.', correct: true,  expli:' correct C Use Amazon CloudWatch Logs to get the web server logs from the EC2 instances.' },
      { text: 'd. Web applications on AWS never have 404 erros.', correct: false,  expli:' Web applications on AWS never have 404 erros. (Web applications on AWS can have 404 errors)' }
    ],
	img: '',  
  },  
  {
    question: '/Explicación antes de Exam 2/ You have written an application that needs access to a particular bucket in Amazon S3. The application will run on an Amazon EC2 instance. What should you do to give the application access to the bucket securely?',
    answers: [
      { text: 'a. Store your access key and secrets key on the Amazon EC2 instance in a file called “secrets ”', correct: false,  expli:' Store your access key and secrets key on the Amazon EC2 instance in a file called “secrets ” (Storing keys on the instance compromises their security)' },
      { text: 'b. Attach an IAM role to the Amazon EC2 instance with a policy that grants it access to the bucket in Amazon S3.', correct: true,  expli:' correct B Attach an IAM role to the Amazon EC2 instance with a policy that grants it access to the bucket in Amazon S3. ' },
	    { text: 'c. Store your access key and secret key on the Amazon EC2 instance in “$HOME/.aws/credentials” ', correct: false,  expli:' Store your access key and secret key on the Amazon EC2 instance in “$HOME/.aws/credentials” (Storing keys on the instance compromises their security)' },
      { text: 'd. Use Amazon S3 bucket policies to make the bucket public. ', correct: false,  expli:'Use Amazon S3 bucket policies to make the bucket public. (Making the bucket public will give it access that is too broad) ' },

    ],
	img: '',  
  },  
  {
    question: '/Explicación antes de Exam 2/ A database is running on an Amazon EC2 instance. The database software has a backup feature that requires block storage. What storage option would be the lowest cost option for the backup data?',
    answers: [
      { text: 'a. Amazon Glacier', correct: false,  expli:'Amazon Glacier (Not a block storage)' },
      { text: 'b. Amazon EBS Cold HDD Volunme (sc1)', correct: true,  expli:' correct B Amazon EBS Cold HDD Volunme (sc1)' },
	    { text: 'c. Amazon S3', correct: false,  expli:' Amazon S3 (Not a block storage)' },
      { text: 'd. Amazon EBS Throughput Optimized HDD Volume (st1)', correct: false,  expli:' Amazon EBS Throughput Optimized HDD Volume (st1) (Not lowest cost volume type)' }
    ],
	img: '',  
  }, 
  {
    question: '/Explicación antes de Exam 1/ A company has decided to host a server on an Amazon EC2 instance. The main requirement for this server is to process large quantities of logs. Which of the following Amazon EBS volume types would be ideal for this implementation?',
    answers: [
      { text: 'a. Amazon EBS Provisioned IOPs (io1)', correct: false,  expli:' ' },
      { text: 'b. Amazon EBS Cold HDD Volume (sc1)', correct: false,  expli:' ' },
	    { text: 'c. Amazon EBS General Purpose SSD (gp2)', correct: false,  expli:' ' },
      { text: 'd. Amazon EBS Throughput Optimized HDD Volume (st 1)', correct: true,  expli:' correct D Amazon EBS Throughput Optimized HDD Volume (st 1)' }
    ],
	img: '',  
  }, 
  {
    question: '/Explicación antes de Exam 1/ Which of the following AWS services facilitate the implementation of loosely coupled architectures? (Select TWO.)',
    answers: [
      { text: 'a. AWS CloudFormation', correct: false,  expli:' AWS CloudFormation (stands up stacks of components)' },
      { text: 'b. Amazon Simple Queue Service', correct: true,  expli:' correct B Amazon Simple Queue Service ' },
	    { text: 'c. AWS CloudTrail', correct: false,  expli:' AWS CloudTrail (logging service)' },
      { text: 'd. Elastic Load Balancing ', correct: true,  expli:' correct D Elastic Load Balancing' },
      { text: 'e. Amazon EMR', correct: false,  expli:' Amazon EMR (managed Hadoop)' }
    ],
	img: '',  
  }, 
  {
    question: '/Explicación antes de Exam 2/ Your web service has a performance SLA to respond to 90% of requests in <5 seconds. Under normal and heavy operations, distributing requests Over four instances meets performance requirements. What architecture ensures cost efficient high availability of your service if an Availability Zone becomes unreachable  ',
    answers: [
      { text: 'a. Deploy the service on four servers in a single Availability Zone.', correct: false,  expli:'Deploy the service on four servers in a single Availability Zone. (single AZ)' },
      { text: 'b. Deploy the service on six servers in a single Availability Zone.', correct: false,  expli:'Deploy the service on six servers in a single Availability Zone. (single AZ)' },
	    { text: 'c. Deploy the service on four servers with auto scaling across two Availability Zones.', correct: true,  expli:' correct C Deploy the service on four servers with auto scaling across two Availability Zones.' },
      { text: 'd. Deploy the service on eight servers with auto scaling across two Availability Zones.', correct: false,  expli:' Deploy the service on eight servers with auto scaling across two Availability Zones. (too much Compute)' }
    ],
	img: '',  
  }, 
  {
    question: '/Explicación antes de Exam 2/ You are planning to use AWS CloudFormation to deploy a Linux EC2 instance in two difterent regions using the same base Amazon Machine Image (AMI). How can you do this using AWS CloudFormation?',
    answers: [
      { text: 'a. Use two different AWS CloudFormation templates since AWS CloudFormation templates are region-specific.', correct: false,  expli:' Use two different AWS CloudFormation templates since AWS CloudFormation templates are region-specific. (Region specific Is not required)' },
      { text: 'b. Use mappings to specify the base AMI since AMI IDs are different in each region', correct: true,  expli:' correct B Use mappings to specify the base AMI since AMI IDs are different in each region ' },
	    { text: 'c. Use parameters to specify the base AMI since AMI IDs are different in each region', correct: false,  expli:'Use parameters to specify the base AMI since AMI IDs are different in each region (Parameters are for inputs from users; AMI IDS are difficult for users to enter)' },
      { text: 'd. AMI IDs are identical across regions', correct: false,  expli:'AMI IDs are identical across regions (AMI IDs differ across regions) ' }
    ],
	img: '',  
  }, 
  {
    question: '/Explicación antes de Exam 2/ How can l access the output of print statements trom AWS Lambda?',
    answers: [
      { text: 'a. Connect by using SSH into Lambda and look at system logs.', correct: false,  expli:'Connect by using SSH into Lambda and look at system logs. (Lambda does not allow SSH access)' },
      { text: 'b. Lambda writes all Output to Amazon S3 by default.', correct: false,  expli:' Lambda writes all Output to Amazon S3 by default. (Lambda does not write all output ro S3 by default )' },
	    { text: 'c. Amazon CloudWatch Logs.', correct: true,  expli:' correct C, Amazon CloudWatch Logs. ' },
      { text: 'd. Print statements are ignored in Lambda.', correct: false,  expli:'Print statements are ignored in Lambda.(Print statements are not ignored in Lambda)' }
    ],
	img: '',  
  }, 
  {
    question: '/Explicación antes de Exam 3/ A development team lead is configuring policies for his team at an IT company. Which of the following policy types only limit permissions but cannot grant permissions (Select two)? Seleccione una o más de una:  <br>',
    answers: [
      { text: 'a. Identity-based policy', correct: false,  expli:' ' },
      { text: 'b. Resource-based policy ', correct: false,  expli:' ' },
	    { text: 'c. Permissions boundary', correct: true,  expli:' una respuesta correcta es : Permissions boundary, AWS Organizations Service Control Policy (SCP)' },
      { text: 'd. Access control list (ACL) ', correct: false,  expli:' ' },
      { text: 'e. AWS Organizations Service Control Policy (SCP)', correct: true,  expli:' una respuesta correcta es : Permissions boundary, AWS Organizations Service Control Policy (SCP). <br>'+
      'Correct options: <br>'+
'AWS Organizations Service Control Policy (SCP) – Use an AWS Organizations Service Control Policy (SCP) to define the maximum permissions for account members of an organization or organizational unit (OU). SCPs limit permissions that identity-based policies or resource-based policies grant to entities (users or roles) within the account, but do not grant permissions.<br>'+
'Permissions boundary - Permissions boundary is a managed policy that is used for an IAM entity (user or role). The policy defines the maximum permissions that the identity-based policies can grant to an entity, but does not grant permissions.<br>'+
'Incorrect options:<br>'+
'Access control list (ACL) - Use ACLs to control which principals in other accounts can access the resource to which the ACL is attached. ACLs are similar to resourcebased policies, although they are the only policy type that does not use the JSON policy document structure. ACLs are cross-account permissions policies that grant permissions to the specified principal.<br>'+
'Resource-based policy - Resource-based policies grant permissions to the principal that is specified in the policy. Principals can be in the same account as the resource or in other accounts. The most common examples of resource-based policies are Amazon S3 bucket policies and IAM role trust policies.<br>'+
'Identity-based policy - Help attach managed and inline policies to IAM identities (users, groups to which users belong, or roles). Identity-based policies grant permissions to an identity.<br>'+
'Reference:<br>'+
'https://docs.aws.amazon.com/IAM/latest/UserGuide/access_policies.html <br>'}
    ],
	img: '',  
  },   
  {
    question: '/Explicación antes de Exam 3/ A Company stores a large volume of non-critical log files in an Amazon S3 bucket. An Amazon EC2 instance processes files from the bucket on a daily basis. Which storage option will be the MOST cost-effective for this scenario? Seleccione una: <br>',
    answers: [
      { text: 'a. Amazon Glacier.', correct: false,  expli:' ' },
      { text: 'b. Amazon S3 Standard-Infrequent Access.', correct: false,  expli:' ' },
	    { text: 'c. Amazon S3 Standard. ', correct: true,  expli:' La respuesta correcta es: Amazon S3 Standard. <br> '+
      'As the data is being frequently accessed the Amazon S3 Standard storage class is the best choice for this particular use case.<br>'+
'CORRECT: "Amazon S3 Standard" is the correct answer. <br>'+
'INCORRECT: "Amazon S3 Standard-Infrequent Access" is incorrect as the data is being frequently accessed and there would be additional retrieval costs.<br>'+
'INCORRECT: "Amazon Glacier" is incorrect as the data is being frequently accessed so it cannot be archived.<br>'+
'INCORRECT: "Amazon Instance Store" is incorrect as this is an ephemeral block storage volume associated with EC2 instances. It is not suitable for this use case.<br>'},
      { text: 'd. Amazon Instance Store.', correct: false,  expli:' ' }
    ],
	img: '',  
  },   
  {
    question: '/Explicación antes de Exam 3/ A company has several AWS accounts in a single organization in AWS Organizations. The company requires that no Amazon S3 buckets can be deleted its production account.  What is the SIMPLEST approach to ensuring that the S3 buckets in the production account cannot be deleted? Seleccione una: <br>',
    answers: [
      { text: 'a. Set up MFA Delete on all the S3 buckets in the production account to prevent the buckets from being deleted. ', correct: false,  expli:' ' },
      { text: 'b. Create an IAM group that has an IAM policy to deny the s3:DeleteBucket action on all buckets in the production account.', correct: false,  expli:' ' },
	    { text: 'c. Create an IAM role that restricts the API actions that can be used for Amazon S3 and assign it to EC2 instances.', correct: false,  expli:' ' },
      { text: 'd. Use a service control policy to deny the s3:DeleteBucket API action in the production account.', correct: true,  expli:'La respuesta correcta es: Use a service control policy to deny the s3:DeleteBucket API action in the production account. <br>'+
      'Service control policies (SCPs) are a type of organization policy that you can use to manage permissions in your organization. SCPs offer central control over the maximum available permissions for all accounts in your organization. <br>'+
'For this scenario, an SCP can be used to restrict the s3:DeleteBucket API action on the production account. This will ensure that no user will be able to delete a bucket in this account as API action is restricted. This will apply even to users who have the necessary IAM permissions to delete the bucket.<br>'+
'CORRECT: "Use a service control policy to deny the s3:DeleteBucket API action in the production account" is the correct answer.<br>'+
'INCORRECT: "Set up MFA Delete on all the S3 buckets in the production account to prevent the buckets from being deleted" is incorrect. MFA delete does not prevent deletion; it just adds a layer of protection to reduce the likelihood of accidental deletion.<br>'+
'INCORRECT: "Create an IAM group that has an IAM policy to deny the s3:DeleteBucket action on all buckets in the production account" is incorrect. This will only apply to users that are added to the group which means ongoing administrative challenges in ensuring that all users are added to the group so that no one has the ability to delete a bucket.<br>'+
'INCORRECT: "Create an IAM role that restricts the API actions that can be used for Amazon S3 and assign it to EC2 instances" is incorrect. You restrict permissions but not API actions when using IAM policies. Also, it doesn’t make sense to just apply the policy to EC2 instances, this must apply to everyone. <br>' }
    ],
	img: '',  
  },   
  {
    question: '/Explicación antes de Exam 3/ A company is testing a new application which is expected to receive a large amount of traffic. The application runs on Amazon EC2 instances in an Auto Scaling group and uses an Amazon RDS Multi-AZ database. Static content is hosted in an Amazon S3 bucket. During performance testing the application response time increased significantly. How can an Architect increase the performance and scalability of the application? Seleccione una: .<br>',
    answers: [
      { text: 'a. Use Amazon CloudFront to cache the static content.', correct: true,  expli:' La respuesta correcta es: Use Amazon CloudFront to cache the static content. <br>'+
      'The only answer that will improve performance and scalability is to cache the static content in Amazon CloudFront. This will improve response times for the static content, especially for global users who are farther from the Region where the data is hosted.<br>'+
'CORRECT: "Use Amazon CloudFront to cache the static content" is the correct answer. <br>'+
'INCORRECT: "Serve the static content from the EC2 instances backed by an Amazon EFS filesystem" is incorrect. This does not improve scalability or performance.<br>'+
'INCORRECT: "Move the database from Amazon RDS to Amazon ElastiCache for Memcached" is incorrect. ElastiCache is not a persistent data store so you can’t use it to move the data. You could use it in front of the RDS database to improve performance but that is a different answer.<br>'+
'INCORRECT: "Use Amazon Route 53 with geolocation routing" is incorrect. This could be used if you had multiple implementations of the application in different Regions and needed to direct traffic according to the location of the user. That is not the case in this scenario. <br>' },
      { text: 'b. Use Amazon Route 53 with geolocation routing.', correct: false,  expli:' ' },
	    { text: 'c. Move the database from Amazon RDS to Amazon ElastiCache for Memcached. ', correct: false,  expli:' ' },
      { text: 'd. Serve the static content from the EC2 instances backed by an Amazon EFS filesystem.', correct: false,  expli:' ' }
    ],
	img: '',  
  },   
  {
    question: '/Explicación antes de Exam 3/ A VPC peering connection has been established between two VPCs in different AWS Regions in the same account. An administrator is attempting to update  the security group configuration to allow inbound connections over HTTP from a security group in the second Region and is unable to complete the configuration. What could be the cause of the issue? Seleccione una: <br>',
    answers: [
      { text: 'a. You cannot enter the security group ID of a security group from another Region.', correct: true,  expli:' La respuesta correcta es: You cannot enter the security group ID of a security group from another Region. <br>'+
      'It is not possible to enter the security group ID of a security group in a different Region. Therefore, the security group should be configured using network address ranges instead.<br>'+
'Requirements for configuring security groups:<br>'+
'The peer VPC can be a VPC in your account, or a VPC in another AWS account. To reference a security group in another AWS account, include the account number in Source or Destination field; for example, 123456789012/sg-1a2b3c4d.<br>'+
'You cannot reference the security group of a peer VPC that\'s in a different region. Instead, use the CIDR block of the peer VPC.<br>'+
'To reference a security group in a peer VPC, the VPC peering connection must be in the active state.<br>'+
'CORRECT: "You cannot enter the security group ID of a security group from another Region" is the correct answer.<br>'+
'INCORRECT: "The Administrator must manually copy the security group ID and paste it in" is incorrect. This is not correct as you cannot enter security groups from a different Region.<br>'+
'INCORRECT: "The Administrator has not yet configured the route tables appropriately" is incorrect. The configuration of security groups is not reliant on setting up the route tables.<br>'+
'INCORRECT: "The VPC peering connection is not in an active state" is incorrect. Even if the VPC peering connection is active this configuration is not possible.<br>' },
      { text: 'b. The VPC peering connection is not in an active state.', correct: false,  expli:' ' },
	    { text: 'c. The Administrator has not yet configured the route tables appropriately. ', correct: false,  expli:' ' },
      { text: 'd. The Administrator must manually copy the security group ID and paste it in.', correct: false,  expli:' ' }
    ],
	img: '',  
  },   
  {
    question: '/Explicación antes de Exam 3/ A new employee has joined a company as a deployment engineer. The deployment engineer will be using AWS CloudFormation templates to create multiple AWS resources. A solutions architect wants the deployment engineer to perform job activities while following the principle of least privilege. Which combination of actions should the solutions architect take to accomplish this goal? (Choose two.) Seleccione una o más de una: ',
    answers: [
      { text: 'a. Create a new IAM User for the deployment engineer and add the IAM user to a group that has an IAM policy that allows AWS CloudFormation actions only. ', correct: true,  expli:' una respuesta correcta es : Create a new IAM User for the deployment engineer and add the IAM user to a group that has an IAM policy that allows AWS CloudFormation actions only.' },
      { text: 'b. Create a new IAM user for the deployment engineer and add the IAM user to a group that has the Administrate/Access IAM policy attached.', correct: false,  expli:' ' },
	    { text: 'c. Have the deployment engineer use AWS account roof user credentials for performing AWS CloudFormation stack operations.', correct: false,  expli:' ' },
      { text: 'd. Create an IAM role for the deployment engineer to explicitly define the permissions specific to the AWS CloudFormation stack and launch stacks using Dial IAM role. ', correct: true,  expli:'una respuesta correcta es : Create an IAM role for the deployment engineer to explicitly define the permissions specific to the AWS CloudFormation stack and launch stacks using Dial IAM role.' },
      { text: 'e. Create a new IAM user for the deployment engineer and add the IAM user to a group that has the PowerUsers IAM policy attached.', correct: false,  expli:' ' }
    ],
	img: '',  
  },   
  {
    question: '/Explicación antes de Exam 3/ A multi-national company has multiple business units with each unit having its own AWS account. The development team at the company would like to debug and trace data across accounts and visualize it in a centralized account As a Developer Associate, which of the following solutions would you suggest for the given use-case? Seleccione una: <br>',
    answers: [
      { text: 'a. VPC Flow Logs', correct: false,  expli:' ' },
      { text: 'b. X-Ray', correct: true,  expli:' La respuesta correcta es: X-Ray. <br>'+
      'Correct option:<br>'+
'X-Ray AWS X-Ray helps developers analyze and debug production, distributed applications, such as those built using a microservices architecture. <br>'+
'With X-Ray, you can understand how your application and its underlying services are performing to identify and troubleshoot the root cause of performance issues and errors. <br>'+
'X-Ray provides an end-to-end view of requests as they travel through your application, and shows a map of your application’s underlying components.<br>'+
'You can use X-Ray to collect data across AWS Accounts. <br>'+
'The X-Ray agent can assume a role to publish data into an account different from the one in which it is running. <br>'+
'This enables you to publish data from various components of your application into a central account.<br>'+

'Incorrect options:<br>'+
'VPC Flow Logs : VPC Flow Logs is a feature that enables you to capture information about the IP traffic going to and from network interfaces in your VPC. <br>'+
'Flow log data is used to analyze network traces and helps with network security. <br>'+
'Flow log data can be published to Amazon CloudWatch Logs or Amazon S3. <br>'+
'You cannot use VPC Flow Logs to debug and trace data across accounts.<br>'+
'CloudWatch Events : Amazon CloudWatch Events delivers a near real-time stream of system events that describe changes in Amazon Web Services (AWS) resources.<br>'+
'These help to trigger notifications based on changes happening in AWS services.<br>'+
'You cannot use CloudWatch Events to debug and trace data across accounts. <br>'+
'CloudTrail : With CloudTrail, you can log, continuously monitor, and retain account activity related to actions across your AWS infrastructure. <br>'+
'You can use AWS CloudTrail to answer questions such as - “Who made an API call to modify this resource?”. CloudTrail provides event history of your AWS account activity thereby enabling governance, compliance, operational auditing, and risk auditing of your AWS account. You cannot use CloudTrail to debug and trace data across accounts. <br>'+
'Reference:<br>'+
'https://aws.amazon.com/xray/ <br>'},
	    { text: 'c. CloudTrail ', correct: false,  expli:' ' },
      { text: 'd. CloudWatch Events', correct: false,  expli:' ' }
    ],
	img: '',  
  },   
  {
    question: '/Explicación antes de Exam 3/ A developer has been asked to create an application that can be deployed across a fleet of EC2 instances. The configuration must allow for full control over the deployment steps using the blue-green deployment. Which service will help you achieve that? Seleccione una:<br>',
    answers: [
      { text: 'a. CodePipeline', correct: false,  expli:' ' },
      { text: 'b. CodeDeploy ', correct: true,  expli:' La respuesta correcta es: CodeDeploy. <br>'+
      'Correct option:<br>'+
'CodeDeploy<br>'+
'AWS CodeDeploy is a deployment service that automates application deployments to Amazon EC2 instances, on-premises instances, or serverless Lambda functions. <br>'+
'AWS CodeBuild is a fully managed continuous integration service that compiles source code, runs tests, and produces software packages that are ready to deploy.<br>'+
'The blue/green deployment type uses the blue/green deployment model controlled by CodeDeploy. <br>'+
'This deployment type enables you to verify a new deployment of service before sending production traffic to it.<br>'+

'Incorrect options:<br>'+
'CodeBuild - AWS CodeBuild is a fully managed continuous integration service that compiles source code, runs tests, and produces software packages that are ready to deploy. It cannot be used to deploy applications.<br>'+
'Elastic Beanstalk - AWS Elastic Beanstalk offers hooks but not as much control as CodeDeploy. <br>'+
'Because AWS Elastic Beanstalk performs an in-place update when you update your application versions, your application can become unavailable to users for a short period of time. <br>'+
'You can avoid this downtime by performing a blue/green deployment, where you deploy the new version to a separate environment, and then swap CNAMEs of the two environments to redirect traffic to the new version instantly.<br>'+
'CodePipeline - CodePipeline automates the build, test, and deploy phases of your release process every time there is a code change. <br>'+
'CodePipeline by itself cannot deploy applications.<br>'+
'Reference:<br>'+
'https://docs.amazonaws.cn/en_us/codedeploy/latest/userguide/deploymentconfigurations.html<br>' },
	    { text: 'c. CodeBuild', correct: false,  expli:' ' },
      { text: 'd. Elastic Beanstalk', correct: false,  expli:' ' }
    ],
	img: '',  
  },   
  {
    question: '/Explicación antes de Exam 3/ The development team has just configured and attached the IAM policy needed to access AWS Billing and Cost Management for all users under the Finance department. But, the users are unable to see AWS Billing and Cost Management service in the AWS console. What could be the reason for this issue? Seleccione una:  <br>',
    answers: [
      { text: 'a. The users might have another policy that restricts them from accessing the Billing information ', correct: false,  expli:' ' },
      { text: 'b. You need to activate IAM user access to the Billing and Cost Management console for all the users who need access', correct: true,  expli:' La respuesta correcta es: You need to activate IAM user access to the Billing and Cost Management console for all the users who need access <br>'+
      'Correct option: <br>'+
'You need to activate IAM user access to the Billing and Cost Management console for all the users who need access - By default, IAM users do not have access to the AWS Billing and Cost Management console.  <br>'+
'You or your account administrator must grant users access. You can do this by activating IAM user access to the Billing and Cost Management console and attaching an IAM policy to your users. <br>'+
'Then, you need to activate IAM user access for IAM policies to take effect.  <br>'+
'You only need to activate IAM user access once. <br>'+
'Incorrect options: <br>'+
'The users might have another policy that restricts them from accessing the Billing information - This is an incorrect option, as deduced from the given use-case. <br>'+
'Only root user has access to AWS Billing and Cost Management console - This is an incorrect statement.  <br>'+
'AWS Billing and Cost Management access can be provided to any user through user activation and policies, as discussed above.  <br>'+
'IAM user should be created under AWS Billing and Cost Management and not under the AWS account to have access to Billing console - IAM is a feature of your AWS account.  <br>'+
'All IAM users are created and managed from a single place, irrespective of the services they wish to you. <br>'+
'Reference: <br>'+
'https://docs.aws.amazon.com/awsaccountbilling/latest/aboutv2/control-accessbilling.html  <br>'},
	    { text: 'c. Only root user has access to AWS Billing and Cost Management console', correct: false,  expli:' ' },
      { text: 'd. IAM user should be created under AWS Billing and Cost Management and not under AWS account to have access to Billing console', correct: false,  expli:' ' }
    ],
	img: '',  
  },   
  {
    question: '/Explicación antes de Exam 3/ A company has an application that calls AWS Lambda functions. A recent code review found database credentials stored in the source code. The database credentials need to be removed from the Lambda source code. The credentials must then be securely stored and rotated on an ongoing basis to meet security policy requirements. What should a solutions architect recommend to meet these requirements? Seleccione una: Reference: <br>',
    answers: [
      { text: 'a. Move the database password to an environment variable associated with the Lambda function. Retrieve the password from the environment variable upon execution.', correct: false,  expli:' ' },
      { text: 'b. Store the password in AWS Key Management Service (AWS KMS). Associate the Lambda function with a role that can retrieve the password from AWS KMS given its key ID. ', correct: false,  expli:' ' },
	    { text: 'c. Store the password in AWS Secrets Manager. Associate the Lambda function with a role that can retrieve the password from Secrets Manager given its secret ID.', correct: true,  expli:' La respuesta correcta es: Store the password in AWS Secrets Manager. Associate the Lambda function with a role that can retrieve the password from Secrets Manager given its secret ID. <br>'+
      'https://aws.amazon.com/blogs/security/how-to-use-aws-secrets-manager-rotate-credentials-amazon-rdsdatabase-types-oracle/ <br>' },
      { text: 'd. Store the password in AWS CloudHSM. Associate the Lambda function with a role that can retrieve the password from CloudHSM given its key ID.', correct: false,  expli:' ' }
    ],
	img: '',  
  },   
  {
    question: '/Explicación antes de Exam 3/ A company has thousands of edge devices that collectively generate 1 TB of status alerts each day. Each alert is approximately 2 KB in size. A solutions architect needs to implement a solution to ingest and store the alerts for future analysis. The company wants a highly available solution. However, the company needs to minimize costs and does not want to manage additional infrastructure. Additionally, the company wants to keep 14 days of data available for immediate analysis and archive any data older than 14 days. What is the MOST operationally efficient solution that meets these requirements? Seleccione una: ',
    answers: [
      { text: 'a. Create an Amazon Kinesis Data Firehose delivery stream to ingest the alerts. Configure the Kinesis Data Firehose stream to deliver the alerts to an Amazon OpenSearch Service (Amazon Elasticsearch Service) cluster. Set up the Amazon OpenSearch Service (Amazon Elasticsearch Service) cluster to take manual snapshots every day and delete data from the cluster that is older than 14 days.', correct: false,  expli:' ' },
      { text: 'b. Launch Amazon EC2 instances across two Availability Zones and place them behind an Elastic Load Balancer to ingest the alerts. Create a script on the EC2 instances that will store the alerts in an Amazon S3 bucket. Set up an S3 Lifecycle configuration to transition data to Amazon S3 Glacier after 14 days.', correct: false,  expli:' ' },
	    { text: 'c. Create an Amazon Kinesis Data Firehose delivery stream to ingest the alerts. Configure the Kinesis Data Firehose stream to deliver the alerts to an Amazon S3 bucket. Set up an S3 Lifecycle configuration to transition data to Amazon S3 Glacier after 14 days.', correct: true,  expli:' La respuesta correcta es: Create an Amazon Kinesis Data Firehose delivery stream to ingest the alerts. Configure the Kinesis Data Firehose stream to deliver the alerts to an Amazon S3 bucket. Set up an S3 Lifecycle configuration to transition data to Amazon S3 Glacier after 14 days.' },
      { text: 'd. Create an Amazon Simple Queue Service (Amazon SQS) standard queue to ingest the alerts, and set the message retention period to 14 days. Configure consumers to poll the SQS queue, check the age of the message, and analyze the message data as needed. If the message is 14 days old, the consumer should copy the message to an Amazon S3 bucket and delete the message from the SQS queue.', correct: false,  expli:' ' }
    ],
	img: '',  
  },   
  {
    question: '/Explicación antes de Exam 3/ A company has NFS servers in an on-premises data center that need to periodically back up small amounts of data to Amazon S3. Which solution meets these requirements and is MOST cost-effective? Seleccione una: ',
    answers: [
      { text: 'a. Set up an AWS DataSync agent on the on-premises servers, and sync the data to Amazon S3. ', correct: true,  expli:' La respuesta correcta es: Set up an AWS DataSync agent on the on-premises servers, and sync the data to Amazon S3.' },
      { text: 'b. Set up an SFTP sync using AWS Transfer for SFTP to sync data from on-premises to Amazon S3.', correct: false,  expli:' ' },
	    { text: 'c. Set up AWS Glue to copy the data from the on-premises servers to Amazon S3.', correct: false,  expli:' ' },
      { text: 'd. Set up an AWS Direct Connect connection between the on-premises data center and a VPC, and copy the data to Amazon S3.', correct: false,  expli:' ' }
    ],
	img: '',  
  },   
  {
    question: '/Explicación antes de Exam 3/ The manager at an IT company wants to set up member access to user-specific folders in an Amazon S3 bucket bucket-a . So, user x can only access files in his folder bucket-a/user/user-x/ and user y can only access files in her folder bucket-a/user/user-y/ and so on. As a Developer Associate, which of the following IAM constructs would you recommend so that the policy snippet can be made generic for all team members and the manager does not need to create separate IAM policy for each team member ?<br>',
    answers: [
      { text: 'a. IAM policy variables', correct: true,  expli:' La respuesta correcta es: IAM policy variables <br>'+ 
      'Correct option:<br>'+
'IAM policy variables<br>'+
'Instead of creating individual policies for each user, you can use policy variables and create a single policy that applies to multiple users (a group policy). <br>'+
'Policy variables act as placeholders. When you make a request to AWS, the placeholder is replaced by a value from the request when the policy is evaluated.<br>'+
'As an example, the following policy gives each of the users in the group full programmatic access to a user-specific object (their own "home directory") in Amazon S3.<br>'+

'Incorrect options:<br>'+
'IAM policy principal - You can use the Principal element in a policy to specify the principal that is allowed or denied access to a resource (In IAM, a principal is a person or application that can make a request for an action or operation on an AWS resource. <br>'+
'The principal is authenticated as the AWS account root user or an IAM entity to make requests to AWS). You cannot use the Principal element in an IAM identity-based policy. You can use it in the trust policies for IAM roles and in resource-based policies.<br>'+
'IAM policy condition - The Condition element (or Condition block) lets you specify conditions for when a policy is in effect, like so - "Condition" : { "StringEquals": { "aws:username" : "johndoe" }} . This can not be used to address the requirements of the given use-case.<br>'+
'IAM policy resource - The Resource element specifies the object or objects that the statement covers. You specify a resource using an ARN. This can not be used to address the requirements of the given use-case.<br>'+
'Reference:<br>'+
'https://aws.amazon.com/blogs/security/writing-iam-policies-grant-access-to-userspecific-folders-in-an-amazon-s3-bucket/ <br>'},
      { text: 'b. IAM policy condition', correct: false,  expli:' ' },
	    { text: 'c. IAM policy principal', correct: false,  expli:' ' },
      { text: 'd. IAM policy resource ', correct: false,  expli:' ' }
    ],
	img: '',  
  },   
  {
    question: '/Explicación antes de Exam 3/ A gaming company hosts a browser-based application on AWS. The users of the application consume a large number of videos and images that are stored in Amazon S3. This content is the same for all users.  The application has increased in popularity, and millions of users worldwide are accessing these media files. The company wants to provide the files to the users while reducing the load on the origin. Which solution meets these requirements MOST cost-effectively? Seleccione una: ',
    answers: [
      { text: 'a. Deploy an Amazon ElastiCache for Memcached instance in front of the web servers.', correct: false,  expli:' ' },
      { text: 'b. Deploy an Amazon ElastiCache for Redis instance in front of the web servers.', correct: false,  expli:' ' },
	    { text: 'c. Deploy an Amazon CloudFront web distribution in front of the S3 bucket.', correct: true,  expli:' La respuesta correcta es: Deploy an Amazon CloudFront web distribution in front of the S3 bucket.' },
      { text: 'd. Deploy an AWS Global Accelerator accelerator in front of the web servers.', correct: false,  expli:' ' }
    ],
	img: '',  
  },   
  {
    question: '/Explicación antes de Exam 3/ A manager has requested that Developers using a dedicated testing account should only be able to use the t2.micro instance type. An Administrator has created an AWS Organizations SCP and applied it to the correct OU. However, Developers are still able to launch other instance types. What needs to be corrected in the SCP policy statement? Seleccione una:  <br>',
    answers: [
      { text: 'a. Change the Effect statement from Deny to Allow ', correct: false,  expli:' ' },
      { text: 'b. Change the date in the version statement to the current date', correct: false,  expli:' ' },
	    { text: 'c. Change the Resource statement to "arn:aws:ec2:*:*:t2.micro/*"', correct: false,  expli:' ' },
      { text: 'd. Change the Condition statement to StringNotEquals', correct: true,  expli:'La respuesta correcta es: Change the Condition statement to StringNotEquals <br>'+
      'The Condition statement should use the StringNotEquals as this is policy uses a deny effect. This change will result in denying any ec2:RunInstances requests where the ec2:InstanceType is not t2.micro. <br>'+
'CORRECT: "Change the Condition statement to StringNotEquals" is the correct answer. <br>'+
'INCORRECT: "Change the Resource statement to "arn:aws:ec2:*:*:t2.micro/*"" is incorrect. This is not the correct syntax. <br>'+
'INCORRECT: "Change the Effect statement from Deny to Allow" is <br>'+
'incorrect. This would not deny the ability to launch other instance types. <br>'+
'INCORRECT: "Change the date in the version statement to the current date" is incorrect. This is not necessary and will not resolve the issue <br>' }
    ],
	img: './aws/question15_exam3_65p.png',  
  },   
  {
    question: '/Explicación antes de Exam 3/ A firm runs its technology operations on a fleet of Amazon EC2 instances. The firm needs a certain software to be available on the instances to support their daily workflows. The developer team has been told to use the user data feature of EC2 instances. Which of the following are true about the user data EC2 configuration? ( Select two) Seleccione una o más de una: <br>',
    answers: [
      { text: 'a. By default, scripts entered as user data do not have root user privileges for executing', correct: false,  expli:' ' },
      { text: 'b. By default, scripts entered as user data are executed with root user privileges', correct: true,  expli:' una respuesta correcta es : By default, scripts entered as user data are executed with root user privileges' },
	    { text: 'c. By default, user data runs only during the boot cycle when you first launch an instance ', correct: true,  expli:'una respuesta correcta es : By default, user data runs only during the boot cycle when you first launch an instance <br>'+
      'Correct options: <br>'+
'User Data is generally used to perform common automated configuration tasks and even run scripts after the instance starts. When you launch an instance in Amazon EC2, you can pass two types of user data - shell scripts and cloud-init directives. You can also pass this data into the launch wizard as plain text or as a file. <br>'+
'By default, scripts entered as user data are executed with root user privileges - Scripts entered as user data are executed as the root user, hence do not need the sudo command in the script. Any files you create will be owned by root; if you need non-root users to have file access, you should modify the permissions accordingly in the script. <br>'+
'By default, user data runs only during the boot cycle when you first launch an instance - By default, user data scripts and cloud-init directives run only during the boot cycle when you first launch an instance. You can update your configuration to ensure that your user data scripts and cloud-init directives run every time you restart your instance. <br>'+
'Incorrect options: <br>'+
'By default, user data is executed every time an EC2 instance is re-started - As discussed above, this is not a default configuration of the system. But, can be achieved by explicitly configuring the instance. <br>'+
'When an instance is running, you can update user data by using root user credentials - You can\'t change the user data if the instance is running (even by using root user credentials), but you can view it. <br>'+
'By default, scripts entered as user data do not have root user privileges for executing - Scripts entered as user data are executed as the root user, hence do not need the sudo command in the script. <br>'+
'Reference: <br>'+
'https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/user-data.html <br>'},
      { text: 'd. When an instance is running, you can update user data by using root user credentials', correct: false,  expli:' ' },
      { text: 'e. By default, user data is executed every time an EC2 instance is re-started ', correct: false,  expli:' ' }
    ],
	img: '',  
  },   
  {
    question: '/Explicación antes de Exam 3/ A company runs an online marketplace web application on AWS. The application serves hundreds of thousands of users during peak hours. The company needs a scalable, near-real-time solution to share the details of millions of financial transactions with several other internal applications. Transactions also need to be processed to remove sensitive data before being stored in a document database for low-latency retrieval. What should a solutions architect recommend to meet these requirements? Seleccione una:',
    answers: [
      { text: 'a. Stream the transactions data into Amazon Kinesis Data Streams. Use AWS Lambda integration to remove sensitive data from every transaction and then store the transactions data in Amazon DynamoDB. Other applications can consume the transactions data off the Kinesis data stream. ', correct: true,  expli:' La respuesta correcta es: Stream the transactions data into Amazon Kinesis Data Streams. Use AWS Lambda integration to remove sensitive data from every transaction and then store the transactions data in Amazon DynamoDB. Other applications can consume the transactions data off the Kinesis data stream.' },
      { text: 'b. Store the batched transactions data in Amazon S3 as files. Use AWS Lambda to process every file and remove sensitive data before updating the files in Amazon S3. The Lambda function then stores the data in Amazon DynamoDB. Other applications can consume transaction files stored in Amazon S3.', correct: false,  expli:' ' },
	    { text: 'c. Store the transactions data into Amazon DynamoDB. Set up a rule in DynamoDB to remove sensitive data from every transaction upon write. Use DynamoDB Streams to share the transactions data with other applications.', correct: false,  expli:' ' },
      { text: 'd. Stream the transactions data into Amazon Kinesis Data Firehose to store data in Amazon DynamoDB and Amazon S3. Use AWS Lambda integration with Kinesis Data Firehose to remove sensitive data. Other applications can consume the data stored in Amazon S3.', correct: false,  expli:' ' }
    ],
	img: '',  
  },   
  {
    question: '/Explicación antes de Exam 3/ You have created an Elastic Load Balancer that has marked all the EC2 instances in the target group as unhealthy. Surprisingly, when you enter the IP address of the EC2 instances in your web browser, you can access your website. What could be the reason your instances are being marked as unhealthy? (Select two) Seleccione una o más de una: ',
    answers: [
      { text: 'a. The route for the health check is misconfigured', correct: true,  expli:' una respuesta correcta es : The route for the health check is misconfigured' },
      { text: 'b. Your web-app has a runtime that is not supported by the Application Load Balancer', correct: false,  expli:' ' },
	    { text: 'c. You need to attach Elastic IP to the EC2 instances', correct: false,  expli:' ' },
      { text: 'd. The EBS volumes have been improperly mounted ', correct: false,  expli:' ' },
      { text: 'e. The security group of the EC2 instance does not allow for traffic from the security group of the Application Load Balancer ', correct: true,  expli:' una respuesta correcta es : The security group of the EC2 instance does not allow for traffic from the security group of the Application Load Balancer <br>'+
      'Correct options <br>'+
'The security group of the EC2 instance does not allow for traffic from the security group of the Application Load Balancer The route for the health check is misconfigured You must ensure that your load balancer can communicate with registered targets on both the listener port and the health check port.  <br>'+
'Whenever you add a listener to your load balancer or update the health check port for a target group used by the load balancer to route requests, you must verify that the security groups associated with the load balancer allow traffic on the new port in both directions. <br>'+

'Incorrect options: <br>'+
'The EBS volumes have been improperly mounted - You can access the website using the IP address which means there is no issue with the EBS volumes. So this option is not correct. <br>'+
'Your web-app has a runtime that is not supported by the Application Load Balancer - There is no connection between a web app and the application load balancer.  <br>'+
'This option has been added as a distractor. <br>'+
'You need to attach Elastic IP to the EC2 instances - This option is a distractor as <br>'+
'Elastic IPs do not need to be assigned to EC2 instances while using an Application Load Balancer. <br>'+
'References: <br>'+
'https://docs.aws.amazon.com/elasticloadbalancing/latest/application/loadbalancer-update-security-groups.html  <br>' }
    ],
	img: '',  
  },   
  {
    question: '/Explicación antes de Exam 3/ A SaaS company runs a HealthCare web application that is used worldwide by users. There have been requests by mobile developers to expose public APIs for the application-specific functionality. You decide to make the APIs available to mobile developers as product offerings. Which of the following options will allow you to do that? Seleccione una:',
    answers: [
      { text: 'a. Use API Gateway Usage Plans ', correct: true,  expli:'La respuesta correcta es: Use API Gateway Usage Plans <br>'+
      'Correct option: <br>'+
'Use API Gateway Usage Plans Amazon API Gateway is an AWS service for creating, publishing, maintaining, monitoring, and securing REST, HTTP, and WebSocket APIs at any scale.  <br>'+
'API developers can create APIs that access AWS or other web services, as well as data stored in the AWS Cloud. <br>'+
'How API Gateway Works: <br>'+
'via - https://aws.amazon.com/api-gateway/ <br>'+
'A usage plan specifies who can access one or more deployed API stages and methods—and also how much and how fast they can access them. The plan uses API keys to identify API clients and meters access to the associated API stages for each key. <br>'+
'You can configure usage plans and API keys to allow customers to access selected APIs at agreed-upon request rates and quotas that meet their business requirements and budget constraints. <br>'+
'Incorrect options: <br>'+
'Use AWS Billing Usage Plans - AWS Billing and Cost Management is the service that you use to pay your AWS bill, monitor your usage, and analyze and control your costs.  <br>'+
'There is no such thing as AWS Billing Usage Plans.  <br>'+
'You cannot use AWS Billing to set up public APIs for the application. <br>'+
'Use CloudFront Usage Plans - Amazon CloudFront is a fast content delivery network (CDN) service that securely delivers data, videos, applications, and APIs to customers globally with low latency, high transfer speeds, all within a developerfriendly environment.  <br>'+
'There is no such thing as CloudFront Usage Plans. You cannot use CloudFront to set up public APIs for the application. <br>'+
'Use AWS Lambda Custom Authorizers - Lambda is a separate service than Gateway API, therefore, it cannot be used to determine the API usage limits. <br>'+
'Reference: <br>'+
'https://docs.aws.amazon.com/apigateway/latest/developerguide/api-gateway-apiusage-plans.html <br>' },
      { text: 'b. Use AWS Lambda Custom Authorizers', correct: false,  expli:' ' },
	    { text: 'c. Use AWS Billing Usage Plans', correct: false,  expli:' ' },
      { text: 'd. Use CloudFront Usage Plans', correct: false,  expli:' ' }
    ],
	img: '',  
  },   
  {
    question: '/Explicación antes de Exam 3/ A distributed application runs across many Amazon EC2 instances and processes large quantities of data. The application is designed to handle processing interruptions without causing issues. An Administrator needs to determine the MOST cost-effective pricing model for this use case. Which EC2 pricing model should the Administrator use? Seleccione una: ',
    answers: [
      { text: 'a. Spot Instances ', correct: true,  expli:' La respuesta correcta es: Spot Instances <br>'+
      'The most cost-effective pricing model for this use case is to use Spot instances. <br>'+
'With Spot instances you need to be able to handle the termination of resources when AWS need the capacity back. <br>'+
'Therefore, it should only be used with applications that can accept processing interruptions.  <br>'+
'In this case this distributed application can handle the processing interruptions so the best way to lower costs is to use Spot instances. <br>'+
'CORRECT: "Spot Instances" is the correct answer. <br>'+
'INCORRECT: "Dedicated Hosts" is incorrect. This is a more expensive option and there are no requirements for the use of dedicated hosts. <br>'+
'INCORRECT: "On-Demand Instances" is incorrect. There are no cost savings to be gained by using on-demand instances. <br>'+
'INCORRECT: "Reserved Instances" is incorrect. This would be a good pricing model for longer term (1 or 3 years) use cases for steady-state workloads. For this particular scenario, Spot instances are better to further lower costs. <br>' },
      { text: 'b. Reserved Instances', correct: false,  expli:' ' },
	    { text: 'c. On-Demand Instances', correct: false,  expli:' ' },
      { text: 'd. Dedicated Hosts', correct: false,  expli:' ' }
    ],
	img: '',  
  },   
  {
    question: '/Explicación antes de Exam 3/ The performance of an Amazon RDS MySQL database has been suffering during a recent busy period. An Architect noticed that database queries were running more slowly than is acceptable. Amazon CloudWatch metrics show that the CPU utilization was reaching close to 100%. Which action should the Administrator take to resolve this issue? Seleccione una:',
    answers: [
      { text: 'a. Enable the Multi-AZ feature for the RDS instance to enable extra capacity.', correct: false,  expli:' ' },
      { text: 'b. Scale horizontally by adding additional RDS MySQL nodes to offload write requests. ', correct: false,  expli:' ' },
	    { text: 'c. Modify the RDS MySQL instance so it is a larger instance type.', correct: true,  expli:' La respuesta correcta es: Modify the RDS MySQL instance so it is a larger instance type.<br>'+
      'There are two ways to scale a database when you need more capacity to serve reads. The first option is to use a Read Replica which can be a target for queries. This scales the database horizontally and is possibly the best solution for this specific scenario. However, it was not provided as an answer. The other way to scale the database is to modify RDS to use a larger instance type. This will provide more CPU and RAM and enable the database to perform better. <br>'+
'Note that you cannot scale writes horizontally, so for use cases where the writes need to be scaled, you only have the single option of scaling up by changing instance types. CORRECT: "Modify the RDS MySQL instance so it is a larger instance type" is the correct answer. <br>'+
'INCORRECT: "Configure Amazon CloudFront to cache database queries and reduce load on RDS" is incorrect. You cannot use CloudFront in front of a database to cache queries. CloudFront would be placed in front of your application servers or ELBs to cache certain content such as images and videos. <br>'+
'INCORRECT: "Scale horizontally by adding additional RDS MySQL nodes to offload write requests" is incorrect. You cannot offload writes to additional RDS MySQL nodes. There is only ever a single writable node in RDS even in a multi-AZ deployment. <br>'+
'INCORRECT: "Enable the Multi-AZ feature for the RDS instance to enable extra capacity" is incorrect. This does enable you to use the extra capacity for reading or writing, it is simply a replicated copy of the primary database used for disaster recovery. <br> '},
      { text: 'd. Configure Amazon CloudFront to cache database queries and reduce load on RDS.', correct: false,  expli:' ' }
    ],
	img: '',  
  },   
  {
    question: '/Explicación antes de Exam 3/ An application is hosted by a 3rd party and exposed at app.example.com. You would like to have your users access your application using www.mydomain.com, which you own and manage under Route 53. What Route 53 record should you create? Seleccione una: ',
    answers: [
      { text: 'a. Create a CNAME record ', correct: true,  expli:' La respuesta correcta es: Create a CNAME record <br>'+ 
      'Correct option: <br>'+ 
'Create a CNAME record A CNAME record maps DNS queries for the name of the current record, such as acme.example.com, to another domain (example.com or example.net) or subdomain (acme.example.com or zenith.example.org). <br>'+ 
'CNAME records can be used to map one domain name to another. Although you should keep in mind that the DNS protocol does not allow you to create a CNAME record for the top node of a DNS namespace, also known as the zone apex.  <br>'+ 
'For example, if you register the DNS name example.com, the zone apex is example.com. You cannot create a CNAME record for example.com, but you can create CNAME records for www.example.com, newproduct.example.com, and soon. <br>'+ 

'Incorrect options: <br>'+ 
'Create an A record - Used to point a domain or subdomain to an IP address. A record cannot be used to map one domain name to another.  <br>'+ 
'Create a PTR record - A Pointer (PTR) record resolves an IP address to a fullyqualified domain name (FQDN) as an opposite to what A record does. PTR records are also called Reverse DNS records. PTR record cannot be used to map one domain name to another. <br>'+ 
'Create an Alias Record - Alias records let you route traffic to selected AWS resources, such as CloudFront distributions and Amazon S3 buckets. They also let you route traffic from one record in a hosted zone to another record. 3rd party websites do not qualify for these as we have no control over those. Alias record cannot be used to map one domain name to another. <br>'+ 
'Reference: <br>'+ 
'https://docs.aws.amazon.com/Route53/latest/DeveloperGuide/resource-recordsets-choosing-alias-non-alias.html  <br>'},
      { text: 'b. Create an A record', correct: false,  expli:' ' },
	    { text: 'c. Create an Alias Record', correct: false,  expli:' ' },
      { text: 'd. Create a PTR record', correct: false,  expli:' ' }
    ],
	img: '',  
  },   
  {
    question: '/Explicación antes de Exam 3/ A development team needs to host a website that will be accessed by other teams. The website contents consist of HTML, CSS, client-side JavaScript, and images. Which method is the MOST cost-effective for hosting the website? Seleccione una',
    answers: [
      { text: 'a. Containerize the website and host it in AWS Fargate.', correct: false,  expli:' ' },
      { text: 'b. Configure an Application Load Balancer with an AWS Lambda target that uses the Express.js framework.', correct: false,  expli:' ' },
	    { text: 'c. Deploy a web server on an Amazon EC2 instance to host the website.', correct: false,  expli:' ' },
      { text: 'd. Create an Amazon S3 bucket and host the website there.', correct: true,  expli:' La respuesta correcta es: Create an Amazon S3 bucket and host the website there.' }
    ],
	img: '',  
  },   
  {
    question: '/Explicación antes de Exam 3/ Amazon Simple Queue Service (SQS) has a set of APIs for various actions supported by the service. As a developer associate, which of the following would you identify as correct regarding the CreateQueue API? (Select two) Seleccione una o más de una: ',
    answers: [
      { text: 'a. Queue tags are case insensitive. A new tag with a key identical to that of an existing tag overwrites the existing tag', correct: false,  expli:' ' },
      { text: 'b. The visibility timeout value for the queue is in seconds, which defaults to 30 seconds ', correct: true,  expli:'  una respuesta correcta es :The visibility timeout value for the queue is in seconds, which defaults to 30 seconds' },
	    { text: 'c. The length of time, in seconds, for which the delivery of all messages in the queue is delayed is configured using MessageRetentionPeriod attribute', correct: false,  expli:' ' },
      { text: 'd. You can\'t change the queue type after you create it ', correct: true,  expli:' una respuesta correcta es : You can\'t change the queue type after you create it <br>'+
                  'Correct options: <br>'+ 
                  'You can\'t change the queue type after you create it - You can\'t change the queue type after you create it and you can\'t convert an existing standard queue into a FIFO queue.  <br>'+ 
                  'You must either create a new FIFO queue for your application or delete your existing standard queue and recreate it as a FIFO queue. <br>'+ 
                  'The visibility timeout value for the queue is in seconds, which defaults to 30 seconds - The visibility timeout for the queue is in seconds.  <br>'+ 
                  'Valid values are: An integer from 0 to 43,200 (12 hours), the Default value is 30. <br>'+ 
                  'Incorrect options: <br>'+ 
                  'The dead-letter queue of a FIFO queue must also be a FIFO queue. Whereas, the dead-letter queue of a standard queue can be a standard queue or a FIFO queue - The dead-letter queue of a FIFO queue must also be a FIFO queue. Similarly, the dead-letter queue of a standard queue must also be a standard queue.  <br>'+ 
                  'The length of time, in seconds, for which the delivery of all messages in the queue is delayed is configured using MessageRetentionPeriod attribute - The length of time, in seconds, for which the delivery of all messages in the queue is delayed is configured using DelaySeconds attribute.  <br>'+ 
                  'MessageRetentionPeriod attribute controls the length of time, in seconds, for which Amazon SQS retains a message.  <br>'+ 
                  'Queue tags are case insensitive. A new tag with a key identical to that of an existing tag overwrites the existing tag - Queue tags are case-sensitive. A new tag with a key identical to that of an existing tag overwrites the existing tag. To be able to tag a queue on creation, you must have the sqs:CreateQueue and sqs:TagQueue permissions. <br>'+ 
                  'Reference: <br>'+ 
                  'https://docs.aws.amazon.com/AWSSimpleQueueService/latest/APIReference/API_CreateQueue.html <br>' },
      { text: 'e. The dead-letter queue of a FIFO queue must also be a FIFO queue. Whereas, the dead-letter queue of a standard queue can be a standard queue or a FIFO queue', correct: false,  expli:' ' }
    ],
	img: '',  
  },   
  {
    question: '/Explicación antes de Exam 3/ A company needs to review its AWS Cloud deployment to ensure that its Amazon S3 buckets do not have unauthorized configuration changes. What should a solutions architect do to accomplish this goal? Seleccione una: ',
    answers: [
      { text: 'a. Turn on Amazon S3 server access logging. Configure Amazon EventBridge (Amazon Cloud Watch Events).', correct: false,  expli:' ' },
      { text: 'b. Turn on AWS Config with the appropriate rules ', correct: true,  expli:'La respuesta correcta es: Turn on AWS Config with the appropriate rules ' },
	    { text: 'c. Turn on AWS Trusted Advisor with the appropriate checks.', correct: false,  expli:' ' },
      { text: 'd. Turn on Amazon Inspector with the appropriate assessment template.', correct: false,  expli:' ' }
    ],
	img: '',  
  },   
  {
    question: '/Explicación antes de Exam 3/ A company recently launched a variety of new workloads on Amazon EC2 instances in its AWS account. The company needs to create a strategy to access and administer the instances remotely and securely. The company needs to implement a repeatable process that works with native AWS services and follows the AWS Well-Architected Framework. Which solution will meet these requirements with the LEAST operational overhead? Seleccione una:',
    answers: [
      { text: 'a. Use the EC2 serial console to directly access the terminal interface of each instance for administration.', correct: false,  expli:' ' },
      { text: 'b. Attach the appropriate IAM role to each existing instance and new instance. Use AWS Systems Manager Session Manager to establish a remote SSH session.', correct: true,  expli:' La respuesta correcta es: Attach the appropriate IAM role to each existing instance and new instance. Use AWS Systems Manager Session Manager to establish a remote SSH session.' },
	    { text: 'c. Create an administrative SSH key pair. Load the public key into each EC2 instance. Deploy a bastion host in a public subnet to provide a tunnel for administration of each instance.', correct: false,  expli:' ' },
      { text: 'd. Establish an AWS Site-to-Site VPN connection. Instruct administrators to use their local on-premises machines to connect directly to the instances by using SSH keys across the VPN tunnel. ', correct: false,  expli:' ' }
    ],
	img: '',  
  },   
  {
    question: '/Explicación antes de Exam 3/ An Administrator has configured an Amazon EC2 instance in a public subnet for remote access over SSH. The Administrator is able to establish an SSH connection from an on-premises network via the internet but is unable to ping the instance. What is the most likely reason for this? Seleccione una: ',
    answers: [
      { text: 'a. The instance is in a VPC that does not have an internet gateway.', correct: false,  expli:' ' },
      { text: 'b. The instance does not have an Elastic IP address', correct: false,  expli:' ' },
	    { text: 'c. The instance is behind a NAT gateway.', correct: false,  expli:' ' },
      { text: 'd. The instance’s security group does not allow ICMP traffic. ', correct: true,  expli:' La respuesta correcta es: The instance’s security group does not allow ICMP traffic. <br>'+
      'The most likely explanation is that the instance’s security group does not have a rule allowing the Internet Control Message Protocol (ICMP). <br>'+ 
 'This protocol must be allowed for ICMP ping requests to be successful. <br>'+ 
'CORRECT: "The instance’s security group does not allow ICMP traffic" is the correct answer. <br>'+ 
'INCORRECT: "The instance does not have an Elastic IP address" is incorrect.  <br>'+ 
'This does not matter; the instance must have a public IP address as an SSH connection has been established. <br>'+ 
'INCORRECT: "The instance is in a VPC that does not have an internet gateway" is incorrect. If this is the case, no connections would be possible. <br>'+ 
'INCORRECT: "The instance is behind a NAT gateway" is incorrect. If this is the case, no connections would be possible <br>' }
    ],
	img: '',  
  },   
  {
    question: '/Explicación antes de Exam 3/ An AWS Lambda function has been connected to an Amazon VPC and is no longer able to connect to an external service on the internet. How can this issue be resolved? Seleccione una:',
    answers: [
      { text: 'a. Enable enhanced VPC routing for the AWS Lambda function.', correct: false,  expli:' ' },
      { text: 'b. Create a virtual private gateway (VGW) to the subnet.', correct: false,  expli:' ' },
	    { text: 'c. Add an entry to the subnet route table pointing to a NAT gateway.', correct: true,  expli:' La respuesta correcta es: Add an entry to the subnet route table pointing to a NAT gateway. <br>'+
      'When you connect a function to a VPC, all outbound requests go through your VPC.  <br>'+ 
'To connect to the internet, configure your VPC to send outbound traffic from the function\'s subnet to a NAT gateway in a public subnet. <br>'+ 
'CORRECT: "Add an entry to the subnet route table pointing to a NAT gateway" is the correct answer. <br>'+ 
'INCORRECT: "Update the function code to avoid the VPC and connect directly" is incorrect. This is not possible. Once the function is connected to a VPC all traffic goes via the VPC. <br>'+ 
'INCORRECT: "Enable enhanced VPC routing for the AWS Lambda function" is incorrect. There is no such thing in relation to Lambda (it exists for Amazon RedShift). <br>'+ 
'INCORRECT: "Create a virtual private gateway (VGW) to the subnet" is <br>'+ 
'incorrect. A VGW is used for connecting to an on-premises network using an AWS Managed VPN. <br>' },
      { text: 'd. Update the function code to avoid the VPC and connect directly.', correct: false,  expli:' ' }
    ],
	img: '',  
  },   
  {
    question: '/Explicación antes de Exam 3/ A developer has been asked to create a web application to be deployed on EC2 instances. The developer just wants to focus on writing application code without worrying about server provisioning, configuration and deployment. Which AWS service would you recommend for the given use-case? Seleccione una:',
    answers: [
      { text: 'a. Serverless Application Model', correct: false,  expli:' ' },
      { text: 'b. CodeDeploy ', correct: false,  expli:' ' },
	    { text: 'c. CloudFormation', correct: false,  expli:' ' },
      { text: 'd. Elastic Beanstalk', correct: true,  expli:' La respuesta correcta es: Elastic Beanstalk <br>'+
    'Correct option: <br>'+ 
'Elastic Beanstalk  <br>'+ 
'AWS Elastic Beanstalk provides an environment to easily deploy and run applications in the cloud.  <br>'+ 
'It is integrated with developer tools and provides a onestop  experience for you to manage the lifecycle of your applications. <br>'+ 
'AWS Elastic Beanstalk lets you manage all of the resources that run your application as environments where each environment runs only a single application version at a time. When an environment is being created, Elastic Beanstalk provisions all the required resources needed to run the application version.  <br>'+ 
'You don\'t need to worry about server provisioning, configuration, and deployment as that\'s taken care of by Beanstalk. <br>'+ 
'Benefits of Elastic Beanstalk:  <br>'+ 
'via - https://aws.amazon.com/elasticbeanstalk/ <br>'+ 
'Incorrect options: <br>'+ 
'CloudFormation - AWS CloudFormation is a service that gives developers and businesses an easy way to create a collection of related AWS and third-party resources and provision them in an orderly and predictable fashion.  <br>'+ 
'With CloudFormation, you still need to create a template to specify the type of resources you need, hence this option is not correct. <br>'+ 
'CodeDeploy - AWS CodeDeploy is a fully managed deployment service that automates software deployments to a variety of compute services such as Amazon EC2, AWS Fargate, AWS Lambda, and your on-premises servers.  <br>'+ 
'AWS CodeDeploy makes it easier for you to rapidly release new features, helps you avoid downtime during application deployment, and handles the complexity of updating your applications.  <br>'+ 
'It can deploy an application to an instance but it cannot provision the instance. <br>'+ 
'Serverless Application Model - The AWS Serverless Application Model (AWS SAM) is an open-source framework for building serverless applications.  <br>'+ 
'It provides shorthand syntax to express functions, APIs, databases, and event source mappings.  <br>'+ 
'You define the application you want with just a few lines per resource and model it using YAML. As the web application needs to be deployed on EC2 instances, so this option is ruled out. <br>'+ 
'References: <br>'+ 
'https://docs.aws.amazon.com/elasticbeanstalk/latest/dg/concepts.html <br>'+ 
'https://aws.amazon.com/cloudformation/ <br>' }
    ],
	img: '',  
  },   
  {
    question: '/Explicación antes de Exam 3/ A developer is configuring a bucket policy that denies upload object permission to any requests that do not include the x-amz-server-side-encryption header requesting server-side encryption with SSE-KMS for an Amazon S3 bucket examplebucket . Which of the following policies is the right fit for the given requirement? Seleccione una:',
    answers: [
      { text: 'a.'+ '<pre>'
      
    +`{
        "Version": "2012-10-17",
        "Id": "PutObjectPolicy",
        "Statement": [
          {
            "Sid": "DenyUnEncryptedObjectUploads",
            "Effect": "Deny",
            "Principal": "*",
            "Action": "s3:PutObject",
            "Resource": "arn:aws:s3:::examplebucket/*",
            "Condition": {
              "StringNotEquals": {
                "s3:x-amz-server-side-encryption": "aws:km s"
              }
            }
          }
        ]
    }`+

  '</pre>' +'', correct: true,  expli:''+ 
      
      
      
`Respuesta correcta      <br>

Correct option:     <br>
{ "Version":"2012-10-17", "Id":"PutObjectPolicy", "Statement":[{      <br>
"Sid":"DenyUnEncryptedObjectUploads", "Effect":"Deny", "Principal":" ",     <br>
"Action":"s3:PutObject", "Resource":"arn:aws:s3:::examplebucket/ ", "Condition":{     <br>
"StringNotEquals":{ "s3:x-amz-server-side-encryption":"aws:kms" } } } ] } - This     <br>
bucket policy denies upload object (s3:PutObject) permission if the request does     <br>
not include the x-amz-server-side-encryption header requesting server-side     <br>
encryption with SSE-KMS. To ensure that a particular AWS KMS CMK be used to     <br>
encrypt the objects in a bucket, you can use the s3:x-amz-server-sideencryption-     <br>
aws-kms-key-id condition key. To specify the AWS KMS CMK, you must     <br>
use a key Amazon Resource Name (ARN) that is in the "arn:aws:kms:region:acctid:     <br>
key/key-id" format.     <br>
When you upload an object, you can specify the AWS KMS CMK using the x-amzserver-     <br>
side-encryption-aws-kms-key-id header. If the header is not present in the     <br>
request, Amazon S3 assumes the AWS-managed CMK.     <br>

Incorrect options:     <br>
{ "Version":"2012-10-17", "Id":"PutObjectPolicy", "Statement":[{     <br>
"Sid":"DenyUnEncryptedObjectUploads", "Effect":"Deny", "Principal":" ",     <br>
"Action":"s3:PutObject", "Resource":"arn:aws:s3:::examplebucket/ ", "Condition":{     <br>
"StringEquals":{ "s3:x-amz-server-side-encryption":"aws:kms" } } } ] } - The     <br>
condition is incorrect in this policy. The condition should use StringNotEquals.     <br>
{ "Version":"2012-10-17", "Id":"PutObjectPolicy", "Statement":[{     <br>
"Sid":"DenyUnEncryptedObjectUploads", "Effect":"Deny", "Principal":" ",     <br>
"Action":"s3:GetObject", "Resource":"arn:aws:s3:::examplebucket/ ", "Condition":{     <br>
"StringNotEquals":{ "s3:x-amz-server-side-encryption":"aws:AES256" } } } ] } -     <br>
AES256 is used for Amazon S3-managed encryption keys (SSE-S3). Amazon S3     <br>
server-side encryption uses one of the strongest block ciphers available to encrypt     <br>
your data, 256-bit Advanced Encryption Standard (AES-256).     <br>
{ "Version":"2012-10-17", "Id":"PutObjectPolicy", "Statement":[{     <br>
"Sid":"DenyUnEncryptedObjectUploads", "Effect":"Deny", "Principal":" ",     <br>
"Action":"s3:PutObject", "Resource":"arn:aws:s3:::examplebucket/ ", "Condition":{     <br>
"StringNotEquals":{ "s3:x-amz-server-side-encryption":"false" } } } ] } - The condition     <br>
is incorrect in this policy. The condition should use "s3:x-amz-server-side-     <br>
encryption":"aws:kms" .     <br>
Reference:     <br>
https://docs.aws.amazon.com/AmazonS3/latest/userguide/UsingKMSEncryption.html     <br>

La respuesta correcta es:     <br>
<pre> {
  "Version": "2012-10-17",
  "Id": "PutObjectPolicy",
  "Statement": [
    {
      "Sid": "DenyUnEncryptedObjectUploads",
      "Effect": "Deny",
      "Principal": "*",
      "Action": "s3:PutObject",
      "Resource": "arn:aws:s3:::examplebucket/*",
      "Condition": {
        "StringNotEquals": {
          "s3:x-amz-server-side-encryption": "aws:km s"
        }
      }
    }
  ]
} </pre>`
      
       
      +'' },







      { text: 'b.'+ '<pre>'
      
    +`{
        "Version": "2012-10-17",
        "Id": "PutObjectPolicy",
        "Statement": [
          {
            "Sid": "DenyUnEncryptedObjectUploads",
            "Effect": "Deny",
            "Principal": "*",
            "Action": "s3:GetObject",
            "Resource": "arn:aws:s3:::examplebucket/*",
            "Condition": {
              "StringNotEquals": {
                "s3:x-amz-server-side-encryption": "aws:AES256"
              }
            }
          }
        ]
      }`+
      
      '</pre>' +'', correct: false,  expli:' ' },
      { text: 'c.'+ '<pre>'
      
      +`{
        "Version": "2012-10-17",
        "Id": "PutObjectPolicy",
        "Statement": [
          {
            "Sid": "DenyUnEncryptedObjectUploads",
            "Effect": "Deny",
            "Principal": "*",
            "Action": "s3:PutObject",
            "Resource": "arn:aws:s3:::examplebucket/*",
            "Condition": {
              "StringNotEquals": {
                "s3:x-amz-server-side-encryption": "false"
              }
            }
          }
        ]
      }`+
            
      '</pre>' +'', correct: false,  expli:' ' },
            { text: 'd.'+ '<pre>'
      
      +`{
          "Version": "2012-10-17",
          "Id": "PutObjectPolicy",
          "Statement": [
            {
              "Sid": "DenyUnEncryptedObjectUploads",
              "Effect": "Deny",
              "Principal": "*",
              "Action": "s3:PutObject",
              "Resource": "arn:aws:s3:::examplebucket/*",
              "Condition": {
                "StringEquals": {
                  "s3:x-amz-server-side-encryption": "aws:kms"
                }
              }
            }
          ]
        }`+
            
        '</pre>' +'', correct: false,  expli:' ' }
    ],
	img: '',  
  },   
  {
    question: '/Explicación antes de Exam 3/ ECS Fargate container tasks are usually spread across Availability Zones (AZs) and the underlying workloads need persistent cross-AZ shared access to the data volumes configured for the container tasks. Which of the following solutions is the best choice for these workloads? Seleccione una: ',
    answers: [
      { text: 'a. AWS Gateway Storage volumes', correct: false,  expli:' ' },
      { text: 'b. Bind mounts', correct: false,  expli:' ' },
	    { text: 'c. Amazon EFS volumes ', correct: true,  expli:' La respuesta correcta es: Amazon EFS volumes <br>'+
      'Correct option:<br>'+ 
'Amazon EFS volumes - EFS volumes provide a simple, scalable, and persistent file storage for use with your Amazon ECS tasks. With Amazon EFS, storage capacity is elastic, growing and shrinking automatically as you add and remove files. <br>'+ 
'Your applications can have the storage they need, when they need it. Amazon EFS volumes are supported for tasks hosted on Fargate or Amazon EC2 instances.<br>'+ 
'You can use Amazon EFS file systems with Amazon ECS to export file system data across your fleet of container instances. <br>'+ 
'That way, your tasks have access to the same persistent storage, no matter the instance on which they land. However, you must configure your container instance AMI to mount the Amazon EFS file system before the Docker daemon starts. Also, your task definitions must reference volume mounts on the container instance to use the file system.<br>'+ 
'Incorrect options:<br>'+ 
'Docker volumes - A Docker-managed volume that is created under /var/lib/docker/volumes on the host Amazon EC2 instance. Docker volume drivers (also referred to as plugins) are used to integrate the volumes with external storage systems, such as Amazon EBS. <br>'+ 
'The built-in local volume driver or a third-party volume driver can be used. Docker volumes are only supported when running tasks on Amazon EC2 instances.<br>'+ 
'Bind mounts - A file or directory on the host, such as an Amazon EC2 instance or AWS Fargate, is mounted into a container. Bind mount host volumes are supported for tasks hosted on Fargate or Amazon EC2 instances. Bind mounts provide temporary storage, and hence these are a wrong choice for this use case. <br>'+ 
'AWS Storage Gateway volumes - This is an incorrect choice, given only as a distractor.<br>'+ 
'Reference:<br>'+ 
'https://docs.aws.amazon.com/AmazonECS/latest/developerguide/using_data_volumes.html<br>'+ 
'https://aws.amazon.com/blogs/containers/amazon-ecs-availability-best-practices/<br>' },
      { text: 'd. Docker volumes', correct: false,  expli:' ' }
    ],
	img: '',  
  },   
  {
    question: '/Explicación antes de Exam 3/ A company is hosting its website by using Amazon EC2 instances behind an Elastic Load Balancer across multiple Availability Zones. The instances run in an EC2 Auto Scaling group. The website uses Amazon Elastic Block Store (Amazon EBS) volumes to store product manuals for users to download. The company updates the product content often, so new instances launched by the Auto Scaling group often have old data. It can take up to 30 minutes for the new instances to receive all the updates. The updates also require the EBS volumes to be resized during business hours. <br>'+ 
    ' The company wants to ensure that the product manuals are always up to date on all instances and that the architecture adjusts quickly to increased user demand. <br>'+
    ' A solutions architect needs to meet these requirements without causing the company to update its application code or adjust its website. <br> What should the solutions architect do to accomplish this goal? Seleccione una: ',
    answers: [
      { text: 'a. Store the product manuals in an EBS volume. Mount that volume to the EC2 instances. ', correct: false,  expli:' ' },
      { text: 'b. Store the product manuals in an Amazon S3 bucket. Redirect the downloads to this bucket.', correct: false,  expli:' ' },
	    { text: 'c. Store the product manuals in an Amazon S3 Standard-Infrequent Access (S3 Standard-IA) bucket. Redirect the downloads to this bucket.', correct: false,  expli:' ' },
      { text: 'd. Store the product manuals in an Amazon Elastic File System (Amazon EFS) volume. Mount that volume to the EC2 instances.', correct: true,  expli:'La respuesta correcta es: Store the product manuals in an Amazon Elastic File System (Amazon EFS) volume. Mount that volume to the EC2 instances. ' }
    ],
	img: '',  
  },   
  {
    question: '/Explicación antes de Exam 3/ A solutions architect needs to design a managed storage solution for a company\'s application that includes high-performance machine learning. This application runs on AWS Fargate, and the connected storage needs to have concurrent access to files and deliver high performance. Which storage option should the solutions architect recommend? Seleccione una:',
    answers: [
      { text: 'a. Create an Amazon S3 bucket for the application and establish an IAM role for Fargate to communicate with Amazon S3.', correct: false,  expli:' ' },
      { text: 'b. Create an Amazon Elastic File System (Amazon EFS) file share and establish an IAM role that allows Fargate to communicate with Amazon EFS.', correct: false,  expli:' ' },
	    { text: 'c. Create an Amazon Elastic Block Store (Amazon EBS) volume for the application and establish an IAM role that allows Fargate to communicate with Amazon EBS.', correct: false,  expli:' ' },
      { text: 'd. Create an Amazon FSx for Lustre file share and establish an IAM role that allows Fargate to communicate with FSx for Lustre. ', correct: true,  expli:' La respuesta correcta es: Create an Amazon FSx for Lustre file share and establish an IAM role that allows Fargate to communicate with FSx for Lustre.' }
    ],
	img: '',  
  },   
  {
    question: '/Explicación antes de Exam 3/ Your company has stored all application secrets in SSM Parameter Store. The audit team has requested to get a report to better understand when and who has issued API calls against SSM Parameter Store. Which of the following options can be used to produce your report? Seleccione una: ',
    answers: [
      { text: 'a. Use SSM Parameter Store List feature to get a record of actions taken by a user', correct: false,  expli:' ' },
      { text: 'b. Use SSM Parameter Store Access Logs in CloudWatch Logs to get a record of actions taken by a user', correct: false,  expli:' ' },
	    { text: 'c. Use AWS CloudTrail to get a record of actions taken by a user ', correct: true,  expli:' La respuesta correcta es: Use AWS CloudTrail to get a record of actions taken by a user <br>'+
      'Correct option:<br>'+
      'Use AWS CloudTrail to get a record of actions taken by a user AWS Systems Manager Parameter Store provides secure, hierarchical storage for configuration data management and secrets management. You can store data such as passwords, database strings, Amazon Machine Image (AMI) IDs, and license codes as parameter values. You can store values as plain text or encrypted data.<br>'+
      'AWS CloudTrail provides a record of actions taken by a user, role, or an AWS service in Systems Manager. <br>'+
      'Using the information collected by AWS CloudTrail, you can determine the request that was made to Systems Manager, the IP address from which the request was made, who made the request, when it was made, and additional details.<br>'+
      'Incorrect options:<br>'+
      'Use SSM Parameter Store List feature to get a record of actions taken by a user -<br>'+
      'This option has been added as a distractor.<br>'+
      'Use SSM Parameter Store Access Logs in CloudWatch Logs to get a record of actions taken by a user - CloudWatch Logs can be integrated but that will not help determine who issued API calls. <br>'+
      'Use SSM Parameter Store Access Logs in S3 to get a record of actions taken by a user - S3 Access Logs can be integrated but that will not help determine who issued API calls. <br>' },
      { text: 'd. Use SSM Parameter Store Access Logs in S3 to get a record of actions taken by a user', correct: false,  expli:' ' }
    ],
	img: '',  
  },   
  {
    question: '/Explicación antes de Exam 3/ A company is looking at optimizing their Amazon EC2 instance costs. Few instances are sure to run for a few years, but the instance type might change based on business requirements. Which EC2 instance purchasing option should they opt to meet the reduced cost criteria? Seleccione una:',
    answers: [
      { text: 'a. Standard Reserved instances', correct: false,  expli:' ' },
      { text: 'b. Convertible Reserved instances ', correct: true,  expli:' La respuesta correcta es: Convertible Reserved instances <br>'+
      'Correct option: <br>'+
'Reserved Instances offer significant savings on Amazon EC2 costs compared to On-Demand Instance pricing.  <br>'+
'A Reserved Instance can be purchased for a one-year or three-year commitment, with the three-year commitment offering a bigger discount.  <br>'+
'Reserved instances come with two offering classes - Standard or Convertible. <br>'+
'Convertible Reserved instances - A Convertible Reserved Instance can be exchanged during the term for another Convertible Reserved Instance with new attributes including instance family, instance type, platform, scope, or tenancy. This is the best fit for the current requirement. <br>'+
'Incorrect options: <br>'+
'Elastic Reserved instances - This option has been added as a distractor. There are no Elastic Reserved Instance types. <br>'+
'Standard Reserved instances - With Standard Reserved Instances, some attributes, such as instance size, can be modified during the term; however, the instance family cannot be modified. You cannot exchange a Standard Reserved Instance, only modify it Scheduled Reserved instances - Scheduled Reserved Instances (Scheduled Instances) enable you to purchase capacity reservations that recur on a daily, <br>'+
'weekly, or monthly basis, with a specified start time and duration, for a one-year term.  <br>'+
'You reserve the capacity in advance so that you know it is available when you need it. <br>'+
'References: <br>'+
'https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/instance-purchasingoptions.html <br>'+
'https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/reserved-instancestypes.html <br>' },
	    { text: 'c. Elastic Reserved instances', correct: false,  expli:' ' },
      { text: 'd. Scheduled Reserved instances', correct: false,  expli:' ' }
    ],
	img: '',  
  },   
  {
    question: '/Explicación antes de Exam 3/ A bicycle sharing company is developing a multi-tier architecture to track the location of its bicycles during peak operating hours. The company wants to use these data points in its existing analytics platform. A solutions architect must determine the most viable multi-tier option to support this architecture. The data points must be accessible from the REST API. Which action meets these requirements for storing and retrieving location data? Seleccione una:',
    answers: [
      { text: 'a. Use Amazon API Gateway with Amazon Kinesis Data Analytics. ', correct: true,  expli:' La respuesta correcta es: Use Amazon API Gateway with Amazon Kinesis Data Analytics. <br>'+
      'Reference: <br>'+
      'https://aws.amazon.com/kinesis/data-analytics/<br>' },
      { text: 'b. Use Amazon QuickSight with Amazon Redshift.', correct: false,  expli:' ' },
	    { text: 'c. Use Amazon Athena with Amazon S3.', correct: false,  expli:' ' },
      { text: 'd. Use Amazon API Gateway with AWS Lambda.', correct: false,  expli:' ' }
    ],
	img: '',  
  },   
  {
    question: '/Explicación antes de Exam 3/ You are running workloads on AWS and have embedded RDS database connection strings within each web server hosting your applications. After failing a security audit, you are looking at a different approach to store your secrets securely and automatically rotate the database credentials. Which AWS service can you use to address this use-case? Seleccione una:',
    answers: [
      { text: 'a. Systems Manager', correct: false,  expli:' ' },
      { text: 'b. Secrets Manager', correct: true,  expli:' La respuesta correcta es: Secrets Manager <br>'+
      'Correct option: <br>'+
'Secrets Manager <br>'+
'AWS Secrets Manager enables you to easily rotate, manage, and retrieve database credentials, API keys, and other secrets throughout their lifecycle.  <br>'+
'Users and applications retrieve secrets with a call to Secrets Manager APIs, eliminating the need to hardcode sensitive information in plain text. Secrets Manager offers secret rotation with built-in integration for Amazon RDS, Amazon Redshift, and Amazon DocumentDB. <br>'+

'Incorrect options: <br>'+
'SSM Parameter Store - AWS Systems Manager Parameter Store provides secure, hierarchical storage for configuration data management and secrets management.  <br>'+
'You can store data such as passwords, database strings, and license codes as parameter values. SSM Parameter Store cannot be used to automatically rotate the database credentials.  <br>'+
'Systems Manager - AWS Systems Manager gives you visibility and control of your infrastructure on AWS. Systems Manager provides a unified user interface so you can view operational data from multiple AWS services and allows you to automate operational tasks across your AWS resources. Systems Manager cannot be used to store your secrets securely and automatically rotate the database credentials.  <br>'+
'KMS - AWS Key Management Service (KMS) makes it easy for you to create and manage cryptographic keys and control their use across a wide range of AWS services and in your applications. KMS cannot be used to store your secrets securely and automatically rotate the database credentials. <br>'+
'References: <br>'+
'https://aws.amazon.com/secrets-manager/ <br>'+
'https://docs.aws.amazon.com/systems-manager/latest/userguide/systemsmanager-paramstore.html <br>' },
	    { text: 'c. KMS', correct: false,  expli:' ' },
      { text: 'd. SSM Parameter Store ', correct: false,  expli:' ' }
    ],
	img: '',  
  },   
  {
    question: '/Explicación antes de Exam 3/ In addition to regular sign-in credentials, AWS supports Multi-Factor Authentication (MFA) for accounts with privileged access. Which of the following MFA mechanisms is NOT for root user authentication? Seleccione una:',
    answers: [
      { text: 'a. U2F security key ', correct: false,  expli:' ' },
      { text: 'b. SMS text message-based MFA', correct: true,  expli:' La respuesta correcta es: SMS text message-based MFA <br>'+
      'Correct options: <br>'+
      'SMS text message-based MFA - A type of MFA in which the IAM user settings include the phone number of the user\'s SMS-compatible mobile device.  <br>'+
      'When the user signs in, AWS sends a six-digit numeric code by SMS text message to the user\'s mobile device.  <br>'+
      'The user is required to type that code on a second webpage during sign-in.  <br>'+
      'SMS-based MFA is available only for IAM users, you cannot use this type of MFA with the AWS account root user. <br>'+

      'Incorrect options: <br>'+
      'Hardware MFA device - This hardware device generates a six-digit numeric code. <br>'+
      'The user must type this code from the device on a second webpage during sign-in.  <br>'+
      'Each MFA device assigned to a user must be unique.  <br>'+
      'A user cannot type a code from another user\'s device to be authenticated. Can be used for root user authentication.  <br>'+
      'U2F security key - A device that you plug into a USB port on your computer.  <br>'+
      'U2F is an open authentication standard hosted by the FIDO Alliance.  <br>'+
      'When you enable a U2F security key, you sign in by entering your credentials and then tapping the device instead of manually entering a code.  <br>'+
      'Virtual MFA devices - A software app that runs on a phone or other device and emulates a physical device. The device generates a six-digit numeric code.  <br>'+
      'The user must type a valid code from the device on a second webpage during sign-in.  <br>'+
      'Each virtual MFA device assigned to a user must be unique. A user cannot type a code from another user\'s virtual MFA device to authenticate. <br>'+
      'Reference: <br>'+
      'https://docs.aws.amazon.com/IAM/latest/UserGuide/id_credentials_mfa.html <br>' },
	    { text: 'c. Virtual MFA devices', correct: false,  expli:' ' },
      { text: 'd. Hardware MFA device', correct: false,  expli:' ' }
    ],
	img: '',  
  },   
  {
    question: '/Explicación antes de Exam 3/ A company is preparing to launch a public-facing web application in the AWS Cloud. The architecture consists of Amazon EC2 instances within a VPC behind an Elastic Load Balancer (ELB). A third-party service is used for the DNS. The company\'s solutions architect must recommend a solution to detect and protect against large-scale DDoS attacks. Which solution meets these requirements? Seleccione una:',
    answers: [
      { text: 'a. Enable AWS Shield and assign Amazon Route 53 to it.', correct: false,  expli:' ' },
      { text: 'b. Enable AWS Shield Advanced and assign the ELB to it.', correct: true,  expli:' La respuesta correcta es: Enable AWS Shield Advanced and assign the ELB to it.' },
	    { text: 'c. Enable Amazon GuardDuty on the account.', correct: false,  expli:' ' },
      { text: 'd. Enable Amazon Inspector on the EC2 instances.', correct: false,  expli:' ' }
    ],
	img: '',  
  },   
  {
    question: '/Explicación antes de Exam 3/ An application uses an Amazon RDS Multi-AZ DB instance. Due to new security compliance requirements an Administrator needs to encrypt the database. Which approach can the Administrator take to encrypt the database? Seleccione una:',
    answers: [
      { text: 'a. Take a snapshot of the RDS instance, copy and encrypt the snapshot, and then restore to the new RDS instance.', correct: true,  expli:' La respuesta correcta es: Take a snapshot of the RDS instance, copy and encrypt the snapshot, and then restore to the new RDS instance. <br>'+
      'You can only enable encryption for an Amazon RDS DB instance when you create it, not after the DB instance is created. However, because you can encrypt a copy of an unencrypted DB snapshot, you can effectively add encryption to an unencrypted DB instance. <br>'+
      'To do this you create a snapshot of your DB instance, and then create an encrypted copy of that snapshot. You can then restore a DB instance from the encrypted snapshot, and thus you have an encrypted copy of your original DB instance. <br>'+
      'CORRECT: "Take a snapshot of the RDS instance, copy and encrypt the snapshot, and then restore to the new RDS instance" is the correct answer. <br>'+
      'INCORRECT: "Encrypt the standby replica in the secondary Availability Zone and promote it to the primary instance" is incorrect. You cannot create an encrypted standby from an unencrypted primary instance. <br>'+
      'INCORRECT: "Create an encrypted read replica and promote the replica to master" is incorrect. You cannot create an encrypted read replica from an unencrypted master. <br>'+
      'INCORRECT: "Use the RDS management console to enable encryption for the database" is incorrect. You cannot add encryption to an existing instance using the RDS management console. <br>' },
      { text: 'b. Use the RDS management console to enable encryption for the database. ', correct: false,  expli:' ' },
	    { text: 'c. Create an encrypted read replica and promote the replica to master.', correct: false,  expli:' ' },
      { text: 'd. Encrypt the standby replica in the secondary Availability Zone and promote it to the primary instance.', correct: false,  expli:' ' }
    ],
	img: '',  
  },   
  {
    question: '/Explicación antes de Exam 3/ A company is reviewing a recent migration of a three-tier application to a VPC. The security team discovers that the principle of least privilege is not being applied to Amazon EC2 security group ingress and egress rules between the application tiers. What should a solutions architect do to correct this issue? Seleccione una:',
    answers: [
      { text: 'a. Create security group rules using the security group ID as the source or destination.', correct: true,  expli:'La respuesta correcta es: Create security group rules using the security group ID as the source or destination. ' },
      { text: 'b. Create security group rules using the subnet CIDR blocks as the source or destination.', correct: false,  expli:' ' },
	    { text: 'c. Create security group rules using the VPC CIDR blocks as the source or destination.', correct: false,  expli:' ' },
      { text: 'd. Create security group rules using the instance ID as the source or destination ', correct: false,  expli:' ' }
    ],
	img: '',  
  },   
  {
    question: '/Explicación antes de Exam 3/ As part of his development work, an AWS Certified Developer Associate is creating policies and attaching them to IAM identities. After creating necessary Identity based policies, he is now creating Resource-based policies. Which is the only resource-based policy that the IAM service supports? Seleccione una:',
    answers: [
      { text: 'a. Permissions boundary ', correct: false,  expli:' ' },
      { text: 'b. Trust policy', correct: true,  expli:' La respuesta correcta es: Trust policy <br>'+
      'Correct option: <br>'+
'You manage access in AWS by creating policies and attaching them to IAM identities (users, groups of users, or roles) or AWS resources.  <br>'+
'A policy is an object in AWS that, when associated with an identity or resource, defines their permissions.  <br>'+
'Resource-based policies are JSON policy documents that you attach to a resource such as an Amazon S3 bucket.  <br>'+
'These policies grant the specified principal permission to perform specific actions on that resource and define under what conditions this applies. <br>'+
'Trust policy - Trust policies define which principal entities (accounts, users, roles, and federated users) can assume the role.  <br>'+
'An IAM role is both an identity and a resource that supports resource-based policies. For this reason, you must attach both a trust policy and an identity-based policy to an IAM role.  <br>'+
'The IAM service supports only one type of resource-based policy called a role trust policy, which is attached to an IAM role. <br>'+


'Incorrect options: <br>'+
'AWS Organizations Service Control Policies (SCP) - If you enable all features of AWS organization, then you can apply service control policies (SCPs) to any or all of your accounts. <br>'+
'SCPs are JSON policies that specify the maximum permissions for an organization or organizational unit (OU). The SCP limits permissions for entities in member accounts, including each AWS account root user. An explicit deny in any of these policies overrides the allow. <br>'+
'Access control list (ACL) - Access control lists (ACLs) are service policies that allow you to control which principals in another account can access a resource. <br>'+
'ACLs cannot be used to control access for a principal within the same account.  <br>'+
'Amazon S3, AWS WAF, and Amazon VPC are examples of services that support ACLs. <br>'+
'Permissions boundary - AWS supports permissions boundaries for IAM entities (users or roles).  <br>'+
'A permissions boundary is an advanced feature for using a managed policy to set the maximum permissions that an identity-based policy can grant to an IAM entity. <br>'+
'An entity\'s permissions boundary allows it to perform only the actions that are allowed by both its identity-based policies and its permissions boundaries. <br>'+
'References: <br>'+
'https://docs.aws.amazon.com/IAM/latest/UserGuide/access_policies.html#policies_resource-based <br>'+
'https://docs.aws.amazon.com/IAM/latest/UserGuide/access_policies_boundaries.html <br>' },
	    { text: 'c. AWS Organizations Service Control Policies (SCP) ', correct: false,  expli:' ' },
      { text: 'd. Access control list (ACL)', correct: false,  expli:' ' }
    ],
	img: '',  
  },   
  {
    question: '/Explicación antes de Exam 3/ You\'re a developer doing contract work for the media sector. Since you work alone, you opt for technologies that require little maintenance, which allows you to focus more on your coding.  You have chosen AWS Elastic Beanstalk to assist with the deployment of your applications. While reading online documentation you find that Elastic Beanstalk relies on another AWS service to provision your resources. Which of the following represents this AWS service? Seleccione una:',
    answers: [
      { text: 'a. Systems Manager', correct: true,  expli:' una respuesta correcta es : Systems Manager' },
      { text: 'b. CloudFormation ', correct: true,  expli:' una respuesta correcta es : CloudFormation <br>'+
      'Correct option: <br>'+
'CloudFormation <br>'+
'AWS CloudFormation is a service that gives developers and businesses an easy way to create a collection of related AWS and third-party resources and provision them in an orderly and predictable fashion. <br>'+
'How CloudFormation Works: <br>'+
'via - https://aws.amazon.com/cloudformation/  <br>'+
'AWS Elastic Beanstalk provides an environment to easily deploy and run applications in the cloud. It is integrated with developer tools and provides a onestop experience for you to manage the lifecycle of your applications.  <br>'+
'Elastic Beanstalk uses AWS CloudFormation to launch the resources in your environment and propagate configuration changes. AWS CloudFormation supports Elastic Beanstalk application environments as one of the AWS resource types.  <br>'+
'This allows you, for example, to create and manage an AWS Elastic Beanstalk–hosted application along with an RDS database to store the application data. <br>'+
'Benefits of Elastic Beanstalk:  <br>'+
'via - https://aws.amazon.com/elasticbeanstalk/ <br>'+

'Incorrect options: <br>'+
'CodeCommit - AWS CodeCommit is a fully-managed source control service that hosts secure Git-based repositories. <br>'+
'You can use the Elastic Beanstalk Command Line Interface (CLI) to deploy your application directly from an AWS CodeCommit repository.  <br>'+
'CodeCommit cannot be used to provision your resources for the Elastic Beanstalk application.  <br>'+
'CodeDeploy - AWS CodeDeploy is a fully managed deployment service that automates software deployments to a variety of compute services such as Amazon EC2, AWS Fargate, AWS Lambda, and your on-premises servers.  <br>'+
'AWS CodeDeploy makes it easier for you to rapidly release new features, helps you avoid downtime during application deployment, and handles the complexity of updating your applications.  <br>'+
'CodeDeploy cannot be used to provision your resources for the Elastic Beanstalk application. <br>'+
'Systems Manager - Using AWS Systems Manager, you can group resources, like Amazon EC2 instances, Amazon S3 buckets, or Amazon RDS instances, by application, view operational data for monitoring and troubleshooting, and take action on your groups of resources. <br>'+
'Systems Manager cannot be used to provision your resources for the Elastic Beanstalk application. <br>'+
'References: <br>'+
'https://aws.amazon.com/cloudformation/ <br>'+
'https://aws.amazon.com/elasticbeanstalk/ <br>' },
	    { text: 'c. CodeDeploy', correct: false,  expli:' ' },
      { text: 'd. CodeCommit', correct: false,  expli:' ' }
    ],
	img: '',  
  },  
  {
    question: '/Explicación antes de Exam 3/ The development team at an IT company wants to make changes to a current application written in Node.js and deployed on a Linux server. The team lead would like to decouple the application into microservices, package the application to a Docker container which is then run on the AWS infrastructure. Which AWS service is best suited for this change? Seleccione una:',
    answers: [
      { text: 'a. Step Functions ', correct: false,  expli:' ' },
      { text: 'b. ECR', correct: false,  expli:' ' },
	    { text: 'c. Lambda', correct: false,  expli:' ' },
      { text: 'd. ECS', correct: true,  expli:' La respuesta correcta es: ECS <br>'+
      'Correct option: <br>'+
'ECS <br>'+
'Amazon Elastic Container Service (Amazon ECS) is a highly scalable, fast, container management service that makes it easy to run, stop, and manage Docker containers on a cluster.  <br>'+
'You can host your cluster on a serverless infrastructure that is managed by Amazon ECS by launching your services or tasks using the Fargate launch type.  <br>'+
'For more control over your infrastructure, you can host your tasks on a cluster of Amazon Elastic Compute Cloud (Amazon EC2) instances that you manage by using the EC2 launch type. <br>'+
'Amazon ECS can be used to create a consistent deployment and build experience, manage, and scale batch and Extract-Transform-Load (ETL) workloads, and build sophisticated application architectures on a microservices model. <br>'+

'Incorrect options: <br>'+
'ECR - Amazon Elastic Container Registry (ECR) is a fully-managed Docker container registry that makes it easy for developers to store, manage, and deploy Docker container images.  <br>'+
'Amazon ECR is integrated with Amazon Elastic Container Service (ECS), simplifying your development to production workflow. <br>'+
'How ECR Works: <br>'+
'via - https://aws.amazon.com/ecr/ <br>'+
'Lambda - AWS Lambda lets you run code without provisioning or managing servers.  <br>'+
'You pay only for the compute time you consume. Lambda cannot be used to run Docker containers. <br>'+
'Step Functions - AWS Step Functions is a web service that enables you to coordinate the components of distributed applications and microservices using visual workflows. You build applications from individual components that each perform a discrete function, or task, allowing you to scale and change applications quickly.  <br>'+
'Step Functions cannot be used to run Docker containers. <br>'+
'How Step Functions Work: <br>'+
'via - https://aws.amazon.com/step-functions/ <br>'+

'References: <br>'+
'https://docs.aws.amazon.com/AmazonECS/latest/developerguide/Welcome.html <br>'+
'https://aws.amazon.com/ecr/ <br>' }
    ],
	img: '',  
  },  
  {
    question: '/Explicación antes de Exam 3/ A Company has identified that a security vulnerability affects a version of MariaDB that is being used with an Amazon RDS database instance. Who is responsible for ensuring that the patch is applied to the database? Seleccione una:',
    answers: [
      { text: 'a. Amazon Web Services (AWS). ', correct: true,  expli:' La respuesta correcta es: Amazon Web Services (AWS). <br>'+
      'Amazon RDS is a managed database service and AWS are responsible for patching the DB instance\'s underlying hardware, underlying operating system (OS), and database engine version. <br>'+
      'Required patching is automatically scheduled only for patches that are related to security and instance reliability. Such patching occurs infrequently (typically once every few months) and seldom requires more than a fraction of your maintenance window.<br>'+
      'CORRECT: "Amazon Web Services (AWS)" is the correct answer.<br>'+
      'INCORRECT: "The database vendor" is incorrect. The database vendor may release patches, but they are not responsible for applying them. <br>'+
      'INCORRECT: "The security department the company" is incorrect<br>' },
      { text: 'b. The security department the company.', correct: false,  expli:' ' },
	    { text: 'c. The database vendor.', correct: false,  expli:' ' },
      { text: 'd. The company’s Administrator.', correct: false,  expli:' ' }
    ],
	img: '',  
  },  
  {
    question: '/Explicación antes de Exam 3/ A company is planning to use an Amazon DynamoDB table for data storage. The company is concerned about cost optimization. The table will not be used on most mornings in the evenings, the read and write traffic will often be unpredictable. When traffic spikes occur they will happen very quickly. What should a solutions architect recommend? Seleccione una:',
    answers: [
      { text: 'a. Create a DynamoDB table with a global secondary Index.', correct: false,  expli:' ' },
      { text: 'b. Create a DynamoDB table in on-demand capacity mode.', correct: true,  expli:' La respuesta correcta es: Create a DynamoDB table in on-demand capacity mode.' },
	    { text: 'c. Create a DynamoDB table with provisioned capacity and auto scaling.', correct: false,  expli:' ' },
      { text: 'd. Create a DynamoDB table in provisioned capacity mode, and configure it as a global table. ', correct: false,  expli:' ' }
    ],
	img: '',  
  },  
  {
    question: '/Explicación antes de Exam 3/ An online learning company is migrating to the AWS Cloud. The company maintains its student records in a PostgreSQL database. The company needs a solution in which its data is available and online across multiple AWS Regions at all times. Which solution will meet these requirements with the LEAST amount of operational overhead? Seleccione una:',
    answers: [
      { text: 'a. Migrate the PostgreSQL database to a PostgreSQL cluster on Amazon EC2 instances.', correct: false,  expli:' ' },
      { text: 'b. Migrate the PostgreSQL database to an Amazon RDS for PostgreSQL DB instance with the Multi-AZ feature turned on.', correct: false,  expli:' ' },
	    { text: 'c. Migrate the PostgreSQL database to an Amazon RDS for PostgreSQL DB instance. Set up DB snapshots to be copied to another Region.', correct: false,  expli:' ' },
      { text: 'd. Migrate the PostgreSQL database to an Amazon RDS for PostgreSQL DB instance. Create a read replica in another Region. ', correct: true,  expli:' La respuesta correcta es: Migrate the PostgreSQL database to an Amazon RDS for PostgreSQL DB instance. Create a read replica in another Region.' }
    ],
	img: '',  
  },  
  {
    question: '/Explicación antes de Exam 3/ A company has primary and secondary data centers that are 580 miles (804.7 km) apart and interconnected with high-speed fiber-optic cable. The company needs a highly available and secure network connection between its data centers and a VPC on AWS for a mission-critical workload. A solutions architect must choose a connection solution that provides maximum resiliency. Which solution meets these requirements? Seleccione una:',
    answers: [
      { text: 'a. A single AWS Direct Connect connection from each of the primary and secondary data centers terminating at one Direct Connect location on two separate devices', correct: false,  expli:' ' },
      { text: 'b. Two AWS Direct Connect connections from each of the primary and secondary data centers terminating at two Direct Connect locations on two separate  devices.', correct: true,  expli:' La respuesta correcta es: Two AWS Direct Connect connections from each of the primary and secondary data centers terminating at two Direct Connect locations on two separate  devices.' },
	    { text: 'c. Two AWS Direct Connect connections from the primary data center terminating at two Direct Connect locations on two separate devices', correct: false,  expli:' ' },
      { text: 'd. A single AWS Direct Connect connection from each of the primary and secondary data centers terminating at one Direct Connect location on the same device ', correct: false,  expli:' ' }
    ],
	img: '',  
  },  
  {
    question: '/Explicación antes de Exam 3/ The security team has notified an Administrator that there may be a vulnerable version of software installed on some Amazon EC2 instances. How can the Administrator verify if the vulnerable software is installed on the EC2 instances with the LEAST operational overhead? Seleccione una:',
    answers: [
      { text: 'a. Create and run an Amazon Inspector assessment template. ', correct: true,  expli:' La respuesta correcta es: Create and run an Amazon Inspector assessment template. <br>'+
      'Amazon Inspector helps you discover potential security issues by using security rules to analyze your AWS resources.  <br>'+
'Amazon Inspector monitors and collects behavioral data (telemetry) about your resources.  <br>'+
'To get started, you create an assessment target (a collection of the AWS resources that you want Amazon Inspector to analyze).  <br>'+
'Next, you create an assessment template (a blueprint that you use to configure your assessment).  <br>'+
'You use the template to start an assessment run, which is the monitoring and analysis process that results in a set of findings. <br>'+
'CORRECT: "Create and run an Amazon Inspector assessment template" is the correct answer. <br>'+
'INCORRECT: "Connect to each instance using SSH and check the software version" is incorrect. This is very manual and not the most effective method. <br>'+
'INCORRECT: "Use AWS CloudTrail to verify Amazon EC2 API activity in the account" is incorrect. API activity will not identify software installed on an EC2 instance. <br>'+
'INCORRECT: "Write some custom code that uses AWS Lambda to check the instances" is incorrect. This is possible but more time consuming than just using the Inspector template. <br>' },
      { text: 'b. Use AWS CloudTrail to verify Amazon EC2 API activity in the account.', correct: false,  expli:' ' },
	    { text: 'c. Write some custom code that uses AWS Lambda to check the instances.', correct: false,  expli:' ' },
      { text: 'd. Connect to each instance using SSH and check the software version.', correct: false,  expli:' ' }
    ],
	img: '',  
  },  
  {
    question: '/Explicación antes de Exam 3/ A development team has configured inbound traffic for the relevant ports in both the Security Group of the EC2 instance as well as the Network Access Control List (NACL) of the subnet for the EC2 instance. The team is, however, unable to connect to the service running on the Amazon EC2 instance. As a developer associate, which of the following will you recommend to fix this issue? Seleccione una:',
    answers: [
      { text: 'a. Network ACLs are stateful, so allowing inbound traffic to the necessary ports enables the connection. Security Groups are stateless, so you must allow both inbound and outbound traffic', correct: false,  expli:' ' },
      { text: 'b. Security Groups are stateful, so allowing inbound traffic to the necessary ports enables the connection. Network ACLs are stateless, so you must  allow both inbound and outbound traffic ', correct: true,  expli:' La respuesta correcta es: Security Groups are stateful, so allowing inbound traffic to the necessary ports enables the connection. Network ACLs are stateless, so you must  allow both inbound and outbound traffic <br>'+
      'Correct option: <br>'+
'Security Groups are stateful, so allowing inbound traffic to the necessary ports enables the connection. Network ACLs are stateless, so you must allow both inbound and outbound traffic - Security groups are stateful, so allowing inbound traffic to the necessary ports enables the connection. Network ACLs are stateless, so you must allow both inbound and outbound traffic. <br>'+
'To enable the connection to a service running on an instance, the associated network ACL must allow both inbound traffic on the port that the service is listening on as well as allow outbound traffic from ephemeral ports. When a client connects to a server, a random port from the ephemeral port range (1024-65535) becomes the client\'s source port. <br>'+
'The designated ephemeral port then becomes the destination port for return traffic from the service, so outbound traffic from the ephemeral port must be allowed in the network ACL. <br>'+
'By default, network ACLs allow all inbound and outbound traffic.  <br>'+
'If your network ACL is more restrictive, then you need to explicitly allow traffic from the ephemeral port range. <br>'+
'If you accept traffic from the internet, then you also must establish a route through an internet gateway. If you accept traffic over VPN or AWS Direct Connect, then you must establish a route through a virtual private gateway. <br>'+

'Incorrect options: <br>'+
'Network ACLs are stateful, so allowing inbound traffic to the necessary ports enables the connection.  <br>'+
'Security Groups are stateless, so you must allow both inbound and outbound traffic - This is incorrect as already discussed.  <br>'+
'IAM Role defined in the Security Group is different from the IAM Role that is given access in the Network ACLs - This is a made-up option and just added as a distractor. <br>'+
'Rules associated with Network ACLs should never be modified from the command line. An attempt to modify rules from the command line blocks the rule and results in an erratic behavior - This option is a distractor. AWS does not support modifying rules of Network ACLs from the command line tool. <br>'+
'Reference: <br>'+
'https://aws.amazon.com/premiumsupport/knowledge-center/resolve-connectionsg-acl-inbound/ <br>' },
	    { text: 'c. Rules associated with Network ACLs should never be modified from the command line. An attempt to modify rules from the command line blocks the rule and results in an erratic behavior', correct: false,  expli:' ' },
      { text: 'd. IAM Role defined in the Security Group is different from the IAM Role that is given access in the Network ACLs', correct: false,  expli:' ' }
    ],
	img: '',  
  },  
  {
    question: '/Explicación antes de Exam 3/ A company runs a fleet of web servers using an Amazon RDS for PostgreSQL DB instance. After a routine compliance check, the company sets a standard that requires a recovery point objective (RPO) of less than 1 second for all its production databases. Which solution meets these requirements? Seleccione una:',
    answers: [
      { text: 'a. Enable auto scaling for the DB instance in one Availability Zone.', correct: false,  expli:' ' },
      { text: 'b. Configure the DB instance in one Availability Zone, and create multiple read replicas in a separate Availability Zone.', correct: false,  expli:' ' },
	    { text: 'c. Enable a Multi-AZ deployment for the DB instance. ', correct: true,  expli:' La respuesta correcta es: Enable a Multi-AZ deployment for the DB instance.' },
      { text: 'd. Configure the DB instance in one Availability Zone, and configure AWS Database Migration Service (AWS DMS) change data capture (CDC) tasks.', correct: false,  expli:' ' }
    ],
	img: '',  
  },  
  {
    question: '/Explicación antes de Exam 3/ A company run an application on a single Amazon EC2 instance in a single Availability Zone (AZ). The company requires that the application is made highly available. An Administrator has created an Application Load Balancer (ALB) and a launch configuration from the running instance. The Administrator needs to create an Auto Scaling group for the launch configuration. How should the Auto Scaling group be configured to make the application highly available? Seleccione una:',
    answers: [
      { text: 'a. Use at least 3 Availability Zones with a minimum size of 2, desired capacity of 2, and a maximum of 2.', correct: true,  expli:' La respuesta correcta es: Use at least 3 Availability Zones with a minimum size of 2, desired capacity of 2, and a maximum of 2. <br>'+
      'For high availability the Auto Scaling group should launch at least 2 instances in at least 2 AZs. Therefore, the minimum size of the ASG should be 2, the desired capacity should be 2, and the maximum should be 2. <br>'+
'CORRECT: "Use at least 3 Availability Zones with a minimum size of 2, desired capacity of 2, and a maximum of 2" is the correct answer. <br>'+
'INCORRECT: "Use at least 2 Availability Zones with a minimum size of 1, desired capacity of 1, and a maximum size of 1" is incorrect. This would result in an outage if the AZ with the 1 running instance fails. <br>'+
'INCORRECT: "Use at least 2 regions with a minimum size of 1, desired capacity of 1, and a maximum size of 1" is incorrect. You cannot select multiple regions in an ASG. <br>'+
'INCORRECT: "Use at least 3 regions with a minimum size of 2, desired capacity of 2, and a maximum size of 2" is incorrect. You cannot select multiple regions in an ASG. <br>' },
      { text: 'b. Use at least 3 regions with a minimum size of 2, desired capacity of 2, and a maximum size of 2.', correct: false,  expli:' ' },
	    { text: 'c. Use at least 2 regions with a minimum size of 1, desired capacity of 1, and a maximum size of 1.', correct: false,  expli:' ' },
      { text: 'd. Use at least 2 Availability Zones with a minimum size of 1, desired capacity of 1, and a maximum size of 1.', correct: false,  expli:' ' }
    ],
	img: '',  
  },  
  {
    question: '/Explicación antes de Exam 3/ You are creating a Cloud Formation template to deploy your CMS application running on an EC2 instance within your AWS account. Since the application will be deployed across multiple regions, you need to create a map of all the possible values for the base AMI. How will you invoke the !FindInMap function to fulfill this use case? Seleccione una:',
    answers: [
      { text: 'a. <pre> !FindInMap [ MapName, TopLevelKey ] </pre>', correct: false,  expli:' ' },
      { text: 'b. <pre> !FindInMap [ MapName ] </pre>', correct: false,  expli:' ' },
	    { text: 'c. <pre> !FindInMap [ MapName, TopLevelKey, SecondLevelKey ] </pre>', correct: true,  expli:' La respuesta correcta es: <pre> !FindInMap [ MapName, TopLevelKey, SecondLevelKey ] </pre> <br>'+
      'Correct option: <br>'+
'!FindInMap  <pre> [ MapName, TopLevelKey, SecondLevelKey ] </pre>- The intrinsic function <br>'+
'Fn::FindInMap returns the value corresponding to keys in a two-level map that is <br>'+
'declared in the Mappings section. YAML Syntax for the full function name: <br>'+
'Fn::FindInMap:  <pre> [ MapName, TopLevelKey, SecondLevelKey ] </pre><br>'+
'Short form of the above syntax is :  <pre> !FindInMap [ MapName, TopLevelKey, SecondLevelKey ] </pre> <br>'+
'Where, <br>'+
'MapName - Is the logical name of a mapping declared in the Mappings section that contains the keys and values. TopLevelKey - The top-level key name.  <br>'+
'Its value is a list of key-value pairs. SecondLevelKey - The second-level key name, which is set to one of the keys from the list assigned to TopLevelKey. <br>'+

'Incorrect options: <br>'+
' <pre> !FindInMap [ MapName, TopLevelKey ] </pre><br>'+
' <pre> !FindInMap [ MapName ]</pre> <br>'+
' <pre> !FindInMap [ MapName, TopLevelKey, SecondLevelKey, ThirdLevelKey ] </pre><br>'+
'These three options contradict the explanation provided above, hence these options are incorrect. <br>'+
'Reference: <br>'+
'https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/intrinsicfunction-reference-findinmap.html <br>' },
      { text: 'd. <pre> !FindInMap [ MapName, TopLevelKey, SecondLevelKey, ThirdLevelKey ] </pre>', correct: false,  expli:' ' }
    ],
	img: '',  
  },  
  {
    question: '/Explicación antes de Exam 3/ A company has been storing analytics data in an Amazon RDS instance for the past few years. The company asked a solutions architect to find a solution that allows users to access this data using an API. The expectation is that the application will experience periods of inactivity but could receive bursts of traffic within seconds. Which solution should the solutions architect suggest? Seleccione una:',
    answers: [
      { text: 'a. Set up an Amazon API Gateway and use Amazon EC2 with Auto Scaling.', correct: false,  expli:' ' },
      { text: 'b. Set up an Amazon API Gateway and use AWS Elastic Beanstalk.', correct: false,  expli:' ' },
	    { text: 'c. Set up an Amazon API Gateway and use Amazon ECS.', correct: false,  expli:' ' },
      { text: 'd. Set up an Amazon API Gateway and use AWS Lambda functions. ', correct: true,  expli:' La respuesta correcta es: Set up an Amazon API Gateway and use AWS Lambda functions. <br>'+
      'AWS Lambda - <br>'+
      'With Lambda, you can run code for virtually any type of application or backend service ג "€ all with zero administration.  <br>'+
      'Just upload your code and Lambda takes care of everything required to run and scale your code with high availability.  <br>'+
      'You can set up your code to automatically trigger from other AWS services or call it directly from any web or mobile app. <br>'+
      'How it works - <br>'+
      'Amazon API Gateway - <br>'+
      'Amazon API Gateway is a fully managed service that makes it easy for developers to create, publish, maintain, monitor, and secure APIs at any scale. APIs act as the "front door" for applications to access data, business logic, or functionality from your backend services.  <br>'+
      'Using API Gateway, you can create RESTful APIs and WebSocket APIs that enable real-time two-way communication applications.  <br>'+
      'API Gateway supports containerized and serverless workloads, as well as web applications. <br>'+
      'API Gateway handles all the tasks involved in accepting and processing up to hundreds of thousands of concurrent API calls, including traffic management, CORS support, authorization and access control, throttling, monitoring, and API version management.  <br>'+
      'API Gateway has no minimum fees or startup costs.  <br>'+
      'You pay for the API calls you receive and the amount of data transferred out and, with the API Gateway tiered pricing model, you can reduce your cost as your API usage scales. <br>'+
      'Reference: <br>'+
      'https://aws.amazon.com/lambda/ <br>'+
      'https://aws.amazon.com/api-gateway/ <br>' }
    ],
	img: '',  
  },  
 

  {
    question: '/Explicación antes de Exam 3/ A Developer has been entrusted with the job of securing certain S3 buckets that are shared by a large team of users. Last time, a bucket policy was changed, the bucket was erroneously available for everyone, outside the organization too. Which feature/service will help the developer identify similar security issues with minimum effort? Seleccione una:',
    answers: [
      { text: 'a. Access Advisor feature on IAM console ', correct: false,  expli:' ' },
      { text: 'b. S3 Analytics', correct: false,  expli:' ' },
	    { text: 'c. IAM Access Analyzer', correct: true,  expli:' La respuesta correcta es: IAM Access Analyzer. <br> '+
      'Correct option: <br>'+
'IAM Access Analyzer - AWS IAM Access Analyzer helps you identify the resources in your organization and accounts, such as Amazon S3 buckets or IAM roles, that are shared with an external entity. This lets you identify unintended access to your resources and data, which is a security risk. <br>'+
'You can set the scope for the analyzer to an organization or an AWS account.  <br>'+
'This is your zone of trust. The analyzer scans all of the supported resources within your zone of trust. When Access Analyzer finds a policy that allows access to a resource from outside of your zone of trust, it generates an active finding. <br>'+
'Incorrect options: <br>'+
'Access Advisor feature on IAM console - To help identify the unused roles, IAM reports the last-used timestamp that represents when a role was last used to make an AWS request. Your security team can use this information to identify, analyze, and then confidently remove unused roles. This helps improve the security posture  of your AWS environments. This does not provide information about non-IAM entities such as S3, hence it\'s not a correct choice here.  <br>'+
'S3 Object Lock - S3 Object Lock enables you to store objects using a "Write Once Read Many" (WORM) model. S3 Object Lock can help prevent accidental or inappropriate deletion of data, it is not the right choice for the current scenario.  <br>'+
'S3 Analytics - By using Amazon S3 analytics Storage Class Analysis you can analyze storage access patterns to help you decide when to transition the right data to the right storage class. You cannot use S3 Analytics to identify unintended access to your S3 resources. <br>'+
'References: <br>'+
'https://docs.aws.amazon.com/IAM/latest/UserGuide/what-is-access-analyzer.html <br>'+
'https://docs.aws.amazon.com/AmazonS3/latest/dev/security-best-practices.html <br>' },
      { text: 'd. S3 Object Lock', correct: false,  expli:' ' }
    ],
	img: '',  
  },  
  {
    question: '/Explicación antes de Exam 3/ An organization has hosted its EC2 instances in two AZs. AZ1 has two instances and AZ2 has 8 instances. The Elastic Load Balancer managing the instances in the two AZs has cross-zone load balancing enabled in its configuration. What percentage traffic will each of the instances in AZ1 receive? Seleccione una:',
    answers: [
      { text: 'a. 25', correct: false,  expli:' ' },
      { text: 'b. 20', correct: false,  expli:' ' },
	    { text: 'c. 15', correct: false,  expli:' ' },
      { text: 'd. 10', correct: true,  expli:' La respuesta correcta es: 10. <br> '+
      'Correct option: <br>'+
'A load balancer accepts incoming traffic from clients and routes requests to its registered targets (such as EC2 instances) in one or more Availability Zones. <br>'+
'The nodes for a load balancer distribute requests from clients to registered targets.  <br>'+
'When cross-zone load balancing is enabled, each load balancer node distributes traffic across the registered targets in all enabled Availability Zones.  <br>'+
'When crosszone load balancing is disabled, each load balancer node distributes traffic only across the registered targets in its Availability Zone. With Application Load Balancers, cross-zone load balancing is always enabled.  <br>'+
'10 - When cross-zone load balancing is enabled, each of the 10 targets receives 10% of the traffic. This is because each load balancer node can route its 50% of the client traffic to all 10 targets (present in both AZs). <br>'+
'Incorrect options: <br>'+
'25 - If cross-zone load balancing is disabled, each of the two targets in AZ1 will receive 25% of the traffic. Because the load balancer is only able to send to the targets registered in AZ1 (AZ2 instances are not accessible for load balancer on AZ1) <br>'+
'20 - Invalid option, given only as a distractor. <br>'+
'15 - Invalid option, given only as a distractor. <br>'+
'Reference: <br>'+
'https://docs.aws.amazon.com/elasticloadbalancing/latest/userguide/how-elasticload-balancing-works.html <br>' }
    ],
	img: '',  
  },  
  {
    question: '/Explicación antes de Exam 3/ A financial services company is undergoing a compliance audit by the regulator. The company has hundreds of IAM users that make API calls but specifically it needs to be determined who is making KMS API calls. Which of the following services should the audit team use? Seleccione una: ',
    answers: [
      { text: 'a. CloudTrail ', correct: true,  expli:' La respuesta correcta es: CloudTrail, <br>' +
      'Correct option: <br> '+
      'CloudTrail <br> '+
      'With CloudTrail, you can log, continuously monitor, and retain account activity related to actions across your AWS infrastructure. You can use AWS CloudTrail to answer questions such as - “Who made an API call to modify this resource?”. <br> '+
      'CloudTrail provides event history of your AWS account activity thereby enabling governance, compliance, operational auditing, and risk auditing of your AWS account.  <br> '+
      'You cannot use CloudTrail to maintain a history of resource configuration changes. <br> '+

      'Exam Alert: <br> '+
      'You may see scenario-based questions asking you to select one of CloudWatch vs CloudTrail vs Config. Just remember this thumb rule - <br> '+
      'Think resource performance monitoring, events, and alerts; think CloudWatch. <br> '+
      'Think account-specific activity and audit; think CloudTrail. <br> '+
      'Think resource-specific history, audit, and compliance; think Config. <br> '+

      'Incorrect options: <br> '+
      'CloudWatch Metrics - CloudWatch provides you with data and actionable insights to monitor your applications, respond to system-wide performance changes, optimize resource utilization, and get a unified view of operational health. <br> '+
      'Amazon CloudWatch allows you to monitor AWS cloud resources and the applications you run on AWS. Metrics are provided automatically for a number of AWS products and services. CloudWatch cannot help determine the source for KMS API calls. <br> '+
      'X-Ray - AWS X-Ray helps developers analyze and debug distributed applications. <br> '+
      'With X-Ray, you can understand how your application and its underlying services are performing to identify and troubleshoot the root cause of performance issues and errors.  <br> '+
      'X-Ray cannot help determine the source for KMS API calls. <br> '+
      'Config - AWS Config is a service that enables you to assess, audit, and evaluate the configurations of your AWS resources. With Config, you can review changes in configurations and relationships between AWS resources, dive into detailed resource configuration histories, and determine your overall compliance against the configurations specified in your internal guidelines.  <br> '+
      'You can use Config to answer questions such as - “What did my AWS resource look like at xyz point in time?”. <br> '+
      'Config cannot help determine the source for KMS API calls. <br> '+
      'References: <br> '+
      'https://aws.amazon.com/config/ <br> '+
      'https://aws.amazon.com/cloudwatch/ <br> '+
      'https://aws.amazon.com/cloudtrail/ <br> ' },
      { text: 'b. Config', correct: false,  expli:' ' },
	    { text: 'c. CloudWatch Metrics', correct: false,  expli:' ' },
      { text: 'd. X-Ray', correct: false,  expli:' ' }
    ],
	img: '',  
  },  
  {
    question: '/Explicación antes de Exam 3/ To enable HTTPS connections for his web application deployed on the AWS Cloud, a developer is in the process of creating server certificate. Which AWS entities can be used to deploy SSL/TLS server certificates? (Select two) Seleccione una o más de una:',
    answers: [
      { text: 'a. AWS Certificate Manager ', correct: true,  expli:' una respuesta correcta es : AWS Certificate Manager' },
      { text: 'b. AWS CloudFormation', correct: false,  expli:' ' },
	    { text: 'c. AWS Systems Manager ', correct: false,  expli:' ' },
      { text: 'd. AWS Secrets Manager', correct: false,  expli:' ' },
      { text: 'e. IAM', correct: true,  expli:' una respuesta correcta es : IAM. <br> '+
      'Correct options: <br> '+
      'AWS Certificate Manager - AWS Certificate Manager (ACM) is the preferred tool to provision, manage, and deploy server certificates.  <br> '+
      'With ACM you can request a certificate or deploy an existing ACM or external certificate to AWS resources. <br> '+
      'Certificates provided by ACM are free and automatically renew.  <br> '+
      'In a supported Region, you can use ACM to manage server certificates from the console or programmatically. <br> '+
      'IAM - IAM is used as a certificate manager only when you must support HTTPS connections in a Region that is not supported by ACM.  <br> '+
      'IAM securely encrypts your private keys and stores the encrypted version in IAM SSL certificate storage.  <br> '+
      'IAM supports deploying server certificates in all Regions, but you must obtain your certificate from an external provider for use with AWS.  <br> '+
      'You cannot upload an ACM certificate to IAM. Additionally, you cannot manage your certificates from the IAM Console. <br> '+
      'Incorrect options: <br> '+
      'AWS Secrets Manager - AWS Secrets Manager helps you protect secrets needed to access your applications, services, and IT resources.  <br> '+
      'The service enables you to easily rotate, manage, and retrieve database credentials, API keys, and other secrets throughout their lifecycle. Users and applications retrieve secrets with a call to Secrets Manager APIs, eliminating the need to hardcode sensitive information in plain text.  <br> '+
      'It cannot be used to discover and protect your sensitive data in AWS. <br> '+
      'AWS Systems Manager - AWS Systems Manager gives you visibility and control of your infrastructure on AWS. Systems Manager provides a unified user interface so you can view operational data from multiple AWS services and allows you to automate operational tasks such as running commands, managing patches, and configuring servers across AWS Cloud as well as on-premises infrastructure. <br> '+
      'AWS CloudFormation - AWS CloudFormation allows you to use programming languages or a simple text file to model and provision, in an automated and secure manner, all the resources needed for your applications across all Regions and accounts.  <br> '+
      'Think infrastructure as code; think CloudFormation.  <br> '+
      'You cannot use CloudFormation for running commands or managing patches on servers. <br> '+
      'Reference: <br> '+
      'https://docs.aws.amazon.com/IAM/latest/UserGuide/id_credentials_servercerts.html <br> ' }
    ],
	img: '',  
  },  
  {
    question: '/Explicación antes de Exam 3/ A group of Developer have been given access to a separate AWS account to work on a new project. The Developers require full administrative access to create IAM policies and roles in the account, but corporate policies require that they are blocked from using a few specific AWS services. What is the BEST way to grant the Developers privileges in the new account while still ensuring compliance with corporate policies? Seleccione una:',
    answers: [
      { text: 'a. Create a service control policy in AWS Organizations and apply it to the new account.', correct: true,  expli:' La respuesta correcta es: Create a service control policy in AWS Organizations and apply it to the new account. <br> '+
      'If the Developers are provided with full administrative access, then the only way to ensure compliance with the corporate policy is to use an AWS. <br> '+
      'Organizations SCP to restrict the API actions relating to use of the specific restricted services. <br> '+
      'Service control policies (SCPs) are a type of organization policy that you can use to manage permissions in your organization.  <br> '+
      'SCPs offer central control over the maximum available permissions for all accounts in your organization. <br> '+
      'This is the only way you can ensure that the Developers don’t modify policies and gain the access to the restricted services. <br> '+
      'CORRECT: "Create a service control policy in AWS Organizations and apply it to the new account" is the correct answer. <br> '+
      'INCORRECT: "Create a customer managed policy in IAM and apply it to all users within the new account" is incorrect.  <br> '+
      'This will not ensure compliance as the Developers have full administrative control and can change policies. <br> '+
      'INCORRECT: "Create a job-specific policy in IAM and apply it to all users within the new account" is incorrect.  <br> '+
      'This will not ensure compliance as the Developers have full administrative control and can change policies. <br> '+ 
      'INCORRECT: "Create an IAM group for the Developers and apply a policy restricting access to the specific services" is incorrect.  <br> '+
      'This will not ensure compliance as the Developers have full administrative control and can change policies. <br> ' },
      { text: 'b. Create a job-specific policy in IAM and apply it to all users within the new account.', correct: false,  expli:' ' },
	    { text: 'c. Create a customer managed policy in IAM and apply it to all users within the new account.', correct: false,  expli:' ' },
      { text: 'd. Create an IAM group for the Developers and apply a policy restricting access to the specific services ', correct: false,  expli:' ' }
    ],
	img: '',  
  },  
  {
    question: '/Explicación antes de Exam 3/ A company needs to improve the security of passwords by forcing all IAM users to rotate their passwords on a regular basis. Which action should be taken take to implement this? Seleccione una:',
    answers: [
      { text: 'a. Configure multi-factor authentication for all IAM users.', correct: false,  expli:' ' },
      { text: 'b. Set up a password policy to enable password expiration for IAM users.', correct: true,  expli:' La respuesta correcta es: Set up a password policy to enable password expiration for IAM users. <br> ' +
      'You can grant IAM users the permission to change their own passwords for signing in to the AWS Management Console. You can do this in one of two ways: <br> '+
      'Allow all IAM users in the account to change their own passwords. <br> '+
      'Allow only selected IAM users to change their own passwords.  <br> '+
      'In this scenario, you disable the option for all users to change their own passwords and you use an IAM policy to grant permissions to only some users to change their own passwords and optionally other credentials like their own access keys. <br> '+
      'CORRECT: "Set up a password policy to enable password expiration for IAM users" is the correct answer. <br> '+
      'INCORRECT: "Set up an access key policy to enable expiration for access keys" is incorrect. There is no policy that can be configured to expire access keys and the questions asks to force password rotation. <br> '+
      'INCORRECT: "Configure multi-factor authentication for all IAM users" is <br> '+
      'incorrect. MFA does not ensure that passwords are rotated. <br> '+
      'INCORRECT: "Use Amazon SNS to send regular notifications that passwords must be changed" is incorrect. This would not force password rotation; it would simply advise users to do i. <br> ' },
	    { text: 'c. Set up an access key policy to enable expiration for access keys.', correct: false,  expli:' ' },
      { text: 'd. Use Amazon SNS to send regular notifications that passwords must be changed.', correct: false,  expli:' ' }
    ],
	img: '',  
  },  
  {
    question: '/Explicación antes de Exam 3/ A security vulnerability has been discovered that impacts a version of Linux that is running on some Amazon EC2 instances in a VPC. How can a SysOps Administrator mitigate the exposure with the LEAST disruption? Seleccione una: ',
    answers: [
      { text: 'a. Redeploy the EC2 instances using an updated AMI through AWS CloudFormation.', correct: false,  expli:' ' },
      { text: 'b. Use Amazon Inspector to produce a report with best practice recommendations. ', correct: false,  expli:' ' },
	    { text: 'c. Use AWS Systems Manager to patch the Linux operating systems.', correct: true,  expli:' La respuesta correcta es: Use AWS Systems Manager to patch the Linux operating systems. <br> '+
      'AWS Systems Manager Patch Manager automates the process of patching managed instances with both security related and other types of updates.  <br> '+
      'You can use Patch Manager to apply patches for both operating systems and applications. <br> '+
      'CORRECT: "Use AWS Systems Manager to patch the Linux operating systems" is the correct answer. <br> '+
      'INCORRECT: "Shut down and then restart the instances so they change underlying hosts" is incorrect. The vulnerability is with the EC2 instance OS so moving hosts will not change anything. <br> '+
      'INCORRECT: "Use Amazon Inspector to produce a report with best practice recommendations" is incorrect. This will not mitigate the exposure. <br> '+
      'INCORRECT: "Redeploy the EC2 instances using an updated AMI through AWS CloudFormation" is incorrect. This would cause more disruption than patching the existing EC2 instances. <br> ' },
      { text: 'd. Shut down and then restart the instances so they change underlying hosts.', correct: false,  expli:' ' }
    ],
	img: '',  
  },  
  {
    question: '/Explicación antes de Exam 3/ A company is hosting a website behind multiple Application Load Balancers. The company has different distribution rights for its content around the world. A solutions architect needs to ensure that users are served the correct content without violating distribution rights. Which configuration should the solutions architect choose to meet these requirements? Seleccione una: ',
    answers: [
      { text: 'a. Configure Amazon CloudFront with AWS WAF.', correct: false,  expli:' ' },
      { text: 'b. Configure Amazon Route 53 with a geolocation policy. ', correct: true,  expli:' La respuesta correcta es: Configure Amazon Route 53 with a geolocation policy. <br> '+
      'Reference: <br> '+
      'https://docs.aws.amazon.com/Route53/latest/DeveloperGuide/routing-policy.html <br> '+
      '(geolocation routing) <br> ' },
	    { text: 'c. Configure Application Load Balancers with AWS WAF.', correct: false,  expli:' ' },
      { text: 'd. Configure Amazon Route 53 with a geoproximity routing policy. ', correct: false,  expli:' ' }
    ],
	img: '',  
  },  
  {
    question: '/Explicación antes de Exam 3/ An E-commerce business, has its applications built on a fleet of Amazon EC2 instances, spread across various Regions and AZs. The technical team has suggested using Elastic Load Balancers for better architectural design. What characteristics of an Elastic Load Balancer make it a winning choice? (Select two) Seleccione una o más de una:',
    answers: [
      { text: 'a. Build a highly available system', correct: true,  expli:' una respuesta correcta es : Build a highly available system ' },
      { text: 'b. Improve vertical scalability of the system', correct: false,  expli:' ' },
	    { text: 'c. Separate public traffic from private traffic ', correct: true,  expli:'una respuesta correcta es : Separate public traffic from private traffic. <br> '+ 
      'Correct options: <br> '+
      'A load balancer accepts incoming traffic from clients and routes requests to its registered targets (such as EC2 instances) in one or more Availability Zones.  <br> '+
      'The load balancer also monitors the health of its registered targets and ensures that it routes traffic only to healthy targets.  <br> '+
      'When the load balancer detects an unhealthy target, it stops routing traffic to that target. It then resumes routing traffic to that target when it detects that the target is healthy again. <br> '+
      'Elastic Load Balancing supports three types of load balancers: <br> '+
      'Application Load Balancers <br> '+
      'Network Load Balancers <br> '+
      'Classic Load Balancers <br> '+
      'Separate public traffic from private traffic - The nodes of an internet-facing load balancer have public IP addresses.  <br> '+
      'Load balancers route requests to your targets using private IP addresses. Therefore, your targets do not need public IP addresses to receive requests from users over the internet.  <br> '+
      'Build a highly available system - Elastic Load Balancing provides fault tolerance for your applications by automatically balancing traffic across targets – Amazon EC2 instances, containers, IP addresses, and Lambda functions – in multiple Availability Zones while ensuring only healthy targets receive traffic. <br> '+
      'Incorrect options: <br> '+
      'The Load Balancer communicates with the underlying EC2 instances using their public IPs - This is an incorrect statement.  <br> '+
      'The Load Balancer communicates with the underlying EC2 instances using their private IPs. <br> '+ 
      'Improve vertical scalability of the system - This is an incorrect statement.  <br> '+
      'Elastic Load Balancers can connect with Auto Scaling groups to provide horizontal scaling. <br> '+
      'Deploy EC2 instances across multiple AWS Regions - A Load Balancer can target EC2 instances only within an AWS Region. <br> '+
      'References: <br> '+
      'https://aws.amazon.com/elasticloadbalancing/ <br> '+
      'https://docs.aws.amazon.com/elasticloadbalancing/latest/userguide/how-elasticload-balancing-works.html <br> ' },
      { text: 'd. The Load Balancer communicates with the underlying EC2 instances using their public IPs', correct: false,  expli:' ' },
      { text: 'e. Deploy EC2 instances across multiple AWS Regions ', correct: false,  expli:' ' }
    ],
	img: '',  
  },  
  {
    question: '/Explicación antes de Exam 3/ A company\'s near-real-time streaming application is running on AWS. As the data is ingested, a job runs on the data and takes 30 minutes to complete. The workload frequently experiences high latency due to large amounts of incoming data. A solutions architect needs to design a scalable and serverless solution to enhance performance. Seleccione una o más de una:',
    answers: [
      { text: 'a. Use AWS Database Migration Service (AWS DMS) to ingest the data.', correct: false,  expli:' ' },
      { text: 'b. Use Amazon EC2 instances in an Auto Scaling group to process the data.', correct: false,  expli:' ' },
	    { text: 'c. Use AWS Lambda with AWS Step Functions to process the data.', correct: false,  expli:' ' },
      { text: 'd. Use AWS Fargate with Amazon Elastic Container Service (Amazon ECS) to process the data.', correct: true,  expli:' una respuesta correcta es : Use AWS Fargate with Amazon Elastic Container Service (Amazon ECS) to process the data.' },
      { text: 'e. Use Amazon Kinesis Data Firehose to ingest the data. ', correct: true,  expli:'una respuesta correcta es : Use Amazon Kinesis Data Firehose to ingest the data. ' }
    ],
	img: '',  
  },  
  {
    question: '/Explicación antes de Exam 3/ A company receives inconsistent service from its data center provider because the company is headquartered in an area affected by natural disasters. The company is not ready to fully migrate to the AWS Cloud, but it wants a failure environment on AWS in case the on-premises data center fails. The company runs web servers that connect to external vendors. The data available on AWS and on premises must be uniform. Which solution should a solutions architect recommend that has the LEAST amount of downtime? Seleccione una: ',
    answers: [
      { text: 'a. Configure an Amazon Route 53 failover record. Run an AWS Lambda function to execute an AWS CloudFormation template to launch two Amazon EC2 instances. Set up AWS Storage Gateway with stored volumes to back up data to Amazon S3. Set up an AWS Direct Connect connection between a VPC and the data center.', correct: false,  expli:' ' },
      { text: 'b. Configure an Amazon Route 53 failover record. Set up an AWS Direct Connect connection between a VPC and the data center. Run application servers on Amazon EC2 in an Auto Scaling group. Run an AWS Lambda function to execute an AWS CloudFormation template to create an Application Load Balancer.', correct: false,  expli:' ' },
	    { text: 'c. Configure an Amazon Route 53 failover record. Execute an AWS CloudFormation template from a script to create Amazon EC2 instances behind an Application Load Balancer. Set up AWS Storage Gateway with stored volumes to back up data to Amazon S3.', correct: false,  expli:' ' },
      { text: 'd. Configure an Amazon Route 53 failover record. Run application servers on Amazon EC2 instances behind an Application Load Balancer in an Auto Scaling group. Set up AWS Storage Gateway with stored volumes to back up data to Amazon S3.', correct: true,  expli:' La respuesta correcta es: Configure an Amazon Route 53 failover record. Run application servers on Amazon EC2 instances behind an Application Load Balancer in an Auto Scaling group. Set up AWS Storage Gateway with stored volumes to back up data to Amazon S3.' }
    ],
	img: '',  
  },  
  {
    question: '/Explicación Exámen 20p - 1/ 1.- A solutions architect is designing a new service behind Amazon API Gateway. The request patterns for the service will be unpredictable and can change suddenly from 0 requests to over 500 per second. The total size of the data that needs to be persisted in a backend database is currently less than 1 GB with unpredictable future growth Data can be queried using simple key-value requests. Which combination of AWS services would meet these requirements? Select TWO Options. (0,50 puntos). Seleccione una o más de una: ',
    answers: [
      { text: 'a. AWS Fargate.', correct: false,  expli:' ' },
      { text: 'b. AWS Lambda. ', correct: true,  expli:' una respuesta correcta es : AWS Lambda.' },
	    { text: 'c. Amazon DynamoDB.', correct: true,  expli:' una respuesta correcta es : Amazon DynamoDB.' },
      { text: 'd. Amazon EC2 Auto Scaling.', correct: false,  expli:' ' },
      { text: 'e. MySQL-compatible Amazon Aurora.', correct: false,  expli:' ' }
    ],
	img: '',  
  },   
  {
    question: '/Explicación Exámen 20p - 2/ 2.- A company has a multi-tier application that runs six front-end web servers in an Amazon EC2 Auto Scaling group in a single Availability Zone behind an Application Load Balancer (ALB). A solutions architect needs to modify the infrastructure to be highly available without modifying the application. Which architecture should the solutions architect choose that provides high availability? (0,50 puntos). Seleccione una: ',
    answers: [
      { text: 'a. Create an Auto Scaling group that uses three instances across each of two Regions.', correct: false,  expli:' ' },
      { text: 'b. Modify the Auto Scaling group to use three instances across each of two Availability Zones.', correct: true,  expli:' La respuesta correcta es: Modify the Auto Scaling group to use three instances across each of two Availability Zones.' },
	    { text: 'c. Create an Auto Scaling template that can be used to quickly create more instances in another Region. ', correct: false,  expli:' ' },
      { text: 'd. Change the ALB in front of the Amazon EC2 instances in a round-robin configuration to balance traffic to the web tier.', correct: false,  expli:' ' }
    ],
	img: '',  
  },   
  {
    question: '/Explicación Exámen 20p - 3/ 3.- A company runs an internal browser-based application The application runs on Amazon EC2 instances behind an Application Load Balancer. The instances run in an Amazon EC2 Auto Scaling group across multiple Availability Zones. The Auto Scaling group scales up to 20 instances during work hours, but scales down to 2 instances overnight Staff are complaining that the application is very slow when the day begins, although it runs well by mid-morning. How should the scaling be changed to address the staff complaints and keep costs to a minimum? (0,50 puntos) Seleccione una: ',
    answers: [
      { text: 'a. Implement a scheduled action that sets the desired capacity to 20 shortly before the office opens.', correct: true,  expli:' La respuesta correcta es: Implement a scheduled action that sets the desired capacity to 20 shortly before the office opens.' },
      { text: 'b. Implement a step scaling action triggered at a lower CPU threshold, and decrease the cooldown period. ', correct: false,  expli:' ' },
	    { text: 'c. Implement a target tracking action triggered at a lower CPU threshold and decrease the cooldown period.', correct: false,  expli:' ' },
      { text: 'd. Implement a scheduled action that sets the minimum and maximum capacity to 20 shortly before the office opens.', correct: false,  expli:' ' }
    ],
	img: '',  
  },   
  {
    question: '/Explicación Exámen 20p - 4/ 4.- A solutions architect is designing a solution to access a catalog of images and provide users with the ability to submit requests to customize images. Image customization parameters will be in any request sent to an AWS API Gateway API. The customized image will be generated on demand, and users will receive a link they can click to view or download their customized image. The solution must be highly available for viewing and customizing images What is the MOST cost-effective solution to meet these requirements? (0,50 puntos). Seleccione una: ',
    answers: [
      { text: 'a. Use Amazon EC2 instances to manipulate the original image into the requested customization. Store the original and manipulated images in Amazon S3. Configure an Elastic Load Balancer in front of the EC2 instances.', correct: false,  expli:' ' },
      { text: 'b. Use AWS Lambda to manipulate the original image to the requested customization. Store the original and manipulated images in Amazon S3. Configure an Amazon CloudFront distribution with the S3 bucket as the ongin. ', correct:  true,  expli:' La respuesta correcta es: Use AWS Lambda to manipulate the original image to the requested customization. Store the original and manipulated images in Amazon S3. Configure an Amazon CloudFront distribution with the S3 bucket as the ongin.' },
	    { text: 'c. Use AWS Lambda to manipulate the original image to the requested customization. Store the original images in Amazon S3 and the manipulated images in Amazon DynamoDB. Configure an Elastic Load Balancer in front of the Amazon EC2 instances.', correct: false,  expli:' ' },
      { text: 'd. Use Amazon EC2 instances to manipulate the original image into the requested customization. Store the original images in Amazon S3 and the manipulated images in Amazon DynamoDB. Configure an Amazon CloudFront distribution with the S3 bucket as the origin.', correct: false,  expli:' ' }
    ],
	img: '',  
  },   
  {
    question: '/Explicación Exámen 20p - 5/ 5.- A bicycle sharing company is developing a multi-tier architecture to track the location of its bicycles during peak operating hours. The company wants to use these data points in its existing analytics platform A solutions architect must determine the most viable multi-tier option to support this architecture. The data points must be accessible from the REST API. Which action meets these requirements for storing and retrieving location data? (0,50 puntos). Seleccione una: ',
    answers: [
      { text: 'a. Use Amazon Athena with Amazon S3.', correct: false,  expli:' ' },
      { text: 'b. Use Amazon API Gateway with AWS Lambda.', correct: true,  expli:'La respuesta correcta es: Use Amazon API Gateway with AWS Lambda. ' },
	    { text: 'c. Use Amazon QuickSight with Amazon Redshift.', correct: false,  expli:' ' },
      { text: 'd. Use Amazon API Gateway with Amazon Kinesis Data Analytics.', correct: false,  expli:' ' }
    ],
	img: '',  
  },   
  {
    question: '/Explicación Exámen 20p - 6/ 6.- A solutions architect needs to ensure that API calls to Amazon DynamoDB from Amazon EC2 instances in a VPC do not traverse the internet. What should the solutions architect do to accomplish this? Select TWO Options. (0,50 puntos). Seleccione una o más de una: ',
    answers: [
      { text: 'a. Create a route table entry for the endpoint.', correct: true,  expli:' una respuesta correcta es : Create a route table entry for the endpoint.' },
      { text: 'b. Create a gateway endpoint for DynamoDB. ', correct: true,  expli:' una respuesta correcta es : Create a gateway endpoint for DynamoDB.' },
	    { text: 'c. Create a new DynamoDB table that uses the endpoint. ', correct: false,  expli:' ' },
      { text: 'd. Create an ENI for the endpoint in each of the subnets of the VPC.', correct: false,  expli:' ' },
      { text: 'e. Create a security group entry in the default security group to provide access.', correct: false,  expli:' ' }
    ],
	img: '',  
  },   
  {
    question: '/Explicación Exámen 20p - 7/ 7.- A company has been storing analytics data in an Amazon RDS instance for the past few years. The company asked a solutions architect to find a solution that allows users to access this data using an API. The expectation is that the application will experience periods of inactivity but could receive bursts of traffic within seconds. Which solution should the solutions architect suggest? (0,50 puntos). Seleccione una: ',
    answers: [
      { text: 'a. Set up an Amazon API Gateway and use Amazon ECS.', correct: false,  expli:' ' },
      { text: 'b. Set up an Amazon API Gateway and use AWS Elastic Beanstalk. ', correct: false,  expli:' ' },
	    { text: 'c. Setup an Amazon API Gateway and use AWS Lambda functions.', correct: true,  expli:' La respuesta correcta es: Setup an Amazon API Gateway and use AWS Lambda functions.' },
      { text: 'd. Set up an Amazon API Gateway and use Amazon EC2 with Auto Scaling.', correct: false,  expli:' ' }
    ],
	img: '',  
  },   
  {
    question: '/Explicación Exámen 20p - 8/ 8.- A company\'s web application is using multiple Linux Amazon EC2 instances and storing data on Amazon EBS volumes. The company is looking for a solution to increase the resiliency of the application in case of a failure and to provide storage that complies with atomicity, consistency, isolation, and durability (ACID). What should a solutions architect do to meet these requirements? (0,50 puntos). Seleccione una: ',
    answers: [
      { text: 'a. Launch the application on EC2 instances in each Availability Zone. Attach EBS volumes to each EC2 instance. ', correct: false,  expli:' ' },
      { text: 'b. Create an Application Load Balancer with Auto Scaling groups across multiple Availability Zones. Mount an instance store on each EC2 instance.', correct: false,  expli:' ' },
	    { text: 'c. Create an Application Load Balancer with Auto Scaling groups across multiple Availability Zones. Store data on Amazon EFS and mount a target on each instance.', correct: true,  expli:' La respuesta correcta es: Create an Application Load Balancer with Auto Scaling groups across multiple Availability Zones. Store data on Amazon EFS and mount a target on each instance.' },
      { text: 'd. Create an Application Load Balancer with Auto Scaling groups across multiple Availability Zones. Store data using Amazon S3 One Zone-Infrequent Access (S3 One Zone-IA).', correct: false,  expli:' ' }
    ],
	img: '',  
  },   
  {
    question: '/Explicación Exámen 20p - 9/ 9.- A company has an application that calls AWS Lambda functions. A recent code review found database credentials stored in the source code The database credentials need to be removed from the Lambda source code The credentials must then be securely stored and rotated on an ongoing basis to meet security policy requirements. What should a solutions architect recommend to meet these requirements? (0,50 puntos). Seleccione una: ',
    answers: [
      { text: 'a. Store the password in AWS CloudHSM. Associate the Lambda function with a role that can retrieve the password from CloudHSM given its key ID.', correct: false,  expli:' ' },
      { text: 'b. Store the password in AWS Secrets Manager. Associate the Lambda function with a role that can retrieve the password from Secrets Manager given its secret ID.', correct: true,  expli:' La respuesta correcta es: Store the password in AWS Secrets Manager. Associate the Lambda function with a role that can retrieve the password from Secrets Manager given its secret ID.' },
	    { text: 'c. Move the database password to an environment variable associated with the Lambda function. Retrieve the password from the environment variable upon execution.', correct: false,  expli:' ' },
      { text: 'd. Store the password in AWS Key Management Service (AWS KMS). Associate the Lambda function with a role that can retrieve the password from AWS KMS given its key ID. ', correct: false,  expli:' ' }
    ],
	img: '',  
  },   
  {
    question: '/Explicación Exámen 20p - 10/ 10.- A solutions architect needs the static website within an Amazon S3 bucket. A solutions architect needs to ensure that data can be recovered in case of accidental deletion. Which action will accomplish this? (0,50 puntos). Seleccione una: ',
    answers: [
      { text: 'a. Enable Amazon S3 versioning. ', correct: true,  expli:' La respuesta correcta es: Enable Amazon S3 versioning.' },
      { text: 'b. Enable Amazon S3 Intelligent-Tiering.', correct: false,  expli:' ' },
	    { text: 'c. Enable an Amazon S3 lifecycle policy.', correct: false,  expli:' ' },
      { text: 'd. Enable Amazon S3 cross-Region replication.', correct: false,  expli:' ' }
    ],
	img: '',  
  },   
  {
    question: '/Explicación Exámen 20p - 11/ 11.- A company currently operates a web application backed by an Amazon RDS MySQL database. It has automated backups that are run daily and are not encrypted. A security audit requires future backups to be encrypted and the unencrypted backups to be destroyed. The company will make at least one encrypted backup before destroying the old backups What should be done to enable encryption for future backups? (0,50 puntos). Seleccione una: ',
    answers: [
      { text: 'a. Enable default encryption for the Amazon S3 bucket where backups are stored.', correct: false,  expli:' ' },
      { text: 'b. Modify the backup section of the database configuration to toggle the Enable encryption check box. ', correct: false,  expli:' ' },
	    { text: 'c. Create a snapshot of the database. Copy it to an encrypted snapshot. Restore the database from the encrypted snapshot.', correct: true,  expli:' La respuesta correcta es: Create a snapshot of the database. Copy it to an encrypted snapshot. Restore the database from the encrypted snapshot.' },
      { text: 'd. Enable an encrypted read replica on RDS for MySQL. Promote the encrypted read replica to primary. Remove the original database instance.', correct: false,  expli:' ' }
    ],
	img: '',  
  },   
  {
    question: '/Explicación Exámen 20p - 12/ 12.- A client reports that they want see an audit log of any changes made to AWS resources in their account. What can the client do to achieve this? (0,50 puntos). Seleccione una: ',
    answers: [
      { text: 'a. Set up Amazon CloudWatch monitors on services they own.', correct: false,  expli:' ' },
      { text: 'b. Enable AWS CloudTrail logs to be delivered to an Amazon S3 bucket. ', correct: true,  expli:' La respuesta correcta es: Enable AWS CloudTrail logs to be delivered to an Amazon S3 bucket.' },
	    { text: 'c. Use Amazon CloudWatch Events to parse logs.', correct: false,  expli:' ' },
      { text: 'd. Use AWS OpsWorks to manage their resources.', correct: false,  expli:' ' }
    ],
	img: '',  
  },   
  {
    question: '/Explicación Exámen 20p - 13/ 13.- An application running in a private subnet accesses an Amazon DynamoDB table. There is a security requirement that the data never leave the AWS network. How should this requirement be met? (0,50 puntos). Seleccione una: ',
    answers: [
      { text: 'a. Configure a network ACL on DynamoDB to limit traffic to the private subnet.', correct: false,  expli:' ' },
      { text: 'b. Enable DynamoDB encryption at rest using an AWS KMS key.', correct: false,  expli:' ' },
	    { text: 'c. Add a NAT gateway and configure the route table on the private subnet.', correct: false,  expli:' ' },
      { text: 'd. Create a VPC endpoint for DynamoDB and configure the endpoint policy. ', correct: true,  expli:' La respuesta correcta es: Create a VPC endpoint for DynamoDB and configure the endpoint policy.' }
    ],
	img: '',  
  },   
  {
    question: '/Explicación Exámen 20p - 14/ 14.- A three-tier application is being created to host small news articles. The application is expected to serve millions of users. When breaking news occurs, the site must handle very large spikes in traffic without significantly impacting database performance. Which design meets these requirements while minimizing costs? (0,50 puntos) Seleccione una: ',
    answers: [
      { text: 'a. Use Auto Scaling groups to increase the number of Amazon EC2 instances delivering the web application.', correct: false,  expli:' ' },
      { text: 'b. Use Auto Scaling groups to increase the size of the Amazon RDS instances delivering the database.', correct: false,  expli:' ' },
	    { text: 'c. Use Amazon DynamoDB strongly consistent reads to adjust for the increase in traffic.', correct: false,  expli:' ' },
      { text: 'd. Use Amazon DynamoDB Accelerator (DAX) to cache read operations to the database. ', correct: true,  expli:'La respuesta correcta es: Use Amazon DynamoDB Accelerator (DAX) to cache read operations to the database. ' }
    ],
	img: '',  
  },   
  {
    question: '/Explicación Exámen 20p - 15/ 15.- A During a review of business applications, a Solutions Architect identifies a critical application with a relational database that was built by a business user and is running on the user\'s desktop. To reduce the risk of a business interruption, the Solutions Architect wants to migrate the application to a highly available, multi-tiered solution in AWS. What should the Solutions Architect do to accomplish this with the LEAST amount of disruption to the business? (0,50 puntos). Seleccione una: ',
    answers: [
      { text: 'a. Create reate an import package of the application code for upload to AWS Lambda, and include a function to create another Lambda function to migrate data into an Amazon RDS database.', correct: false,  expli:' ' },
      { text: 'b. Create an image of the user\'s desktop, migrate it to Amazon EC2 using VM Import, and place the EC2 instance in an Auto Scaling group.', correct: false,  expli:' ' },
	    { text: 'c. Pre-stage new Amazon EC2 instances running the application code on AWS behind an Application Load Balancer and an Amazon RDS Multi-AZ DB instance.', correct: false,  expli:' ' },
      { text: 'd. Use AWS DMS to migrate the backend database to an Amazon RDS Multi-AZ DB instance. Migrate the application code to AWS Elastic Beanstalk. ', correct: true,  expli:' La respuesta correcta es: Use AWS DMS to migrate the backend database to an Amazon RDS Multi-AZ DB instance. Migrate the application code to AWS Elastic Beanstalk.' }
    ],
	img: '',  
  },   
  {
    question: '/Explicación Exámen 20p - 16/ 16.- A company has thousands of files stored in an Amazon S3 bucket that has a well-defined access pattern. The files are accessed by an application multiple times a day for the first 30 days. Files are rarely accessed within the next 90 days. After that, the files are never accessed again. During the first 120 days, accessing these files should never take more than a few seconds. Which lifecycle policy should be used for the S3 objects to minimize costs based on the access pattern? (0,50 puntos). Seleccione una: ',
    answers: [
      { text: 'a. Use Amazon S3 Standard-Infrequent Access (S3 Standard-IA) storage for the first 30 days. Then move the files to the GLACIER storage class for the next 90 days. Allow the data to expire after that.', correct: false,  expli:' ' },
      { text: 'b. Use Amazon S3 Standard storage for the first 30 days. Then move the files to Amazon S3 Standard- Infrequent Access (S3 Standard-IA) for the next 90 days. Allow the data to expire after that. ', correct: true,  expli:' La respuesta correcta es: Use Amazon S3 Standard storage for the first 30 days. Then move the files to Amazon S3 Standard- Infrequent Access (S3 Standard-IA) for the next 90 days. Allow the data to expire after that.' },
	    { text: 'c. Use Amazon S3 Standard storage for first 30 days. Then move the files to the GLACIER storage class for the next 90 days. Allow the data to expire after that.', correct: false,  expli:' ' },
      { text: 'd. Use Amazon S3 Standard-Infrequent Access (S3 Standard-IA) for the first 30 days. After that, move the data to the GLACIER storage class, where is will be deleted automatically.', correct: false,  expli:' ' }
    ],
	img: '',  
  },   
  {
    question: '/Explicación Exámen 20p - 17/ 17.- A company creates business-critical 3D images every night. The images are batch-processed every Friday and require an uninterrupted 48 hours to complete. What is the MOST cost- effective Amazon EC2 pricing model for this scenario? (0,50 puntos). Seleccione una: ',
    answers: [
      { text: 'a. On-Demand Instances.', correct: false,  expli:' ' },
      { text: 'b. Scheduled Reserved Instances. ', correct: true,  expli:' La respuesta correcta es: Scheduled Reserved Instances.' },
	    { text: 'c. Reserved Instances.', correct: false,  expli:' ' },
      { text: 'd. Spot Instances.', correct: false,  expli:' ' }
    ],
	img: '',  
  },   
  {
    question: '/Explicación Exámen 20p - 18/ 18.- A An application generates audit logs of operational activities. Compliance requirements mandate that the application retain the logs for 5 years. How can these requirements be met? (0,50 puntos). Seleccione una: ',
    answers: [
      { text: 'a. Save the logs in an Amazon S3 bucket and enable Multi-Factor Authentication Delete (MFA Delete) on the bucket.', correct: false,  expli:' ' },
      { text: 'b. Save the logs in an Amazon EFS volume and use Network File System version 4 (NFSv4) locking with the volume. ', correct: false,  expli:' ' },
	    { text: 'c. Save the logs in an Amazon Glacier vault and use the Vault Lock feature. ', correct: true,  expli:' La respuesta correcta es: Save the logs in an Amazon Glacier vault and use the Vault Lock feature.' },
      { text: 'd. Save the logs in an Amazon EBS volume and take monthly snapshots.', correct: false,  expli:' ' }
    ],
	img: '',  
  },   
  {
    question: '/Explicación Exámen 20p - 19/ 19.- A Solutions Architect is creating an application running in an Amazon VPC that needs to access AWS Systems Manager Parameter Store Network security rules prohibit any route table entry with a 0. 0. 0. 0/0 destination. What infrastructure addition will allow access to the AWS service while meeting the requirements? (0,50 puntos). Seleccione una: ',
    answers: [
      { text: 'a. VPC peering.', correct: false,  expli:' ' },
      { text: 'b. NAT instance.', correct: false,  expli:' ' },
	    { text: 'c. NAT gateway.', correct: false,  expli:' ' },
      { text: 'd. AWS PrivateLink. ', correct: true,  expli:' La respuesta correcta es: AWS PrivateLink.' } 
    ],
	img: '',  
  },   
  {
    question: '/Explicación Exámen 20p - 20/ 20.- A company is implementing a data lake solution on Amazon S3. Its security policy mandates that the data stored in Amazon S3 should be encrypted at rest. Which options can achieve this? Select TWO Options. (0,50 puntos). Seleccione una o más de una: ',
    answers: [
      { text: 'a. Use S3 server-side encryption with an Amazon EC2 key pair.', correct: false,  expli:' ' },
      { text: 'b. Use S3 server-side encryption with customer-provided keys (SSE-C). ', correct: true,  expli:' una respuesta correcta es : Use S3 server-side encryption with customer-provided keys (SSE-C).' },
	    { text: 'c. Use S3 bucket policies to restrict access to the data at rest.', correct: false,  expli:' ' },
      { text: 'd. Use client-side encryption before ingesting the data to Amazon S3 using encryption keys. ', correct: true,  expli:' una respuesta correcta es : Use client-side encryption before ingesting the data to Amazon S3 using encryption keys.' },
      { text: 'e. Use SSL to encrypt the data while in transit to Amazon S3.', correct: false,  expli:' ' }
    ],
	img: '',  
  },   
  {
    question: '/Explicación antes de Exam 3/ You have to run a batch job every Sunday night. The job completes in less than 90 minutes and cannot be postponed. Which Amazon EC2 payment model should you use for the best price?',
    answers: [
      { text: 'a. On-demand', correct: false,  expli:'On-demand (not as cheap as other options)' },
      { text: 'b. Reserved', correct: false,  expli:'Reserved (reservation would be wasted when the job is not running)' },
	    { text: 'c. Schediuled Reserved Instance', correct: true,  expli:' correct C Schediuled Reserved Instance' },
      { text: 'd. Spot', correct: false,  expli:'Spot (job cannot be postponed)' }
    ],
	img: '',  
  }, 
  {
    question: '/Explicación antes de Exam 3/ You are asked to make a PDF file publicly available on the web. This file will be downloaded by customers using their browsers millions of times. Which option will be the most cost effective?',
    answers: [
      { text: 'a. Store the file in Amazon S3 Standard', correct: true,  expli:' correct A Store the file in Amazon S3 Standard' },
      { text: 'b. Store the file in Amazon S3 Standard-Infrequent Access (53 Standard-IA)', correct: false,  expli:' Store the file in Amazon S3 Standard-Infrequent Access (53 Standard-IA)(A is cheaper tor storage but more expensive tor trequent retrieval)' },
	    { text: 'c. Store the file in Amazon Glacier', correct: false,  expli:' Store the file in Amazon Glacier (Amazon Glacier does not support public files)' },
      { text: 'd. Store the file on Amazon Elastic File System (Amazon EFS)', correct: false,  expli:'Store the file on Amazon Elastic File System (Amazon EFS) (Amazen-EFSHAmazon EFS does not support public files natively)' }
    ],
	img: '',  
  }, 
  {
    question: '/Explicación antes de Exam 3/ You have deployed an instance running a web server. When you try to connect to it using HTTP over the intenet, the connection times out. Which of these steps could fix the problem? (Select THRE) ',
    answers: [
      { text: 'a. Check if the subnet\'s route table is routing 0.0.0.0/0 to the Internet Gateway.', correct: true,  expli:' correct A Check if the subnet\'s route table is routing 0.0.0.0/0 to the Internet Gateway.' },
      { text: 'b. Check if the subnet\'s route table is routing 0.0.0.0/0 to the Virtual Private Gateway', correct: false,  expli:' Check if the subnet\'s route table is routing 0.0.0.0/0 to the Virtual Private Gateway (VGW request originating from internet, not on-prem netwerk)' },
	    { text: 'c. Check that the security group allows inbound access on port 80.', correct: true,  expli:' correct C Check that the security group allows inbound access on port 80.' },
      { text: 'd. Check that the security group allows outbound access on port 80.', correct: false,  expli:'Check that the security group allows outbound access on port 80. (Not required since security groups are stateful)' },
      { text: 'e. Check that the custom nctwork ACL allows inbound access on port 80', correct: true,  expli:' correct E Check that the custom nctwork ACL allows inbound access on port 80 ' }
    ],
	img: '',  
  }, 
  {
    question: '/Explicación antes de Exam 3/ You are required to design an online application running in a VPC on EC2 instances behind an ELB. The application tier must read and write data to a customer-managed database cluster. There should be no access to the database frorm the Internet, but the cluster must be able to obtain software patches from the Internet. Which solution meets these requirements?',
    answers: [
      { text: 'a. Public subnets for both the application tier and the database cluster', correct: false,  expli:' ' },
      { text: 'b. Public subnets for the application tier, and private subnets for the database cluster', correct: false,  expli:' ' },
	    { text: 'c. Public subnets for the application tier and NAT Gateway, and prvate subnets for the database cluster', correct: true,  expli:' correct C Public subnets for the application tier and NAT Gateway, and prvate subnets for the database cluster' },
      { text: 'd. Public subnets for the application tier, and private subngts for the database cluster and NAT Gateway', correct: false,  expli:' ' }
    ],
	img: '',  
  }, 
  {
    question: '/Explicación antes de Exam 3/ A company uses EBS volumes to store critical and confidential data hosted on their EC2 instances. A new mandate has been released requiring the company to encrypt all EBS volumes. Which of the following can be used to meet this requirement?',
    answers: [
      { text: 'a. AWS KMS', correct: true,  expli:' correct A AWS KMS' },
      { text: 'b. AWS Cetificate Manager', correct: false,  expli:'AWS Cetificate Manager (Used to encrypt data in transit, pot at rest)' },
	    { text: 'c. IAM Access Keys', correct: false,  expli:' IAM Access Keys (Used to secure access to EC2 instances)' },
      { text: 'd. API Gateway with AssumeRole', correct: false,  expli:'API Gateway with AssumeRole (Used for issuing tokens while using the API Gateway)' }
    ],
	img: '',  
  }, 
  {
    question: '/Explicación antes de Exam 3/ You have a newly developed application hosted on an Amazon EC2 instance. This application needs to access an Amazon DynamoDB table. Which of the following is the most secure way for the application to access the DynamoDB table?',
    answers: [
      { text: 'a. Configure APl credential into EC2 instance user data for automation', correct: false,  expli:' ' },
      { text: 'b. Store APl credentials in Amazon S3 for durability.', correct: false,  expli:' ' },
	    { text: 'c. Embed API credentials to DynamoDB in the application code', correct: false,  expli:' ' },
      { text: 'd. Assign IAM roles to the EC2 instance.', correct: true,  expli:' correct D Assign IAM roles to the EC2 instance.' }
    ],
	img: '',  
  }, 
  {
    question: '/Explicación antes de Exam 3/ Your AWS Account Administrator left your company today. The Administrator had access to the root userand a personal IAM administrator account. With these accounts, he generated other IAM users and keys. Which of the following should you do today to protect your AWS infrastructure? (Select TI IRCC.)',
    answers: [
      { text: 'a. Change the password and add MFA to the root user', correct: true,  expli:' correct A Change the password and add MFA to the root user' },
      { text: 'b. Put an IP restriction on root user logins.', correct: false,  expli:'Put an IP restriction on root user logins. (Not currently supported)' },
	    { text: 'c. Rotate keys and change passwords for IAM users.', correct: true,  expli:'correct C Rotate keys and change passwords for IAM users. ' },
      { text: 'd. Delete all IAM users.', correct: false,  expli:'Delete all IAM users.  (Not needed )' },
      { text: 'e. Delete the Administrator\'s IAM use', correct: true,  expli:' correct E Delete the Administrator\'s IAM use' },
      { text: 'f. Relaunch all EC2 instances with new roles', correct: false,  expli:'Relaunch all EC2 instances with new roles (Roles are temporary credentials)' }
    ],
	img: '',  
  }, 
  {
    question: '/AWS Certified Solutions Architect STUDY GUIDE ASSOCIATE (SAA-CO3) EXAM 37p - 1 / Truelfalse: The Developer Support plan provides access to a support application programming interface (API).',
    answers: [
      { text: 'a. True', correct: false,  expli:' ' },
      { text: 'b. False', correct: true,  expli:' correct B. The Business plan offers access to a support API, but the Developer plan does not. ' }
    ],
	img: '',  
  }, 
  {
    question: '/AWS Certified Solutions Architect STUDY GUIDE ASSOCIATE (SAA-CO3) EXAM 37p - 2 / True/false: AWS is responsible for managing the network configuration of your EC2 instances.',
    answers: [
      { text: 'a. True', correct: false,  expli:' ' },
      { text: 'b. False', correct: true,  expli:'correct B. Customers are responsible for managing the network configuration of EC2 instances. AWS is responsible for the physical network infrastructure. ' }
    ],
	img: '',  
  }, 
  {
    question: '/AWS Certified Solutions Architect STUDY GUIDE ASSOCIATE (SAA-CO3) EXAM 37p - 3 / Which of the following services is most useful for decoupling the components of a monolithic application?',
    answers: [
      { text: 'a. SNS', correct: false,  expli:' ' },
      { text: 'b. KMS', correct: false,  expli:' ' },
	    { text: 'c. SQS', correct: true,  expli:' correct C. Simple Queue Service (SQS) allows for event-driven messaging within distributed systems that can decouple while coordinating the discrete steps of a larger process.  ' },
      { text: 'd. Glacier', correct: false,  expli:' ' }
    ],
	img: '',  
  }, 
  {
    question: '/AWS Certified Solutions Architect STUDY GUIDE ASSOCIATE (SAA-CO3) EXAM 37p - 4 / 4. An application you want to run on EC2 requires you to license it based on the number of physical CPU sockets and cores on the hardware you plan to run the application on. Which of the following tenancy models should you specify?',
    answers: [
      { text: 'a. Dedicated host', correct: true,  expli:'correct A. The dedicated host option lets you see the number of physical CPU sockets and cores on a host.' },
      { text: 'b. Dedicated instance', correct: false,  expli:' ' },
	    { text: 'c. Shared tenancy', correct: false,  expli:' ' },
      { text: 'd. Bring your own license', correct: false,  expli:' ' }
    ],
	img: '',  
  }, 
  {
    question: '/AWS Certified Solutions Architect STUDY GUIDE ASSOCIATE (SAA-CO3) EXAM 37p - 5 / 5. True/false: Changing the instance type of an EC2 instance will change its elastic IP address.',
    answers: [
      { text: 'a. True', correct: false,  expli:' ' },
      { text: 'b. False', correct: true,  expli:'correct B. An elastic IP address will not change. A public IP address attached to an instance will change if the instance is stopped, as would happen when changing the instance type. ' }
    ],
	img: '',  
  }, 
  {
    question: '/AWS Certified Solutions Architect STUDY GUIDE ASSOCIATE (SAA-CO3) EXAM 37p - 6 / True/talse: You can use a Quick Start Amazon Machine lmage (AMI) to create any instance type.',
    answers: [
      { text: 'a. True', correct: true,  expli:'correct A. A Quick Start AMI is independent of the instance type.  ' },
      { text: 'b. False', correct: false,  expli:' ' }
    ],
	img: '',  
  }, 
  {
    question: '/AWS Certified Solutions Architect STUDY GUIDE ASSOCIATE (SAA-CO3) EXAM 37p - 7 / 7 Which S3 encryption option does inot require AWS persistently storing the encryption keys it uses to decrypt data?',
    answers: [
      { text: 'a. Client-side encryption', correct: false,  expli:' ' },
      { text: 'b. SSE-KMS', correct: false,  expli:' ' },
	    { text: 'c. SSE-S3', correct: false,  expli:' ' },
      { text: 'd. SSE-C', correct: true,  expli:' correct D. With SSE-C you provide your own keys for Amazon to use to decrypt and encrypt your data. AWS doesn\'t persistently store the keys.  ' }
    ],
	img: '',  
  }, 
  {
    question: '/AWS Certified Solutions Architect STUDY GUIDE ASSOCIATE (SAA-CO3) EXAM 37p - 8 /8. True/false: Durability measures the percentage of likelihood that a given object will not be inadvertently lost by AWS over the course of a year.',
    answers: [
      { text: 'a. True', correct: true,  expli:' correct A. Durability corresponds to an average annual expected loss of objects stored on S3, not including objects you delete. Availability measures the amount of time $3 will be available to let you retrieve those objects. ' },
      { text: 'b. False', correct: false,  expli:' ' }
    ],
	img: '',  
  }, 
  {
    question: '/AWS Certified Solutions Architect STUDY GUIDE ASSOCIATE (SAA-CO3) EXAM 37p - 9 /9. True/false: After uploading a new object to S3, there will be a slight delay (one to two seconds) before the object is available.',
    answers: [
      { text: 'a. True', correct: false,  expli:' ' },
      { text: 'b. False', correct: true,  expli:'correct B. S3 uses a read-after-write consistency model for new objects, so once you upload an object to S3, it\'s immediately available. ' }
    ],
	img: '',  
  }, 
  {
    question: '/AWS Certified Solutions Architect STUDY GUIDE ASSOCIATE (SAA-CO3) EXAM 37p - 10 / 10. You created a virtual private cloud (VPC) using the Classless Inter-Domain Routing (CIDR) block 10.0.0.0/24. You need to connect to this VPC from your internal network, but the IP addresses in use on your internal network overlap with the CIDR. Which of the following is a valid way to address this problem?',
    answers: [
      { text: 'a. Remove the CIDR and use IPv6 instead.', correct: false,  expli:' ' },
      { text: 'b. Change the VPC\'s CIDR.', correct: false,  expli:' ' },
	    { text: 'c. Create a new VPC with a different CIDR.', correct: true,  expli:'correct C. You can\'t change the primary CIDR for a VPC, so you must create a new one to connect it to your internal network.  ' },
      { text: 'd. Create a secondary CIDR for the VPC.', correct: false,  expli:' ' }
    ],
	img: '',  
  }, 
  {
    question: '/AWS Certified Solutions Architect STUDY GUIDE ASSOCIATE (SAA-CO3) EXAM 37p - 11 / 11. True/talse: An EC2 instance must be in a public subnet to access the Internet.',
    answers: [
      { text: 'a. True', correct: false,  expli:' ' },
      { text: 'b. False', correct: true,  expli:' correct B. An EC2 instance can access the Internet from a private subnet provided it uses a NAT gateway or NAT instance.   ' }
    ],
	img: '',  
  }, 
  {
    question: '/AWS Certified Solutions Architect STUDY GUIDE ASSOCIATE (SAA-CO3) EXAM 37p - 12 / 12. True/false: The route table for a public subnet must have a default route pointing to an Internet gateway as a target.',
    answers: [
      { text: 'a. True', correct: true,  expli:' correct A. The definition of a public subnet is a subnet that has a default route pointing to an Inter net gateway as a target. Otherwise, it\'s a private subnet.  ' },
      { text: 'b. False', correct: false,  expli:' ' }
    ],
	img: '',  
  }, 
  {
    question: '/AWS Certified Solutions Architect STUDY GUIDE ASSOCIATE (SAA-CO3) EXAM 37p - 13 / 13. Which of the following use cases is well suited for DynamoDB?',
    answers: [
      { text: 'a. Running a MongoDB database on AWS', correct: false,  expli:' ' },
      { text: 'b. Storing large binary files exceeding 1 GB in size', correct: false,  expli:' ' },
	    { text: 'c. Storing JSON documents that have a consistent structure', correct: true,  expli:' correct C. DynamoDB is a key-value store that can be used to store items up to 400 KB in size. ' },
      { text: 'd.Storing image assets for a website ', correct: false,  expli:' ' }
    ],
	img: '',  
  }, 
  {
    question: '/AWS Certified Solutions Architect STUDY GUIDE ASSOCIATE (SAA-CO3) EXAM 37p - 14 / 14. True/false: You can create a DynamoDB global secondary index for an existing table at any time.',
    answers: [
      { text: 'a. True', correct: true,  expli:' correct A. You can create a global secondary index for an existing table at any time. You can create a local secondary index only when you create the table. ' },
      { text: 'b. False', correct: false,  expli:' ' }
    ],
	img: '',  
  }, 
  {
    question: '/AWS Certified Solutions Architect STUDY GUIDE ASSOCIATE (SAA-CO3) EXAM 37p - 15 / ',
    answers: [
      { text: 'a. True', correct: true,  expli:' correct A. Enabling point-in-time recovery gives you an RPO of about five minutes. The recovery time objective (RTO) depends on the amount of data to restore.  ' },
      { text: 'b. False', correct: false,  expli:' ' }
    ],
	img: '',  
  }, 
  {
    question: '/AWS Certified Solutions Architect STUDY GUIDE ASSOCIATE (SAA-CO3) EXAM 37p - 16 / 16. Which of the following steps does the most to protect your AWS account?',
    answers: [
      { text: 'a. Deleting unused Identity and Access Management (IAM) policies', correct: false,  expli:' ' },
      { text: 'b. Revoking unnecessary access for IAM users', correct: true,  expli:' correct  B. Revoking unnecessary access for IAM users is the most effective of the listed measures for protecting your AWS account.   ' },
	    { text: 'c. Rotating root access keys', correct: false,  expli:' ' },
      { text: 'd. Restricting access to S3 buckets', correct: false,  expli:' ' },
      { text: 'e. Rotating Secure Shell (SSH) key pairs', correct: false,  expli:' ' }
    ],
	img: '',  
  }, 
  {
    question: '/AWS Certified Solutions Architect STUDY GUIDE ASSOCIATE (SAA-CO3) EXAM 37p - 17 / 17. Which of the following can be used to encrypt the operating system of an EC2 instance?',
    answers: [
      { text: 'a. AWS Secrets Manager', correct: false,  expli:' ' },
      { text: 'b. CloudHSM', correct: false,  expli:' ' },
	    { text: 'c. AWS Key Management Service (KMS)', correct: true,  expli:' correct C. KMS can be used to encrypt Elastic Block Store (EBS) volumes that store an instance\'s operating system.  ' },
      { text: 'd. AWS Security Token Service (STS) ', correct: false,  expli:' ' }
    ],
	img: '',  
  }, 
  {
    question: '/AWS Certified Solutions Architect STUDY GUIDE ASSOCIATE (SAA-CO3) EXAM 37p - 18 / 18. What is a difference between a token generated by the AWS Security Token Service (STS) and an IAM access key?',
    answers: [
      { text: 'a. The token generated by STS can\'t be used by an IAM principal. ', correct: false,  expli:' ' },
      { text: 'b. An IAM access key is unique.', correct: false,  expli:' ' },
	    { text: 'c. The token generated by STS can be used only once', correct: false,  expli:' ' },
      { text: 'd. The token generated by STS expires.', correct: true,  expli:' correct D. STS tokens expire and IAM access keys do not. An STS token can be used more than once. IAM access keys and STS tokens are both unique. An TAM principal can use an STS token.  ' }
    ],
	img: '',  
  }, 
  {
    question: '/AWS Certified Solutions Architect STUDY GUIDE ASSOCIATE (SAA-CO3) EXAM 37p - 19 / 19. True/false: EC2 sends instance memory utilization metrics to Cloud Watch every five minutes.',
    answers: [
      { text: 'a. True', correct: false,  expli:' ' },
      { text: 'b. False', correct: true,  expli:'correct B. EC2 doesn\'t track instance memory utilization. ' }
    ],
	img: '',  
  }, 
  {
    question: '/AWS Certified Solutions Architect STUDY GUIDE ASSOCIATE (SAA-CO3) EXAM 37p - 20 / 20. You configured a Cloud Watch alarm to monitor CPU utilization for an EC2 instance. The alarm began in the INSUFFICIENT_DATA state and then entered the ALARM state. What can you conclude from this?',
    answers: [
      { text: 'a. The instance recently rebooted.', correct: false,  expli:' ' },
      { text: 'b. CPU utilization is too high.', correct: false,  expli:' ' },
	    { text: 'c. The CPU utilization metric crossed the alarm threshold.', correct: true,  expli:' correct C. T he transition to the ALARM state simply implies that the metric crossed a threshold but doesn\'t tell you what the threshold is. Newly created alarms start out in the INSUFFICIENT_DATA state.   ' },
      { text: 'd. The instance is stopped.', correct: false,  expli:' ' }
    ],
	img: '',  
  }, 
  {
    question: '/AWS Certified Solutions Architect STUDY GUIDE ASSOCIATE (SAA-CO3) EXAM 37p - 21 / 21. Where do AWS Config and Cloud Trail store their logs?',
    answers: [
      { text: 'a. S3 buckets', correct: true,  expli:' correct  A. Both store their logs in S3 buckets.  ' },
      { text: 'b. CloudWatch Logs', correct: false,  expli:' ' },
	    { text: 'c. CloudTrail Events', correct: false,  expli:' ' },
      { text: 'd. DynamoDB', correct: false,  expli:' ' },
      { text: 'e. Amazon Athena', correct: false,  expli:' ' }
    ],
	img: '',  
  }, 
  {
    question: '/AWS Certified Solutions Architect STUDY GUIDE ASSOCIATE (SAA-CO3) EXAM 37p -22 / 22. True/talse: An EC2 instance in a private subnet can resolve an "A" resource record for a public hosted zone hosted in Route 53.',
    answers: [
      { text: 'a. True', correct: true,  expli:' correct A. An EC2 instance in a private subnet still has access to Amazon\'s private DNS servers, which can resolve records stored in public hosted zones. ' },
      { text: 'b. False', correct: false,  expli:' ' }
    ],
	img: '',  
  }, 
  {
    question: '/AWS Certified Solutions Architect STUDY GUIDE ASSOCIATE (SAA-CO3) EXAM 37p - 23 / 23. You want to use Route 53 to send users to the application load balancer closest to them. Which of the following routing policies lets you do this with the least effort?',
    answers: [
      { text: 'a. Latency routing', correct: false,  expli:' ' },
      { text: 'b. Geolocation routing', correct: false,  expli:' ' },
	    { text: 'c. Geoproximity routing', correct: true,  expli:' correct C. Geoproximity routing routes users to the location closest to them. Geolocation routing requires you to create records tor specihc locations or create a detault record.  ' },
      { text: 'd. Edge routing', correct: false,  expli:' ' }
    ],
	img: '',  
  }, 
  {
    question: '/AWS Certified Solutions Architect STUDY GUIDE ASSOCIATE (SAA-CO3) EXAM 37p - 24 / 24. True/false: You can use an existing domain name with Route 53 without switching its registration to AWS.',
    answers: [
      { text: 'a. True', correct: true,  expli:' correct A. Route 53 is a true DNS service in that it can host zones for any domain name. You can also register domain names with or transfer them to Route 53.   ' },
      { text: 'b. False', correct: false,  expli:' ' }
    ],
	img: '',  
  }, 
  {
    question: '/AWS Certified Solutions Architect STUDY GUIDE ASSOCIATE (SAA-CO3) EXAM 37p - 25 / 25. You\'re designing an application that takes multiple image files and combines them into a video file that users on the Internet can download. Which of the following can help you quickly implement your application in the fastest, most highly available, and most cost eftective manner?',
    answers: [
      { text: 'a. EC2 spot fleet', correct: false,  expli:' ' },
      { text: 'b. Lambda', correct: true,  expli:' correct B. Lambda is a highly available, reliable, "serverless" compute platform that runs functions as needed and scales elastically to meet demand. EC2 spot instances can be shut down on short notice.   ' },
	    { text: 'c. Relational Database Service (RDS)', correct: false,  expli:' ' },
      { text: 'd. Auto Scaling', correct: false,  expli:' ' }
    ],
	img: '',  
  }, 
  {
    question: '/AWS Certified Solutions Architect STUDY GUIDE ASSOCIATE (SAA-CO3) EXAM 37p - 26 / 26. You\'re using EC2 Auto Scaling and want to implement a scaling policy that adds one extra instance only when the average CPU utilization of each instance exceeds 90 percent. However, you don\'t want it to add more than one instance every five minutes. Which of the following scaling policies should you use?',
    answers: [
      { text: 'a. Simple', correct: true,  expli:' correct A. A simple scaling policy changes the group size and then has a cooldown period before doing so again. Step scaling policies don\'t have cooldown periods. Target tracking policies attempt to keep a metric at a set value. PercentChangeInCapacity is a simple scaling adjustment type, not a scaling policy.  ' },
      { text: 'b. Step', correct: false,  expli:' ' },
	    { text: 'c. Target tracking', correct: false,  expli:' ' },
      { text: 'd. PercentChangeInCapacity', correct: false,  expli:' ' }
    ],
	img: '',  
  }, 
  {
    question: '/AWS Certified Solutions Architect STUDY GUIDE ASSOCIATE (SAA-CO3) EXAM 37p - 27 / 27. True/false: EC2 Auto Scaling automatically replaces group instances directly terminated by the root user.',
    answers: [
      { text: 'a. True', correct: true,  expli:' correct A. Auto Scaling always attempts to maintain the minimum group size or, if set, the desired capacity.  ' },
      { text: 'b. False', correct: false,  expli:' ' }
    ],
	img: '',  
  }, 
  {
    question: '/AWS Certified Solutions Architect STUDY GUIDE ASSOCIATE (SAA-CO3) EXAM 37p - 28 / 28. Which ElastiCache engine can persistently store data?',
    answers: [
      { text: 'a. MysQL', correct: false,  expli:' ' },
      { text: 'b. Memcached', correct: false,  expli:' ' },
	    { text: 'c. MongoDB', correct: false,  expli:' ' },
      { text: 'd. Redis', correct: true,  expli:' correct  D. ElastiCache supports Memcached and Redis, but only the latter can store data persistently. ' }
    ],
	img: '',  
  }, 
  {
    question: '/AWS Certified Solutions Architect STUDY GUIDE ASSOCIATE (SAA-CO3) EXAM 37p - 29 / 29. Which of the following is not an AWS service?',
    answers: [
      { text: 'a. CloudFormation', correct: false,  expli:' ' },
      { text: 'b. Puppet', correct: true,  expli:' correct B. Puppet is a configuration management platform that AWS offers via OpsWorks but is not itself an AWS service.  ' },
	    { text: 'c. OpsWorks', correct: false,  expli:' ' },
      { text: 'd. Snowball', correct: false,  expli:' ' }
    ],
	img: '',  
  }, 
  {
    question: '/AWS Certified Solutions Architect STUDY GUIDE ASSOCIATE (SAA-CO3) EXAM 37p - 30 / 30. True/false: S3 cross-region replication uses transfer acceleration.',
    answers: [
      { text: 'a. True', correct: false,  expli:' ' },
      { text: 'b. False', correct: true,  expli:'correct B. S3 cross-region replication transfers objects between different buckets. Transfer acceleration uses a CloudFront edge location to speed up transfers between S3 and the Internet.  ' }
    ],
	img: '',  
  }, 
  {
    question: '/AWS Certified Solutions Architect STUDY GUIDE ASSOCIATE (SAA-CO3) EXAM 37p - 31 / 31. Which of the following services can you deactivate on your account?',
    answers: [
      { text: 'a. Security Token Service (STS)', correct: true,  expli:' correct  A. You can deactivate SIS for all regions except US East. ' },
      { text: 'b. CloudWatch', correct: false,  expli:' ' },
	    { text: 'c. Virtual private cloud (VPC)', correct: false,  expli:' ' },
      { text: 'd. Lambda', correct: false,  expli:' ' }
    ],
	img: '',  
  }, 
  {
    question: '/AWS Certified Solutions Architect STUDY GUIDE ASSOCIATE (SAA-CO3) EXAM 37p - 32 / 32. Which of the following services can alert you to malware on an EC2 instance?',
    answers: [
      { text: 'a. AWS GuardDuty', correct: true,  expli:' correct A. GuardDuty looks for potentially malicious activity. Inspector looks for vulnerabilities that may result in compromise. Shield and Web Application Firewall protect applications from attack. ' },
      { text: 'b. AWS Inspector', correct: false,  expli:' ' },
	    { text: 'c. AWS Shield', correct: false,  expli:' ' },
      { text: 'd. AWS Web Application Firewall', correct: false,  expli:' ' }
    ],
	img: '',  
  }, 
  {
    question: '/AWS Certified Solutions Architect STUDY GUIDE ASSOCIATE (SAA-CO3) EXAM 37p - 33 / 33. True/false: If versioning is enabled on an $3 bucket, applying encryption to an unencrypted object in that bucket will create a new, encrypted version of that object.',
    answers: [
      { text: 'a. True', correct: true,  expli:' correct A. Applying encryption to an unencrypted object will create a new, encrypted version of that object. Previous versions remain unencrypted. ' },
      { text: 'b. False', correct: false,  expli:' ' }
    ],
	img: '',  
  }, 
  {
    question: '/AWS Certified Solutions Architect STUDY GUIDE ASSOCIATE (SAA-CO3) EXAM 37p - 34 / 34. Which instance type will, it left running, continue to incur costs?',
    answers: [
      { text: 'a. Spot', correct: false,  expli:' ' },
      { text: 'b. Standard reserved', correct: false,  expli:' ' },
	    { text: 'c. On-demand', correct: true,  expli:' correct C. On-demand instances will continue to run and incur costs. Reserved instances cost the same whether they\'re running or stopped. Spot instances will be ternminated when the spot price exceeds your bid price. ' },
      { text: 'd. Convertible reserved', correct: false,  expli:' ' }
    ],
	img: '',  
  }, 
  {
    question: '/AWS Certified Solutions Architect STUDY GUIDE ASSOCIATE (SAA-CO3) EXAM 37p - 35/ 35. True/false: The EBS Lifecycle Manager can take snapshots of volumes that were once attached to terminated instances.',
    answers: [
      { text: 'a. True', correct: true,  expli:' correct A. The EBS Lifecycle Manager can take scheduled snapshots of any EBS volume, regardless of attachment state. ' },
      { text: 'b. False', correct: false,  expli:' ' }
    ],
	img: '',  
  }, 
  {
    question: '/AWS Certified Solutions Architect STUDY GUIDE ASSOCIATE (SAA-CO3) EXAM 37p - 36 / 36. Which of the following lets you spin up new web servers the quickest?',
    answers: [
      { text: 'a. Lambda', correct: false,  expli:' ' },
      { text: 'b. Auto Scaling', correct: false,  expli:' ' },
	    { text: 'c. Elastic Container Service', correct: true,  expli:' correct C. Elastic Container Service lets you run containers that can launch in a matter of seconds. EC2 instances take longer. Lambda is *serverless," so you can\'t use it to run a web server. CloudFront provides caching but isn\'t a web server.  ' },
      { text: 'd. CloudFront', correct: false,  expli:' ' }
    ],
	img: '',  
  }, 
  {
    question: '/AWS Certified Solutions Architect STUDY GUIDE ASSOCIATE (SAA-CO3) EXAM 37p - 37 / 37. True/false: CloudFormation stack names are case-sensitive.',
    answers: [
      { text: 'a. True', correct: true,  expli:' correct A. Almost everything in CloudFormation is case sensitive.  ' },
      { text: 'b. False', correct: false,  expli:' ' }
    ],
	img: '',  
  }, 
  {
    question: '/AWS Certified Solutions Architect STUDY GUIDE ASSOCIATE (SAA-CO3) EXAM Chapter 1 Introduction to Cloud Computing and AWS 12p - 1 / 1. Your developers want to run fully provisioned EC2 instances to support their application code deployments but prefer not to have to worry about manually configuring and launching the necessary infrastructure. Which of the following should they use?',
    answers: [
      { text: 'a. AWS Lambda', correct: false,  expli:' ' },
      { text: 'b. AWS Elastic Beanstalk', correct: true,  expli:' correct B. Elastic Beanstalk takes care of the ongoing underlying deployment details for you, allow ing you to focus exclusively on your code. Lambda will respond to trigger events by running code a single time, Auto Scaling will ramp up existing infrastructure in response to demand, and Route 53 manages DNS and network routing' },
	    { text: 'c. Amazon EC2 Auto Scaling', correct: false,  expli:' ' },
      { text: 'd. Amazon Route 53', correct: false,  expli:' ' }
    ],
	img: '',  
  }, 
  {
    question: '/AWS Certified Solutions Architect STUDY GUIDE ASSOCIATE (SAA-CO3) EXAM Chapter 1 Introduction to Cloud Computing and AWS 12p - 2/ 2. Some of your application\'s end users are complaining of delays when accessing your resources from remote geographic locations. Which of these services would be the most likely to help reduce the delays?',
    answers: [
      { text: 'a. Amazon CloudFront', correct: true,  expli:' correct A. CloudFront maintains a network of endpoints where cached versions of your application data are stored to provide quicker responses to user requests. Route 53 manages DNS and network routing, Elastic Load Balancing routes incoming user requests among a cluster of available servers, and Glacier provides high-latency low-cost file storage' },
      { text: 'b. Amazon Route 53', correct: false,  expli:' ' },
	    { text: 'c. Elastic Load Balancing', correct: false,  expli:' ' },
      { text: 'd. Amazon Glacier', correct: false,  expli:' ' }
    ],
	img: '',  
  }, 
  {
    question: '/AWS Certified Solutions Architect STUDY GUIDE ASSOCIATE (SAA-CO3) EXAM Chapter 1 Introduction to Cloud Computing and AWS 12p - 3 / 3. Which of the following is the best use-case scenario for Elastic Block Store?',
    answers: [
      { text: 'a. You need a cheap and reliable place to store files your application can access.', correct: false,  expli:' ' },
      { text: 'b. You need a safe place to store backup archives from your local servers.', correct: false,  expli:' ' },
	    { text: 'c. You need a source tor on-demand compute cycles to meet fluctuating demand for your application.', correct: false,  expli:' ' },
      { text: 'd. You need persistent storage for the filesystem run by your EC2 instance.', correct: true,  expli:' correct D. Elastic Block Store provides virtual block devices (think: storage drives) on which you can install and run filesystems and data operations. It is not normally a cost-effective option for long-term data storage.' }
    ],
	img: '',  
  }, 
  {
    question: '/AWS Certified Solutions Architect STUDY GUIDE ASSOCIATE (SAA-CO3) EXAM Chapter 1 Introduction to Cloud Computing and AWS 12p - 4 / 4. You need to integrate your company\'s local user access controls with some of your AWS resources. Which of the following can help you control the way your local users access your AWS services and administration console? (Choose two.)',
    answers: [
      { text: 'a. AWS Identity and Access Management (IAM)', correct: true,  expli:' correct A ' },
      { text: 'b. Key Management Service (KMS)', correct: false,  expli:' ' },
	    { text: 'c. AWS Directory Service', correct: true,  expli:' correct C,  A y C. AWS TAM lets you create user accounts, groups, and roles and assign them rights and permissions over specific services and resources within your AWS account. Directory Service allows you to integrate your resources with external users and resources through third-party authentication services. KMS is a tool for generating and managing encryption keys, and SWE is a tool tor coordinating application tasks. Amazon Cognito can be used to manage authentication tor your application users, but not your internal admin teams. ' },
      { text: 'd. Simple WorkFlow (SWF)', correct: false,  expli:' ' },
      { text: 'e. Amazon Cognito', correct: false,  expli:' ' }
    ],
	img: '',  
  }, 
  {
    question: '/AWS Certified Solutions Architect STUDY GUIDE ASSOCIATE (SAA-CO3) EXAM Chapter 1 Introduction to Cloud Computing and AWS 12p - 5 / 5. The data consumed by the application you\'re planning will require more speed and flexibility than you can get from a closely defined relational database structure. Which AWS database service should you choose?',
    answers: [
      { text: 'a. Relational Database Service (RDS) ', correct: false,  expli:' ' },
      { text: 'b. Amazon Aurora', correct: false,  expli:' ' },
	    { text: 'c. Amazon DynamoDB', correct: true,  expli:' correct C. DynamoDB provides a NoSQL (nonrelational) database service. Both are good for work- loads that can be more efficiently run without the relational schema of SQL database engines (like those, including Aurora, that are offered by RDS). KMS is a tool for generating and managing encryption keys.' },
      { text: 'd. Key Management Service (KMS)', correct: false,  expli:' ' }
    ],
	img: '',  
  }, 
  {
    question: '/AWS Certified Solutions Architect STUDY GUIDE ASSOCIATE (SAA-CO3) EXAM Chapter 1 Introduction to Cloud Computing and AWS 12p - 6 / 6. You\'ve launched an EC2 application server instance in the AWS Ireland region and you need to access it from the web. Which of the following is the correct endpoint address that you should use?',
    answers: [
      { text: 'a. compute.eu-central-1.amazonaws.com', correct: false,  expli:' ' },
      { text: 'b. ec2.eu-central-1.amazonaws.com', correct: false,  expli:' ' },
	    { text: 'c. elasticcomputecloud.eu-west-2.amazonaws.com', correct: false,  expli:' ' },
      { text: 'd. ec2.eu-west-1.amazonaws.com', correct: true,  expli:' correct D. EC2 endpoints will always start with an EC2 prefix followed by the region designation (eu-west-1 in the case of Ireland).' }
    ],
	img: '',  
  }, 
  {
    question: '/AWS Certified Solutions Architect STUDY GUIDE ASSOCIATE (SAA-CO3) EXAM Chapter 1 Introduction to Cloud Computing and AWS 12p - 7 / 7. When working to set up your first AWS deployment, you keep coming across the term availability zone. What exactly is an availability zone?',
    answers: [
      { text: 'a. An isolated physical datacenter within an AWS region', correct: true,  expli:' correct A. An availability zone is an isolated physical datacenter within an AWS region. Regions are geographic areas that contain multiple availability zones, subnets are IP address blocks that can be used within a zone to organize your networked resources, and there can be multiple datacenters within an availability zone.' },
      { text: 'b. A region containing multiple isolated datacenters', correct: false,  expli:' ' },
	    { text: 'c. A single network subnet used by resources within a single region', correct: false,  expli:' ' },
      { text: 'd. A single isolated server room within a datacenter', correct: false,  expli:' ' }
    ],
	img: '',  
  }, 
  {
    question: '/AWS Certified Solutions Architect STUDY GUIDE ASSOCIATE (SAA-CO3) EXAM Chapter 1 Introduction to Cloud Computing and AWS 12p - 8 / 8. As you plan your multi-tiered, multi-instance AWS application, you need a way to effectively organize your instances and contigure their network connectivity and access control. Which tool will let you do that?',
    answers: [
      { text: 'a. Load Balancing', correct: false,  expli:' ' },
      { text: 'b. Amazon Virtual Private Cloud (VPC)', correct: true,  expli:' correct B. VPCs are virtualized network environments where you can control the connectivity of your EC2 (and RDS, etc.) infrastructure. Load Balancing routes incoming user requests among a cluster of available servers, CloudFront maintains a network of endpoints where cached versions of your application data are stored to provide quicker responses to user requests, and AwS endpoints are URls that point to AWS resources within your account.' },
	    { text: 'c. Amazon CloudFront', correct: false,  expli:' ' },
      { text: 'd. AWS endpoints', correct: false,  expli:' ' }
    ],
	img: '',  
  }, 
  {
    question: '/AWS Certified Solutions Architect STUDY GUIDE ASSOCIATE (SAA-CO3) EXAM Chapter 1 Introduction to Cloud Computing and AWS 12p - 9 / 9. You want to be sure that the application you\'re building using EC2 and S3 resources will be reliable enough to meet the regulatory standards required within your industry. What should you check?',
    answers: [
      { text: 'a. Historical uptime log records', correct: false,  expli:' ' },
      { text: 'b. The AWS Program Compliance Tool', correct: false,  expli:' ' },
	    { text: 'c. The AWS service level agreement (SLA)', correct: true,  expli:' correct C. The AWS service level agreement tells you the level of service availability you can realistically expect from a particular AWS service. You can use this information when assessing your compliance with external standards. Log records, though they can offer important historical pertormance metrics, probably won\'t be enough to prove compliance. The AWS Compliance Programs page will show you only which regulatory programs can be satisfied with AWS resources, not whether a particular configuration will meet their demands. The AWS Shared Responsibility Model outlines who is responsible for various elements of your AWS infrastructure. There is no AWS Program Compliance tool. ' },
      { text: 'd. The AWS Compliance Programs documentation page', correct: false,  expli:' ' },
      { text: 'e. The AWS Shared Responsibility Model', correct: false,  expli:' ' }
    ],
	img: '',  
  }, 
  {
    question: '/AWS Certified Solutions Architect STUDY GUIDE ASSOCIATE (SAA-CO3) EXAM Chapter 1 Introduction to Cloud Computing and AWS 12p - 10 / 10. Your organization\'s operations team members need a way to access and administer your AWS infrastructure via your local command line or shell scripts. Which of the following tools will let them do that?',
    answers: [
      { text: 'a. AWS Config', correct: false,  expli:' ' },
      { text: 'b. AWS CLI', correct: true,  expli:'correct B. The AWS Command-Line Interface (CLI) is a tool for accessing AWS APIs from the command-line shell ot your local computer. The AWS SDK is for accessing resources programmatically, the AWS Console works graphically through your browser, and AWS Config is a service for editing and auditing your AWS account resources. ' },
	    { text: 'c. AWS SDK', correct: false,  expli:' ' },
      { text: 'd. The AWS Console', correct: false,  expli:' ' }
    ],
	img: '',  
  }, 
  {
    question: '/AWS Certified Solutions Architect STUDY GUIDE ASSOCIATE (SAA-CO3) EXAM Chapter 1 Introduction to Cloud Computing and AWS 12p - 11 / 11. While building a large AWS-based application, your company has been facing configuration problems they can\'t solve on their own. As a result, they need direct access to AWS support for both development and IT team leaders. Which support plan should you purchase?',
    answers: [
      { text: 'a. Business', correct: true,  expli:'correct A. Unlike the Basic and Developer plans (which allow access to a support associate to no or one user, respectively), the Business plan allows multiple team members. ' },
      { text: 'b. Developer', correct: false,  expli:' ' },
	    { text: 'c. Basic', correct: false,  expli:' ' },
      { text: 'd. Enterprise', correct: false,  expli:' ' }
    ],
	img: '',  
  }, 
  {
    question: '/AWS Certified Solutions Architect STUDY GUIDE ASSOCIATE (SAA-CO3) EXAM Chapter 1 Introduction to Cloud Computing and AWS 12p - 12 / 12. You\'ve got a complex, multi-tiered application running on local servers that you want to migrate to the cloud. Which of these tools will provide you with the specific tools you\'ll need to move the application with the least risk and the least disruption?',
    answers: [
      { text: 'a. AWS Application Migration Service', correct: true,  expli:' correct A. Application Migration Service can automate the testing and transter of AWS-bound migrations of your non-cloud application servers. That, therefore, is the correct answer. Migration Hub is a high-level tools for coordinating migrations. Application Discovery Service takes an inventory of your infrastructure but doesn\'t migrate anything itself. Lift and Shift doesn\'t actually exist, but don\'t you wish it did.' },
      { text: 'b. AWS Migration Hub', correct: false,  expli:' ' },
	    { text: 'c. AWS Application Discovery Service', correct: false,  expli:' ' },
      { text: 'd. AWS Lift and Shift', correct: false,  expli:' ' }
    ],
	img: '',  
  }, 
  {
    question: '/AWS Certified Solutions Architect STUDY GUIDE ASSOCIATE (SAA-CO3) EXAM Chapter 2 Compute Services 24p - 1 / 1. You need to deploy multiple EC2 Linux instances that will provide your company with virtual private networks (VPNs) using software called OpenVPN. Which of the following will be the most efticient solutions? (Choose two.)',
    answers: [
      { text: 'a. Select a regular Linux AMI and bootstrap it using user data that will install and configure the OpenVPN package on the instance and use it for your VPN instances.', correct: true,  expli:' correct A  ' },
      { text: 'b. Search the community AMIs for an official AMI provided and supported by the OpenVPN company. Search the AWS] ported by the OpenVPN company.', correct: false,  expli:' ' },
	    { text: 'c. ketplace to see whether there\'s an official AMI provided and sup', correct: true,  expli:' correct C, A y C. Many third-party companies maintain otticial and supported AMls running their software on the AWS Marketplace. AMIs hosted among the community AMls are not always official and supported versions. Since your company will need several such instances, you\'ll be better oft automating the process by bootstrapping rather than having to configure the software manually each time. The site-to-site VPN tool doesn\'t use OpenVPN.' },
      { text: 'd. Select a regular Linux AMI and SSH to manually install and configure the OpenVPN package.', correct: false,  expli:' ' },
      { text: 'e. Create a site-to-site VPN connection from the wizard in the AWS VPC dashboard.', correct: false,  expli:' ' }
    ],
	img: '',  
  }, 
  {
    question: '/AWS Certified Solutions Architect STUDY GUIDE ASSOCIATE (SAA-CO3) EXAM Chapter 2 Compute Services 24p - 2 / 2. As part of your company\'s long-term cloud migration strategy, you have a VMware virtual machine in your local intrastructure that you\'d like to copy to your AWS account and run as an EC2 instance. Which of the tollowing will be necessary steps? (Choose two.)',
    answers: [
      { text: 'a. Import the virtual machine to your AWS region using a secure SSH tunnel.', correct: false,  expli:' ' },
      { text: 'b. Import the virtual machine using VM Import/Export.', correct: true,  expli:' correct B ' },
	    { text: 'c. Select the imported VM from among your private AMIs and launch an instance.', correct: true,  expli:' correct B, B y C. The VM Import/Export tool handles the secure and reliable transfer for a virtual machine between your AWS account and local datacenter. A successfully imported VM will appear among the private AMIs in the region you selected. Direct S3 uploads and SSH tunnels are not associated with VM Import/Export.' },
      { text: 'd. Select the imported VM from the AWS Marketplace AMIs and launch an instance.', correct: false,  expli:' ' },
      { text: 'e. Use the AWS CLI to securely copy your virtual machine image to an S3 bucket within the AWS region you\'ll be using.', correct: false,  expli:' ' }
    ],
	img: '',  
  }, 
  {
    question: '/AWS Certified Solutions Architect STUDY GUIDE ASSOCIATE (SAA-CO3) EXAM Chapter 2 Compute Services 24p - 3 / 3. Your AWS CLI command to launch an AMI as an EC2 instance has failed, giving you an error message that includes InvalidAMIID. NotFound. What of the following is the most likely cause?',
    answers: [
      { text: 'a. You haven\'t properly configured the ~/. aws/config file.', correct: false,  expli:' ' },
      { text: 'b. The AMI is being updated and is temporarily unavailable.', correct: false,  expli:' ' },
	    { text: 'c. Your key pair file has been given the wrong (overly permissive) permissions.', correct: false,  expli:' ' },
      { text: 'd. The AMI you specified exists in a different region than the one you\'ve currently specified.', correct: true,  expli:' correct D. AMIs are specific to a single AWS region and cannot be deployed into any other region. If your AWS CLI or its key pair was not configured properly, your connection would have failed completely. A public AMI being unavailable because it\'s "updating" is theoretically possible but unlikely.' }
    ],
	img: '',  
  }, 
  {
    question: '/AWS Certified Solutions Architect STUDY GUIDE ASSOCIATE (SAA-CO3) EXAM Chapter 2 Compute Services 24p - 4 / 4. The sensitivity of the data your company works with means that the instances you run must be secured through complete physical isolation. What should you specify as you configure a new instance?',
    answers: [
      { text: 'a. Dedicated Host tenancy', correct: true,  expli:' correct A. Only Dedicated Host tenancy offers full isolation. Shared tenancy instances will often share hardware with operations belonging to other organizations. Dedicated instance tenancy instances may be hosted on the same physical server as other instances Within your account.' },
      { text: 'b. Shared tenancy', correct: false,  expli:' ' },
	    { text: 'c. Dedicated Instance tenancy', correct: false,  expli:' ' },
      { text: 'd. Isolated tenancy', correct: false,  expli:' ' }
    ],
	img: '',  
  }, 
  {
    question: '/AWS Certified Solutions Architect STUDY GUIDE ASSOCIATE (SAA-CO3) EXAM Chapter 2 Compute Services 24p - 5 / 5. Normally, two instances running m5.large instance types can handle the trattic accessing your online e-commerce site, but you know that you will face short, unpredictable periods of high demand. Which of the following choices should you implement? (Choose two.)',
    answers: [
      { text: 'a. Configure autoscaling', correct: true,  expli:' correct A ' },
      { text: 'b. Configure load balancing', correct: false,  expli:' ' },
	    { text: 'c. Purchase two ms.large instances on the spot market and as many on-demand instances as necessary.', correct: false,  expli:' ' },
      { text: 'd. Shut down your m5.large instances and purchase instances using a more robust instance type to replace them.', correct: false,  expli:' ' },
      { text: 'e. Purchase two m5.large reserve instances and as many on-demand instances as necessary.', correct: true,  expli:' correct E , A y E. Reserve instances will give you the best price for instances you know will be running 24/7, whereas on-demand makes the most sense for workloads that will run at unpredictable times but can\'t be shut down until they\'re no longer needed. Load balancing controls traffic routing and, on its own, has no impact on your ability to meet changing demand. Since the ms.large instance type is all you need to meet normal workloads, you\'ll be wasting money by running a larger type 24/7.' }
    ],
	img: '',  
  }, 
  {
    question: '/AWS Certified Solutions Architect STUDY GUIDE ASSOCIATE (SAA-CO3) EXAM Chapter 2 Compute Services 24p - 6 / 6. Which of the following use cases would be most cost effective if run using spot market instances?',
    answers: [
      { text: 'a. Your e-commerce website is built using a publicly available AMI.', correct: false,  expli:' ' },
      { text: 'b. You provide high-end video rendering services using a fault-tolerant process that can easily manage a job that was unexpectedly interrupted.', correct: true,  expli:' correct B. Spot market instances can be shut down with only a minimal (two-minute) warning, so they\'re not recommended for workloads that require reliably predictable service. Even if your AMI can be relaunched, the interrupted workload will still be lost. Static S3 websites dont run on EC2 infrastructure in the first place.' },
	    { text: 'c. You\'re running a backend database that must be reliably updated to keep track of critical transactions.', correct: false,  expli:' ' },
      { text: 'd. Your deployment runs as a static website on S3.', correct: false,  expli:' ' }
    ],
	img: '',  
  }, 
  {
    question: '/AWS Certified Solutions Architect STUDY GUIDE ASSOCIATE (SAA-CO3) EXAM Chapter 2 Compute Services 24p - 7 / 7. In the course of a routine intrastructure audit, your organization discovers that some of your running EC2 instances are not configured properly and must be updated. Which of the following configuration details cannot be changed on an existing EC2 instance?',
    answers: [
      { text: 'a. AMI', correct: true,  expli:' correct A. You can edit or even add or remove security groups from running instances and the changes will take effect instantly. Similarly, you can associate or release an elastic IP address to/from a running instance. You can change an instance type as long as you shut down the instance first. But the AMI can\'t be changed, you\'ll need to create an entirely new instance.' },
      { text: 'b. Instance type', correct: false,  expli:' ' },
	    { text: 'c. Security group', correct: false,  expli:' ' },
      { text: 'd. Public IP address', correct: false,  expli:' ' }
    ],
	img: '',  
  }, 
  {
    question: '/AWS Certified Solutions Architect STUDY GUIDE ASSOCIATE (SAA-CO3) EXAM Chapter 2 Compute Services 24p - 8 / 8. For an account with multiple resources running as part of multiple projects, which of the following key/value combination examples would make for the most ettective identification convention for resource tags?',
    answers: [
      { text: 'a. servers:server1', correct: false,  expli:' ' },
      { text: 'b. projectl:serverl', correct: true,  expli:' correct B. The first of two (and not three) strings in a resource tag is the key--the group to which the specific resource belongs. The second string is the value, which identifies the resource itself. If the key looks too much like the value, it can cause confusion.' },
	    { text: 'c. EC2:projectl:serverl', correct: false,  expli:' ' },
      { text: 'd. serverl:project1', correct: false,  expli:' ' }
    ],
	img: '',  
  }, 
  {
    question: '/AWS Certified Solutions Architect STUDY GUIDE ASSOCIATE (SAA-CO3) EXAM Chapter 2 Compute Services 24p - 9 / 9. Which of the following EBS options will you need to keep your data-hungry application that requires up to 20,000 1OPS happy?',
    answers: [
      { text: 'a. Cold HDD', correct: false,  expli:' ' },
      { text: 'b. General-purpose SSD', correct: false,  expli:' ' },
	    { text: 'c. Throughput-optimized HDD', correct: false,  expli:' ' },
      { text: 'd. Provisioned-IOPS SSD', correct: true,  expli:' correct D. Provisioned-IOPS SSD volumes are currently the only type that comes close to 20,000 IOPS. In fact, under the right circumstances, they can deliver up to 256,000 IOPS.' }
    ],
	img: '',  
  }, 
  {
    question: '/AWS Certified Solutions Architect STUDY GUIDE ASSOCIATE (SAA-CO3) EXAM Chapter 2 Compute Services 24p - 10 / 10. Your organization needs to introduce Auto Scaling to its infrastructure and needs to generate a "golden image" AMI from an existing EBS volume. This image will need to be shared among multiple AwS accounts belonging to your organization. Which of the following steps will get you there? (Choose three.)',
    answers: [
      { text: 'a. Create an image from a detached EBS volume, use it to create a snapshot, select your new AMI from your private collection, and use it for your launch configuration.', correct: false,  expli:' ' },
      { text: 'b. Create a snapshot of the EBS root volume you need, use it to create an image, select your new AMl from your private collection, and use it for your launch configuration.', correct: true,  expli:' correct B' },
	    { text: 'c. Create an image from the EBS volume attached to the instance, select your new AMI from your private collection, and use it for your launch configuration.', correct: true,  expli:' correct C' },
      { text: 'd. Search the AWS Marketplace for the appropriate image and use it for your launch configuration.', correct: false,  expli:' ' },
      { text: 'e. Import the snapshot of an EBS root volume from a different AWS account, use it to create an image, select your new AMI from your private collection, and use it for your launch configuration.', correct: true,  expli:'correct E,  B, C, E. Options B, C, and E are steps necessary for creating and sharing such an image. When an image is created, a snapshot is automatically created from which an AMI is built. You do not, however, create a snapshot from an image. The AWS Marketplace contains only public images; hopefully, no one will have uploaded your organization\'s private image there! ' }
    ],
	img: '',  
  }, 
  {
    question: '/AWS Certified Solutions Architect STUDY GUIDE ASSOCIATE (SAA-CO3) EXAM Chapter 2 Compute Services 24p - 11 / 11. Which of the following are benefits of instance store volumes? (Choose two.)',
    answers: [
      { text: 'a. Instance volumes are physically attached to the server that\'s hosting your instance, allowing faster data access.', correct: true,  expli:' correct A ' },
      { text: 'b. Instance volumes can be used to store data even after the instance is shut down.', correct: false,  expli:' ' },
	    { text: 'c. The use of instance volumes does not incur costs (beyond those for the instance itselt).', correct: true,  expli:'  correct C , A y C. The fact that instance volumes are physically attached to the host server and add nothing to an instance cost is a benefit. The data on instance volumes is ephemeral and will be lost as soon as the instance is shut down. There is no way to set termination protection for instance volumes because they\'re dependent on the lite cycle of their host instances.' },
      { text: 'd. You can set termination protection so that an instance volume can\'t be accidentally shut down.', correct: false,  expli:' ' },
      { text: 'e. Instance volumes are commonly used as a base for the creation of AMIs.', correct: false,  expli:' ' }
    ],
	img: '',  
  }, 
  {
    question: '/AWS Certified Solutions Architect STUDY GUIDE ASSOCIATE (SAA-CO3) EXAM Chapter 2 Compute Services 24p - 12 / 12. According to default behavior (and AWS recommendations), which of the following IP addresses could be assigned as the private IP for an EC2 instance? (Choose two.)',
    answers: [
      { text: 'a. 54.61.211.98', correct: false,  expli:' ' },
      { text: 'b. 23.176.92.3', correct: false,  expli:' ' },
	    { text: 'c. 172.17.23.43', correct:true,  expli:' correct C' },
      { text: 'd. 10.0.32.176', correct: false,  expli:' ' },
      { text: 'e. 192.140.2.118', correct: true,  expli:' correct D , C y D. By default, EC2 uses the standard address blocks for private subnets, so all private addresses will fall within these ranges: 10.0.0.0 to 10.2S5.255.255, 172.16.0.0 to 172.31.255.255, and 192.168.0.0 to 192.168.255.255.' }
    ],
	img: '',  
  }, 
  {
    question: '/AWS Certified Solutions Architect STUDY GUIDE ASSOCIATE (SAA-CO3) EXAM Chapter 2 Compute Services 24p - 13 / 13. You need to restrict access to your EC2 instance-based application to only certain clients and only certain targets. Which three attributes of an incoming data packet are used by a security group to determine whether it should be allowed through? (Choose three.) ',
    answers: [
      { text: 'a. Network port', correct: true,  expli:' correct A ' },
      { text: 'b. Source address', correct: true,  expli:' correct B ' },
	    { text: 'c. Datagram header size', correct: false,  expli:' ' },
      { text: 'd. Network protocol', correct: false,  expli:' ' },
      { text: 'e. Destination address', correct: true,  expli:'correct D,  A, B, D. Ports and source and destinations addresses are considered by security group rules. Security group rules do not take packet size into consideration. Since a security group is directly associated with specitic objects, there\'s no need to reference the target address.' }
    ],
	img: '',  
  }, 
  {
    question: '/AWS Certified Solutions Architect STUDY GUIDE ASSOCIATE (SAA-CO3) EXAM Chapter 2 Compute Services 24p - 14 / 14. How are IAM roles commonly used to ensure secure resource access in relation to EC2 instances?',
    answers: [
      { text: 'a. A role can assign processes running on the EC2 instance itself permission to access other AWS resources.', correct: false,  expli:' ' },
      { text: 'b. A user can be given permission to authenticate as a role and access all assoCiated resources.', correct: false,  expli:' ' },
	    { text: 'c. A role can be associated with individual instance-based processes (Linux instances only). giving them permisSion to access other AWS resources.', correct: false,  expli:' ' },
      { text: 'd. A role can give users and resources permission to access the EC2 instance.', correct: true,  expli:' correct D , D. TAM roles define how resources access other resources. Users cannot authenticate as an instance role, nor can a role be associated with an instance\'s internal system process.' }
    ],
	img: '',  
  }, 
  {
    question: '/AWS Certified Solutions Architect STUDY GUIDE ASSOCIATE (SAA-CO3) EXAM Chapter 2 Compute Services 24p - 15 / 15. You have an instance running within a private subnet that needs external network access to receive software updates and patches. Which of the following can securely provide that access from a public subnet within the same VPC? (Choose two.)',
    answers: [
      { text: 'a. Internet gateway', correct: false,  expli:' ' },
      { text: 'b. NAT instance', correct: true,  expli:' correct B ' },
	    { text: 'c. Virtual private gateway', correct: false,  expli:' ' },
      { text: 'd. NAT gateway', correct: false,  expli:' ' },
      { text: 'e. VPN', correct: true,  expli:' correct D, B y D. NAT instances and NAT gateways are AWS tools for safely routing traffic between private and public subnets and from there, out to the Internet. An Internet gateway connects a VPC with the Internet, and a virtual private gateway connects a VPC with a remote site Over a secure VPN. A stand-alone VPN wouldn\'t normally be helptul for this purpose.' }
    ],
	img: '',  
  }, 
  {
    question: '/AWS Certified Solutions Architect STUDY GUIDE ASSOCIATE (SAA-CO3) EXAM Chapter 2 Compute Services 24p - 16 / 16. What do you have to do to securely authenticate to the GUI console of a Windows EC2 ession?',
    answers: [
      { text: 'a. Use the private key of your key pair to initiate an SSH tunnel session. ', correct: false,  expli:' ' },
      { text: 'b. Use the public key of your key pair to initiate an SSH tunnel session.', correct: false,  expli:' ' },
	    { text: 'c. Use the public key of your key pair to retrieve the password you\'ll use to log in.', correct: false,  expli:' ' },
      { text: 'd. Use the private key of your key pair to retrieve the password you\'ll use to log in.', correct: true,  expli:' correct D. The client computer in an encrypted operation must always use the private key to authenticate. For EC2 instances running Windows, you retrieve the password you\'ll use for the GUI login using your private key.' }
    ],
	img: '',  
  }, 
  {
    question: '/AWS Certified Solutions Architect STUDY GUIDE ASSOCIATE (SAA-CO3) EXAM Chapter 2 Compute Services 24p - 17 / 17. Your application deployment includes multiple EC2 instances that need low-latency connections to each other. Which of the following AWS tools will allow you to locate EC2 instances closer to each other to reduce network latency?',
    answers: [
      { text: 'a. Load balancing', correct: false,  expli:' ' },
      { text: 'b. Placement groups', correct: true,  expli:' correct B. Placement groups allow you to specify where your EC2 instances will live. Load balancing directs external user requests between multiple EC2 instances, Systems Manager provides tools for monitoring and managing your resources, and Fargate is an interface for administering Docker containers on Amazon ECS.' },
	    { text: 'c. AWS Systems Manager', correct: false,  expli:' ' },
      { text: 'd. AWS Fargate', correct: false,  expli:' ' }
    ],
	img: '',  
  }, 
  {
    question: '/AWS Certified Solutions Architect STUDY GUIDE ASSOCIATE (SAA-CO3) EXAM Chapter 2 Compute Services 24p - 18 / 18. To save configuration time and money, you want your application to run only when network events trigger it but shut down immediately after. Which of the following will do that for you?',
    answers: [
      { text: 'a. AWS Lambda', correct: true,  expli:' correct A. Lambda can be used as such a trigger. Beanstalk launches and manages infrastructure for your application that will remain running until you manually stop it, ECS manages Docker containers but doesn\'t necessarily stop them when a task is done, and Auto Scaling can add instances to an already running deployment to meet demand.' },
      { text: 'b. AWS Elastic Beanstalk', correct: false,  expli:' ' },
	    { text: 'c. Amazon Elastic Container Service (ECS)', correct: false,  expli:' ' },
      { text: 'd. Auto Scaling', correct: false,  expli:' ' }
    ],
	img: '',  
  }, 
  {
    question: '/AWS Certified Solutions Architect STUDY GUIDE ASSOCIATE (SAA-CO3) EXAM Chapter 2 Compute Services 24p - 19 / 19. Which of the following will allow you to quickly copy a virtual machine image from your local infrastructure to your AWS VPC?',
    answers: [
      { text: 'a. AWS Simple Storage Service (S3) ', correct: false,  expli:' ' },
      { text: 'b. AWS Snowball', correct: false,  expli:' ' },
	    { text: 'c. VM Import/Export', correct: true,  expli:' correct C. VM Import/Export will do this. S3 buckets are used to store an image, but they\'re not directly involved in the import operation. Snowball is a physical high-capacity storage device that Amazon ships to your ottice for you to load data and ship back. Direct Connect uses Amazon partner providers to build a high-speed connection between your servers and your AWS VPC. ' },
      { text: 'd. AWS Direct Connect', correct: false,  expli:' ' }
    ],
	img: '',  
  }, 
  {
    question: '/AWS Certified Solutions Architect STUDY GUIDE ASSOCIATE (SAA-CO3) EXAM Chapter 2 Compute Services 24p - 20 / 20. You\'ve configured an EC2 Auto Scaling group to use a launch configuration to provision and install an application on several instances. You now need to reconfigure Auto Scaling to install an additional application on new instances. Which of the following should you do?',
    answers: [
      { text: 'a. Modify the launch configuration.', correct: false,  expli:' ' },
      { text: 'b. Create a launch template and configure the Auto Scaling group to use it.', correct: true,  expli:' correct B. You can modify a launch template by creating a new version of it; however, the question indicates that the Auto Scaling group was created using a launch configuration. You can\'t modify a launch configuration. Auto Scaling doesn\'t use CloudFormati templates.' },
	    { text: 'c. Modify the launch template.', correct: false,  expli:' ' },
      { text: 'd. Modify the CloudFormation template.', correct: false,  expli:' ' }
    ],
	img: '',  
  }, 
  {
    question: '/AWS Certified Solutions Architect STUDY GUIDE ASSOCIATE (SAA-CO3) EXAM Chapter 2 Compute Services 24p - 21 / 21. You create an Auto Scaling group with a minimum group size of 3, a maximum group size of 10, and a desired capacity of 5. You then manually terminate two instances in the group. Which of the following will Auto Scaling do?',
    answers: [
      { text: 'a. Create two new instances.', correct: true,  expli:'correct A. Auto Scaling strives to maintain the number of instances specitied in the desired capacity setting. If the desired capacity setting isn\'t set, Auto Scaling will attempt to maintain the number of instances specified by the minimum group size. Given a desired capacity value of 5, there should be five healthy instances. If you manually terminate two of them, Auto Scaling will create two new ones to replace them. Auto Scaling will not adjust the desired capacity or minimum group size. ' },
      { text: 'b. Reduce the desired capacity to 3.', correct: false,  expli:' ' },
	    { text: 'c. Nothing.', correct: false,  expli:' ' },
      { text: 'd. Increment the minimum group size to 5.', correct: false,  expli:' ' }
    ],
	img: '',  
  }, 
  {
    question: '/AWS Certified Solutions Architect STUDY GUIDE ASSOCIATE (SAA-CO3) EXAM Chapter 2 Compute Services 24p - 22 / 22. You\'re running an application that receives a spike in traffic on the first day of every month. You want to configure Auto Scaling to add more instances before the spike begins and then add additional instances in proportion to the CPU utilization of each instance. Which of the following should you implement? (Choose all that apply.)',
    answers: [
      { text: 'a. Target tracking policies', correct: false,  expli:' ' },
      { text: 'b. Scheduled actions', correct: true,  expli:' correct B ' },
	    { text: 'c. Step scaling policies', correct: true,  expli:' correct C, B y C. Scheduled actions can adjust the minimum and maximum group sizes and the desired capacity on a schedule, which is useful when your application has a predictable load pattern. To add more instances in proportion to the aggregate CPU utilization of the group, implement step scaling policies. Target tracking policies adjust the desired capacity of a group to keep the threshold of a given metric near a predetined value. Simple scaling policies simply add more instances when a defined CloudWatch alarm triggers, but the number of instances added is not proportional to the value of the metric. ' },
      { text: 'd. Simple scaling policies', correct: false,  expli:' ' },
      { text: 'e. Load balancing', correct: false,  expli:' ' }
    ],
	img: '',  
  }, 
  {
    question: '/AWS Certified Solutions Architect STUDY GUIDE ASSOCIATE (SAA-CO3) EXAM Chapter 2 Compute Services 24p - 23 / 23. As part of your new data backup protocols, you need to manually take EBS snapshots of several hundred volumes. Which type of Systems Manager document enables you to do this? ',
    answers: [
      { text: 'a. Command ', correct: false,  expli:' ' },
      { text: 'b. Automation', correct: true,  expli:' correct B. Automation documents let you perform actions against your AWS resources, including taking EBS snapshots. Although called automation documents, you can stil manually execute them. A command document performs actions within a Linux or a Windows instance. A policy document works only with State Manager and can\'t take an EBS snapshot. There\'s no manual document type.' },
	    { text: 'c. Policy ', correct: false,  expli:' ' },
      { text: 'd. Manual', correct: false,  expli:' ' }
    ],
	img: '',  
  }, 
  {
    question: '/AWS Certified Solutions Architect STUDY GUIDE ASSOCIATE (SAA-CO3) EXAM Chapter 2 Compute Services 24p - 24 / 24. You want to launch and manage a complex microservices container workload in AWS but you want to avoid as many configuration headaches as possible, You figure you\'ll be fine with whatever defaults you\'re offered. Which of these platforms is your best choice?',
    answers: [
      { text: 'a. Amazon Elastic Kubernetes Service', correct: false,  expli:' ' },
      { text: 'b. AWS Fargate', correct: true,  expli:' correct B. Fargate is a service that uses either ECS or EKS intrastructure under the hood, but actually abstracts away most of the configuration details. Therefore, Fargate is your best bet. EKS and ECS give you far greater control over your configuration but, as a result, are more complex. EKS Distro is a way of running K8s containers in your own intrastructure and, if anything, is the most complex option of all.' },
	    { text: 'c. Amazon EKS Distro', correct: false,  expli:' ' },
      { text: 'd. Amazon Elastic Container Service', correct: false,  expli:' ' }
    ],
	img: '',  
  }, 
  {
    question: '/AWS Certified Solutions Architect STUDY GUIDE ASSOCIATE (SAA-CO3) EXAM Chapter 2 Compute Services 24p - 1 / ',
    answers: [
      { text: 'a. ', correct: false,  expli:' ' },
      { text: 'b. ', correct: false,  expli:' ' },
	    { text: 'c. ', correct: false,  expli:' ' },
      { text: 'd. ', correct: false,  expli:' ' },
      { text: 'e. ', correct: false,  expli:' ' }
    ],
	img: '',  
  }, 
  
  
 

// final de array
]
      </script>
</body>
</html>

<!-- modelo

  {
    question: '/Test 30p Cuestionario 8  1/ ',
    answers: [
      { text: ' ', correct: false,  expli:' ' },
      { text: ' ', correct: false,  expli:' ' },
	    { text: ' ', correct: false,  expli:' ' },
      { text: ' ', correct: false,  expli:' ' }
    ],
	img: '',  
  }, 

  {
    question: '/Test 30p Cuestionario 14 1/ ',
    answers: [
      { text: 'a. ', correct: false,  expli:' ' },
      { text: 'b. ', correct: false,  expli:' ' },
	    { text: 'c. ', correct: false,  expli:' ' },
      { text: 'd. ', correct: false,  expli:' ' },
      { text: 'e. ', correct: false,  expli:' ' }
    ],
	img: '',  
  }, 
  {
    question: '/Test 10p Cuestionario 1 - 1  DíA 1-MÓDULO 3.  ARCHITECTING ON AWS/',
    answers: [
      { text: 'a. ', correct: false,  expli:' ' },
      { text: 'b. ', correct: false,  expli:' ' },
	    { text: 'c. ', correct: false,  expli:' ' },
      { text: 'd. ', correct: false,  expli:' ' },
      { text: 'e. ', correct: false,  expli:' ' },
    ],
	img: '',  
  },


-->
<footer id="footer">
  <p id="p_footer"> WE ALL HATE THE 847 con 24 QUESTIONS ABOUT THE CLOUD  </p>
</footer>
</body>
